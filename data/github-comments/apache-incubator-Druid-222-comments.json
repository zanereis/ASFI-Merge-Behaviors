[{"url":"https://api.github.com/repos/apache/druid/issues/comments/463406954","html_url":"https://github.com/apache/druid/pull/7046#issuecomment-463406954","issue_url":"https://api.github.com/repos/apache/druid/issues/7046","id":463406954,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQwNjk1NA==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-13T22:46:52Z","updated_at":"2019-02-13T22:46:52Z","author_association":"CONTRIBUTOR","body":"Thanks for updating! I think commit messages are fine. I'll take another look. In the meantime, would you please check this CI failure?\r\n\r\n```\r\n[ERROR] /home/travis/build/apache/incubator-druid/indexing-service/src/test/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTaskTest.java:34:8: Unused import - org.apache.druid.java.util.common.logger.Logger. [UnusedImports]\r\n```","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463406954/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463409491","html_url":"https://github.com/apache/druid/pull/7046#issuecomment-463409491","issue_url":"https://api.github.com/repos/apache/druid/issues/7046","id":463409491,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQwOTQ5MQ==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-13T22:55:28Z","updated_at":"2019-02-13T22:55:28Z","author_association":"CONTRIBUTOR","body":"I fixed that one already; the current failures are some odd Maven issues like\r\n\r\n```\r\n[FATAL] Non-resolvable parent POM for org.apache.druid.extensions.contrib:druid-momentsketch:[unknown-version]: Could not find artifact org.apache.druid:druid:pom:0.14.0-incubating-SNAPSHOT in sonatype-snapshots (https://oss.sonatype.org/content/repositories/snapshots/) and 'parent.relativePath' points at wrong local POM @ line 24, column 13\r\n```\r\n\r\nwhich I don't think are my fault? Unfortunately as a non project owner I think the only way I can rerun these CI tasks is to push a new commit, and I can't even kill other subjobs in the old job.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463409491/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463413247","html_url":"https://github.com/apache/druid/pull/6581#issuecomment-463413247","issue_url":"https://api.github.com/repos/apache/druid/issues/6581","id":463413247,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQxMzI0Nw==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-13T23:08:57Z","updated_at":"2019-02-13T23:08:57Z","author_association":"CONTRIBUTOR","body":"This seems to have broken CI on master.\r\nSee https://travis-ci.org/apache/incubator-druid/builds/492938510 from master (and my PRs on top of it are failing too).","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463413247/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463413314","html_url":"https://github.com/apache/druid/pull/7046#issuecomment-463413314","issue_url":"https://api.github.com/repos/apache/druid/issues/7046","id":463413314,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQxMzMxNA==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-13T23:09:15Z","updated_at":"2019-02-13T23:09:15Z","author_association":"CONTRIBUTOR","body":"Ah yeah #6581 seems to have broken master.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463413314/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463414535","html_url":"https://github.com/apache/druid/issues/7071#issuecomment-463414535","issue_url":"https://api.github.com/repos/apache/druid/issues/7071","id":463414535,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQxNDUzNQ==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-13T23:14:00Z","updated_at":"2019-02-13T23:14:00Z","author_association":"CONTRIBUTOR","body":"How would this apply to the delegating implementations like CombiningFirehoseFactory, ClippedFirehoseFactory, and FixedCountFirehoseFactory?  I don't know to what degree they are actually used, but Clipped seems like something that could be useful with the LocalFirehoseFactory and local index task. Would these need to implement FiniteFirehoseFactory too?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463414535/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463416488","html_url":"https://github.com/apache/druid/pull/6581#issuecomment-463416488","issue_url":"https://api.github.com/repos/apache/druid/issues/6581","id":463416488,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQxNjQ4OA==","user":{"login":"jon-wei","id":8729063,"node_id":"MDQ6VXNlcjg3MjkwNjM=","avatar_url":"https://avatars.githubusercontent.com/u/8729063?v=4","gravatar_id":"","url":"https://api.github.com/users/jon-wei","html_url":"https://github.com/jon-wei","followers_url":"https://api.github.com/users/jon-wei/followers","following_url":"https://api.github.com/users/jon-wei/following{/other_user}","gists_url":"https://api.github.com/users/jon-wei/gists{/gist_id}","starred_url":"https://api.github.com/users/jon-wei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jon-wei/subscriptions","organizations_url":"https://api.github.com/users/jon-wei/orgs","repos_url":"https://api.github.com/users/jon-wei/repos","events_url":"https://api.github.com/users/jon-wei/events{/privacy}","received_events_url":"https://api.github.com/users/jon-wei/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-13T23:21:17Z","updated_at":"2019-02-13T23:21:17Z","author_association":"CONTRIBUTOR","body":"@glasser I'm making a PR to fix the build issues ","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463416488/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463421875","html_url":"https://github.com/apache/druid/pull/7074#issuecomment-463421875","issue_url":"https://api.github.com/repos/apache/druid/issues/7074","id":463421875,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQyMTg3NQ==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-13T23:41:29Z","updated_at":"2019-02-13T23:41:29Z","author_association":"CONTRIBUTOR","body":"+1 after CI.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463421875/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463422920","html_url":"https://github.com/apache/druid/pull/7073#issuecomment-463422920","issue_url":"https://api.github.com/repos/apache/druid/issues/7073","id":463422920,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQyMjkyMA==","user":{"login":"fjy","id":428325,"node_id":"MDQ6VXNlcjQyODMyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/428325?v=4","gravatar_id":"","url":"https://api.github.com/users/fjy","html_url":"https://github.com/fjy","followers_url":"https://api.github.com/users/fjy/followers","following_url":"https://api.github.com/users/fjy/following{/other_user}","gists_url":"https://api.github.com/users/fjy/gists{/gist_id}","starred_url":"https://api.github.com/users/fjy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fjy/subscriptions","organizations_url":"https://api.github.com/users/fjy/orgs","repos_url":"https://api.github.com/users/fjy/repos","events_url":"https://api.github.com/users/fjy/events{/privacy}","received_events_url":"https://api.github.com/users/fjy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-13T23:45:53Z","updated_at":"2019-02-13T23:45:53Z","author_association":"CONTRIBUTOR","body":"ðŸ‘Ž This isn't a true veto, but I caution all other reviewers to not merge this without much more careful inspection of all surrounding code. There is logic in the load rules that is not immediately obvious upon first reading it but can have dramatic impacts and completely destabilize entire clusters. ","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463422920/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463423797","html_url":"https://github.com/apache/druid/issues/7071#issuecomment-463423797","issue_url":"https://api.github.com/repos/apache/druid/issues/7071","id":463423797,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQyMzc5Nw==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-13T23:49:14Z","updated_at":"2019-02-13T23:49:14Z","author_association":"CONTRIBUTOR","body":"Good question. [ClippedFirehoseFactory is for Tranquility](https://github.com/druid-io/tranquility/blob/master/docs/overview.md#task-creation), so I don't think it needs to be finiteFirehoseFactory. I'm not sure who is using FixedCountFirehoseFactory, but it was added in https://github.com/apache/incubator-druid/pull/3856 and looks its purpose was testing.\r\n\r\nFor CombiningFirehoseFactory, I think it would be useful and worth to add `CombiningFiniteFirehoseFactory` which supports split.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463423797/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463425688","html_url":"https://github.com/apache/druid/pull/7073#issuecomment-463425688","issue_url":"https://api.github.com/repos/apache/druid/issues/7073","id":463425688,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQyNTY4OA==","user":{"login":"samarthjain","id":1642180,"node_id":"MDQ6VXNlcjE2NDIxODA=","avatar_url":"https://avatars.githubusercontent.com/u/1642180?v=4","gravatar_id":"","url":"https://api.github.com/users/samarthjain","html_url":"https://github.com/samarthjain","followers_url":"https://api.github.com/users/samarthjain/followers","following_url":"https://api.github.com/users/samarthjain/following{/other_user}","gists_url":"https://api.github.com/users/samarthjain/gists{/gist_id}","starred_url":"https://api.github.com/users/samarthjain/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/samarthjain/subscriptions","organizations_url":"https://api.github.com/users/samarthjain/orgs","repos_url":"https://api.github.com/users/samarthjain/repos","events_url":"https://api.github.com/users/samarthjain/events{/privacy}","received_events_url":"https://api.github.com/users/samarthjain/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-13T23:56:59Z","updated_at":"2019-02-13T23:56:59Z","author_association":"CONTRIBUTOR","body":"> ðŸ‘Ž This isn't a true veto, but I caution all other reviewers to not merge this without much more careful inspection of all surrounding code. There is logic in the load rules that is not immediately obvious upon first reading it but can have dramatic impacts and completely destabilize entire clusters.\r\n\r\nNot sure I understand the concern here. It looks fairly straightforward to me. The only caller of LoadRule#run method is DruidCoordinatorRuleRunner.\r\n\r\nAnd the DruidCoordinatorRuleRunner#run method is effectively doing the contains check here\r\n```\r\nfor (DataSegment segment : params.getAvailableSegments()) {\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463425688/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463427151","html_url":"https://github.com/apache/druid/pull/7073#issuecomment-463427151","issue_url":"https://api.github.com/repos/apache/druid/issues/7073","id":463427151,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQyNzE1MQ==","user":{"login":"fjy","id":428325,"node_id":"MDQ6VXNlcjQyODMyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/428325?v=4","gravatar_id":"","url":"https://api.github.com/users/fjy","html_url":"https://github.com/fjy","followers_url":"https://api.github.com/users/fjy/followers","following_url":"https://api.github.com/users/fjy/following{/other_user}","gists_url":"https://api.github.com/users/fjy/gists{/gist_id}","starred_url":"https://api.github.com/users/fjy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fjy/subscriptions","organizations_url":"https://api.github.com/users/fjy/orgs","repos_url":"https://api.github.com/users/fjy/repos","events_url":"https://api.github.com/users/fjy/events{/privacy}","received_events_url":"https://api.github.com/users/fjy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T00:02:56Z","updated_at":"2019-02-14T00:02:56Z","author_association":"CONTRIBUTOR","body":"> > ðŸ‘Ž This isn't a true veto, but I caution all other reviewers to not merge this without much more careful inspection of all surrounding code. There is logic in the load rules that is not immediately obvious upon first reading it but can have dramatic impacts and completely destabilize entire clusters.\r\n> \r\n> Not sure I understand the concern here. It looks fairly straightforward to me. The only caller of LoadRule#run method is DruidCoordinatorRuleRunner.\r\n> \r\n> And the DruidCoordinatorRuleRunner#run method is effectively doing the contains check here\r\n> \r\n> ```\r\n> for (DataSegment segment : params.getAvailableSegments()) {\r\n> ```\r\n\r\nWe've had so many problems with similar seemingly straightforward changes in these blocks of code that I want to be extra careful because of its impacts on clusters. I recall when writing this code that some of the checks are very important even if they don't appear to be. I just don't recall all the reasons why.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463427151/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463429473","html_url":"https://github.com/apache/druid/issues/7068#issuecomment-463429473","issue_url":"https://api.github.com/repos/apache/druid/issues/7068","id":463429473,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQyOTQ3Mw==","user":{"login":"samarthjain","id":1642180,"node_id":"MDQ6VXNlcjE2NDIxODA=","avatar_url":"https://avatars.githubusercontent.com/u/1642180?v=4","gravatar_id":"","url":"https://api.github.com/users/samarthjain","html_url":"https://github.com/samarthjain","followers_url":"https://api.github.com/users/samarthjain/followers","following_url":"https://api.github.com/users/samarthjain/following{/other_user}","gists_url":"https://api.github.com/users/samarthjain/gists{/gist_id}","starred_url":"https://api.github.com/users/samarthjain/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/samarthjain/subscriptions","organizations_url":"https://api.github.com/users/samarthjain/orgs","repos_url":"https://api.github.com/users/samarthjain/repos","events_url":"https://api.github.com/users/samarthjain/events{/privacy}","received_events_url":"https://api.github.com/users/samarthjain/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T00:12:33Z","updated_at":"2019-02-14T00:12:33Z","author_association":"CONTRIBUTOR","body":"@fjy or @gianm - would you happen to remember if this was a deliberate design decision? Before I go down the path of making changes, I want to be sure I am not missing out on some tricky issues here. \r\n\r\nThe issue is fairly severe. In my logs, I see that it took over 5 hours for the coordinator to create zk entries and roughly the same time for historicals to download 3TB of segments from s3.\r\n\r\nWe have also seen that in some cases, after a largish batch ingestion of a few hundred GBs, the segments are not available on the cluster for almost a couple of hours. ","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463429473/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463443019","html_url":"https://github.com/apache/druid/issues/7036#issuecomment-463443019","issue_url":"https://api.github.com/repos/apache/druid/issues/7036","id":463443019,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQ0MzAxOQ==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T01:10:06Z","updated_at":"2019-02-14T01:10:06Z","author_association":"CONTRIBUTOR","body":"Nice proposal! I have some questions/comments.\r\n\r\n> This runner would open each segment file, perform a k-way merge on the files, and return a `Sequence` of 1-event `ScanResultValues`.\r\n\r\nDoes this mean, the merged result in historicals would be a sequence of a single `ScanResultValue` which contains all time-ordered events of input segments? I understand the merge needs to block for sorting, but how does it work with stream merge in the broker? I guess the broker would also wait until it gets all events in `ScanResultValue`?\r\n\r\n> Alternatively, to avoid creating a new `QueryRunnerFactory` the existing query runner can check the `ScanQuery` object's limit and ordering, and decide what runner to provide in the `mergeRunners()` function.\r\n\r\nI think this is better than adding a new QueryRunnerFactory to minimize the complexity.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463443019/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463454209","html_url":"https://github.com/apache/druid/issues/7057#issuecomment-463454209","issue_url":"https://api.github.com/repos/apache/druid/issues/7057","id":463454209,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQ1NDIwOQ==","user":{"login":"justinborromeo","id":9417701,"node_id":"MDQ6VXNlcjk0MTc3MDE=","avatar_url":"https://avatars.githubusercontent.com/u/9417701?v=4","gravatar_id":"","url":"https://api.github.com/users/justinborromeo","html_url":"https://github.com/justinborromeo","followers_url":"https://api.github.com/users/justinborromeo/followers","following_url":"https://api.github.com/users/justinborromeo/following{/other_user}","gists_url":"https://api.github.com/users/justinborromeo/gists{/gist_id}","starred_url":"https://api.github.com/users/justinborromeo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/justinborromeo/subscriptions","organizations_url":"https://api.github.com/users/justinborromeo/orgs","repos_url":"https://api.github.com/users/justinborromeo/repos","events_url":"https://api.github.com/users/justinborromeo/events{/privacy}","received_events_url":"https://api.github.com/users/justinborromeo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T01:58:24Z","updated_at":"2019-02-14T01:58:24Z","author_association":"CONTRIBUTOR","body":"Looking at the code, I noticed that NonBlockingStatsDEmitter is a library class.  Does it make sense to ignore it when refactoring since we can't change it or do you think that a custom implementation should be written?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463454209/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463454542","html_url":"https://github.com/apache/druid/issues/7059#issuecomment-463454542","issue_url":"https://api.github.com/repos/apache/druid/issues/7059","id":463454542,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQ1NDU0Mg==","user":{"login":"asdf2014","id":8108788,"node_id":"MDQ6VXNlcjgxMDg3ODg=","avatar_url":"https://avatars.githubusercontent.com/u/8108788?v=4","gravatar_id":"","url":"https://api.github.com/users/asdf2014","html_url":"https://github.com/asdf2014","followers_url":"https://api.github.com/users/asdf2014/followers","following_url":"https://api.github.com/users/asdf2014/following{/other_user}","gists_url":"https://api.github.com/users/asdf2014/gists{/gist_id}","starred_url":"https://api.github.com/users/asdf2014/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/asdf2014/subscriptions","organizations_url":"https://api.github.com/users/asdf2014/orgs","repos_url":"https://api.github.com/users/asdf2014/repos","events_url":"https://api.github.com/users/asdf2014/events{/privacy}","received_events_url":"https://api.github.com/users/asdf2014/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T01:59:51Z","updated_at":"2019-02-14T01:59:51Z","author_association":"MEMBER","body":"@leventov Yep, it makes sense to me.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463454542/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463459567","html_url":"https://github.com/apache/druid/pull/6683#issuecomment-463459567","issue_url":"https://api.github.com/repos/apache/druid/issues/6683","id":463459567,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQ1OTU2Nw==","user":{"login":"kaijianding","id":8663725,"node_id":"MDQ6VXNlcjg2NjM3MjU=","avatar_url":"https://avatars.githubusercontent.com/u/8663725?v=4","gravatar_id":"","url":"https://api.github.com/users/kaijianding","html_url":"https://github.com/kaijianding","followers_url":"https://api.github.com/users/kaijianding/followers","following_url":"https://api.github.com/users/kaijianding/following{/other_user}","gists_url":"https://api.github.com/users/kaijianding/gists{/gist_id}","starred_url":"https://api.github.com/users/kaijianding/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kaijianding/subscriptions","organizations_url":"https://api.github.com/users/kaijianding/orgs","repos_url":"https://api.github.com/users/kaijianding/repos","events_url":"https://api.github.com/users/kaijianding/events{/privacy}","received_events_url":"https://api.github.com/users/kaijianding/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T02:21:57Z","updated_at":"2019-02-14T02:21:57Z","author_association":"CONTRIBUTOR","body":"@leventov I added comments to toAnnounce, toUpdate, parentsIBuilt, and modified some other comments to help better understanding. Could you tell me which part of comments you think can improve?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463459567/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463467298","html_url":"https://github.com/apache/druid/issues/7057#issuecomment-463467298","issue_url":"https://api.github.com/repos/apache/druid/issues/7057","id":463467298,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQ2NzI5OA==","user":{"login":"justinborromeo","id":9417701,"node_id":"MDQ6VXNlcjk0MTc3MDE=","avatar_url":"https://avatars.githubusercontent.com/u/9417701?v=4","gravatar_id":"","url":"https://api.github.com/users/justinborromeo","html_url":"https://github.com/justinborromeo","followers_url":"https://api.github.com/users/justinborromeo/followers","following_url":"https://api.github.com/users/justinborromeo/following{/other_user}","gists_url":"https://api.github.com/users/justinborromeo/gists{/gist_id}","starred_url":"https://api.github.com/users/justinborromeo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/justinborromeo/subscriptions","organizations_url":"https://api.github.com/users/justinborromeo/orgs","repos_url":"https://api.github.com/users/justinborromeo/repos","events_url":"https://api.github.com/users/justinborromeo/events{/privacy}","received_events_url":"https://api.github.com/users/justinborromeo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T02:57:47Z","updated_at":"2019-02-14T02:57:47Z","author_association":"CONTRIBUTOR","body":"Opened a proposal (#7075) since the change adds a config.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463467298/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463471858","html_url":"https://github.com/apache/druid/issues/6320#issuecomment-463471858","issue_url":"https://api.github.com/repos/apache/druid/issues/6320","id":463471858,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQ3MTg1OA==","user":{"login":"yurmix","id":1529282,"node_id":"MDQ6VXNlcjE1MjkyODI=","avatar_url":"https://avatars.githubusercontent.com/u/1529282?v=4","gravatar_id":"","url":"https://api.github.com/users/yurmix","html_url":"https://github.com/yurmix","followers_url":"https://api.github.com/users/yurmix/followers","following_url":"https://api.github.com/users/yurmix/following{/other_user}","gists_url":"https://api.github.com/users/yurmix/gists{/gist_id}","starred_url":"https://api.github.com/users/yurmix/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yurmix/subscriptions","organizations_url":"https://api.github.com/users/yurmix/orgs","repos_url":"https://api.github.com/users/yurmix/repos","events_url":"https://api.github.com/users/yurmix/events{/privacy}","received_events_url":"https://api.github.com/users/yurmix/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T03:19:48Z","updated_at":"2019-02-14T03:19:48Z","author_association":"CONTRIBUTOR","body":"@jihoonson The similarity between `PostAggregator` and `Averager` is that they both run post the query aggregation. They run in the Broker on the aggregated resultset. But while `PostAggregator` works on a single `Row` in the post-aggregation result set, `Averager` aggregated data over multiple Rows.\r\n\r\nHow? Averagers collects previous records into a buffer (called `BaseAverager.buckets`) and uses that to compute a moving-average result for each Row. In the code, there is a collaberation between `Averager` and `MovingAverageIterable` to iterate over GroupBy's result-set while keeping a buffer and while returning the averager's result per each record.\r\n\r\nYou can take a look at MovingAverageIterable and how `MovingAverageIterable#computeMovingAverage()` is calling `Averager#getResult()` -> `BaseAverager#computeResults()`.\r\nhttps://github.com/apache/incubator-druid/pull/6430/files#diff-0cbedd32f92fe9f41d7c47a628a2974fR270","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463471858/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463494234","html_url":"https://github.com/apache/druid/issues/7047#issuecomment-463494234","issue_url":"https://api.github.com/repos/apache/druid/issues/7047","id":463494234,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzQ5NDIzNA==","user":{"login":"quenlang","id":11764573,"node_id":"MDQ6VXNlcjExNzY0NTcz","avatar_url":"https://avatars.githubusercontent.com/u/11764573?v=4","gravatar_id":"","url":"https://api.github.com/users/quenlang","html_url":"https://github.com/quenlang","followers_url":"https://api.github.com/users/quenlang/followers","following_url":"https://api.github.com/users/quenlang/following{/other_user}","gists_url":"https://api.github.com/users/quenlang/gists{/gist_id}","starred_url":"https://api.github.com/users/quenlang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/quenlang/subscriptions","organizations_url":"https://api.github.com/users/quenlang/orgs","repos_url":"https://api.github.com/users/quenlang/repos","events_url":"https://api.github.com/users/quenlang/events{/privacy}","received_events_url":"https://api.github.com/users/quenlang/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T05:22:56Z","updated_at":"2019-02-14T05:22:56Z","author_association":"NONE","body":"@AlexanderSaydakov Thanks for quick reply!\r\nIt is an existing process that used to work before and it worked very well until the exception happening.\r\nI have other two tasks ingest data from the same kafka topic always runing smoothly with  hour and day query granularity.\r\n\r\nI'm sorry for my poor english. i mean, the bug #6877 was found after druid 0.13.0 released and i found this bug will fix in druid 0.14.0, so there is no available version for this problem. What should i do?\r\n\r\nAnother question, i found that, the query result with quantiles sketch is varied for the same query but only a small error.\r\nIs that rightï¼Ÿ\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463494234/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463513209","html_url":"https://github.com/apache/druid/pull/7046#issuecomment-463513209","issue_url":"https://api.github.com/repos/apache/druid/issues/7046","id":463513209,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzUxMzIwOQ==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T06:52:43Z","updated_at":"2019-02-14T06:52:43Z","author_association":"CONTRIBUTOR","body":"CI now passing.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463513209/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463517312","html_url":"https://github.com/apache/druid/pull/6690#issuecomment-463517312","issue_url":"https://api.github.com/repos/apache/druid/issues/6690","id":463517312,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzUxNzMxMg==","user":{"login":"pzhdfy","id":2594619,"node_id":"MDQ6VXNlcjI1OTQ2MTk=","avatar_url":"https://avatars.githubusercontent.com/u/2594619?v=4","gravatar_id":"","url":"https://api.github.com/users/pzhdfy","html_url":"https://github.com/pzhdfy","followers_url":"https://api.github.com/users/pzhdfy/followers","following_url":"https://api.github.com/users/pzhdfy/following{/other_user}","gists_url":"https://api.github.com/users/pzhdfy/gists{/gist_id}","starred_url":"https://api.github.com/users/pzhdfy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pzhdfy/subscriptions","organizations_url":"https://api.github.com/users/pzhdfy/orgs","repos_url":"https://api.github.com/users/pzhdfy/repos","events_url":"https://api.github.com/users/pzhdfy/events{/privacy}","received_events_url":"https://api.github.com/users/pzhdfy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T07:10:11Z","updated_at":"2019-02-14T07:11:22Z","author_association":"CONTRIBUTOR","body":"@jihoonson \r\nI have updated the pr,   \r\nremoving entry after iteration instead of using ConcurrentMap, and add unit test","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463517312/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463524867","html_url":"https://github.com/apache/druid/pull/6988#issuecomment-463524867","issue_url":"https://api.github.com/repos/apache/druid/issues/6988","id":463524867,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzUyNDg2Nw==","user":{"login":"pzhdfy","id":2594619,"node_id":"MDQ6VXNlcjI1OTQ2MTk=","avatar_url":"https://avatars.githubusercontent.com/u/2594619?v=4","gravatar_id":"","url":"https://api.github.com/users/pzhdfy","html_url":"https://github.com/pzhdfy","followers_url":"https://api.github.com/users/pzhdfy/followers","following_url":"https://api.github.com/users/pzhdfy/following{/other_user}","gists_url":"https://api.github.com/users/pzhdfy/gists{/gist_id}","starred_url":"https://api.github.com/users/pzhdfy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pzhdfy/subscriptions","organizations_url":"https://api.github.com/users/pzhdfy/orgs","repos_url":"https://api.github.com/users/pzhdfy/repos","events_url":"https://api.github.com/users/pzhdfy/events{/privacy}","received_events_url":"https://api.github.com/users/pzhdfy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T07:40:53Z","updated_at":"2019-02-14T07:44:52Z","author_association":"CONTRIBUTOR","body":"historical size:   100k segments and 10TB size\r\nEach time, We will drop the page cache\r\n\r\n**1. without this patch**\r\n\r\n\r\n\r\n **1) druid.segmentCache.numBootstrapThreads = 1**\r\n        40min\r\n    **2) druid.segmentCache.numBootstrapThreads = 10**\r\n        also 40 min, because when numBootstrapThreads=1, reading all columns metadata has cost 100% disk util, setting numBootstrapThreads a  higher number makes no sense\r\n\r\n**2. with this patch and lazyLoadOnStart = false**\r\n   the result is very similar with scenario 1ï¼Œthere are not any odd performance effectsï¼Œ becauce we don't use  memoized suppliers when  lazyLoadOnStart = false\r\n\r\n**3. with this patch and lazyLoadOnStart = true**\r\n   **1) druid.segmentCache.numBootstrapThreads = 1**\r\n        8min\r\n    **2) druid.segmentCache.numBootstrapThreads = 10**\r\n        2 min, 4 times faster than numBootstrapThreads = 1, because when numBootstrapThreads=1 and  lazyLoadOnStart = true , we don't read all columns metadata , disk util will less than 100%, setting numBootstrapThreads a  higher number will benefit\r\n","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463524867/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463528940","html_url":"https://github.com/apache/druid/pull/6988#issuecomment-463528940","issue_url":"https://api.github.com/repos/apache/druid/issues/6988","id":463528940,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzUyODk0MA==","user":{"login":"kaijianding","id":8663725,"node_id":"MDQ6VXNlcjg2NjM3MjU=","avatar_url":"https://avatars.githubusercontent.com/u/8663725?v=4","gravatar_id":"","url":"https://api.github.com/users/kaijianding","html_url":"https://github.com/kaijianding","followers_url":"https://api.github.com/users/kaijianding/followers","following_url":"https://api.github.com/users/kaijianding/following{/other_user}","gists_url":"https://api.github.com/users/kaijianding/gists{/gist_id}","starred_url":"https://api.github.com/users/kaijianding/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kaijianding/subscriptions","organizations_url":"https://api.github.com/users/kaijianding/orgs","repos_url":"https://api.github.com/users/kaijianding/repos","events_url":"https://api.github.com/users/kaijianding/events{/privacy}","received_events_url":"https://api.github.com/users/kaijianding/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T07:58:31Z","updated_at":"2019-02-14T17:12:57Z","author_association":"CONTRIBUTOR","body":"@pzhdfy I did similar lazy load thing in my code base, but I found there is a consequence. If historical node is force killed(kill -9) when it is asked to download new segment, it is very likely unzip failure and left a corrupted segment folder. When lazy load=false, this segment can be ignored during historical startup(loading will fail), but when lazy load=true, this corruption is only known when a query comes in. Currently there is no interface to tell SegmentLoaderLocalCacheManager to unload this segment or reload this segment, thus queries always fail. Currently the only solution is to delete this segment folder and restart historical node to ignore this segment(because folder is gone).\r\n\r\nBetter introduce unload/reload interface together in this PR.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463528940/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463536769","html_url":"https://github.com/apache/druid/pull/7063#issuecomment-463536769","issue_url":"https://api.github.com/repos/apache/druid/issues/7063","id":463536769,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzUzNjc2OQ==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T08:26:07Z","updated_at":"2019-02-14T08:26:07Z","author_association":"CONTRIBUTOR","body":"De-generalized setContext to setTaskToolbox. CI is passing.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463536769/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463692702","html_url":"https://github.com/apache/druid/issues/7047#issuecomment-463692702","issue_url":"https://api.github.com/repos/apache/druid/issues/7047","id":463692702,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzY5MjcwMg==","user":{"login":"AlexanderSaydakov","id":13126686,"node_id":"MDQ6VXNlcjEzMTI2Njg2","avatar_url":"https://avatars.githubusercontent.com/u/13126686?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexanderSaydakov","html_url":"https://github.com/AlexanderSaydakov","followers_url":"https://api.github.com/users/AlexanderSaydakov/followers","following_url":"https://api.github.com/users/AlexanderSaydakov/following{/other_user}","gists_url":"https://api.github.com/users/AlexanderSaydakov/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexanderSaydakov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexanderSaydakov/subscriptions","organizations_url":"https://api.github.com/users/AlexanderSaydakov/orgs","repos_url":"https://api.github.com/users/AlexanderSaydakov/repos","events_url":"https://api.github.com/users/AlexanderSaydakov/events{/privacy}","received_events_url":"https://api.github.com/users/AlexanderSaydakov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T16:25:43Z","updated_at":"2019-02-14T16:25:43Z","author_association":"CONTRIBUTOR","body":"You do not have to wait for the release. You can build from master any time and upgrade your test cluster to make sure.\r\n\r\nRegarding the variation, quantiles sketch is not deterministic. If you build several sketches from the same data they can be different, and produce slightly different results, but with the same guarantees on the error.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463692702/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463693982","html_url":"https://github.com/apache/druid/pull/6365#issuecomment-463693982","issue_url":"https://api.github.com/repos/apache/druid/issues/6365","id":463693982,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzY5Mzk4Mg==","user":{"login":"zhaojiandong","id":5977839,"node_id":"MDQ6VXNlcjU5Nzc4Mzk=","avatar_url":"https://avatars.githubusercontent.com/u/5977839?v=4","gravatar_id":"","url":"https://api.github.com/users/zhaojiandong","html_url":"https://github.com/zhaojiandong","followers_url":"https://api.github.com/users/zhaojiandong/followers","following_url":"https://api.github.com/users/zhaojiandong/following{/other_user}","gists_url":"https://api.github.com/users/zhaojiandong/gists{/gist_id}","starred_url":"https://api.github.com/users/zhaojiandong/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhaojiandong/subscriptions","organizations_url":"https://api.github.com/users/zhaojiandong/orgs","repos_url":"https://api.github.com/users/zhaojiandong/repos","events_url":"https://api.github.com/users/zhaojiandong/events{/privacy}","received_events_url":"https://api.github.com/users/zhaojiandong/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T16:29:04Z","updated_at":"2019-02-14T16:29:04Z","author_association":"CONTRIBUTOR","body":"> Very sorry for the delayed review, thanks for your patience!\r\n\r\nThank you for your review ðŸ‘ @clintropolis ","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463693982/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463717609","html_url":"https://github.com/apache/druid/issues/5727#issuecomment-463717609","issue_url":"https://api.github.com/repos/apache/druid/issues/5727","id":463717609,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzcxNzYwOQ==","user":{"login":"scrawfor","id":7061689,"node_id":"MDQ6VXNlcjcwNjE2ODk=","avatar_url":"https://avatars.githubusercontent.com/u/7061689?v=4","gravatar_id":"","url":"https://api.github.com/users/scrawfor","html_url":"https://github.com/scrawfor","followers_url":"https://api.github.com/users/scrawfor/followers","following_url":"https://api.github.com/users/scrawfor/following{/other_user}","gists_url":"https://api.github.com/users/scrawfor/gists{/gist_id}","starred_url":"https://api.github.com/users/scrawfor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/scrawfor/subscriptions","organizations_url":"https://api.github.com/users/scrawfor/orgs","repos_url":"https://api.github.com/users/scrawfor/repos","events_url":"https://api.github.com/users/scrawfor/events{/privacy}","received_events_url":"https://api.github.com/users/scrawfor/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T17:32:24Z","updated_at":"2019-02-14T17:38:19Z","author_association":"CONTRIBUTOR","body":"Unfortunately it doesn't.  It prevents lookups from loading on both the middle manager and the peons. The option is passed, but it's passed first, and then overridden by the configuration.\r\n\r\n\r\nJob Log:\r\n```\r\n[LookupConfig{snapshotWorkingDir='', enableLookupSyncOnStartup=false, numLookupLoadingThreads=4, coordinatorFetchRetries=3, lookupStartRetries=3, coordinatorRetryDelay=60000}]\r\n...\r\n-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager -Ddruid.lookup.enableLookupSyncOnStartup=true\r\n...\r\n2019-02-14T14:14:37,380 INFO [main] org.apache.druid.cli.CliPeon - * druid.lookup.enableLookupSyncOnStartup: false  \r\n...\r\n```","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463717609/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463727202","html_url":"https://github.com/apache/druid/pull/7062#issuecomment-463727202","issue_url":"https://api.github.com/repos/apache/druid/issues/7062","id":463727202,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzcyNzIwMg==","user":{"login":"yurmix","id":1529282,"node_id":"MDQ6VXNlcjE1MjkyODI=","avatar_url":"https://avatars.githubusercontent.com/u/1529282?v=4","gravatar_id":"","url":"https://api.github.com/users/yurmix","html_url":"https://github.com/yurmix","followers_url":"https://api.github.com/users/yurmix/followers","following_url":"https://api.github.com/users/yurmix/following{/other_user}","gists_url":"https://api.github.com/users/yurmix/gists{/gist_id}","starred_url":"https://api.github.com/users/yurmix/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yurmix/subscriptions","organizations_url":"https://api.github.com/users/yurmix/orgs","repos_url":"https://api.github.com/users/yurmix/repos","events_url":"https://api.github.com/users/yurmix/events{/privacy}","received_events_url":"https://api.github.com/users/yurmix/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T17:59:30Z","updated_at":"2019-02-14T17:59:30Z","author_association":"CONTRIBUTOR","body":"LGTM, thanks for providing that!","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463727202/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463743611","html_url":"https://github.com/apache/druid/issues/7036#issuecomment-463743611","issue_url":"https://api.github.com/repos/apache/druid/issues/7036","id":463743611,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2Mzc0MzYxMQ==","user":{"login":"justinborromeo","id":9417701,"node_id":"MDQ6VXNlcjk0MTc3MDE=","avatar_url":"https://avatars.githubusercontent.com/u/9417701?v=4","gravatar_id":"","url":"https://api.github.com/users/justinborromeo","html_url":"https://github.com/justinborromeo","followers_url":"https://api.github.com/users/justinborromeo/followers","following_url":"https://api.github.com/users/justinborromeo/following{/other_user}","gists_url":"https://api.github.com/users/justinborromeo/gists{/gist_id}","starred_url":"https://api.github.com/users/justinborromeo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/justinborromeo/subscriptions","organizations_url":"https://api.github.com/users/justinborromeo/orgs","repos_url":"https://api.github.com/users/justinborromeo/repos","events_url":"https://api.github.com/users/justinborromeo/events{/privacy}","received_events_url":"https://api.github.com/users/justinborromeo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T18:44:28Z","updated_at":"2019-02-14T18:44:28Z","author_association":"CONTRIBUTOR","body":"> Does this mean, the merged result in historicals would be a sequence of a single `ScanResultValue` which contains all time-ordered events of input segments? I understand the merge needs to block for sorting, but how does it work with stream merge in the broker? I guess the broker would also wait until it gets all events in `ScanResultValue`?\r\n\r\nYes.  From `CachingClusteredClient.SpecificQueryRunnable#run()`,\r\n\r\n```\r\nreturn new LazySequence<>(() -> {\r\n        List<Sequence<T>> sequencesByInterval = new ArrayList<>(alreadyCachedResults.size() + segmentsByServer.size());\r\n        addSequencesFromCache(sequencesByInterval, alreadyCachedResults);\r\n        addSequencesFromServer(sequencesByInterval, segmentsByServer);\r\n        return Sequences\r\n            .simple(sequencesByInterval)\r\n            .flatMerge(seq -> seq, query.getResultOrdering());\r\n      });\r\n```\r\n\r\nFrom what I understand, the `Sequences#flatMerge()` function accepts a List of ordered sequences and the ordering for the sequences, then performs a k-way merge.  Since it's assumed that the returned Sequences from the Historicals are already sorted, only the first element of each sequence needs to be materialized to perform the merge.  This should be able to maintain the streaming nature of the Scan query.\r\n","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463743611/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463746494","html_url":"https://github.com/apache/druid/pull/6581#issuecomment-463746494","issue_url":"https://api.github.com/repos/apache/druid/issues/6581","id":463746494,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2Mzc0NjQ5NA==","user":{"login":"edgan8","id":2577963,"node_id":"MDQ6VXNlcjI1Nzc5NjM=","avatar_url":"https://avatars.githubusercontent.com/u/2577963?v=4","gravatar_id":"","url":"https://api.github.com/users/edgan8","html_url":"https://github.com/edgan8","followers_url":"https://api.github.com/users/edgan8/followers","following_url":"https://api.github.com/users/edgan8/following{/other_user}","gists_url":"https://api.github.com/users/edgan8/gists{/gist_id}","starred_url":"https://api.github.com/users/edgan8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/edgan8/subscriptions","organizations_url":"https://api.github.com/users/edgan8/orgs","repos_url":"https://api.github.com/users/edgan8/repos","events_url":"https://api.github.com/users/edgan8/events{/privacy}","received_events_url":"https://api.github.com/users/edgan8/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T18:52:17Z","updated_at":"2019-02-14T18:52:17Z","author_association":"CONTRIBUTOR","body":"Thanks for your help @jon-wei, @leventov, and @leerho ! ","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463746494/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463786310","html_url":"https://github.com/apache/druid/issues/7075#issuecomment-463786310","issue_url":"https://api.github.com/repos/apache/druid/issues/7075","id":463786310,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2Mzc4NjMxMA==","user":{"login":"leventov","id":609240,"node_id":"MDQ6VXNlcjYwOTI0MA==","avatar_url":"https://avatars.githubusercontent.com/u/609240?v=4","gravatar_id":"","url":"https://api.github.com/users/leventov","html_url":"https://github.com/leventov","followers_url":"https://api.github.com/users/leventov/followers","following_url":"https://api.github.com/users/leventov/following{/other_user}","gists_url":"https://api.github.com/users/leventov/gists{/gist_id}","starred_url":"https://api.github.com/users/leventov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leventov/subscriptions","organizations_url":"https://api.github.com/users/leventov/orgs","repos_url":"https://api.github.com/users/leventov/repos","events_url":"https://api.github.com/users/leventov/events{/privacy}","received_events_url":"https://api.github.com/users/leventov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T20:40:00Z","updated_at":"2019-02-14T20:40:00Z","author_association":"MEMBER","body":"`AmbariMetricsEmitter` doesn't need to extend `AbstractTimelineMetricsSink`. This is actually a bad use of inheritance instead of composition. Its internal `ConsumerRunnable` can extend `AbstractTimelineMetricsSink`, or a separate private class.\r\n\r\nI'm not sure we should introduce configurations before somebody actually needs them. One reason is that it's hard to change `HttpPostEmitter` to support policies different from \"drop oldest batch\", that is also not exactly equivalent to queue-based emitters's \"drop oldest events\". I think we may start with just dropping oldest events in queue-based emitters and reporting, for example, one 1000th drop (but making sure that we report the very first one).","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463786310/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463787477","html_url":"https://github.com/apache/druid/issues/7057#issuecomment-463787477","issue_url":"https://api.github.com/repos/apache/druid/issues/7057","id":463787477,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2Mzc4NzQ3Nw==","user":{"login":"leventov","id":609240,"node_id":"MDQ6VXNlcjYwOTI0MA==","avatar_url":"https://avatars.githubusercontent.com/u/609240?v=4","gravatar_id":"","url":"https://api.github.com/users/leventov","html_url":"https://github.com/leventov","followers_url":"https://api.github.com/users/leventov/followers","following_url":"https://api.github.com/users/leventov/following{/other_user}","gists_url":"https://api.github.com/users/leventov/gists{/gist_id}","starred_url":"https://api.github.com/users/leventov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leventov/subscriptions","organizations_url":"https://api.github.com/users/leventov/orgs","repos_url":"https://api.github.com/users/leventov/repos","events_url":"https://api.github.com/users/leventov/events{/privacy}","received_events_url":"https://api.github.com/users/leventov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T20:43:09Z","updated_at":"2019-02-14T20:43:09Z","author_association":"MEMBER","body":"I've created an issue in the repo of that library: https://github.com/DataDog/java-dogstatsd-client/issues/71","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463787477/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463803804","html_url":"https://github.com/apache/druid/issues/7057#issuecomment-463803804","issue_url":"https://api.github.com/repos/apache/druid/issues/7057","id":463803804,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzgwMzgwNA==","user":{"login":"justinborromeo","id":9417701,"node_id":"MDQ6VXNlcjk0MTc3MDE=","avatar_url":"https://avatars.githubusercontent.com/u/9417701?v=4","gravatar_id":"","url":"https://api.github.com/users/justinborromeo","html_url":"https://github.com/justinborromeo","followers_url":"https://api.github.com/users/justinborromeo/followers","following_url":"https://api.github.com/users/justinborromeo/following{/other_user}","gists_url":"https://api.github.com/users/justinborromeo/gists{/gist_id}","starred_url":"https://api.github.com/users/justinborromeo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/justinborromeo/subscriptions","organizations_url":"https://api.github.com/users/justinborromeo/orgs","repos_url":"https://api.github.com/users/justinborromeo/repos","events_url":"https://api.github.com/users/justinborromeo/events{/privacy}","received_events_url":"https://api.github.com/users/justinborromeo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T21:26:14Z","updated_at":"2019-02-14T21:26:14Z","author_association":"CONTRIBUTOR","body":"Does that correspond to what we're using?  NonBlockingStatsDClient isn't a Datadog library.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463803804/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463823547","html_url":"https://github.com/apache/druid/pull/7073#issuecomment-463823547","issue_url":"https://api.github.com/repos/apache/druid/issues/7073","id":463823547,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzgyMzU0Nw==","user":{"login":"egor-ryashin","id":14215045,"node_id":"MDQ6VXNlcjE0MjE1MDQ1","avatar_url":"https://avatars.githubusercontent.com/u/14215045?v=4","gravatar_id":"","url":"https://api.github.com/users/egor-ryashin","html_url":"https://github.com/egor-ryashin","followers_url":"https://api.github.com/users/egor-ryashin/followers","following_url":"https://api.github.com/users/egor-ryashin/following{/other_user}","gists_url":"https://api.github.com/users/egor-ryashin/gists{/gist_id}","starred_url":"https://api.github.com/users/egor-ryashin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/egor-ryashin/subscriptions","organizations_url":"https://api.github.com/users/egor-ryashin/orgs","repos_url":"https://api.github.com/users/egor-ryashin/repos","events_url":"https://api.github.com/users/egor-ryashin/events{/privacy}","received_events_url":"https://api.github.com/users/egor-ryashin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T22:17:04Z","updated_at":"2019-02-14T22:17:04Z","author_association":"CONTRIBUTOR","body":"Looks correct.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463823547/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463829947","html_url":"https://github.com/apache/druid/pull/7066#issuecomment-463829947","issue_url":"https://api.github.com/repos/apache/druid/issues/7066","id":463829947,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2MzgyOTk0Nw==","user":{"login":"egor-ryashin","id":14215045,"node_id":"MDQ6VXNlcjE0MjE1MDQ1","avatar_url":"https://avatars.githubusercontent.com/u/14215045?v=4","gravatar_id":"","url":"https://api.github.com/users/egor-ryashin","html_url":"https://github.com/egor-ryashin","followers_url":"https://api.github.com/users/egor-ryashin/followers","following_url":"https://api.github.com/users/egor-ryashin/following{/other_user}","gists_url":"https://api.github.com/users/egor-ryashin/gists{/gist_id}","starred_url":"https://api.github.com/users/egor-ryashin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/egor-ryashin/subscriptions","organizations_url":"https://api.github.com/users/egor-ryashin/orgs","repos_url":"https://api.github.com/users/egor-ryashin/repos","events_url":"https://api.github.com/users/egor-ryashin/events{/privacy}","received_events_url":"https://api.github.com/users/egor-ryashin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T22:34:28Z","updated_at":"2019-02-14T22:34:28Z","author_association":"CONTRIBUTOR","body":"I suppose AutoScaler can provision only one type of workers still?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463829947/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463840282","html_url":"https://github.com/apache/druid/issues/3851#issuecomment-463840282","issue_url":"https://api.github.com/repos/apache/druid/issues/3851","id":463840282,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2Mzg0MDI4Mg==","user":{"login":"buckeyze","id":39911219,"node_id":"MDQ6VXNlcjM5OTExMjE5","avatar_url":"https://avatars.githubusercontent.com/u/39911219?v=4","gravatar_id":"","url":"https://api.github.com/users/buckeyze","html_url":"https://github.com/buckeyze","followers_url":"https://api.github.com/users/buckeyze/followers","following_url":"https://api.github.com/users/buckeyze/following{/other_user}","gists_url":"https://api.github.com/users/buckeyze/gists{/gist_id}","starred_url":"https://api.github.com/users/buckeyze/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/buckeyze/subscriptions","organizations_url":"https://api.github.com/users/buckeyze/orgs","repos_url":"https://api.github.com/users/buckeyze/repos","events_url":"https://api.github.com/users/buckeyze/events{/privacy}","received_events_url":"https://api.github.com/users/buckeyze/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-14T23:10:43Z","updated_at":"2019-02-14T23:10:43Z","author_association":"NONE","body":"https://groups.google.com/forum/m/?utm_medium=email&utm_source=footer#!msg/druid-user/5qmrmMEDD8g/yrh7wOVVBAAJ\r\n\r\nI just posted about my similar issue in the Druid forums at the link above. I would be very grateful if you could recommend how to fix my problem. I am also getting the unable to register shutdown hook in my logs. Thank you very much","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463840282/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463888690","html_url":"https://github.com/apache/druid/issues/7077#issuecomment-463888690","issue_url":"https://api.github.com/repos/apache/druid/issues/7077","id":463888690,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2Mzg4ODY5MA==","user":{"login":"hellobabygogo","id":8693129,"node_id":"MDQ6VXNlcjg2OTMxMjk=","avatar_url":"https://avatars.githubusercontent.com/u/8693129?v=4","gravatar_id":"","url":"https://api.github.com/users/hellobabygogo","html_url":"https://github.com/hellobabygogo","followers_url":"https://api.github.com/users/hellobabygogo/followers","following_url":"https://api.github.com/users/hellobabygogo/following{/other_user}","gists_url":"https://api.github.com/users/hellobabygogo/gists{/gist_id}","starred_url":"https://api.github.com/users/hellobabygogo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hellobabygogo/subscriptions","organizations_url":"https://api.github.com/users/hellobabygogo/orgs","repos_url":"https://api.github.com/users/hellobabygogo/repos","events_url":"https://api.github.com/users/hellobabygogo/events{/privacy}","received_events_url":"https://api.github.com/users/hellobabygogo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T03:03:36Z","updated_at":"2019-02-15T03:03:36Z","author_association":"NONE","body":"you can collect request log to kafka ","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463888690/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/463891913","html_url":"https://github.com/apache/druid/pull/7066#issuecomment-463891913","issue_url":"https://api.github.com/repos/apache/druid/issues/7066","id":463891913,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2Mzg5MTkxMw==","user":{"login":"QiuMM","id":15156517,"node_id":"MDQ6VXNlcjE1MTU2NTE3","avatar_url":"https://avatars.githubusercontent.com/u/15156517?v=4","gravatar_id":"","url":"https://api.github.com/users/QiuMM","html_url":"https://github.com/QiuMM","followers_url":"https://api.github.com/users/QiuMM/followers","following_url":"https://api.github.com/users/QiuMM/following{/other_user}","gists_url":"https://api.github.com/users/QiuMM/gists{/gist_id}","starred_url":"https://api.github.com/users/QiuMM/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/QiuMM/subscriptions","organizations_url":"https://api.github.com/users/QiuMM/orgs","repos_url":"https://api.github.com/users/QiuMM/repos","events_url":"https://api.github.com/users/QiuMM/events{/privacy}","received_events_url":"https://api.github.com/users/QiuMM/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T03:23:05Z","updated_at":"2019-02-15T03:23:05Z","author_association":"MEMBER","body":"> I suppose AutoScaler can provision only one type of workers still?\r\n\r\nThanks for your reminder. I have not considered this since I have never used AutoScaler. It need to support tier for AutoScaler since different tier might have different resource configuration, I have no idea about current auto scale strategy would use which tier's configuration to create new workers.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/463891913/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464017959","html_url":"https://github.com/apache/druid/pull/6991#issuecomment-464017959","issue_url":"https://api.github.com/repos/apache/druid/issues/6991","id":464017959,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDAxNzk1OQ==","user":{"login":"QiuMM","id":15156517,"node_id":"MDQ6VXNlcjE1MTU2NTE3","avatar_url":"https://avatars.githubusercontent.com/u/15156517?v=4","gravatar_id":"","url":"https://api.github.com/users/QiuMM","html_url":"https://github.com/QiuMM","followers_url":"https://api.github.com/users/QiuMM/followers","following_url":"https://api.github.com/users/QiuMM/following{/other_user}","gists_url":"https://api.github.com/users/QiuMM/gists{/gist_id}","starred_url":"https://api.github.com/users/QiuMM/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/QiuMM/subscriptions","organizations_url":"https://api.github.com/users/QiuMM/orgs","repos_url":"https://api.github.com/users/QiuMM/repos","events_url":"https://api.github.com/users/QiuMM/events{/privacy}","received_events_url":"https://api.github.com/users/QiuMM/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T11:46:42Z","updated_at":"2019-02-15T11:46:42Z","author_association":"MEMBER","body":"I think I know why the pending tasks aren't going to run, two cases:\r\n\r\n- If one worker is added to the black list, it will backoff for 15 minutes. The `workerBlackListCleanupPeriod` is 5 minutes, so 15 minutes later the worker still need to wait for several minutes (max to 5 minutes) to be removed from the black list and start to run the pending tasks. \r\n\r\n- Every time I update and restart the Overlord, some tasks may fail to be assigned and I get the debug log \"Unsuccessful task-assign attempt for task...\".  If there are no new tasks to be added to the task queue or any other condition to trigger the `runPendingTasks()`, the pending tasks would never go to run (I have observed this situation several times). \r\n\r\nHave updated this PR since just modified the `RemoteTaskRunner` didn't fix this issue, we also need to modify the `TaskQueue`.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464017959/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464081792","html_url":"https://github.com/apache/druid/issues/5727#issuecomment-464081792","issue_url":"https://api.github.com/repos/apache/druid/issues/5727","id":464081792,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDA4MTc5Mg==","user":{"login":"scrawfor","id":7061689,"node_id":"MDQ6VXNlcjcwNjE2ODk=","avatar_url":"https://avatars.githubusercontent.com/u/7061689?v=4","gravatar_id":"","url":"https://api.github.com/users/scrawfor","html_url":"https://github.com/scrawfor","followers_url":"https://api.github.com/users/scrawfor/followers","following_url":"https://api.github.com/users/scrawfor/following{/other_user}","gists_url":"https://api.github.com/users/scrawfor/gists{/gist_id}","starred_url":"https://api.github.com/users/scrawfor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/scrawfor/subscriptions","organizations_url":"https://api.github.com/users/scrawfor/orgs","repos_url":"https://api.github.com/users/scrawfor/repos","events_url":"https://api.github.com/users/scrawfor/events{/privacy}","received_events_url":"https://api.github.com/users/scrawfor/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T15:04:46Z","updated_at":"2019-02-15T15:04:51Z","author_association":"CONTRIBUTOR","body":"I found the magic settings to prevent the lookups from loading on the middle manager. \r\n\r\n```\r\n# Disable lookups on middleManager, but enable on peon.\r\ndruid.lookup.enableLookupSyncOnStartup=false\r\ndruid.indexer.fork.property.druid.lookup.enableLookupSyncOnStartup=true\r\n```\r\n\r\nCreated #7082","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464081792/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464143818","html_url":"https://github.com/apache/druid/pull/7034#issuecomment-464143818","issue_url":"https://api.github.com/repos/apache/druid/issues/7034","id":464143818,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDE0MzgxOA==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T18:04:37Z","updated_at":"2019-02-15T18:04:37Z","author_association":"CONTRIBUTOR","body":"@surekhasaharan thanks! LGTM.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464143818/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464166412","html_url":"https://github.com/apache/druid/issues/7057#issuecomment-464166412","issue_url":"https://api.github.com/repos/apache/druid/issues/7057","id":464166412,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDE2NjQxMg==","user":{"login":"leventov","id":609240,"node_id":"MDQ6VXNlcjYwOTI0MA==","avatar_url":"https://avatars.githubusercontent.com/u/609240?v=4","gravatar_id":"","url":"https://api.github.com/users/leventov","html_url":"https://github.com/leventov","followers_url":"https://api.github.com/users/leventov/followers","following_url":"https://api.github.com/users/leventov/following{/other_user}","gists_url":"https://api.github.com/users/leventov/gists{/gist_id}","starred_url":"https://api.github.com/users/leventov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leventov/subscriptions","organizations_url":"https://api.github.com/users/leventov/orgs","repos_url":"https://api.github.com/users/leventov/repos","events_url":"https://api.github.com/users/leventov/events{/privacy}","received_events_url":"https://api.github.com/users/leventov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T19:16:02Z","updated_at":"2019-02-15T19:16:02Z","author_association":"MEMBER","body":"@justinborromeo https://github.com/DataDog/java-dogstatsd-client/blob/de8c7982d208b1458e17eef81e4d18085d7fd9f5/src/main/java/com/timgroup/statsd/NonBlockingStatsDClient.java don't we use this class?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464166412/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464168378","html_url":"https://github.com/apache/druid/issues/7057#issuecomment-464168378","issue_url":"https://api.github.com/repos/apache/druid/issues/7057","id":464168378,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDE2ODM3OA==","user":{"login":"justinborromeo","id":9417701,"node_id":"MDQ6VXNlcjk0MTc3MDE=","avatar_url":"https://avatars.githubusercontent.com/u/9417701?v=4","gravatar_id":"","url":"https://api.github.com/users/justinborromeo","html_url":"https://github.com/justinborromeo","followers_url":"https://api.github.com/users/justinborromeo/followers","following_url":"https://api.github.com/users/justinborromeo/following{/other_user}","gists_url":"https://api.github.com/users/justinborromeo/gists{/gist_id}","starred_url":"https://api.github.com/users/justinborromeo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/justinborromeo/subscriptions","organizations_url":"https://api.github.com/users/justinborromeo/orgs","repos_url":"https://api.github.com/users/justinborromeo/repos","events_url":"https://api.github.com/users/justinborromeo/events{/privacy}","received_events_url":"https://api.github.com/users/justinborromeo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T19:22:08Z","updated_at":"2019-02-15T19:22:08Z","author_association":"CONTRIBUTOR","body":"Sorry, I misread something.  You are correct.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464168378/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464170859","html_url":"https://github.com/apache/druid/issues/7036#issuecomment-464170859","issue_url":"https://api.github.com/repos/apache/druid/issues/7036","id":464170859,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDE3MDg1OQ==","user":{"login":"justinborromeo","id":9417701,"node_id":"MDQ6VXNlcjk0MTc3MDE=","avatar_url":"https://avatars.githubusercontent.com/u/9417701?v=4","gravatar_id":"","url":"https://api.github.com/users/justinborromeo","html_url":"https://github.com/justinborromeo","followers_url":"https://api.github.com/users/justinborromeo/followers","following_url":"https://api.github.com/users/justinborromeo/following{/other_user}","gists_url":"https://api.github.com/users/justinborromeo/gists{/gist_id}","starred_url":"https://api.github.com/users/justinborromeo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/justinborromeo/subscriptions","organizations_url":"https://api.github.com/users/justinborromeo/orgs","repos_url":"https://api.github.com/users/justinborromeo/repos","events_url":"https://api.github.com/users/justinborromeo/events{/privacy}","received_events_url":"https://api.github.com/users/justinborromeo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T19:29:51Z","updated_at":"2019-02-15T19:31:10Z","author_association":"CONTRIBUTOR","body":"Adding on to my previous comment, `ScanResultValue`s contain many events at the historical level.  To facilitate streaming and easier sorting using `Sequences#flatMerge()` at the broker level, I plan to \"deaggregate\" each `ScanResultValue` into several `ScanResultValue`s with one event each prior to streaming from the Historical -> Broker.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464170859/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464172173","html_url":"https://github.com/apache/druid/issues/4275#issuecomment-464172173","issue_url":"https://api.github.com/repos/apache/druid/issues/4275","id":464172173,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDE3MjE3Mw==","user":{"login":"leventov","id":609240,"node_id":"MDQ6VXNlcjYwOTI0MA==","avatar_url":"https://avatars.githubusercontent.com/u/609240?v=4","gravatar_id":"","url":"https://api.github.com/users/leventov","html_url":"https://github.com/leventov","followers_url":"https://api.github.com/users/leventov/followers","following_url":"https://api.github.com/users/leventov/following{/other_user}","gists_url":"https://api.github.com/users/leventov/gists{/gist_id}","starred_url":"https://api.github.com/users/leventov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leventov/subscriptions","organizations_url":"https://api.github.com/users/leventov/orgs","repos_url":"https://api.github.com/users/leventov/repos","events_url":"https://api.github.com/users/leventov/events{/privacy}","received_events_url":"https://api.github.com/users/leventov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T19:34:04Z","updated_at":"2019-02-15T19:34:04Z","author_association":"MEMBER","body":"I think we can prohibit `Optional` in fields as well.\r\n\r\nThere is an \"Optional used as field or parameter type\" inspection in IntelliJ. We can make it error-level.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464172173/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464173080","html_url":"https://github.com/apache/druid/issues/7075#issuecomment-464173080","issue_url":"https://api.github.com/repos/apache/druid/issues/7075","id":464173080,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDE3MzA4MA==","user":{"login":"justinborromeo","id":9417701,"node_id":"MDQ6VXNlcjk0MTc3MDE=","avatar_url":"https://avatars.githubusercontent.com/u/9417701?v=4","gravatar_id":"","url":"https://api.github.com/users/justinborromeo","html_url":"https://github.com/justinborromeo","followers_url":"https://api.github.com/users/justinborromeo/followers","following_url":"https://api.github.com/users/justinborromeo/following{/other_user}","gists_url":"https://api.github.com/users/justinborromeo/gists{/gist_id}","starred_url":"https://api.github.com/users/justinborromeo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/justinborromeo/subscriptions","organizations_url":"https://api.github.com/users/justinborromeo/orgs","repos_url":"https://api.github.com/users/justinborromeo/repos","events_url":"https://api.github.com/users/justinborromeo/events{/privacy}","received_events_url":"https://api.github.com/users/justinborromeo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T19:37:07Z","updated_at":"2019-02-15T20:36:46Z","author_association":"CONTRIBUTOR","body":"I'm looking at the Kafka metrics emitter and I'm kinda stumped about a design decision.  The way it's currently implemented, it follows the pattern of all the other emitters where events are pushed to some queue then some thread dequeues events and does something with them.  In this case, the thread sends the event to Kafka using the KafkaProducer.  From what I understand, the Kafka producer has its own memory-bounded buffer where records are batched before actually being sent.  From the [javadoc](https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html):\r\n\r\n> The producer consists of a pool of buffer space that holds records that haven't yet been transmitted to the server as well as a background I/O thread that is responsible for turning these records into requests and transmitting them to the cluster.\r\n\r\nIf this is the case, is there any benefit of having the first queue if it's being buffered on the same machine at a later stage?  From the original [commit](https://github.com/apache/incubator-druid/pull/3860#issuecomment-279918357), \r\n\r\n> In terms of code maintenance, Using `block.on.buffer.full` is a little bit questionable solution. also, @b-slim mentioned, `emit` should never be blocking but using `producer.send` in `emit` has potential blocking issue because of `max.block.ms`. This is why I use another queue and using `queue.add` in `emit`.\r\n\r\nHowever, if `max.block.ms` is set to 0, wouldn't it just fast-fail if the buffer is full?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464173080/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464187589","html_url":"https://github.com/apache/druid/issues/6001#issuecomment-464187589","issue_url":"https://api.github.com/repos/apache/druid/issues/6001","id":464187589,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDE4NzU4OQ==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T20:25:37Z","updated_at":"2019-02-15T20:25:37Z","author_association":"CONTRIBUTOR","body":"Would it work to hook into the checkpointing logic? As in, have the supervisor _not_ tell tasks in a group to resume until after any earlier groups (offset-wise) have completed. This would have the effect of having the `T2` tasks stay paused until the `T1` tasks have finished.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464187589/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464191157","html_url":"https://github.com/apache/druid/pull/7046#issuecomment-464191157","issue_url":"https://api.github.com/repos/apache/druid/issues/7046","id":464191157,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDE5MTE1Nw==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T20:39:23Z","updated_at":"2019-02-15T20:39:23Z","author_association":"CONTRIBUTOR","body":"This does now work, but I'm now realizing I would never actually want to use it in my use case, since if your input data accidentally contains one stray row from outside the interval you're trying to replace, it'll delete a ton of data.  (And we just found a bug that could lead to rows derived from our Kafka backups being outside the interval you'd think they'd be in.)  Maybe I should add some scarier warnings to the docs?\r\n\r\nPart of me does feel like it would be easier to reason about if non-appending batch ingestion always required you to specify a target interval and always replaced *all* segments inside that interval on success (like I was thinking about in part 3 of https://github.com/apache/incubator-druid/issues/6989#issuecomment-461108169), but I'm sure there are use cases where that isn't desired.  The current semantics of \"non-appending batch ingestion replaces any data that happens to be within segmentGranularity of specific rows produced by the firehose\" seems harder for me to reason about.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464191157/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464211404","html_url":"https://github.com/apache/druid/issues/6001#issuecomment-464211404","issue_url":"https://api.github.com/repos/apache/druid/issues/6001","id":464211404,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDIxMTQwNA==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T21:40:51Z","updated_at":"2019-02-15T21:40:51Z","author_association":"CONTRIBUTOR","body":"@gianm that sounds a possible option, but, I don't want to block the stream ingestion if possible. I think it's possible to not block if we can add a new signal which the supervisor can send to tasks to start publishing segments. The changed algorithm I'm thinking is like\r\n\r\n1. Checkpointing is initialized by the task or the supervisor\r\n2. The supervisor sends `pause` request to all tasks in the same taskGroup.\r\n3. Tasks send their current offsets to the supervisor.\r\n4. The supervisor finds the max and sends it to all tasks in the taskGroup.\r\n5. Tasks resume and read up to the updated endOffsets. They generate and push segments, but _**wouldn't publish them immediately**_. Instead, they add the set of segments to a queue and send a publish request to the supervisor. \r\n6. The supervisor adds the publish request to a queue. This publish request contains a taskGroup ID.\r\n7. If it's the first request of the previous publish has finished, the supervisor pops a request from the queue and sends a signal to tasks to start publishing.\r\n8. Tasks pops a set of segments from its queue, publishes them, and tells the supervisor that publish is finished.\r\n\r\nSo, 1-4 steps are same with the current, but 5-8 is to guarantee the publish order across taskGroups. What do you think?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464211404/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464215051","html_url":"https://github.com/apache/druid/pull/7046#issuecomment-464215051","issue_url":"https://api.github.com/repos/apache/druid/issues/7046","id":464215051,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDIxNTA1MQ==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T21:51:39Z","updated_at":"2019-02-15T21:51:39Z","author_association":"CONTRIBUTOR","body":"@glasser hmm good point. I think it would be fine by adding a scary warning to doc for now. Probably worth to discuss how we can improve the native task behavior to be more intuitive.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464215051/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464216514","html_url":"https://github.com/apache/druid/issues/6001#issuecomment-464216514","issue_url":"https://api.github.com/repos/apache/druid/issues/6001","id":464216514,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDIxNjUxNA==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T21:56:00Z","updated_at":"2019-02-15T21:56:00Z","author_association":"CONTRIBUTOR","body":"Probably we need a way for throttling to prevent the queues in the task or the supervisor from becoming huge. I think the task can pause itself if its queue is too large. The supervisor can reject the publish request if its queue is too large.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464216514/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464243329","html_url":"https://github.com/apache/druid/issues/7081#issuecomment-464243329","issue_url":"https://api.github.com/repos/apache/druid/issues/7081","id":464243329,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDI0MzMyOQ==","user":{"login":"jon-wei","id":8729063,"node_id":"MDQ6VXNlcjg3MjkwNjM=","avatar_url":"https://avatars.githubusercontent.com/u/8729063?v=4","gravatar_id":"","url":"https://api.github.com/users/jon-wei","html_url":"https://github.com/jon-wei","followers_url":"https://api.github.com/users/jon-wei/followers","following_url":"https://api.github.com/users/jon-wei/following{/other_user}","gists_url":"https://api.github.com/users/jon-wei/gists{/gist_id}","starred_url":"https://api.github.com/users/jon-wei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jon-wei/subscriptions","organizations_url":"https://api.github.com/users/jon-wei/orgs","repos_url":"https://api.github.com/users/jon-wei/repos","events_url":"https://api.github.com/users/jon-wei/events{/privacy}","received_events_url":"https://api.github.com/users/jon-wei/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T23:19:50Z","updated_at":"2019-02-15T23:19:50Z","author_association":"CONTRIBUTOR","body":"Hi @pbalaguer19, \r\n\r\nThe Escalator controls what authentication scheme will be used by Druid's internal clients when communicating with other Druid processes, it must be defined.\r\n\r\nIf you're using the Basic Security extension, you can base your configurations off the info in the first link you provided, no code needs to be written.\r\n\r\nThe info in the second link you provided is targeted at extension developers who are adding their own authentication/authorization implementations.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464243329/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464252147","html_url":"https://github.com/apache/druid/issues/6001#issuecomment-464252147","issue_url":"https://api.github.com/repos/apache/druid/issues/6001","id":464252147,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDI1MjE0Nw==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-15T23:52:53Z","updated_at":"2019-02-15T23:52:53Z","author_association":"CONTRIBUTOR","body":"Hmm, what about having the supervisor publish the segments itself, so steps (7) and (8) are not necessary? Nothing really says that tasks need to publish their own segments.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464252147/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464254629","html_url":"https://github.com/apache/druid/issues/6001#issuecomment-464254629","issue_url":"https://api.github.com/repos/apache/druid/issues/6001","id":464254629,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDI1NDYyOQ==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-16T00:01:53Z","updated_at":"2019-02-16T00:01:53Z","author_association":"CONTRIBUTOR","body":"i was thinking about it in #5492, but ended up not doing it because publishing segments is currently allowed for only tasks but the supervisor is not a task.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464254629/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464259005","html_url":"https://github.com/apache/druid/pull/6865#issuecomment-464259005","issue_url":"https://api.github.com/repos/apache/druid/issues/6865","id":464259005,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDI1OTAwNQ==","user":{"login":"clintropolis","id":1577461,"node_id":"MDQ6VXNlcjE1Nzc0NjE=","avatar_url":"https://avatars.githubusercontent.com/u/1577461?v=4","gravatar_id":"","url":"https://api.github.com/users/clintropolis","html_url":"https://github.com/clintropolis","followers_url":"https://api.github.com/users/clintropolis/followers","following_url":"https://api.github.com/users/clintropolis/following{/other_user}","gists_url":"https://api.github.com/users/clintropolis/gists{/gist_id}","starred_url":"https://api.github.com/users/clintropolis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/clintropolis/subscriptions","organizations_url":"https://api.github.com/users/clintropolis/orgs","repos_url":"https://api.github.com/users/clintropolis/repos","events_url":"https://api.github.com/users/clintropolis/events{/privacy}","received_events_url":"https://api.github.com/users/clintropolis/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-16T00:20:48Z","updated_at":"2019-02-16T00:20:48Z","author_association":"MEMBER","body":"@leerho are your concerns specific to the fix this PR is doing or the Druid hll implementation in general?\r\n\r\nThis seems like it's fixing an oversight in the original implementation, since it was already converting itself to dense representation if it wasn't, but wasn't checking the `other` hll collector to do the same thing during the fold.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464259005/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464299323","html_url":"https://github.com/apache/druid/pull/7048#issuecomment-464299323","issue_url":"https://api.github.com/repos/apache/druid/issues/7048","id":464299323,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDI5OTMyMw==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-16T06:15:30Z","updated_at":"2019-02-16T06:15:30Z","author_association":"CONTRIBUTOR","body":"What do you think a good default value for maxInputSegmentBytesPerTask is? I was thinking of just copying what the Kafka indexing service uses for its default segment size limit, but that's a row count, not bytes.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464299323/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464312575","html_url":"https://github.com/apache/druid/pull/7048#issuecomment-464312575","issue_url":"https://api.github.com/repos/apache/druid/issues/7048","id":464312575,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDMxMjU3NQ==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-16T08:18:05Z","updated_at":"2019-02-16T08:18:05Z","author_association":"CONTRIBUTOR","body":"> So I think the algorithm would be something like: list the segments for the whole interval as a timeline. Select the first segment, and take the set of all segments that overlap it, transitively. If this set of segments has more than one interval, then all of those segments are constrained to go in the same subtask. Otherwise, each of the segments in this set (all of which are for the same interval) may go in their own subtask.\r\n\r\nOK, I think this was overcomplicating it. An easier way to solve the overlapping segment problem is just to make the task specify directly to the subtask a `List<WindowedSegment>`, where a WindowedSegment is a class that holds a segment ID (String) and a `List<Interval>`.  This can be read off directly from the full timeline when calculating splits.\r\n\r\nThe sub-task won't need to recalculate a timeline at all: it'll just set up some WindowedStorageAdapters to read the appropriate parts of the segments.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464312575/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464369003","html_url":"https://github.com/apache/druid/pull/7046#issuecomment-464369003","issue_url":"https://api.github.com/repos/apache/druid/issues/7046","id":464369003,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDM2OTAwMw==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-16T18:17:38Z","updated_at":"2019-02-16T18:17:38Z","author_association":"CONTRIBUTOR","body":"OK, test concerns fixed and passing CI, and docs made a little scarier.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464369003/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464375632","html_url":"https://github.com/apache/druid/pull/7063#issuecomment-464375632","issue_url":"https://api.github.com/repos/apache/druid/issues/7063","id":464375632,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDM3NTYzMg==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-16T19:29:58Z","updated_at":"2019-02-16T19:29:58Z","author_association":"CONTRIBUTOR","body":"A potential other approach: instead of setting a TaskToolbox, just inject (`@JacksonInject`? still learning Jackon/Guice) a CoordinatorClient, which can learn how to `POST` `/druid/coordinator/v1/metadata/datasources/{dataSourceName}/segments?full`. That's equivalent to the SegmentListUsedAction.\r\n\r\nThe only other thing you need from the toolbox is the SegmentLoader, which maybe can also be injected?\r\n\r\nIt's nice how the DataSegments returned from the coordinator are self-describing: you can even imagine configuring this to talk to an unrelated Druid cluster, as long as you have the proper permissions to download segments from deep storage.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464375632/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464376708","html_url":"https://github.com/apache/druid/pull/7063#issuecomment-464376708","issue_url":"https://api.github.com/repos/apache/druid/issues/7063","id":464376708,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDM3NjcwOA==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-16T19:39:22Z","updated_at":"2019-02-16T19:39:22Z","author_association":"CONTRIBUTOR","body":"(Or even just inject the IndexerMetadataStorageCoordinator directly? I don't quite understand what's going on in CliPeon's configureTaskActionClient with respect to local vs remote.)","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464376708/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464409814","html_url":"https://github.com/apache/druid/pull/6865#issuecomment-464409814","issue_url":"https://api.github.com/repos/apache/druid/issues/6865","id":464409814,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDQwOTgxNA==","user":{"login":"leerho","id":12941506,"node_id":"MDQ6VXNlcjEyOTQxNTA2","avatar_url":"https://avatars.githubusercontent.com/u/12941506?v=4","gravatar_id":"","url":"https://api.github.com/users/leerho","html_url":"https://github.com/leerho","followers_url":"https://api.github.com/users/leerho/followers","following_url":"https://api.github.com/users/leerho/following{/other_user}","gists_url":"https://api.github.com/users/leerho/gists{/gist_id}","starred_url":"https://api.github.com/users/leerho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leerho/subscriptions","organizations_url":"https://api.github.com/users/leerho/orgs","repos_url":"https://api.github.com/users/leerho/repos","events_url":"https://api.github.com/users/leerho/events{/privacy}","received_events_url":"https://api.github.com/users/leerho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-17T02:36:43Z","updated_at":"2019-02-17T02:36:43Z","author_association":"CONTRIBUTOR","body":"@clintropolis \r\n\r\nSorry about the delay, I was pulled off onto other problems :)\r\n\r\nThis code has so many serious issues that I hardly know where to start.  If we are going to submit fixes, then I would suggest that we fix an issue throughout the code and not just in one place.\r\n\r\n- Checking for sparse vs dense\r\nSpecifically, your added check if sparse in the fold() routine may be OK on the surface, but one of the serious problems in the code is that the author uses a very fragile method for determining whether the sketch is sparse or dense and it is done differently in different parts of the code.  (It should have been a simple boolean in the header!)\r\n\r\nIn your check you compare (and in other parts the author does this as well ...)\r\n`if (other.storageBuffer.remaining() != other.getNumBytesForDenseStorage())`\r\n\r\nThe `isSparce(buffer)` method compares:  `buffer.remaining() != NUM_BYTES_FOR_BUCKETS;`\r\n\r\nThey are different!  NUM_BYTES_FOR_BUCKETS = 1024, while getNumBytesForDenseStorage() = 1031.\r\n\r\nThe author should have used `isSparse(buffer)` everywhere.\r\n\r\nIt is fragile because the remaining size of the buffer relies on the current state of the buffer position and limit.  Yikes!    \r\n\r\nAnd `isSparse(buffer)` sometimes fails as follows:\r\n\r\nOne of the tests you added demonstrates this. In `testRegisterSwapWithSparse()` after you artificially fill all the registers with 1's, when you check the cardinality it returns zero and you say it is \"fine\".  \r\nIt is not \"fine\".  It is a symptom of more serious issues.\r\n\r\nThe reason it returns zero is because the toByteBuffer() returns a sparse representation when it should be dense, and  estimateCardinality() of sparse uses the linear (or Poisson) estimator which is `k log (k/v)` where v = k, and the estimate is zero!   The sketch should not have been sparse and even if it was sparse, the linear estimator should never be used when v approaches k!  \r\n\r\nThese issues could be fixed, but it will require a version change and a lot of careful coding.\r\n\r\nI have more, but I have to go now.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464409814/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464448219","html_url":"https://github.com/apache/druid/issues/7047#issuecomment-464448219","issue_url":"https://api.github.com/repos/apache/druid/issues/7047","id":464448219,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDQ0ODIxOQ==","user":{"login":"quenlang","id":11764573,"node_id":"MDQ6VXNlcjExNzY0NTcz","avatar_url":"https://avatars.githubusercontent.com/u/11764573?v=4","gravatar_id":"","url":"https://api.github.com/users/quenlang","html_url":"https://github.com/quenlang","followers_url":"https://api.github.com/users/quenlang/followers","following_url":"https://api.github.com/users/quenlang/following{/other_user}","gists_url":"https://api.github.com/users/quenlang/gists{/gist_id}","starred_url":"https://api.github.com/users/quenlang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/quenlang/subscriptions","organizations_url":"https://api.github.com/users/quenlang/orgs","repos_url":"https://api.github.com/users/quenlang/repos","events_url":"https://api.github.com/users/quenlang/events{/privacy}","received_events_url":"https://api.github.com/users/quenlang/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-17T12:02:47Z","updated_at":"2019-02-17T12:02:47Z","author_association":"NONE","body":"@AlexanderSaydakov \r\nI had manually merged the bug fix #6877 in to druid 0.13.0 source code and built to the binary tar.\r\nThen i upgraded up to 0.13.0, it seems working.\r\nThank you so much !\r\n","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464448219/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464552923","html_url":"https://github.com/apache/druid/issues/7077#issuecomment-464552923","issue_url":"https://api.github.com/repos/apache/druid/issues/7077","id":464552923,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDU1MjkyMw==","user":{"login":"helianthuslulu","id":4606832,"node_id":"MDQ6VXNlcjQ2MDY4MzI=","avatar_url":"https://avatars.githubusercontent.com/u/4606832?v=4","gravatar_id":"","url":"https://api.github.com/users/helianthuslulu","html_url":"https://github.com/helianthuslulu","followers_url":"https://api.github.com/users/helianthuslulu/followers","following_url":"https://api.github.com/users/helianthuslulu/following{/other_user}","gists_url":"https://api.github.com/users/helianthuslulu/gists{/gist_id}","starred_url":"https://api.github.com/users/helianthuslulu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/helianthuslulu/subscriptions","organizations_url":"https://api.github.com/users/helianthuslulu/orgs","repos_url":"https://api.github.com/users/helianthuslulu/repos","events_url":"https://api.github.com/users/helianthuslulu/events{/privacy}","received_events_url":"https://api.github.com/users/helianthuslulu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-18T02:03:58Z","updated_at":"2019-02-18T02:03:58Z","author_association":"NONE","body":"Thanks for your comments, I will have a try.~","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464552923/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464555857","html_url":"https://github.com/apache/druid/pull/6865#issuecomment-464555857","issue_url":"https://api.github.com/repos/apache/druid/issues/6865","id":464555857,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDU1NTg1Nw==","user":{"login":"leerho","id":12941506,"node_id":"MDQ6VXNlcjEyOTQxNTA2","avatar_url":"https://avatars.githubusercontent.com/u/12941506?v=4","gravatar_id":"","url":"https://api.github.com/users/leerho","html_url":"https://github.com/leerho","followers_url":"https://api.github.com/users/leerho/followers","following_url":"https://api.github.com/users/leerho/following{/other_user}","gists_url":"https://api.github.com/users/leerho/gists{/gist_id}","starred_url":"https://api.github.com/users/leerho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leerho/subscriptions","organizations_url":"https://api.github.com/users/leerho/orgs","repos_url":"https://api.github.com/users/leerho/repos","events_url":"https://api.github.com/users/leerho/events{/privacy}","received_events_url":"https://api.github.com/users/leerho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-18T02:19:25Z","updated_at":"2019-02-18T02:19:25Z","author_association":"CONTRIBUTOR","body":"@drcrallen @clintropolis \r\n...continued:\r\n\r\n- I'm not sure if you noticed but Line 388 in HyperLogLogCollector just above your inserted lines is a no-op:\r\n\r\n`storageBuffer.duplicate().put(other.storageBuffer.asReadOnlyBuffer());`\r\n\r\nThe returned duplicated read-only buffer is never captured or used.\r\n\r\n- Inside the scope where you put your sparse check:\r\n```\r\n    if (getRegisterOffset() < other.getRegisterOffset()) {\r\n      // \"Swap\" the buffers so that we are folding into the one with the higher offset\r\n      final ByteBuffer tmpBuffer = ByteBuffer.allocate(storageBuffer.remaining());\r\n      tmpBuffer.put(storageBuffer.asReadOnlyBuffer());\r\n      tmpBuffer.clear();\r\n\r\n      storageBuffer.duplicate().put(other.storageBuffer.asReadOnlyBuffer());\r\n\r\n      //Added by PR #6865\r\n      if (other.storageBuffer.remaining() != other.getNumBytesForDenseStorage()) {\r\n        // The other buffer was sparse, densify it\r\n        final int newLImit = storageBuffer.position() + other.storageBuffer.remaining();\r\n        storageBuffer.limit(newLImit);\r\n        convertToDenseStorage();\r\n      } //end of PR #6865\r\n\r\n      other = HyperLogLogCollector.makeCollector(tmpBuffer);\r\n    }\r\n```\r\nThe `other`  sketch can never be sparse! ... Once the sketch has increased the Register Offset bigger than zero, the sketch should **never** be placed back into the sparse state, ever!   ... **Unless you fill the registers artificially with impossible values as you do in your test!**.    \r\n\r\nThe HLL sketch is a complex state machine, and if implemented correctly, should never allow itself to be placed in illegal states especially from public methods.  It is hard enough to validate that the state machine operates correctly, but placing them in illegal states and then expecting meaningful results is asking for trouble.  You are not the only one to fall into this trap, clearly the author did too.\r\n\r\n- The swap logic itself is rather risky.  Because of the existence of the overflow register, there are a number of corner cases that complicate the merging and it is hard to confirm that they are all handled correctly.  The test code doesn't seem to check for these corner cases either.  (There are much safer ways to do this merging, but that is another topic.) \r\n\r\n- WRT your test called ` testCanFillUpOnMod()`.    I sense that what you are trying to do is use this as an example of what NOT to do.  However, it should be annotated with @Ignore so that it doesn't always log the message \"Filled up registers after %s random numbers\". \r\n\r\nNonetheless, the real issue to warn users about is to never ever use `Hashing.murmur3_128()` without specifying a non-zero seed AND using that hash function to effectively select the hash values that are presented to the sketch.  All that your test essentially does is select only odd hash values to be presented to the sketch, thus all the registers of the sketch will end up with 1's.  The likelihood that this could ever occur using the sketch properly is probably longer than the age of the universe.  \r\n\r\nThis goes back to what I have said before, that the hashing operation should never have been exposed and delegated to the user.  But that is history.\r\n\r\nIn conclusion\r\n1. The additional code added to `HyperLogLogCollector` is unnecessary.  It would only ever be executed from tests that create illegal states of the sketch.  What should be modified is the tests!\r\n\r\n2. Both of the tests added to `HyperLogLogCollectorTest` use methods that place the sketch in illegal states.  The first test could be rewritten to easily confirm proper swapping logic without doing this. The second test IMHO, is too complex and misses the bigger danger of misusing the hash function.\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464555857/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464613589","html_url":"https://github.com/apache/druid/issues/7081#issuecomment-464613589","issue_url":"https://api.github.com/repos/apache/druid/issues/7081","id":464613589,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDYxMzU4OQ==","user":{"login":"pbalaguer19","id":17141165,"node_id":"MDQ6VXNlcjE3MTQxMTY1","avatar_url":"https://avatars.githubusercontent.com/u/17141165?v=4","gravatar_id":"","url":"https://api.github.com/users/pbalaguer19","html_url":"https://github.com/pbalaguer19","followers_url":"https://api.github.com/users/pbalaguer19/followers","following_url":"https://api.github.com/users/pbalaguer19/following{/other_user}","gists_url":"https://api.github.com/users/pbalaguer19/gists{/gist_id}","starred_url":"https://api.github.com/users/pbalaguer19/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pbalaguer19/subscriptions","organizations_url":"https://api.github.com/users/pbalaguer19/orgs","repos_url":"https://api.github.com/users/pbalaguer19/repos","events_url":"https://api.github.com/users/pbalaguer19/events{/privacy}","received_events_url":"https://api.github.com/users/pbalaguer19/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-18T07:16:25Z","updated_at":"2019-02-18T07:16:25Z","author_association":"NONE","body":"Thank you so much!\r\n","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464613589/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464691586","html_url":"https://github.com/apache/druid/issues/7086#issuecomment-464691586","issue_url":"https://api.github.com/repos/apache/druid/issues/7086","id":464691586,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDY5MTU4Ng==","user":{"login":"manjudr","id":16288575,"node_id":"MDQ6VXNlcjE2Mjg4NTc1","avatar_url":"https://avatars.githubusercontent.com/u/16288575?v=4","gravatar_id":"","url":"https://api.github.com/users/manjudr","html_url":"https://github.com/manjudr","followers_url":"https://api.github.com/users/manjudr/followers","following_url":"https://api.github.com/users/manjudr/following{/other_user}","gists_url":"https://api.github.com/users/manjudr/gists{/gist_id}","starred_url":"https://api.github.com/users/manjudr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/manjudr/subscriptions","organizations_url":"https://api.github.com/users/manjudr/orgs","repos_url":"https://api.github.com/users/manjudr/repos","events_url":"https://api.github.com/users/manjudr/events{/privacy}","received_events_url":"https://api.github.com/users/manjudr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-18T11:13:56Z","updated_at":"2019-02-18T11:13:56Z","author_association":"NONE","body":"**Things which i have tried out.**\r\n\r\n\r\n\r\n\r\n1.  When i tried by change **$.edata.visits[*].index** to **$.edata.visits[0].index** I was able index the data into druid without any error but what if i want to index all visits list values into druid? without referring any index of visits list?\r\n\r\n```js\r\n\"fields\": [\r\n            {\r\n              \"type\": \"path\",\r\n              \"name\": \"edata_visits_index\",\r\n              \"expr\": \"$.edata.visits[0].index\"\r\n            }\r\n          ]\r\n\r\n```\r\n\r\n2. When I changed the data type from `long` to `string` then i was able to index all visits list value into druid as a string format.\r\nBut what if i want to index all visits values as long/integer data type format?\r\n```\r\n       \"dimensions\": [\r\n            {\r\n              \"type\": \"string\",\r\n              \"name\": \"edata_visits_index\"\r\n            }\r\n          ],\r\n```\r\n\r\nBut If i try to index all visits value as long data type format then it will throw `\" java.lang.UnsupportedOperationException: Numeric columns do not support multivalue rows.` error\r\n\r\n**Any work around to index all visits value as long/integer format ?**\r\n\r\n\r\n\r\n\r\n\r\n ","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464691586/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464796590","html_url":"https://github.com/apache/druid/issues/7080#issuecomment-464796590","issue_url":"https://api.github.com/repos/apache/druid/issues/7080","id":464796590,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDc5NjU5MA==","user":{"login":"dylwylie","id":3107079,"node_id":"MDQ6VXNlcjMxMDcwNzk=","avatar_url":"https://avatars.githubusercontent.com/u/3107079?v=4","gravatar_id":"","url":"https://api.github.com/users/dylwylie","html_url":"https://github.com/dylwylie","followers_url":"https://api.github.com/users/dylwylie/followers","following_url":"https://api.github.com/users/dylwylie/following{/other_user}","gists_url":"https://api.github.com/users/dylwylie/gists{/gist_id}","starred_url":"https://api.github.com/users/dylwylie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dylwylie/subscriptions","organizations_url":"https://api.github.com/users/dylwylie/orgs","repos_url":"https://api.github.com/users/dylwylie/repos","events_url":"https://api.github.com/users/dylwylie/events{/privacy}","received_events_url":"https://api.github.com/users/dylwylie/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-18T16:20:54Z","updated_at":"2019-02-18T16:20:54Z","author_association":"CONTRIBUTOR","body":"Can you share your Broker runtime.properties and jvm config please?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464796590/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464867792","html_url":"https://github.com/apache/druid/pull/6794#issuecomment-464867792","issue_url":"https://api.github.com/repos/apache/druid/issues/6794","id":464867792,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDg2Nzc5Mg==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-18T20:31:26Z","updated_at":"2019-02-18T20:31:26Z","author_association":"CONTRIBUTOR","body":"@sascha-coenen,\r\n\r\n> I meant to mention that there is an Israeli startup which is specialising in FPGA accelerations. With AWS F1 instance types being a thing now, FPGA might finally be getting some more traction. This startup has customised Druid's Query Engine to delegate the aggregation to FPGA hardware and they claim a 35x speedup for mostly-in-memory use-cases.\r\n>\r\n> They might be an interesting technology partner in validating the design of a vectorisation layer and providing an FPGA based extension for it. I'm not affiliated with them in any way, so this is not me advertising or pitching them. I just found it interesting what they are doing and was curious as to whether you guys have heard of them and whether this sort of stuff would be a fit for what you are trying to achieve with this PR.\r\n\r\nIt sounds cool, I haven't heard of them. I searched around for a bit and didn't see anything do you have a link? My feeling is that it is useful to optimize performance on CPU (what this patch does) regardless of the existence of specialized hardware. Specialized hardware is still quite interesting though in its own right. And if optimizations geared towards improving performance on CPUs help on other types of hardware too, all the better.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464867792/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464882134","html_url":"https://github.com/apache/druid/issues/7075#issuecomment-464882134","issue_url":"https://api.github.com/repos/apache/druid/issues/7075","id":464882134,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDg4MjEzNA==","user":{"login":"leventov","id":609240,"node_id":"MDQ6VXNlcjYwOTI0MA==","avatar_url":"https://avatars.githubusercontent.com/u/609240?v=4","gravatar_id":"","url":"https://api.github.com/users/leventov","html_url":"https://github.com/leventov","followers_url":"https://api.github.com/users/leventov/followers","following_url":"https://api.github.com/users/leventov/following{/other_user}","gists_url":"https://api.github.com/users/leventov/gists{/gist_id}","starred_url":"https://api.github.com/users/leventov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leventov/subscriptions","organizations_url":"https://api.github.com/users/leventov/orgs","repos_url":"https://api.github.com/users/leventov/repos","events_url":"https://api.github.com/users/leventov/events{/privacy}","received_events_url":"https://api.github.com/users/leventov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-18T21:16:49Z","updated_at":"2019-02-18T21:16:49Z","author_association":"MEMBER","body":"@justinborromeo interesting. Does KafkaProducer support custom event dropping policies? It seems to me that we should treat it as we treat `NonBlockingStatsDClient`.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464882134/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464933495","html_url":"https://github.com/apache/druid/pull/7088#issuecomment-464933495","issue_url":"https://api.github.com/repos/apache/druid/issues/7088","id":464933495,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDkzMzQ5NQ==","user":{"login":"samarthjain","id":1642180,"node_id":"MDQ6VXNlcjE2NDIxODA=","avatar_url":"https://avatars.githubusercontent.com/u/1642180?v=4","gravatar_id":"","url":"https://api.github.com/users/samarthjain","html_url":"https://github.com/samarthjain","followers_url":"https://api.github.com/users/samarthjain/followers","following_url":"https://api.github.com/users/samarthjain/following{/other_user}","gists_url":"https://api.github.com/users/samarthjain/gists{/gist_id}","starred_url":"https://api.github.com/users/samarthjain/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/samarthjain/subscriptions","organizations_url":"https://api.github.com/users/samarthjain/orgs","repos_url":"https://api.github.com/users/samarthjain/repos","events_url":"https://api.github.com/users/samarthjain/events{/privacy}","received_events_url":"https://api.github.com/users/samarthjain/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T00:39:49Z","updated_at":"2019-02-19T00:39:49Z","author_association":"CONTRIBUTOR","body":"Overview of the main changes:\r\n\r\n1) I have added a new class CuratorBasedLoadQueuePeonV2. The class borrows from CuratorBasedLoadQueuePeon. The biggest different between the two classes is that I have removed the notion of tracking the segment being currently processed. Also, we now use a fixed sized threadpool for creating nodes in zookeeper. The default size of the pool is twenty threads which can be changed by the setting the ```druid.coordinator.curator.create.zknode.numThreads``` in coordinator config. I have also introduced a random delay in these threads so that there is some jitter in zookeeper create node requests.\r\n\r\nFor now, I have left the CuratorBasedLoadQueuePeon class as it is. We can either get rid of it or we can introduce an additional config which controls which version of Curator based peon to use. Right now I have hardcoded to use CuratorBasedLoadQueuePeonV2 in LoadQueueTaskMaster.\r\n\r\n2) In ZkCoordinator we now use a multi threaded pool to process segment change requests. The size of this thread pool can be configured via ```druid.segmentCache.numLoadingThreads```. Yes, this change brings back the earlier non effective config.\r\n","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464933495/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464942888","html_url":"https://github.com/apache/druid/pull/6365#issuecomment-464942888","issue_url":"https://api.github.com/repos/apache/druid/issues/6365","id":464942888,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDk0Mjg4OA==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T01:31:58Z","updated_at":"2019-02-19T01:31:58Z","author_association":"CONTRIBUTOR","body":"I restarted the TeamCity build; the errors it noticed were in unchanged files. If it trips again, @zhaojiandong, you might need to merge from master to get it to pass.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464942888/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464943684","html_url":"https://github.com/apache/druid/issues/6834#issuecomment-464943684","issue_url":"https://api.github.com/repos/apache/druid/issues/6834","id":464943684,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDk0MzY4NA==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T01:35:58Z","updated_at":"2019-02-19T01:35:58Z","author_association":"CONTRIBUTOR","body":"It looks like phase 1 was implemented by #6901, and phase 2 remains unimplemented.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464943684/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464943923","html_url":"https://github.com/apache/druid/issues/6832#issuecomment-464943923","issue_url":"https://api.github.com/repos/apache/druid/issues/6832","id":464943923,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDk0MzkyMw==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T01:37:21Z","updated_at":"2019-02-19T01:37:21Z","author_association":"CONTRIBUTOR","body":"Implemented by #6923.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464943923/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464943979","html_url":"https://github.com/apache/druid/issues/6838#issuecomment-464943979","issue_url":"https://api.github.com/repos/apache/druid/issues/6838","id":464943979,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDk0Mzk3OQ==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T01:37:37Z","updated_at":"2019-02-19T01:37:37Z","author_association":"CONTRIBUTOR","body":"Implemented by #6916.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464943979/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464983747","html_url":"https://github.com/apache/druid/issues/2313#issuecomment-464983747","issue_url":"https://api.github.com/repos/apache/druid/issues/2313","id":464983747,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDk4Mzc0Nw==","user":{"login":"wzy1213","id":44253572,"node_id":"MDQ6VXNlcjQ0MjUzNTcy","avatar_url":"https://avatars.githubusercontent.com/u/44253572?v=4","gravatar_id":"","url":"https://api.github.com/users/wzy1213","html_url":"https://github.com/wzy1213","followers_url":"https://api.github.com/users/wzy1213/followers","following_url":"https://api.github.com/users/wzy1213/following{/other_user}","gists_url":"https://api.github.com/users/wzy1213/gists{/gist_id}","starred_url":"https://api.github.com/users/wzy1213/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wzy1213/subscriptions","organizations_url":"https://api.github.com/users/wzy1213/orgs","repos_url":"https://api.github.com/users/wzy1213/repos","events_url":"https://api.github.com/users/wzy1213/events{/privacy}","received_events_url":"https://api.github.com/users/wzy1213/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T05:01:43Z","updated_at":"2019-02-19T05:01:43Z","author_association":"NONE","body":"hi, are you fix this problem?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464983747/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/464988450","html_url":"https://github.com/apache/druid/issues/6854#issuecomment-464988450","issue_url":"https://api.github.com/repos/apache/druid/issues/6854","id":464988450,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NDk4ODQ1MA==","user":{"login":"pdeva","id":3190176,"node_id":"MDQ6VXNlcjMxOTAxNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3190176?v=4","gravatar_id":"","url":"https://api.github.com/users/pdeva","html_url":"https://github.com/pdeva","followers_url":"https://api.github.com/users/pdeva/followers","following_url":"https://api.github.com/users/pdeva/following{/other_user}","gists_url":"https://api.github.com/users/pdeva/gists{/gist_id}","starred_url":"https://api.github.com/users/pdeva/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pdeva/subscriptions","organizations_url":"https://api.github.com/users/pdeva/orgs","repos_url":"https://api.github.com/users/pdeva/repos","events_url":"https://api.github.com/users/pdeva/events{/privacy}","received_events_url":"https://api.github.com/users/pdeva/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T05:26:07Z","updated_at":"2019-02-19T05:26:07Z","author_association":"CONTRIBUTOR","body":"if KIS is being marked as stable (ref #6970) , this bug might be worth either fixing or atleast documenting.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/464988450/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465045135","html_url":"https://github.com/apache/druid/pull/7089#issuecomment-465045135","issue_url":"https://api.github.com/repos/apache/druid/issues/7089","id":465045135,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTA0NTEzNQ==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T08:57:36Z","updated_at":"2019-02-19T08:57:36Z","author_association":"CONTRIBUTOR","body":"Note that this PR is integration-tested by ITIndexerTest.\r\n\r\nPlease note two FIXME comments in the PR.\r\n\r\nMy intention is to squash the two commits of the PR together (and keep the PR description as the commit message). I thought reviewers might like to see my initial attempt which injected a SegmentLoaderFactory instead of directly creating a SegmentLoaderLocalCacheManager. That commit led to this error in ITIndexerTest:\r\n\r\n```\r\nCan not construct instance of org.apache.druid.indexing.firehose.IngestSegmentFirehoseFactory, problem: Unable to provision, see the following errors:\r\n\r\n1) druid.segmentCache.locations - may not be empty\r\n  at org.apache.druid.guice.JsonConfigProvider.bind(JsonConfigProvider.java:151) (via modules: com.google.inject.util.Modules$OverrideModule -> com.google.inject.util.Modules$OverrideModule -> org.apache.druid.guice.StorageNodeModule)\r\n  at org.apache.druid.guice.JsonConfigProvider.bind(JsonConfigProvider.java:151) (via modules: com.google.inject.util.Modules$OverrideModule -> com.google.inject.util.Modules$OverrideModule -> org.apache.druid.guice.StorageNodeModule)\r\n  while locating com.google.common.base.Supplier<org.apache.druid.segment.loading.SegmentLoaderConfig>\r\n  at org.apache.druid.guice.ConfigProvider.bind(JsonConfigProvider.java:152) (via modules: com.google.inject.util.Modules$OverrideModule -> com.google.inject.util.Modules$OverrideModule -> org.apache.druid.guice.StorageNodeModule)\r\n  while locating org.apache.druid.segment.loading.SegmentLoaderConfig\r\n    for the 2nd parameter of org.apache.druid.segment.loading.SegmentLoaderLocalCacheManager.<init>(SegmentLoaderLocalCacheManager.java:67)\r\n  while locating org.apache.druid.segment.loading.SegmentLoaderLocalCacheManager\r\n    for the 1st parameter of org.apache.druid.indexing.common.SegmentLoaderFactory.<init>(SegmentLoaderFactory.java:41)\r\n  while locating org.apache.druid.indexing.common.SegmentLoaderFactory\r\n\r\n1 error\r\n at [Source: HttpInputOverHTTP@3eff14c3[c=1623,q=0,[0]=null,s=STREAM]; line: 47, column: 13] (through reference chain: org.apache.druid.indexing.common.task.IndexTask[\"spec\"]->org.apache.druid.indexing.common.task.IndexIngestionSpec[\"ioConfig\"]->org.apache.druid.indexing.common.task.IndexIOConfig[\"firehose\"])\r\n```","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465045135/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465045317","html_url":"https://github.com/apache/druid/pull/7063#issuecomment-465045317","issue_url":"https://api.github.com/repos/apache/druid/issues/7063","id":465045317,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTA0NTMxNw==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T08:58:10Z","updated_at":"2019-02-19T08:58:10Z","author_association":"CONTRIBUTOR","body":"I think #7089 is a better approach to solving this problem.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465045317/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465048979","html_url":"https://github.com/apache/druid/issues/7080#issuecomment-465048979","issue_url":"https://api.github.com/repos/apache/druid/issues/7080","id":465048979,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTA0ODk3OQ==","user":{"login":"prashant-shahi","id":11138844,"node_id":"MDQ6VXNlcjExMTM4ODQ0","avatar_url":"https://avatars.githubusercontent.com/u/11138844?v=4","gravatar_id":"","url":"https://api.github.com/users/prashant-shahi","html_url":"https://github.com/prashant-shahi","followers_url":"https://api.github.com/users/prashant-shahi/followers","following_url":"https://api.github.com/users/prashant-shahi/following{/other_user}","gists_url":"https://api.github.com/users/prashant-shahi/gists{/gist_id}","starred_url":"https://api.github.com/users/prashant-shahi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashant-shahi/subscriptions","organizations_url":"https://api.github.com/users/prashant-shahi/orgs","repos_url":"https://api.github.com/users/prashant-shahi/repos","events_url":"https://api.github.com/users/prashant-shahi/events{/privacy}","received_events_url":"https://api.github.com/users/prashant-shahi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T09:09:34Z","updated_at":"2019-02-19T09:09:34Z","author_association":"NONE","body":"\r\n\r\nSystem configuration is 8 vCPUs and 30GB memory.\r\n\r\n**jvm.config**\r\n```\r\n-server\r\n-Xms24g\r\n-Xmx24g\r\n-XX:MaxDirectMemorySize=28g\r\n-Duser.timezone=UTC\r\n-Dfile.encoding=UTF-8\r\n-Djava.io.tmpdir=/var/tmp\r\n-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager\r\n```","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465048979/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465060126","html_url":"https://github.com/apache/druid/pull/7089#issuecomment-465060126","issue_url":"https://api.github.com/repos/apache/druid/issues/7089","id":465060126,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTA2MDEyNg==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T09:42:37Z","updated_at":"2019-02-19T09:42:37Z","author_association":"CONTRIBUTOR","body":"OK, I had a better idea â€” it seemed like not too hard to improve SegmentLoaderFactory to be injectible without needing to inject SegmentLoaderConfig.  Hopefully this works; I stayed up too late and don't want to wait for tests to run :)","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465060126/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465068788","html_url":"https://github.com/apache/druid/issues/7075#issuecomment-465068788","issue_url":"https://api.github.com/repos/apache/druid/issues/7075","id":465068788,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTA2ODc4OA==","user":{"login":"justinborromeo","id":9417701,"node_id":"MDQ6VXNlcjk0MTc3MDE=","avatar_url":"https://avatars.githubusercontent.com/u/9417701?v=4","gravatar_id":"","url":"https://api.github.com/users/justinborromeo","html_url":"https://github.com/justinborromeo","followers_url":"https://api.github.com/users/justinborromeo/followers","following_url":"https://api.github.com/users/justinborromeo/following{/other_user}","gists_url":"https://api.github.com/users/justinborromeo/gists{/gist_id}","starred_url":"https://api.github.com/users/justinborromeo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/justinborromeo/subscriptions","organizations_url":"https://api.github.com/users/justinborromeo/orgs","repos_url":"https://api.github.com/users/justinborromeo/repos","events_url":"https://api.github.com/users/justinborromeo/events{/privacy}","received_events_url":"https://api.github.com/users/justinborromeo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T10:07:10Z","updated_at":"2019-02-19T10:07:10Z","author_association":"CONTRIBUTOR","body":"I don't think it does.  I think it just fails the message that's being added to the full queue.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465068788/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465131938","html_url":"https://github.com/apache/druid/issues/6043#issuecomment-465131938","issue_url":"https://api.github.com/repos/apache/druid/issues/6043","id":465131938,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTEzMTkzOA==","user":{"login":"achelimed","id":3107387,"node_id":"MDQ6VXNlcjMxMDczODc=","avatar_url":"https://avatars.githubusercontent.com/u/3107387?v=4","gravatar_id":"","url":"https://api.github.com/users/achelimed","html_url":"https://github.com/achelimed","followers_url":"https://api.github.com/users/achelimed/followers","following_url":"https://api.github.com/users/achelimed/following{/other_user}","gists_url":"https://api.github.com/users/achelimed/gists{/gist_id}","starred_url":"https://api.github.com/users/achelimed/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/achelimed/subscriptions","organizations_url":"https://api.github.com/users/achelimed/orgs","repos_url":"https://api.github.com/users/achelimed/repos","events_url":"https://api.github.com/users/achelimed/events{/privacy}","received_events_url":"https://api.github.com/users/achelimed/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T13:41:47Z","updated_at":"2019-02-19T13:45:42Z","author_association":"NONE","body":"Hello,\r\n\r\nI have the same problem with Hive 2.3.x from AWS EMR 5.13\r\n\r\nHave you an idea please?\r\n\r\nThe stacktrace is below:\r\n\r\n````\r\nhive> show tables;\r\nOK\r\nemr_druid_wikipedia\r\nTime taken: 0.523 seconds, Fetched: 1 row(s)\r\n\r\n\r\nhive>explain SELECT SUM(1) AS `sum_number_of_records_ok` FROM `default`.`emr_druid_wikipedia` `emr_druid_wikipedia` GROUP BY 1.1000000000000001;\r\nWarning: Using constant number  1.1000000000000001 in group by. If you try to use position alias when hive.groupby.position.alias is false, the position alias will be ignored.\r\nOK\r\nPlan optimized by CBO.\r\n\r\nVertex dependency in root stage\r\nReducer 2 <- Map 1 (SIMPLE_EDGE)\r\n\r\nStage-0\r\n  Fetch Operator\r\n    limit:-1\r\n    Stage-1\r\n      Reducer 2 llap\r\n      File Output Operator [FS_7]\r\n        Select Operator [SEL_6] (rows=1 width=8)\r\n          Output:[\"_col0\"]\r\n          Group By Operator [GBY_5] (rows=1 width=8)\r\n            Output:[\"_col0\",\"_col1\"],aggregations:[\"sum(VALUE._col0)\"],keys:KEY._col0\r\n          <-Map 1 [SIMPLE_EDGE] llap\r\n            SHUFFLE [RS_4]\r\n              PartitionCols:_col0\r\n              Group By Operator [GBY_3] (rows=1 width=8)\r\n                Output:[\"_col0\",\"_col1\"],aggregations:[\"sum(1)\"],keys:1.1000000000000001\r\n                Select Operator [SEL_1] (rows=1 width=0)\r\n                  TableScan [TS_0] (rows=1 width=0)\r\n                    default@emr_druid_wikipedia,emr_druid_wikipedia,Tbl:PARTIAL,Col:COMPLETE,properties:{\"druid.query.json\":\"{\\\"queryType\\\":\\\"select\\\",\\\"dataSource\\\":\\\"wikipedia\\\",\\\"descending\\\":false,\\\"intervals\\\":[\\\"1900-01-01T00:00:00.000Z/3000-01-01T00:00:00.000Z\\\"],\\\"dimensions\\\":[],\\\"metrics\\\":[],\\\"granularity\\\":\\\"all\\\",\\\"pagingSpec\\\":{\\\"threshold\\\":16384},\\\"context\\\":{\\\"druid.query.fetch\\\":false}}\",\"druid.query.type\":\"select\"}\r\n\r\nTime taken: 2.407 seconds, Fetched: 24 row(s)\r\n\r\n\r\n\r\nhive>SELECT SUM(1) AS `sum_number_of_records_ok` FROM `default`.`emr_druid_wikipedia` `emr_druid_wikipedia` GROUP BY 1.1000000000000001;\r\nWarning: Using constant number  1.1000000000000001 in group by. If you try to use position alias when hive.groupby.position.alias is false, the position alias will be ignored.\r\nQuery ID = hadoop_20190219125215_26b24f62-6260-48a4-ba2b-a514d95a62b4\r\nTotal jobs = 1\r\nLaunching Job 1 out of 1\r\nStatus: Running (Executing on YARN cluster with App id application_1550571294354_0005)\r\n\r\n----------------------------------------------------------------------------------------------\r\n        VERTICES      MODE        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED\r\n----------------------------------------------------------------------------------------------\r\nMap 1                 llap       RUNNING      1          0        0        1       4       0\r\nReducer 2             llap        INITED      1          0        0        1       0       0\r\n----------------------------------------------------------------------------------------------\r\nVERTICES: 00/02  [>>--------------------------] 0%    ELAPSED TIME: 2,44 s\r\n----------------------------------------------------------------------------------------------\r\nStatus: Failed\r\nVertex failed, vertexName=Map 1, vertexId=vertex_1550571294354_0005_1_00, diagnostics=[Task failed, taskId=task_1550571294354_0005_1_00_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Error while running task ( failure ) : attempt_1550571294354_0005_1_00_000000_0:java.lang.RuntimeException: java.lang.RuntimeException: java.io.IOException: java.io.IOException: java.io.IOException: org.apache.hive.druid.org.jboss.netty.channel.ChannelException: Faulty channel in resource pool\r\n\tat org.apache.hadoop.hive.druid.DruidStorageHandlerUtils.submitRequest(DruidStorageHandlerUtils.java:196)\r\n\tat org.apache.hadoop.hive.druid.serde.DruidQueryRecordReader.initialize(DruidQueryRecordReader.java:100)\r\n\tat org.apache.hadoop.hive.druid.io.DruidQueryBasedInputFormat.getRecordReader(DruidQueryBasedInputFormat.java:484)\r\n\tat org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:376)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:203)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.<init>(TezGroupedSplitsInputFormat.java:145)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat.getRecordReader(TezGroupedSplitsInputFormat.java:111)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setupOldRecordReader(MRReaderMapred.java:157)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setSplit(MRReaderMapred.java:83)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEventInternal(MRInput.java:694)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEvent(MRInput.java:653)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.checkAndAwaitRecordReaderInitialization(MRInputLegacy.java:145)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.init(MRInputLegacy.java:109)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.getMRInput(MapRecordProcessor.java:525)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:171)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\r\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\r\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\r\n\tat org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.hive.druid.org.jboss.netty.channel.ChannelException: Faulty channel in resource pool\r\n\tat org.apache.hive.druid.com.metamx.http.client.NettyHttpClient.go(NettyHttpClient.java:137)\r\n\tat org.apache.hive.druid.com.metamx.http.client.AbstractHttpClient.go(AbstractHttpClient.java:14)\r\n\tat org.apache.hadoop.hive.druid.DruidStorageHandlerUtils.submitRequest(DruidStorageHandlerUtils.java:194)\r\n\t... 30 more\r\nCaused by: java.nio.channels.UnresolvedAddressException\r\n\tat sun.nio.ch.Net.checkAddress(Net.java:101)\r\n\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.connect(NioClientSocketPipelineSink.java:108)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:70)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:779)\r\n\tat org.apache.hive.druid.org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:54)\r\n\tat org.apache.hive.druid.org.jboss.netty.handler.codec.http.HttpClientCodec.handleDownstream(HttpClientCodec.java:97)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.Channels.connect(Channels.java:634)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.AbstractChannel.connect(AbstractChannel.java:216)\r\n\tat org.apache.hive.druid.org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:229)\r\n\tat org.apache.hive.druid.org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ChannelResourceFactory.generate(ChannelResourceFactory.java:84)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ChannelResourceFactory.generate(ChannelResourceFactory.java:41)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ResourcePool$ImmediateCreationResourceHolder.get(ResourcePool.java:188)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ResourcePool.take(ResourcePool.java:76)\r\n\tat org.apache.hive.druid.com.metamx.http.client.NettyHttpClient.go(NettyHttpClient.java:133)\r\n\t... 32 more\r\n\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:211)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\r\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\r\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\r\n\tat org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.RuntimeException: java.io.IOException: java.io.IOException: java.io.IOException: org.apache.hive.druid.org.jboss.netty.channel.ChannelException: Faulty channel in resource pool\r\n\tat org.apache.hadoop.hive.druid.DruidStorageHandlerUtils.submitRequest(DruidStorageHandlerUtils.java:196)\r\n\tat org.apache.hadoop.hive.druid.serde.DruidQueryRecordReader.initialize(DruidQueryRecordReader.java:100)\r\n\tat org.apache.hadoop.hive.druid.io.DruidQueryBasedInputFormat.getRecordReader(DruidQueryBasedInputFormat.java:484)\r\n\tat org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:376)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:203)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.<init>(TezGroupedSplitsInputFormat.java:145)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat.getRecordReader(TezGroupedSplitsInputFormat.java:111)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setupOldRecordReader(MRReaderMapred.java:157)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setSplit(MRReaderMapred.java:83)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEventInternal(MRInput.java:694)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEvent(MRInput.java:653)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.checkAndAwaitRecordReaderInitialization(MRInputLegacy.java:145)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.init(MRInputLegacy.java:109)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.getMRInput(MapRecordProcessor.java:525)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:171)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\r\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\r\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\r\n\tat org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.hive.druid.org.jboss.netty.channel.ChannelException: Faulty channel in resource pool\r\n\tat org.apache.hive.druid.com.metamx.http.client.NettyHttpClient.go(NettyHttpClient.java:137)\r\n\tat org.apache.hive.druid.com.metamx.http.client.AbstractHttpClient.go(AbstractHttpClient.java:14)\r\n\tat org.apache.hadoop.hive.druid.DruidStorageHandlerUtils.submitRequest(DruidStorageHandlerUtils.java:194)\r\n\t... 30 more\r\nCaused by: java.nio.channels.UnresolvedAddressException\r\n\tat sun.nio.ch.Net.checkAddress(Net.java:101)\r\n\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.connect(NioClientSocketPipelineSink.java:108)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:70)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:779)\r\n\tat org.apache.hive.druid.org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:54)\r\n\tat org.apache.hive.druid.org.jboss.netty.handler.codec.http.HttpClientCodec.handleDownstream(HttpClientCodec.java:97)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.Channels.connect(Channels.java:634)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.AbstractChannel.connect(AbstractChannel.java:216)\r\n\tat org.apache.hive.druid.org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:229)\r\n\tat org.apache.hive.druid.org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ChannelResourceFactory.generate(ChannelResourceFactory.java:84)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ChannelResourceFactory.generate(ChannelResourceFactory.java:41)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ResourcePool$ImmediateCreationResourceHolder.get(ResourcePool.java:188)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ResourcePool.take(ResourcePool.java:76)\r\n\tat org.apache.hive.druid.com.metamx.http.client.NettyHttpClient.go(NettyHttpClient.java:133)\r\n\t... 32 more\r\n\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:206)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.<init>(TezGroupedSplitsInputFormat.java:145)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat.getRecordReader(TezGroupedSplitsInputFormat.java:111)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setupOldRecordReader(MRReaderMapred.java:157)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setSplit(MRReaderMapred.java:83)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEventInternal(MRInput.java:694)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEvent(MRInput.java:653)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.checkAndAwaitRecordReaderInitialization(MRInputLegacy.java:145)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.init(MRInputLegacy.java:109)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.getMRInput(MapRecordProcessor.java:525)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:171)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\r\n\t... 15 more\r\nCaused by: java.io.IOException: java.io.IOException: java.io.IOException: org.apache.hive.druid.org.jboss.netty.channel.ChannelException: Faulty channel in resource pool\r\n\tat org.apache.hadoop.hive.druid.DruidStorageHandlerUtils.submitRequest(DruidStorageHandlerUtils.java:196)\r\n\tat org.apache.hadoop.hive.druid.serde.DruidQueryRecordReader.initialize(DruidQueryRecordReader.java:100)\r\n\tat org.apache.hadoop.hive.druid.io.DruidQueryBasedInputFormat.getRecordReader(DruidQueryBasedInputFormat.java:484)\r\n\tat org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:376)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:203)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.<init>(TezGroupedSplitsInputFormat.java:145)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat.getRecordReader(TezGroupedSplitsInputFormat.java:111)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setupOldRecordReader(MRReaderMapred.java:157)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setSplit(MRReaderMapred.java:83)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEventInternal(MRInput.java:694)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEvent(MRInput.java:653)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.checkAndAwaitRecordReaderInitialization(MRInputLegacy.java:145)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.init(MRInputLegacy.java:109)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.getMRInput(MapRecordProcessor.java:525)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:171)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\r\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\r\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\r\n\tat org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.hive.druid.org.jboss.netty.channel.ChannelException: Faulty channel in resource pool\r\n\tat org.apache.hive.druid.com.metamx.http.client.NettyHttpClient.go(NettyHttpClient.java:137)\r\n\tat org.apache.hive.druid.com.metamx.http.client.AbstractHttpClient.go(AbstractHttpClient.java:14)\r\n\tat org.apache.hadoop.hive.druid.DruidStorageHandlerUtils.submitRequest(DruidStorageHandlerUtils.java:194)\r\n\t... 30 more\r\nCaused by: java.nio.channels.UnresolvedAddressException\r\n\tat sun.nio.ch.Net.checkAddress(Net.java:101)\r\n\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.connect(NioClientSocketPipelineSink.java:108)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:70)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:779)\r\n\tat org.apache.hive.druid.org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:54)\r\n\tat org.apache.hive.druid.org.jboss.netty.handler.codec.http.HttpClientCodec.handleDownstream(HttpClientCodec.java:97)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.Channels.connect(Channels.java:634)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.AbstractChannel.connect(AbstractChannel.java:216)\r\n\tat org.apache.hive.druid.org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:229)\r\n\tat org.apache.hive.druid.org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ChannelResourceFactory.generate(ChannelResourceFactory.java:84)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ChannelResourceFactory.generate(ChannelResourceFactory.java:41)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ResourcePool$ImmediateCreationResourceHolder.get(ResourcePool.java:188)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ResourcePool.take(ResourcePool.java:76)\r\n\tat org.apache.hive.druid.com.metamx.http.client.NettyHttpClient.go(NettyHttpClient.java:133)\r\n\t... 32 more\r\n\r\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)\r\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)\r\n\tat org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:379)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:203)\r\n\t... 26 more\r\nCaused by: java.io.IOException: java.io.IOException: org.apache.hive.druid.org.jboss.netty.channel.ChannelException: Faulty channel in resource pool\r\n\tat org.apache.hadoop.hive.druid.DruidStorageHandlerUtils.submitRequest(DruidStorageHandlerUtils.java:196)\r\n\tat org.apache.hadoop.hive.druid.serde.DruidQueryRecordReader.initialize(DruidQueryRecordReader.java:100)\r\n\tat org.apache.hadoop.hive.druid.io.DruidQueryBasedInputFormat.getRecordReader(DruidQueryBasedInputFormat.java:484)\r\n\tat org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:376)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:203)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.<init>(TezGroupedSplitsInputFormat.java:145)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat.getRecordReader(TezGroupedSplitsInputFormat.java:111)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setupOldRecordReader(MRReaderMapred.java:157)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setSplit(MRReaderMapred.java:83)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEventInternal(MRInput.java:694)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEvent(MRInput.java:653)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.checkAndAwaitRecordReaderInitialization(MRInputLegacy.java:145)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.init(MRInputLegacy.java:109)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.getMRInput(MapRecordProcessor.java:525)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:171)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\r\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\r\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\r\n\tat org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.hive.druid.org.jboss.netty.channel.ChannelException: Faulty channel in resource pool\r\n\tat org.apache.hive.druid.com.metamx.http.client.NettyHttpClient.go(NettyHttpClient.java:137)\r\n\tat org.apache.hive.druid.com.metamx.http.client.AbstractHttpClient.go(AbstractHttpClient.java:14)\r\n\tat org.apache.hadoop.hive.druid.DruidStorageHandlerUtils.submitRequest(DruidStorageHandlerUtils.java:194)\r\n\t... 30 more\r\nCaused by: java.nio.channels.UnresolvedAddressException\r\n\tat sun.nio.ch.Net.checkAddress(Net.java:101)\r\n\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.connect(NioClientSocketPipelineSink.java:108)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:70)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:779)\r\n\tat org.apache.hive.druid.org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:54)\r\n\tat org.apache.hive.druid.org.jboss.netty.handler.codec.http.HttpClientCodec.handleDownstream(HttpClientCodec.java:97)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.Channels.connect(Channels.java:634)\r\n\tat org.apache.hive.druid.org.jboss.netty.channel.AbstractChannel.connect(AbstractChannel.java:216)\r\n\tat org.apache.hive.druid.org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:229)\r\n\tat org.apache.hive.druid.org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ChannelResourceFactory.generate(ChannelResourceFactory.java:84)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ChannelResourceFactory.generate(ChannelResourceFactory.java:41)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ResourcePool$ImmediateCreationResourceHolder.get(ResourcePool.java:188)\r\n\tat org.apache.hive.druid.com.metamx.http.client.pool.ResourcePool.take(ResourcePool.java:76)\r\n\tat org.apache.hive.druid.com.metamx.http.client.NettyHttpClient.go(NettyHttpClient.java:133)\r\n\t... 32 more\r\n\r\n\tat org.apache.hadoop.hive.druid.serde.DruidQueryRecordReader.initialize(DruidQueryRecordReader.java:104)\r\n\tat org.apache.hadoop.hive.druid.io.DruidQueryBasedInputFormat.getRecordReader(DruidQueryBasedInputFormat.java:484)\r\n\tat org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:376)\r\n\t... 27 more\r\n], TaskAttempt 1 failed, info=[Error: Error while running task ( failure ) : attempt_1550571294354_0005_1_00_000000_1:java.lang.RuntimeException: java.lang.RuntimeException: java.io.IOException: java.io.IOException: java.io.IOException: org.apache.hive.druid.org.jboss.netty.channel.ChannelException: Faulty channel in resource pool\r\n\tat org.apache.hadoop.hive.druid.DruidStorageHandlerUtils.submitRequest(DruidStorageHandlerUtils.java:196)\r\n\tat org.apache.hadoop.hive.druid.serde.DruidQueryRecordReader.initialize(DruidQueryRecordReader.java:100)\r\n\tat org.apache.hadoop.hive.druid.io.DruidQueryBasedInputFormat.getRecordReader(DruidQueryBasedInputFormat.java:484)\r\n\tat org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:376)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:203)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.<init>(TezGroupedSplitsInputFormat.java:145)\r\n\tat org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat.getRecordReader(TezGroupedSplitsInputFormat.java:111)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setupOldRecordReader(MRReaderMapred.java:157)\r\n\tat org.apache.tez.mapreduce.lib.MRReaderMapred.setSplit(MRReaderMapred.java:83)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEventInternal(MRInput.java:694)\r\n\tat org.apache.tez.mapreduce.input.MRInput.initFromEvent(MRInput.java:653)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.checkAndAwaitRecordReaderInitialization(MRInputLegacy.java:145)\r\n\tat org.apache.tez.mapreduce.input.MRInputLegacy.init(MRInputLegacy.java:109)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.getMRInput(MapRecordProcessor.java:525)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:171)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\r\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\r\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\r\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\r\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\r\n\tat org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.hive.druid.org.jboss.netty.channel.ChannelException: Faulty channel in resource pool\r\n\tat org.apache.hive.druid.com.metamx.http.client.NettyHttpClient.go(NettyHttpClient.java:137)\r\n\tat org.apache.hive.druid.com.metamx.http.client.AbstractHttpClient.go(AbstractHttpClient.java:14)\r\n\tat org.apache.hadoop.hive.druid.DruidStorageHandlerUtils.submitRequest(DruidStorageHandlerUtils.java:194)\r\n\t... 30 more\r\nCaused by: java.nio.channels.UnresolvedAddressException\r\n````\r\n","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465131938/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465166634","html_url":"https://github.com/apache/druid/pull/7089#issuecomment-465166634","issue_url":"https://api.github.com/repos/apache/druid/issues/7089","id":465166634,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTE2NjYzNA==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T15:06:19Z","updated_at":"2019-02-19T15:06:19Z","author_association":"CONTRIBUTOR","body":"Ok great, that worked... But I don't understand how to interpret the Team City report. Looks like tens of thousands of errors in files I didn't touch...","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465166634/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465201812","html_url":"https://github.com/apache/druid/pull/7089#issuecomment-465201812","issue_url":"https://api.github.com/repos/apache/druid/issues/7089","id":465201812,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTIwMTgxMg==","user":{"login":"glasser","id":16724,"node_id":"MDQ6VXNlcjE2NzI0","avatar_url":"https://avatars.githubusercontent.com/u/16724?v=4","gravatar_id":"","url":"https://api.github.com/users/glasser","html_url":"https://github.com/glasser","followers_url":"https://api.github.com/users/glasser/followers","following_url":"https://api.github.com/users/glasser/following{/other_user}","gists_url":"https://api.github.com/users/glasser/gists{/gist_id}","starred_url":"https://api.github.com/users/glasser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glasser/subscriptions","organizations_url":"https://api.github.com/users/glasser/orgs","repos_url":"https://api.github.com/users/glasser/repos","events_url":"https://api.github.com/users/glasser/events{/privacy}","received_events_url":"https://api.github.com/users/glasser/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T16:21:15Z","updated_at":"2019-02-19T16:21:15Z","author_association":"CONTRIBUTOR","body":"OK, looks like it somehow split my 4-commit PR into two changes (because I pushed twice?) The [first](https://teamcity.jetbrains.com/viewLog.html?buildId=1988242&tab=buildResultsDiv&buildTypeId=OpenSourceProjects_Druid_InspectionsPullRequests&logTab=) adds 1 error and removes 2813. The [second](https://teamcity.jetbrains.com/viewLog.html?buildId=1988393&buildTypeId=OpenSourceProjects_Druid_InspectionsPullRequests) adds 2812 errors and removes 1.  That... seems like net negative?  (That one new added error is definitely a problem in an earlier part of my PR that is fixed on HEAD.)\r\n\r\nDid it get confused because I rebased?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465201812/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465240958","html_url":"https://github.com/apache/druid/issues/7080#issuecomment-465240958","issue_url":"https://api.github.com/repos/apache/druid/issues/7080","id":465240958,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI0MDk1OA==","user":{"login":"dylwylie","id":3107079,"node_id":"MDQ6VXNlcjMxMDcwNzk=","avatar_url":"https://avatars.githubusercontent.com/u/3107079?v=4","gravatar_id":"","url":"https://api.github.com/users/dylwylie","html_url":"https://github.com/dylwylie","followers_url":"https://api.github.com/users/dylwylie/followers","following_url":"https://api.github.com/users/dylwylie/following{/other_user}","gists_url":"https://api.github.com/users/dylwylie/gists{/gist_id}","starred_url":"https://api.github.com/users/dylwylie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dylwylie/subscriptions","organizations_url":"https://api.github.com/users/dylwylie/orgs","repos_url":"https://api.github.com/users/dylwylie/repos","events_url":"https://api.github.com/users/dylwylie/events{/privacy}","received_events_url":"https://api.github.com/users/dylwylie/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T17:56:58Z","updated_at":"2019-02-19T17:56:58Z","author_association":"CONTRIBUTOR","body":"The above gives the JVM 24GB of heap but also allows the process to acquire up to 28gb of memory for offheap structures like direct bytebuffers, exceeding the system;s total memory. You may want to look at the example configuration  https://github.com/apache/incubator-druid/blob/master/examples/conf/druid/broker/runtime.properties","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465240958/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465247271","html_url":"https://github.com/apache/druid/issues/3878#issuecomment-465247271","issue_url":"https://api.github.com/repos/apache/druid/issues/3878","id":465247271,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI0NzI3MQ==","user":{"login":"egor-ryashin","id":14215045,"node_id":"MDQ6VXNlcjE0MjE1MDQ1","avatar_url":"https://avatars.githubusercontent.com/u/14215045?v=4","gravatar_id":"","url":"https://api.github.com/users/egor-ryashin","html_url":"https://github.com/egor-ryashin","followers_url":"https://api.github.com/users/egor-ryashin/followers","following_url":"https://api.github.com/users/egor-ryashin/following{/other_user}","gists_url":"https://api.github.com/users/egor-ryashin/gists{/gist_id}","starred_url":"https://api.github.com/users/egor-ryashin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/egor-ryashin/subscriptions","organizations_url":"https://api.github.com/users/egor-ryashin/orgs","repos_url":"https://api.github.com/users/egor-ryashin/repos","events_url":"https://api.github.com/users/egor-ryashin/events{/privacy}","received_events_url":"https://api.github.com/users/egor-ryashin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T18:13:40Z","updated_at":"2019-02-19T18:13:40Z","author_association":"CONTRIBUTOR","body":"> a bitset of matching dimension value indexes ([like here](https://github.com/druid-io/druid/blob/master/processing/src/main/java/io/druid/query/filter/StringValueMatcherColumnSelectorStrategy.java#L109-L115))\r\n\r\nThe link is broken, unfortunately.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465247271/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465259170","html_url":"https://github.com/apache/druid/issues/7087#issuecomment-465259170","issue_url":"https://api.github.com/repos/apache/druid/issues/7087","id":465259170,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI1OTE3MA==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T18:44:20Z","updated_at":"2019-02-19T18:44:20Z","author_association":"CONTRIBUTOR","body":"@leventov I'm not sure what problem you're trying to solve with online aggregation. Is it the problem of \"heavy queries blocking light queries\"? For this problem, I think https://github.com/apache/incubator-druid/issues/6993 is a better approach because it also considers what query is important. Sometimes, a heavy query is more important than others and should be finished quickly.\r\n\r\nAlso, as far as I remember, the online aggregation defines query interface as well as query processing method. The query interface of online aggregation shows the query result with an error rate before the entire query processing completes. As query processing progresses, the query result becomes more accurate. \r\n\r\nI'm not sure where this interface is appropriate for. Usually people already know what error is allowed and want for their queries to be finished as soon as possible in the error bound. Do you have any particular example of this use case?\r\n\r\nFinally, the query result accuracy is highly related to the input sampling. Do you have an idea of how good the accuracy is with the random segment selection?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465259170/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465260076","html_url":"https://github.com/apache/druid/issues/7087#issuecomment-465260076","issue_url":"https://api.github.com/repos/apache/druid/issues/7087","id":465260076,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI2MDA3Ng==","user":{"login":"jihoonson","id":2322288,"node_id":"MDQ6VXNlcjIzMjIyODg=","avatar_url":"https://avatars.githubusercontent.com/u/2322288?v=4","gravatar_id":"","url":"https://api.github.com/users/jihoonson","html_url":"https://github.com/jihoonson","followers_url":"https://api.github.com/users/jihoonson/followers","following_url":"https://api.github.com/users/jihoonson/following{/other_user}","gists_url":"https://api.github.com/users/jihoonson/gists{/gist_id}","starred_url":"https://api.github.com/users/jihoonson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jihoonson/subscriptions","organizations_url":"https://api.github.com/users/jihoonson/orgs","repos_url":"https://api.github.com/users/jihoonson/repos","events_url":"https://api.github.com/users/jihoonson/events{/privacy}","received_events_url":"https://api.github.com/users/jihoonson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T18:46:19Z","updated_at":"2019-02-19T18:46:19Z","author_association":"CONTRIBUTOR","body":"Also, I think we have agreed on the proposal template. Would you please update the proposal based on the [template](https://github.com/apache/incubator-druid/issues/new/choose)?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465260076/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465268300","html_url":"https://github.com/apache/druid/pull/6794#issuecomment-465268300","issue_url":"https://api.github.com/repos/apache/druid/issues/6794","id":465268300,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI2ODMwMA==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T19:07:29Z","updated_at":"2019-02-19T19:07:29Z","author_association":"CONTRIBUTOR","body":"I have moved the proposal to #7093, used the new proposal template, and added a lot of info, including tables detailing changes to interfaces and calling out differences between standard and vectorized versions.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465268300/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465272584","html_url":"https://github.com/apache/druid/issues/7075#issuecomment-465272584","issue_url":"https://api.github.com/repos/apache/druid/issues/7075","id":465272584,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI3MjU4NA==","user":{"login":"leventov","id":609240,"node_id":"MDQ6VXNlcjYwOTI0MA==","avatar_url":"https://avatars.githubusercontent.com/u/609240?v=4","gravatar_id":"","url":"https://api.github.com/users/leventov","html_url":"https://github.com/leventov","followers_url":"https://api.github.com/users/leventov/followers","following_url":"https://api.github.com/users/leventov/following{/other_user}","gists_url":"https://api.github.com/users/leventov/gists{/gist_id}","starred_url":"https://api.github.com/users/leventov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leventov/subscriptions","organizations_url":"https://api.github.com/users/leventov/orgs","repos_url":"https://api.github.com/users/leventov/repos","events_url":"https://api.github.com/users/leventov/events{/privacy}","received_events_url":"https://api.github.com/users/leventov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T19:19:11Z","updated_at":"2019-02-19T19:19:11Z","author_association":"MEMBER","body":"Could you please open an issue in the Kafka library?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465272584/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465276736","html_url":"https://github.com/apache/druid/pull/7088#issuecomment-465276736","issue_url":"https://api.github.com/repos/apache/druid/issues/7088","id":465276736,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI3NjczNg==","user":{"login":"samarthjain","id":1642180,"node_id":"MDQ6VXNlcjE2NDIxODA=","avatar_url":"https://avatars.githubusercontent.com/u/1642180?v=4","gravatar_id":"","url":"https://api.github.com/users/samarthjain","html_url":"https://github.com/samarthjain","followers_url":"https://api.github.com/users/samarthjain/followers","following_url":"https://api.github.com/users/samarthjain/following{/other_user}","gists_url":"https://api.github.com/users/samarthjain/gists{/gist_id}","starred_url":"https://api.github.com/users/samarthjain/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/samarthjain/subscriptions","organizations_url":"https://api.github.com/users/samarthjain/orgs","repos_url":"https://api.github.com/users/samarthjain/repos","events_url":"https://api.github.com/users/samarthjain/events{/privacy}","received_events_url":"https://api.github.com/users/samarthjain/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T19:30:25Z","updated_at":"2019-02-19T19:30:25Z","author_association":"CONTRIBUTOR","body":"We have been testing this patch internally for the last week and we have seen significant performance improvements. For our larger clusters, it takes now 20-30 mins for the cluster to download segments from cold storage (S3 in our case) and be ready to serve them. Without the patch it used to take over 5 hrs for the same set of segments.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465276736/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465278829","html_url":"https://github.com/apache/druid/issues/7068#issuecomment-465278829","issue_url":"https://api.github.com/repos/apache/druid/issues/7068","id":465278829,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI3ODgyOQ==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T19:36:16Z","updated_at":"2019-02-19T19:36:16Z","author_association":"CONTRIBUTOR","body":"> @fjy or @gianm - would you happen to remember if this was a deliberate design decision? Before I go down the path of making changes, I want to be sure I am not missing out on some tricky issues here.\r\n\r\nI don't remember that far back - sorry! I would have to guess it was done that way because it was easier and didn't cause a problem at the time. Fwiw, HttpLoadQueuePeon does do things in a more parallel way, but, given that it is still experimental I think there is value in adding better parallelism to the CuratorBasedLoadQueuePeon mechanism as well.\r\n\r\n> 1. In CuratorBasedLoadQueuePeon - remove the restriction of only processing one segment at a time. And utilize a thread pool to create zookeeper nodes corresponding to segments that need to be processed (load/drop).\r\n> 2. In ZkCoordinator, utilize a thread pool to download the segments from the historical. This new threadpool, to do the actual segment processing, will be different from the single threaded pool being used by the PathChildren cache for handling child created events.\r\n\r\nThe basic idea sounds good to me. The only potential thing to watch out for, that I can think of, is making sure that code that cleans up directories (e.g. when a segment fails to download, or when the last segment of a particular interval is dropped) doesn't have any races with the code that loads up new segments.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465278829/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465280189","html_url":"https://github.com/apache/druid/issues/3878#issuecomment-465280189","issue_url":"https://api.github.com/repos/apache/druid/issues/3878","id":465280189,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI4MDE4OQ==","user":{"login":"egor-ryashin","id":14215045,"node_id":"MDQ6VXNlcjE0MjE1MDQ1","avatar_url":"https://avatars.githubusercontent.com/u/14215045?v=4","gravatar_id":"","url":"https://api.github.com/users/egor-ryashin","html_url":"https://github.com/egor-ryashin","followers_url":"https://api.github.com/users/egor-ryashin/followers","following_url":"https://api.github.com/users/egor-ryashin/following{/other_user}","gists_url":"https://api.github.com/users/egor-ryashin/gists{/gist_id}","starred_url":"https://api.github.com/users/egor-ryashin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/egor-ryashin/subscriptions","organizations_url":"https://api.github.com/users/egor-ryashin/orgs","repos_url":"https://api.github.com/users/egor-ryashin/repos","events_url":"https://api.github.com/users/egor-ryashin/events{/privacy}","received_events_url":"https://api.github.com/users/egor-ryashin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T19:40:19Z","updated_at":"2019-02-19T19:40:19Z","author_association":"CONTRIBUTOR","body":"> Sometimes Filters/DimFilters (Like, Regex, Bound, etc.) on dimensions of very high cardinality\r\n\r\nDo queries with simple `dim = 'VALUE'` fall into that category?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465280189/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465281068","html_url":"https://github.com/apache/druid/issues/3878#issuecomment-465281068","issue_url":"https://api.github.com/repos/apache/druid/issues/3878","id":465281068,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI4MTA2OA==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T19:42:44Z","updated_at":"2019-02-19T19:42:44Z","author_association":"CONTRIBUTOR","body":"> Do queries with simple `dim = 'VALUE'` fall into that category?\r\n\r\nI doubt it, unless you have a _lot_ of them ORed together. Then, maybe.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465281068/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465283757","html_url":"https://github.com/apache/druid/issues/7075#issuecomment-465283757","issue_url":"https://api.github.com/repos/apache/druid/issues/7075","id":465283757,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI4Mzc1Nw==","user":{"login":"justinborromeo","id":9417701,"node_id":"MDQ6VXNlcjk0MTc3MDE=","avatar_url":"https://avatars.githubusercontent.com/u/9417701?v=4","gravatar_id":"","url":"https://api.github.com/users/justinborromeo","html_url":"https://github.com/justinborromeo","followers_url":"https://api.github.com/users/justinborromeo/followers","following_url":"https://api.github.com/users/justinborromeo/following{/other_user}","gists_url":"https://api.github.com/users/justinborromeo/gists{/gist_id}","starred_url":"https://api.github.com/users/justinborromeo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/justinborromeo/subscriptions","organizations_url":"https://api.github.com/users/justinborromeo/orgs","repos_url":"https://api.github.com/users/justinborromeo/repos","events_url":"https://api.github.com/users/justinborromeo/events{/privacy}","received_events_url":"https://api.github.com/users/justinborromeo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T19:50:05Z","updated_at":"2019-02-19T19:50:05Z","author_association":"CONTRIBUTOR","body":"Done: https://issues.apache.org/jira/browse/KAFKA-7953","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465283757/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465288084","html_url":"https://github.com/apache/druid/issues/3878#issuecomment-465288084","issue_url":"https://api.github.com/repos/apache/druid/issues/3878","id":465288084,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI4ODA4NA==","user":{"login":"egor-ryashin","id":14215045,"node_id":"MDQ6VXNlcjE0MjE1MDQ1","avatar_url":"https://avatars.githubusercontent.com/u/14215045?v=4","gravatar_id":"","url":"https://api.github.com/users/egor-ryashin","html_url":"https://github.com/egor-ryashin","followers_url":"https://api.github.com/users/egor-ryashin/followers","following_url":"https://api.github.com/users/egor-ryashin/following{/other_user}","gists_url":"https://api.github.com/users/egor-ryashin/gists{/gist_id}","starred_url":"https://api.github.com/users/egor-ryashin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/egor-ryashin/subscriptions","organizations_url":"https://api.github.com/users/egor-ryashin/orgs","repos_url":"https://api.github.com/users/egor-ryashin/repos","events_url":"https://api.github.com/users/egor-ryashin/events{/privacy}","received_events_url":"https://api.github.com/users/egor-ryashin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T20:02:06Z","updated_at":"2019-02-19T20:02:06Z","author_association":"CONTRIBUTOR","body":"I wonder whether `a lot of them` means 10, 100, >1000?","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465288084/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465292651","html_url":"https://github.com/apache/druid/issues/7087#issuecomment-465292651","issue_url":"https://api.github.com/repos/apache/druid/issues/7087","id":465292651,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI5MjY1MQ==","user":{"login":"leventov","id":609240,"node_id":"MDQ6VXNlcjYwOTI0MA==","avatar_url":"https://avatars.githubusercontent.com/u/609240?v=4","gravatar_id":"","url":"https://api.github.com/users/leventov","html_url":"https://github.com/leventov","followers_url":"https://api.github.com/users/leventov/followers","following_url":"https://api.github.com/users/leventov/following{/other_user}","gists_url":"https://api.github.com/users/leventov/gists{/gist_id}","starred_url":"https://api.github.com/users/leventov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leventov/subscriptions","organizations_url":"https://api.github.com/users/leventov/orgs","repos_url":"https://api.github.com/users/leventov/repos","events_url":"https://api.github.com/users/leventov/events{/privacy}","received_events_url":"https://api.github.com/users/leventov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T20:15:25Z","updated_at":"2019-02-19T20:15:25Z","author_association":"MEMBER","body":"> Is it the problem of \"heavy queries blocking light queries\"?\r\n\r\nNo, that's an orthogonal issue. Online aggregation addresses two big things:\r\n - Fault tolerance and query latency: show a user something quickly, rather than waiting for the latest struggling segment computation, or failing a query completely if one segment computation has failed or one segment is not loaded in the cluster. See [this post](https://medium.com/@leventov/the-problems-with-druid-at-large-scale-and-high-load-part-1-714d475e84c9).\r\n - Avoid making unneeded computations: it's assumed that when a user sees first approximate results, he may move on to the next query, not interested in precise results of the previous query anymore. Less selective queries are sometimes (often?) used just as a means of navigation to more selective queries.\r\n\r\n> Also, as far as I remember, the online aggregation defines query interface as well as query processing method. The query interface of online aggregation shows the query result with an error rate before the entire query processing completes. As query processing progresses, the query result becomes more accurate.\r\n\r\n> I'm not sure where this interface is appropriate for. Usually people already know what error is allowed and want for their queries to be finished as soon as possible in the error bound. Do you have any particular example of this use case?\r\n\r\nI don't see how the sentence \"Usually people already know what error is allowed and want for their queries to be finished as soon as possible in the error bound.\" is connected with the rest of this part of your message. But I think that usually people don't know and/or don't care about error bounds. People want to see *something* as soon as possible. For navigational topN queries in the interface, for example, they often care only about top1 to filter on it, or filter on some value that they already have in mind (e. g. \"country = US\"), so they merely need to start to see dimension values to be able to click on one of them, not caring about the topN values themselves at all.\r\n\r\n> I'm not sure where this interface is appropriate for.\r\n\r\nI think all interfaces such as Superset, Imply's interface and Metamarkets's Exlore can adapt to online aggregation to improve user experience.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465292651/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465295035","html_url":"https://github.com/apache/druid/issues/3878#issuecomment-465295035","issue_url":"https://api.github.com/repos/apache/druid/issues/3878","id":465295035,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTI5NTAzNQ==","user":{"login":"leventov","id":609240,"node_id":"MDQ6VXNlcjYwOTI0MA==","avatar_url":"https://avatars.githubusercontent.com/u/609240?v=4","gravatar_id":"","url":"https://api.github.com/users/leventov","html_url":"https://github.com/leventov","followers_url":"https://api.github.com/users/leventov/followers","following_url":"https://api.github.com/users/leventov/following{/other_user}","gists_url":"https://api.github.com/users/leventov/gists{/gist_id}","starred_url":"https://api.github.com/users/leventov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leventov/subscriptions","organizations_url":"https://api.github.com/users/leventov/orgs","repos_url":"https://api.github.com/users/leventov/repos","events_url":"https://api.github.com/users/leventov/events{/privacy}","received_events_url":"https://api.github.com/users/leventov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T20:22:34Z","updated_at":"2019-02-19T20:22:34Z","author_association":"MEMBER","body":"@egor-ryashin experiments should be run to determine that.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465295035/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465300396","html_url":"https://github.com/apache/druid/pull/7070#issuecomment-465300396","issue_url":"https://api.github.com/repos/apache/druid/issues/7070","id":465300396,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTMwMDM5Ng==","user":{"login":"jon-wei","id":8729063,"node_id":"MDQ6VXNlcjg3MjkwNjM=","avatar_url":"https://avatars.githubusercontent.com/u/8729063?v=4","gravatar_id":"","url":"https://api.github.com/users/jon-wei","html_url":"https://github.com/jon-wei","followers_url":"https://api.github.com/users/jon-wei/followers","following_url":"https://api.github.com/users/jon-wei/following{/other_user}","gists_url":"https://api.github.com/users/jon-wei/gists{/gist_id}","starred_url":"https://api.github.com/users/jon-wei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jon-wei/subscriptions","organizations_url":"https://api.github.com/users/jon-wei/orgs","repos_url":"https://api.github.com/users/jon-wei/repos","events_url":"https://api.github.com/users/jon-wei/events{/privacy}","received_events_url":"https://api.github.com/users/jon-wei/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T20:38:48Z","updated_at":"2019-02-19T20:38:48Z","author_association":"CONTRIBUTOR","body":"Merging, TeamCity check isn't meaningful here","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465300396/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/druid/issues/comments/465302581","html_url":"https://github.com/apache/druid/issues/3878#issuecomment-465302581","issue_url":"https://api.github.com/repos/apache/druid/issues/3878","id":465302581,"node_id":"MDEyOklzc3VlQ29tbWVudDQ2NTMwMjU4MQ==","user":{"login":"gianm","id":1214075,"node_id":"MDQ6VXNlcjEyMTQwNzU=","avatar_url":"https://avatars.githubusercontent.com/u/1214075?v=4","gravatar_id":"","url":"https://api.github.com/users/gianm","html_url":"https://github.com/gianm","followers_url":"https://api.github.com/users/gianm/followers","following_url":"https://api.github.com/users/gianm/following{/other_user}","gists_url":"https://api.github.com/users/gianm/gists{/gist_id}","starred_url":"https://api.github.com/users/gianm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gianm/subscriptions","organizations_url":"https://api.github.com/users/gianm/orgs","repos_url":"https://api.github.com/users/gianm/repos","events_url":"https://api.github.com/users/gianm/events{/privacy}","received_events_url":"https://api.github.com/users/gianm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-02-19T20:45:24Z","updated_at":"2019-02-19T20:45:24Z","author_association":"CONTRIBUTOR","body":"It also depends on whether those filters match anything or not (not-matching means it doesn't add any union work, just index-search work). So it can be very hard / impossible to predict which one is better without doing a lot of the work, and the algorithm is going to need to make some guesses.","reactions":{"url":"https://api.github.com/repos/apache/druid/issues/comments/465302581/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]