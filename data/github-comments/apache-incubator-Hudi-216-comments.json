[{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073202233","html_url":"https://github.com/apache/hudi/pull/5075#issuecomment-1073202233","issue_url":"https://api.github.com/repos/apache/hudi/issues/5075","id":1073202233,"node_id":"IC_kwDOBI7nWM4_98Q5","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-20T08:51:10Z","updated_at":"2022-03-20T08:51:10Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"c4ad59e550a77c8139eac5ad329ec6eb73d800ac\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7101\",\n    \"triggerID\" : \"c4ad59e550a77c8139eac5ad329ec6eb73d800ac\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"fff30820fd24133f32b8b4e8fad9f87b0284a36a\",\n    \"status\" : \"UNKNOWN\",\n    \"url\" : \"TBD\",\n    \"triggerID\" : \"fff30820fd24133f32b8b4e8fad9f87b0284a36a\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"bd25c00ab1183b6f5eca4f0cb1287c0cf7bceba8\",\n    \"status\" : \"SUCCESS\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7102\",\n    \"triggerID\" : \"bd25c00ab1183b6f5eca4f0cb1287c0cf7bceba8\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* fff30820fd24133f32b8b4e8fad9f87b0284a36a UNKNOWN\n* bd25c00ab1183b6f5eca4f0cb1287c0cf7bceba8 Azure: [SUCCESS](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7102) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073202233/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073231293","html_url":"https://github.com/apache/hudi/issues/4864#issuecomment-1073231293","issue_url":"https://api.github.com/repos/apache/hudi/issues/4864","id":1073231293,"node_id":"IC_kwDOBI7nWM4_-DW9","user":{"login":"bkosuru","id":7408351,"node_id":"MDQ6VXNlcjc0MDgzNTE=","avatar_url":"https://avatars.githubusercontent.com/u/7408351?v=4","gravatar_id":"","url":"https://api.github.com/users/bkosuru","html_url":"https://github.com/bkosuru","followers_url":"https://api.github.com/users/bkosuru/followers","following_url":"https://api.github.com/users/bkosuru/following{/other_user}","gists_url":"https://api.github.com/users/bkosuru/gists{/gist_id}","starred_url":"https://api.github.com/users/bkosuru/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bkosuru/subscriptions","organizations_url":"https://api.github.com/users/bkosuru/orgs","repos_url":"https://api.github.com/users/bkosuru/repos","events_url":"https://api.github.com/users/bkosuru/events{/privacy}","received_events_url":"https://api.github.com/users/bkosuru/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-20T11:33:57Z","updated_at":"2022-03-23T13:07:01Z","author_association":"NONE","body":"Hi @nsivabalan,\r\n\r\nCould you please give some suggestions for tuning bloom index configs? Our data is immutable but we have duplicate data. We want to insert unique rows only. We have allocated enough resources(400 executors, 50G) and it still fails. Do you think we should allocate more resources? Is there a way to insert_drop_dup to a single partition to make it more efficient. We know that the data we are going to insert belongs to a single partition. \r\n\r\nThanks!\r\nBindu","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073231293/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073274097","html_url":"https://github.com/apache/hudi/pull/4080#issuecomment-1073274097","issue_url":"https://api.github.com/repos/apache/hudi/issues/4080","id":1073274097,"node_id":"IC_kwDOBI7nWM4_-Nzx","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-20T15:22:44Z","updated_at":"2022-03-20T15:24:51Z","author_association":"MEMBER","body":"> Hey Guys,\r\n> \r\n> Any chance to merge this soon?\r\n\r\n@rubenssoto @sshah90 Taking over this. Porting over to https://github.com/apache/hudi/pull/5076","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073274097/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073287297","html_url":"https://github.com/apache/hudi/issues/4891#issuecomment-1073287297","issue_url":"https://api.github.com/repos/apache/hudi/issues/4891","id":1073287297,"node_id":"IC_kwDOBI7nWM4_-RCB","user":{"login":"suryaprasanna","id":20996567,"node_id":"MDQ6VXNlcjIwOTk2NTY3","avatar_url":"https://avatars.githubusercontent.com/u/20996567?v=4","gravatar_id":"","url":"https://api.github.com/users/suryaprasanna","html_url":"https://github.com/suryaprasanna","followers_url":"https://api.github.com/users/suryaprasanna/followers","following_url":"https://api.github.com/users/suryaprasanna/following{/other_user}","gists_url":"https://api.github.com/users/suryaprasanna/gists{/gist_id}","starred_url":"https://api.github.com/users/suryaprasanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/suryaprasanna/subscriptions","organizations_url":"https://api.github.com/users/suryaprasanna/orgs","repos_url":"https://api.github.com/users/suryaprasanna/repos","events_url":"https://api.github.com/users/suryaprasanna/events{/privacy}","received_events_url":"https://api.github.com/users/suryaprasanna/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-20T16:37:43Z","updated_at":"2022-03-20T16:37:43Z","author_association":"CONTRIBUTOR","body":"[FelixKJose](https://github.com/FelixKJose)\r\n> 1. Let's say my each partitions (date) are large partitions (eg. 6.5 TB uncompressed data), so having the frequent async clustering is suggested right? I am running on r5.4xlarge (meaning 37GB driver memory), so what will be best clusering frequency?\r\n\r\nYou can start with one spark per partition(so it creates one replacecommit for one sorting  operation on a partition) and keep increasing no. of partitions to cluster in a single job,  to find out the breaking point. I think with the above driver memory it can easily handle 4 partitions. \r\nYou need to play around with your data to figure out the amount of parallelism you can give.\r\nAlthough locking, archival or other services will be bottleneck when you run clustering with very high parallelism. \r\n\r\n**Note:** Make `\"hoodie.clustering.async.max.commits\"` to `\"0\"`, that way multiple clustering plans can be generated in parallel. Since the clustering jobs are running on different partitions you should be ok. \r\n\r\n> 2. What will be the best value for hoodie.clustering.plan.strategy.small.file.limit?\r\nAlso any other configurations I should be using considering the partition size as mentioned above\r\n\r\nSince, you are using `\"hoodie.clustering.plan.strategy.sort.columns\"` config, I am assuming you want to sort the partitions. Sorting operation main objective is to sort the data based on columns and create new set of files with parquet file sizes close to value, that is given under `hoodie.clustering.plan.strategy.target.file.max.bytes`. So, you should not worry about small.file.limit, since sorting operation is anyway going to rewrite entire partition and create larger parquet files. I would suggest to keep the small.file.limit value to be higher that way all the files are included.\r\n\r\n`hoodie.clustering.plan.strategy.small.file.limit` is mainly used for stitching operation. Where you are not sorting data but stitching small files together so that you can reduce the small file limit.\r\n\r\n> 3. Which lock provider is advised if I am running on AWS EMR?\r\n\r\nI do not have much knowledge about AWS stack, default lock provider i.e. ZookeeperBasedLockProvider works just fine.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073287297/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073297369","html_url":"https://github.com/apache/hudi/pull/4489#issuecomment-1073297369","issue_url":"https://api.github.com/repos/apache/hudi/issues/4489","id":1073297369,"node_id":"IC_kwDOBI7nWM4_-TfZ","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-20T17:31:52Z","updated_at":"2022-03-20T17:31:52Z","author_association":"CONTRIBUTOR","body":"@XuQianJin-Stars : let me know once all feedback has been addressed. I can take another look and get it landed. \r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073297369/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073413701","html_url":"https://github.com/apache/hudi/issues/4993#issuecomment-1073413701","issue_url":"https://api.github.com/repos/apache/hudi/issues/4993","id":1073413701,"node_id":"IC_kwDOBI7nWM4_-v5F","user":{"login":"BruceKellan","id":13477122,"node_id":"MDQ6VXNlcjEzNDc3MTIy","avatar_url":"https://avatars.githubusercontent.com/u/13477122?v=4","gravatar_id":"","url":"https://api.github.com/users/BruceKellan","html_url":"https://github.com/BruceKellan","followers_url":"https://api.github.com/users/BruceKellan/followers","following_url":"https://api.github.com/users/BruceKellan/following{/other_user}","gists_url":"https://api.github.com/users/BruceKellan/gists{/gist_id}","starred_url":"https://api.github.com/users/BruceKellan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/BruceKellan/subscriptions","organizations_url":"https://api.github.com/users/BruceKellan/orgs","repos_url":"https://api.github.com/users/BruceKellan/repos","events_url":"https://api.github.com/users/BruceKellan/events{/privacy}","received_events_url":"https://api.github.com/users/BruceKellan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T01:57:34Z","updated_at":"2022-03-21T01:57:34Z","author_association":"CONTRIBUTOR","body":"Can someone help me,\r\nCan I create partitions in advance?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073413701/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073424942","html_url":"https://github.com/apache/hudi/pull/4286#issuecomment-1073424942","issue_url":"https://api.github.com/repos/apache/hudi/issues/4286","id":1073424942,"node_id":"IC_kwDOBI7nWM4_-you","user":{"login":"LaurenceGA","id":10292869,"node_id":"MDQ6VXNlcjEwMjkyODY5","avatar_url":"https://avatars.githubusercontent.com/u/10292869?v=4","gravatar_id":"","url":"https://api.github.com/users/LaurenceGA","html_url":"https://github.com/LaurenceGA","followers_url":"https://api.github.com/users/LaurenceGA/followers","following_url":"https://api.github.com/users/LaurenceGA/following{/other_user}","gists_url":"https://api.github.com/users/LaurenceGA/gists{/gist_id}","starred_url":"https://api.github.com/users/LaurenceGA/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/LaurenceGA/subscriptions","organizations_url":"https://api.github.com/users/LaurenceGA/orgs","repos_url":"https://api.github.com/users/LaurenceGA/repos","events_url":"https://api.github.com/users/LaurenceGA/events{/privacy}","received_events_url":"https://api.github.com/users/LaurenceGA/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T02:28:34Z","updated_at":"2022-03-21T02:28:34Z","author_association":"NONE","body":"Would you be able to upgrade Hadoop to 3.3.2? It was just released this month.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073424942/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073426858","html_url":"https://github.com/apache/hudi/pull/5072#issuecomment-1073426858","issue_url":"https://api.github.com/repos/apache/hudi/issues/5072","id":1073426858,"node_id":"IC_kwDOBI7nWM4_-zGq","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T02:34:18Z","updated_at":"2022-03-21T02:34:18Z","author_association":"CONTRIBUTOR","body":"> hi @danny0405 `bot.yml` add the flink multi version to build?\r\n\r\nYes, can you help with that ? I tried to add it but find that there would be too many builds if i add in another dimension, there are already 2 dimensions now: spark and scala","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073426858/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073427339","html_url":"https://github.com/apache/hudi/issues/4678#issuecomment-1073427339","issue_url":"https://api.github.com/repos/apache/hudi/issues/4678","id":1073427339,"node_id":"IC_kwDOBI7nWM4_-zOL","user":{"login":"YannByron","id":10036681,"node_id":"MDQ6VXNlcjEwMDM2Njgx","avatar_url":"https://avatars.githubusercontent.com/u/10036681?v=4","gravatar_id":"","url":"https://api.github.com/users/YannByron","html_url":"https://github.com/YannByron","followers_url":"https://api.github.com/users/YannByron/followers","following_url":"https://api.github.com/users/YannByron/following{/other_user}","gists_url":"https://api.github.com/users/YannByron/gists{/gist_id}","starred_url":"https://api.github.com/users/YannByron/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YannByron/subscriptions","organizations_url":"https://api.github.com/users/YannByron/orgs","repos_url":"https://api.github.com/users/YannByron/repos","events_url":"https://api.github.com/users/YannByron/events{/privacy}","received_events_url":"https://api.github.com/users/YannByron/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T02:35:55Z","updated_at":"2022-03-21T02:35:55Z","author_association":"CONTRIBUTOR","body":"@nsivabalan In my private opinion, I think the usage of `schema` that can not convert datatype in branch-0.10.0 is reasonable. If want to convert data, should use `select` or `withColumnn` after `load` data. So I don't treat it as a bug.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073427339/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073440851","html_url":"https://github.com/apache/hudi/issues/4635#issuecomment-1073440851","issue_url":"https://api.github.com/repos/apache/hudi/issues/4635","id":1073440851,"node_id":"IC_kwDOBI7nWM4_-2hT","user":{"login":"rkkalluri","id":3401900,"node_id":"MDQ6VXNlcjM0MDE5MDA=","avatar_url":"https://avatars.githubusercontent.com/u/3401900?v=4","gravatar_id":"","url":"https://api.github.com/users/rkkalluri","html_url":"https://github.com/rkkalluri","followers_url":"https://api.github.com/users/rkkalluri/followers","following_url":"https://api.github.com/users/rkkalluri/following{/other_user}","gists_url":"https://api.github.com/users/rkkalluri/gists{/gist_id}","starred_url":"https://api.github.com/users/rkkalluri/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rkkalluri/subscriptions","organizations_url":"https://api.github.com/users/rkkalluri/orgs","repos_url":"https://api.github.com/users/rkkalluri/repos","events_url":"https://api.github.com/users/rkkalluri/events{/privacy}","received_events_url":"https://api.github.com/users/rkkalluri/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T03:13:00Z","updated_at":"2022-03-21T03:13:00Z","author_association":"CONTRIBUTOR","body":"I am able to reproduce this locally on 0.11.0-SNAPSHOT\r\n\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[==>20220320215909174__commit__INFLIGHT]}\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating View Manager with storage type :REMOTE_FIRST\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating remote first table view\r\n22/03/20 21:59:22 INFO TransactionUtils: Successfully resolved conflicts, if any\r\n22/03/20 21:59:22 INFO BaseHoodieWriteClient: Committing 20220320215909174 action commit\r\n22/03/20 21:59:22 INFO SparkContext: Starting job: collect at HoodieSparkEngineContext.java:134\r\n22/03/20 21:59:22 INFO DAGScheduler: Got job 680 (collect at HoodieSparkEngineContext.java:134) with 1 output partitions\r\n22/03/20 21:59:22 INFO DAGScheduler: Final stage: ResultStage 984 (collect at HoodieSparkEngineContext.java:134)\r\n22/03/20 21:59:22 INFO DAGScheduler: Parents of final stage: List()\r\n22/03/20 21:59:22 INFO DAGScheduler: Missing parents: List()\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting ResultStage 984 (MapPartitionsRDD[2117] at flatMap at HoodieSparkEngineContext.java:134), which has no missing parents\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_848 stored as values in memory (estimated size 99.5 KiB, free 357.5 MiB)\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_848_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 357.5 MiB)\r\n22/03/20 21:59:22 INFO BlockManagerInfo: Added broadcast_848_piece0 in memory on rkalluri.attlocal.net:63252 (size: 35.1 KiB, free: 364.0 MiB)\r\n22/03/20 21:59:22 INFO SparkContext: Created broadcast 848 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 984 (MapPartitionsRDD[2117] at flatMap at HoodieSparkEngineContext.java:134) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Adding task set 984.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 984.0 (TID 2266) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4387 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:22 INFO Executor: Running task 0.0 in stage 984.0 (TID 2266)\r\n22/03/20 21:59:22 INFO Executor: Finished task 0.0 in stage 984.0 (TID 2266). 888 bytes result sent to driver\r\n22/03/20 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 984.0 (TID 2266) in 22 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 984.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:22 INFO DAGScheduler: ResultStage 984 (collect at HoodieSparkEngineContext.java:134) finished in 0.041 s\r\n22/03/20 21:59:22 INFO DAGScheduler: Job 680 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 984: Stage finished\r\n22/03/20 21:59:22 INFO DAGScheduler: Job 680 finished: collect at HoodieSparkEngineContext.java:134, took 0.042314 s\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215908164__deltacommit__COMPLETED]}\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:22 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:22 INFO HoodieTableMetadataUtil: Loading latest file slices for metadata table partition files\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:22 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Building file system view for partition (files)\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=14, NumFileGroups=1, FileGroupsCreationTime=1, StoreTimeTaken=0\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215908164__deltacommit__COMPLETED]}\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[==>20220320215909174__commit__INFLIGHT]}\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableMetadataUtil: Updating at 20220320215909174 from Commit/BULK_INSERT. #partitions_updated=2\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215908164__deltacommit__COMPLETED]}\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:22 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:22 INFO HoodieTableMetadataUtil: Loading latest file slices for metadata table partition files\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:22 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Building file system view for partition (files)\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=14, NumFileGroups=1, FileGroupsCreationTime=2, StoreTimeTaken=0\r\n22/03/20 21:59:22 INFO BaseHoodieClient: Embedded Timeline Server is disabled. Not starting timeline service\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading Active commit timeline for file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215908164__deltacommit__COMPLETED]}\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating View Manager with storage type :MEMORY\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating in-memory based Table View\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215908164__deltacommit__COMPLETED]}\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[==>20220320215909174__commit__INFLIGHT]}\r\n22/03/20 21:59:22 INFO BaseHoodieWriteClient: Scheduling table service COMPACT\r\n22/03/20 21:59:22 INFO BaseHoodieWriteClient: Scheduling compaction at instant time :20220320215908164001\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading Active commit timeline for file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215908164__deltacommit__COMPLETED]}\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating View Manager with storage type :MEMORY\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating in-memory based Table View\r\n22/03/20 21:59:22 INFO ScheduleCompactionActionExecutor: Checking if compaction needs to be run on file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading Active commit timeline for file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215908164__deltacommit__COMPLETED]}\r\n22/03/20 21:59:22 INFO BaseHoodieWriteClient: Generate a new instant time: 20220320215909174 action: deltacommit\r\n22/03/20 21:59:22 INFO HoodieHeartbeatClient: Received request to start heartbeat for instant time 20220320215909174\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Creating a new instant [==>20220320215909174__deltacommit__REQUESTED]\r\n22/03/20 21:59:22 INFO BlockManagerInfo: Removed broadcast_848_piece0 on rkalluri.attlocal.net:63252 in memory (size: 35.1 KiB, free: 364.0 MiB)\r\n22/03/20 21:59:22 INFO BlockManagerInfo: Removed broadcast_847_piece0 on rkalluri.attlocal.net:63252 in memory (size: 196.6 KiB, free: 364.2 MiB)\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieTableMetaClient: Loading Active commit timeline for file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[==>20220320215909174__deltacommit__REQUESTED]}\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating View Manager with storage type :MEMORY\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating in-memory based Table View\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating InMemory based view for basePath file:/tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:22 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[==>20220320215909174__deltacommit__REQUESTED]}\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:22 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:22 INFO AsyncCleanerService: The HoodieWriteClient is not configured to auto & async clean. Async clean service will not start.\r\n22/03/20 21:59:22 INFO AsyncArchiveService: The HoodieWriteClient is not configured to auto & async archive. Async archive service will not start.\r\n22/03/20 21:59:22 INFO SparkContext: Starting job: countByKey at BaseSparkCommitActionExecutor.java:190\r\n22/03/20 21:59:22 INFO DAGScheduler: Registering RDD 2123 (countByKey at BaseSparkCommitActionExecutor.java:190) as input to shuffle 182\r\n22/03/20 21:59:22 INFO DAGScheduler: Got job 681 (countByKey at BaseSparkCommitActionExecutor.java:190) with 1 output partitions\r\n22/03/20 21:59:22 INFO DAGScheduler: Final stage: ResultStage 986 (countByKey at BaseSparkCommitActionExecutor.java:190)\r\n22/03/20 21:59:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 985)\r\n22/03/20 21:59:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 985)\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting ShuffleMapStage 985 (MapPartitionsRDD[2123] at countByKey at BaseSparkCommitActionExecutor.java:190), which has no missing parents\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_849 stored as values in memory (estimated size 9.5 KiB, free 358.4 MiB)\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_849_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 358.3 MiB)\r\n22/03/20 21:59:22 INFO BlockManagerInfo: Added broadcast_849_piece0 in memory on rkalluri.attlocal.net:63252 (size: 5.2 KiB, free: 364.2 MiB)\r\n22/03/20 21:59:22 INFO SparkContext: Created broadcast 849 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 985 (MapPartitionsRDD[2123] at countByKey at BaseSparkCommitActionExecutor.java:190) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Adding task set 985.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 985.0 (TID 2267) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4800 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:22 INFO Executor: Running task 0.0 in stage 985.0 (TID 2267)\r\n22/03/20 21:59:22 INFO MemoryStore: Block rdd_2121_0 stored as values in memory (estimated size 367.0 B, free 358.3 MiB)\r\n22/03/20 21:59:22 INFO BlockManagerInfo: Added rdd_2121_0 in memory on rkalluri.attlocal.net:63252 (size: 367.0 B, free: 364.2 MiB)\r\n22/03/20 21:59:22 INFO Executor: Finished task 0.0 in stage 985.0 (TID 2267). 1052 bytes result sent to driver\r\n22/03/20 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 985.0 (TID 2267) in 5 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 985.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:22 INFO DAGScheduler: ShuffleMapStage 985 (countByKey at BaseSparkCommitActionExecutor.java:190) finished in 0.008 s\r\n22/03/20 21:59:22 INFO DAGScheduler: looking for newly runnable stages\r\n22/03/20 21:59:22 INFO DAGScheduler: running: Set()\r\n22/03/20 21:59:22 INFO DAGScheduler: waiting: Set(ResultStage 986)\r\n22/03/20 21:59:22 INFO DAGScheduler: failed: Set()\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting ResultStage 986 (ShuffledRDD[2124] at countByKey at BaseSparkCommitActionExecutor.java:190), which has no missing parents\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_850 stored as values in memory (estimated size 5.5 KiB, free 358.3 MiB)\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_850_piece0 stored as bytes in memory (estimated size 3.1 KiB, free 358.3 MiB)\r\n22/03/20 21:59:22 INFO BlockManagerInfo: Added broadcast_850_piece0 in memory on rkalluri.attlocal.net:63252 (size: 3.1 KiB, free: 364.2 MiB)\r\n22/03/20 21:59:22 INFO SparkContext: Created broadcast 850 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 986 (ShuffledRDD[2124] at countByKey at BaseSparkCommitActionExecutor.java:190) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Adding task set 986.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 986.0 (TID 2268) (rkalluri.attlocal.net, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:22 INFO Executor: Running task 0.0 in stage 986.0 (TID 2268)\r\n22/03/20 21:59:22 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\r\n22/03/20 21:59:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\r\n22/03/20 21:59:22 INFO Executor: Finished task 0.0 in stage 986.0 (TID 2268). 1318 bytes result sent to driver\r\n22/03/20 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 986.0 (TID 2268) in 4 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 986.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:22 INFO DAGScheduler: ResultStage 986 (countByKey at BaseSparkCommitActionExecutor.java:190) finished in 0.005 s\r\n22/03/20 21:59:22 INFO DAGScheduler: Job 681 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 986: Stage finished\r\n22/03/20 21:59:22 INFO DAGScheduler: Job 681 finished: countByKey at BaseSparkCommitActionExecutor.java:190, took 0.014181 s\r\n22/03/20 21:59:22 INFO BaseSparkCommitActionExecutor: Input workload profile :WorkloadProfile {globalStat=WorkloadStat {numInserts=0, numUpdates=2}, InputPartitionStat={files=WorkloadStat {numInserts=0, numUpdates=2}}, OutputPartitionStat={}, operationType=UPSERT_PREPPED}\r\n22/03/20 21:59:22 INFO UpsertPartitioner: AvgRecordSize => 1024\r\n22/03/20 21:59:22 INFO SparkContext: Starting job: collectAsMap at UpsertPartitioner.java:272\r\n22/03/20 21:59:22 INFO DAGScheduler: Got job 682 (collectAsMap at UpsertPartitioner.java:272) with 1 output partitions\r\n22/03/20 21:59:22 INFO DAGScheduler: Final stage: ResultStage 987 (collectAsMap at UpsertPartitioner.java:272)\r\n22/03/20 21:59:22 INFO DAGScheduler: Parents of final stage: List()\r\n22/03/20 21:59:22 INFO DAGScheduler: Missing parents: List()\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting ResultStage 987 (MapPartitionsRDD[2126] at mapToPair at UpsertPartitioner.java:271), which has no missing parents\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_851 stored as values in memory (estimated size 328.6 KiB, free 358.0 MiB)\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_851_piece0 stored as bytes in memory (estimated size 116.9 KiB, free 357.9 MiB)\r\n22/03/20 21:59:22 INFO BlockManagerInfo: Added broadcast_851_piece0 in memory on rkalluri.attlocal.net:63252 (size: 116.9 KiB, free: 364.1 MiB)\r\n22/03/20 21:59:22 INFO SparkContext: Created broadcast 851 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 987 (MapPartitionsRDD[2126] at mapToPair at UpsertPartitioner.java:271) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Adding task set 987.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 987.0 (TID 2269) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4337 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:22 INFO Executor: Running task 0.0 in stage 987.0 (TID 2269)\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating View Manager with storage type :MEMORY\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating in-memory based Table View\r\n22/03/20 21:59:22 INFO FileSystemViewManager: Creating InMemory based view for basePath file:/tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:22 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Building file system view for partition (files)\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=14, NumFileGroups=1, FileGroupsCreationTime=2, StoreTimeTaken=0\r\n22/03/20 21:59:22 INFO Executor: Finished task 0.0 in stage 987.0 (TID 2269). 829 bytes result sent to driver\r\n22/03/20 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 987.0 (TID 2269) in 19 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 987.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:22 INFO DAGScheduler: ResultStage 987 (collectAsMap at UpsertPartitioner.java:272) finished in 0.074 s\r\n22/03/20 21:59:22 INFO DAGScheduler: Job 682 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 987: Stage finished\r\n22/03/20 21:59:22 INFO DAGScheduler: Job 682 finished: collectAsMap at UpsertPartitioner.java:272, took 0.074789 s\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:22 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:22 INFO UpsertPartitioner: Total Buckets :1, buckets info => {0=BucketInfo {bucketType=UPDATE, fileIdPrefix=files-0000, partitionPath=files}},\r\nPartition to insert buckets => {},\r\nUpdateLocations mapped to buckets =>{files-0000=0}\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Checking for file exists ?file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/20220320215909174.deltacommit.requested\r\n22/03/20 21:59:22 INFO FileIOUtils: Created a new file in meta path: file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/20220320215909174.deltacommit.inflight\r\n22/03/20 21:59:22 INFO HoodieActiveTimeline: Create new file for toInstant ?file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/20220320215909174.deltacommit.inflight\r\n22/03/20 21:59:22 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:22 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:22 INFO SparkContext: Starting job: collect at BaseSparkUpdateStrategy.java:51\r\n22/03/20 21:59:22 INFO DAGScheduler: Registering RDD 2129 (distinct at BaseSparkUpdateStrategy.java:51) as input to shuffle 183\r\n22/03/20 21:59:22 INFO DAGScheduler: Got job 683 (collect at BaseSparkUpdateStrategy.java:51) with 1 output partitions\r\n22/03/20 21:59:22 INFO DAGScheduler: Final stage: ResultStage 989 (collect at BaseSparkUpdateStrategy.java:51)\r\n22/03/20 21:59:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 988)\r\n22/03/20 21:59:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 988)\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting ShuffleMapStage 988 (MapPartitionsRDD[2129] at distinct at BaseSparkUpdateStrategy.java:51), which has no missing parents\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_852 stored as values in memory (estimated size 9.5 KiB, free 357.9 MiB)\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_852_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 357.9 MiB)\r\n22/03/20 21:59:22 INFO BlockManagerInfo: Added broadcast_852_piece0 in memory on rkalluri.attlocal.net:63252 (size: 5.1 KiB, free: 364.1 MiB)\r\n22/03/20 21:59:22 INFO SparkContext: Created broadcast 852 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 988 (MapPartitionsRDD[2129] at distinct at BaseSparkUpdateStrategy.java:51) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Adding task set 988.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 988.0 (TID 2270) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4800 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:22 INFO Executor: Running task 0.0 in stage 988.0 (TID 2270)\r\n22/03/20 21:59:22 INFO BlockManager: Found block rdd_2121_0 locally\r\n22/03/20 21:59:22 INFO Executor: Finished task 0.0 in stage 988.0 (TID 2270). 1138 bytes result sent to driver\r\n22/03/20 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 988.0 (TID 2270) in 5 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 988.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:22 INFO DAGScheduler: ShuffleMapStage 988 (distinct at BaseSparkUpdateStrategy.java:51) finished in 0.007 s\r\n22/03/20 21:59:22 INFO DAGScheduler: looking for newly runnable stages\r\n22/03/20 21:59:22 INFO DAGScheduler: running: Set()\r\n22/03/20 21:59:22 INFO DAGScheduler: waiting: Set(ResultStage 989)\r\n22/03/20 21:59:22 INFO DAGScheduler: failed: Set()\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting ResultStage 989 (MapPartitionsRDD[2131] at distinct at BaseSparkUpdateStrategy.java:51), which has no missing parents\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_853 stored as values in memory (estimated size 6.3 KiB, free 357.9 MiB)\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_853_piece0 stored as bytes in memory (estimated size 3.4 KiB, free 357.9 MiB)\r\n22/03/20 21:59:22 INFO BlockManagerInfo: Added broadcast_853_piece0 in memory on rkalluri.attlocal.net:63252 (size: 3.4 KiB, free: 364.1 MiB)\r\n22/03/20 21:59:22 INFO SparkContext: Created broadcast 853 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 989 (MapPartitionsRDD[2131] at distinct at BaseSparkUpdateStrategy.java:51) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Adding task set 989.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 989.0 (TID 2271) (rkalluri.attlocal.net, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:22 INFO Executor: Running task 0.0 in stage 989.0 (TID 2271)\r\n22/03/20 21:59:22 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\r\n22/03/20 21:59:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\r\n22/03/20 21:59:22 INFO Executor: Finished task 0.0 in stage 989.0 (TID 2271). 1249 bytes result sent to driver\r\n22/03/20 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 989.0 (TID 2271) in 4 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 989.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:22 INFO DAGScheduler: ResultStage 989 (collect at BaseSparkUpdateStrategy.java:51) finished in 0.005 s\r\n22/03/20 21:59:22 INFO DAGScheduler: Job 683 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 989: Stage finished\r\n22/03/20 21:59:22 INFO DAGScheduler: Job 683 finished: collect at BaseSparkUpdateStrategy.java:51, took 0.012885 s\r\n22/03/20 21:59:22 INFO BaseSparkCommitActionExecutor: no validators configured.\r\n22/03/20 21:59:22 INFO BaseCommitActionExecutor: Auto commit enabled: Committing 20220320215909174\r\n22/03/20 21:59:22 INFO SparkContext: Starting job: collect at BaseSparkCommitActionExecutor.java:275\r\n22/03/20 21:59:22 INFO DAGScheduler: Registering RDD 2132 (mapToPair at BaseSparkCommitActionExecutor.java:227) as input to shuffle 184\r\n22/03/20 21:59:22 INFO DAGScheduler: Got job 684 (collect at BaseSparkCommitActionExecutor.java:275) with 1 output partitions\r\n22/03/20 21:59:22 INFO DAGScheduler: Final stage: ResultStage 991 (collect at BaseSparkCommitActionExecutor.java:275)\r\n22/03/20 21:59:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 990)\r\n22/03/20 21:59:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 990)\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting ShuffleMapStage 990 (MapPartitionsRDD[2132] at mapToPair at BaseSparkCommitActionExecutor.java:227), which has no missing parents\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_854 stored as values in memory (estimated size 332.8 KiB, free 357.6 MiB)\r\n22/03/20 21:59:22 INFO MemoryStore: Block broadcast_854_piece0 stored as bytes in memory (estimated size 119.4 KiB, free 357.4 MiB)\r\n22/03/20 21:59:22 INFO BlockManagerInfo: Added broadcast_854_piece0 in memory on rkalluri.attlocal.net:63252 (size: 119.4 KiB, free: 364.0 MiB)\r\n22/03/20 21:59:22 INFO SparkContext: Created broadcast 854 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 990 (MapPartitionsRDD[2132] at mapToPair at BaseSparkCommitActionExecutor.java:227) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Adding task set 990.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 990.0 (TID 2272) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4800 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:22 INFO Executor: Running task 0.0 in stage 990.0 (TID 2272)\r\n22/03/20 21:59:22 INFO BlockManager: Found block rdd_2121_0 locally\r\n22/03/20 21:59:22 INFO Executor: Finished task 0.0 in stage 990.0 (TID 2272). 1052 bytes result sent to driver\r\n22/03/20 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 990.0 (TID 2272) in 19 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 990.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:22 INFO DAGScheduler: ShuffleMapStage 990 (mapToPair at BaseSparkCommitActionExecutor.java:227) finished in 0.073 s\r\n22/03/20 21:59:22 INFO DAGScheduler: looking for newly runnable stages\r\n22/03/20 21:59:22 INFO DAGScheduler: running: Set()\r\n22/03/20 21:59:22 INFO DAGScheduler: waiting: Set(ResultStage 991)\r\n22/03/20 21:59:22 INFO DAGScheduler: failed: Set()\r\n22/03/20 21:59:22 INFO DAGScheduler: Submitting ResultStage 991 (MapPartitionsRDD[2137] at map at BaseSparkCommitActionExecutor.java:275), which has no missing parents\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_855 stored as values in memory (estimated size 435.7 KiB, free 357.0 MiB)\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_855_piece0 stored as bytes in memory (estimated size 156.4 KiB, free 356.9 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Added broadcast_855_piece0 in memory on rkalluri.attlocal.net:63252 (size: 156.4 KiB, free: 363.8 MiB)\r\n22/03/20 21:59:23 INFO SparkContext: Created broadcast 855 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 991 (MapPartitionsRDD[2137] at map at BaseSparkCommitActionExecutor.java:275) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Adding task set 991.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 991.0 (TID 2273) (rkalluri.attlocal.net, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:23 INFO Executor: Running task 0.0 in stage 991.0 (TID 2273)\r\n22/03/20 21:59:23 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\r\n22/03/20 21:59:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\r\n22/03/20 21:59:23 INFO BaseSparkDeltaCommitActionExecutor: Merging updates for commit 20220320215909174 for file files-0000\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating View Manager with storage type :MEMORY\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating in-memory based Table View\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating InMemory based view for basePath file:/tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:23 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:23 INFO AbstractTableFileSystemView: Building file system view for partition (files)\r\n22/03/20 21:59:23 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=14, NumFileGroups=1, FileGroupsCreationTime=1, StoreTimeTaken=0\r\n22/03/20 21:59:23 INFO DirectWriteMarkers: Creating Marker Path=file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/.temp/20220320215909174/files/files-0000_0-991-2273_20220320215907162001.hfile.marker.APPEND\r\n22/03/20 21:59:23 INFO DirectWriteMarkers: [direct] Created marker file file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/.temp/20220320215909174/files/files-0000_0-991-2273_20220320215907162001.hfile.marker.APPEND in 23 ms\r\n22/03/20 21:59:23 INFO HoodieLogFormat$WriterBuilder: Building HoodieLogFormat Writer\r\n22/03/20 21:59:23 INFO HoodieLogFormat$WriterBuilder: HoodieLogFile on path file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.1_0-975-2255\r\n22/03/20 21:59:23 INFO HoodieLogFormatWriter: Append not supported.. Rolling over to HoodieLogFile{pathStr='file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.2_0-991-2273', fileLen=-1}\r\n22/03/20 21:59:23 INFO CacheConfig: Created cacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=392960, freeSize=381498432, maxSize=381891392, heapSize=392960, minSize=362796832, minFactor=0.95, multiSize=181398416, multiFactor=0.5, singleSize=90699208, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false\r\n22/03/20 21:59:23 INFO CodecPool: Got brand-new compressor [.gz]\r\n22/03/20 21:59:23 INFO CodecPool: Got brand-new compressor [.gz]\r\n22/03/20 21:59:23 INFO HoodieAppendHandle: AppendHandle for partitionPath files filePath files/.files-0000_20220320215907162001.log.2_0-991-2273, took 47 ms.\r\n22/03/20 21:59:23 INFO MemoryStore: Block rdd_2136_0 stored as values in memory (estimated size 339.0 B, free 356.9 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Added rdd_2136_0 in memory on rkalluri.attlocal.net:63252 (size: 339.0 B, free: 363.8 MiB)\r\n22/03/20 21:59:23 INFO Executor: Finished task 0.0 in stage 991.0 (TID 2273). 1635 bytes result sent to driver\r\n22/03/20 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 991.0 (TID 2273) in 72 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 991.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:23 INFO DAGScheduler: ResultStage 991 (collect at BaseSparkCommitActionExecutor.java:275) finished in 0.145 s\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 684 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 991: Stage finished\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 684 finished: collect at BaseSparkCommitActionExecutor.java:275, took 0.219633 s\r\n22/03/20 21:59:23 INFO CommitUtils: Creating  metadata for UPSERT_PREPPED numWriteStats:1numReplaceFileIds:0\r\n22/03/20 21:59:23 INFO SparkContext: Starting job: collect at BaseSparkCommitActionExecutor.java:283\r\n22/03/20 21:59:23 INFO DAGScheduler: Got job 685 (collect at BaseSparkCommitActionExecutor.java:283) with 1 output partitions\r\n22/03/20 21:59:23 INFO DAGScheduler: Final stage: ResultStage 993 (collect at BaseSparkCommitActionExecutor.java:283)\r\n22/03/20 21:59:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 992)\r\n22/03/20 21:59:23 INFO DAGScheduler: Missing parents: List()\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting ResultStage 993 (MapPartitionsRDD[2138] at map at BaseSparkCommitActionExecutor.java:283), which has no missing parents\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_856 stored as values in memory (estimated size 435.7 KiB, free 356.4 MiB)\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_856_piece0 stored as bytes in memory (estimated size 156.4 KiB, free 356.3 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Added broadcast_856_piece0 in memory on rkalluri.attlocal.net:63252 (size: 156.4 KiB, free: 363.7 MiB)\r\n22/03/20 21:59:23 INFO SparkContext: Created broadcast 856 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 993 (MapPartitionsRDD[2138] at map at BaseSparkCommitActionExecutor.java:283) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Adding task set 993.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 993.0 (TID 2274) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:23 INFO Executor: Running task 0.0 in stage 993.0 (TID 2274)\r\n22/03/20 21:59:23 INFO BlockManager: Found block rdd_2136_0 locally\r\n22/03/20 21:59:23 INFO Executor: Finished task 0.0 in stage 993.0 (TID 2274). 1248 bytes result sent to driver\r\n22/03/20 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 993.0 (TID 2274) in 20 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 993.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:23 INFO DAGScheduler: ResultStage 993 (collect at BaseSparkCommitActionExecutor.java:283) finished in 0.092 s\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 685 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 993: Stage finished\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 685 finished: collect at BaseSparkCommitActionExecutor.java:283, took 0.093105 s\r\n22/03/20 21:59:23 INFO BaseSparkCommitActionExecutor: Committing 20220320215909174, action Type deltacommit, operation Type UPSERT_PREPPED\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Removed broadcast_851_piece0 on rkalluri.attlocal.net:63252 in memory (size: 116.9 KiB, free: 363.8 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Removed broadcast_856_piece0 on rkalluri.attlocal.net:63252 in memory (size: 156.4 KiB, free: 363.9 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Removed broadcast_849_piece0 on rkalluri.attlocal.net:63252 in memory (size: 5.2 KiB, free: 363.9 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Removed broadcast_854_piece0 on rkalluri.attlocal.net:63252 in memory (size: 119.4 KiB, free: 364.1 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Removed broadcast_853_piece0 on rkalluri.attlocal.net:63252 in memory (size: 3.4 KiB, free: 364.1 MiB)\r\n22/03/20 21:59:23 INFO SparkContext: Starting job: collect at HoodieSparkEngineContext.java:134\r\n22/03/20 21:59:23 INFO DAGScheduler: Got job 686 (collect at HoodieSparkEngineContext.java:134) with 1 output partitions\r\n22/03/20 21:59:23 INFO DAGScheduler: Final stage: ResultStage 994 (collect at HoodieSparkEngineContext.java:134)\r\n22/03/20 21:59:23 INFO DAGScheduler: Parents of final stage: List()\r\n22/03/20 21:59:23 INFO DAGScheduler: Missing parents: List()\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Removed broadcast_855_piece0 on rkalluri.attlocal.net:63252 in memory (size: 156.4 KiB, free: 364.2 MiB)\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting ResultStage 994 (MapPartitionsRDD[2140] at flatMap at HoodieSparkEngineContext.java:134), which has no missing parents\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Removed broadcast_852_piece0 on rkalluri.attlocal.net:63252 in memory (size: 5.1 KiB, free: 364.2 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Removed broadcast_850_piece0 on rkalluri.attlocal.net:63252 in memory (size: 3.1 KiB, free: 364.2 MiB)\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_857 stored as values in memory (estimated size 99.5 KiB, free 358.3 MiB)\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_857_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 358.2 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Added broadcast_857_piece0 in memory on rkalluri.attlocal.net:63252 (size: 35.1 KiB, free: 364.2 MiB)\r\n22/03/20 21:59:23 INFO SparkContext: Created broadcast 857 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 994 (MapPartitionsRDD[2140] at flatMap at HoodieSparkEngineContext.java:134) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Adding task set 994.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 994.0 (TID 2275) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4408 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:23 INFO Executor: Running task 0.0 in stage 994.0 (TID 2275)\r\n22/03/20 21:59:23 INFO Executor: Finished task 0.0 in stage 994.0 (TID 2275). 796 bytes result sent to driver\r\n22/03/20 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 994.0 (TID 2275) in 15 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 994.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:23 INFO DAGScheduler: ResultStage 994 (collect at HoodieSparkEngineContext.java:134) finished in 0.036 s\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 686 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 994: Stage finished\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 686 finished: collect at HoodieSparkEngineContext.java:134, took 0.035978 s\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Marking instant complete [==>20220320215909174__deltacommit__INFLIGHT]\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Checking for file exists ?file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/20220320215909174.deltacommit.inflight\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Create new file for toInstant ?file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/20220320215909174.deltacommit\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Completed [==>20220320215909174__deltacommit__INFLIGHT]\r\n22/03/20 21:59:23 INFO BaseSparkCommitActionExecutor: Committed 20220320215909174\r\n22/03/20 21:59:23 INFO SparkContext: Starting job: collectAsMap at HoodieSparkEngineContext.java:148\r\n22/03/20 21:59:23 INFO DAGScheduler: Got job 687 (collectAsMap at HoodieSparkEngineContext.java:148) with 1 output partitions\r\n22/03/20 21:59:23 INFO DAGScheduler: Final stage: ResultStage 995 (collectAsMap at HoodieSparkEngineContext.java:148)\r\n22/03/20 21:59:23 INFO DAGScheduler: Parents of final stage: List()\r\n22/03/20 21:59:23 INFO DAGScheduler: Missing parents: List()\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting ResultStage 995 (MapPartitionsRDD[2142] at mapToPair at HoodieSparkEngineContext.java:145), which has no missing parents\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_858 stored as values in memory (estimated size 99.7 KiB, free 358.1 MiB)\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_858_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 358.1 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Added broadcast_858_piece0 in memory on rkalluri.attlocal.net:63252 (size: 35.2 KiB, free: 364.1 MiB)\r\n22/03/20 21:59:23 INFO SparkContext: Created broadcast 858 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 995 (MapPartitionsRDD[2142] at mapToPair at HoodieSparkEngineContext.java:145) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Adding task set 995.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 995.0 (TID 2276) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4408 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:23 INFO Executor: Running task 0.0 in stage 995.0 (TID 2276)\r\n22/03/20 21:59:23 INFO Executor: Finished task 0.0 in stage 995.0 (TID 2276). 836 bytes result sent to driver\r\n22/03/20 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 995.0 (TID 2276) in 6 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 995.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:23 INFO DAGScheduler: ResultStage 995 (collectAsMap at HoodieSparkEngineContext.java:148) finished in 0.025 s\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 687 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 995: Stage finished\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 687 finished: collectAsMap at HoodieSparkEngineContext.java:148, took 0.026164 s\r\n22/03/20 21:59:23 INFO FSUtils: Removed directory at file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/.temp/20220320215909174\r\n22/03/20 21:59:23 INFO HoodieHeartbeatClient: Stopping heartbeat for instant 20220320215909174\r\n22/03/20 21:59:23 INFO HoodieHeartbeatClient: Stopped heartbeat for instant 20220320215909174\r\n22/03/20 21:59:23 INFO HeartbeatUtils: Deleted the heartbeat for instant 20220320215909174\r\n22/03/20 21:59:23 INFO HoodieHeartbeatClient: Deleted heartbeat file for instant 20220320215909174\r\n22/03/20 21:59:23 INFO SparkContext: Starting job: collect at SparkHoodieBackedTableMetadataWriter.java:154\r\n22/03/20 21:59:23 INFO DAGScheduler: Got job 688 (collect at SparkHoodieBackedTableMetadataWriter.java:154) with 1 output partitions\r\n22/03/20 21:59:23 INFO DAGScheduler: Final stage: ResultStage 997 (collect at SparkHoodieBackedTableMetadataWriter.java:154)\r\n22/03/20 21:59:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 996)\r\n22/03/20 21:59:23 INFO DAGScheduler: Missing parents: List()\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting ResultStage 997 (MapPartitionsRDD[2136] at flatMap at BaseSparkCommitActionExecutor.java:175), which has no missing parents\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_859 stored as values in memory (estimated size 435.3 KiB, free 357.7 MiB)\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_859_piece0 stored as bytes in memory (estimated size 156.3 KiB, free 357.5 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Added broadcast_859_piece0 in memory on rkalluri.attlocal.net:63252 (size: 156.3 KiB, free: 364.0 MiB)\r\n22/03/20 21:59:23 INFO SparkContext: Created broadcast 859 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 997 (MapPartitionsRDD[2136] at flatMap at BaseSparkCommitActionExecutor.java:175) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Adding task set 997.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 997.0 (TID 2277) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:23 INFO Executor: Running task 0.0 in stage 997.0 (TID 2277)\r\n22/03/20 21:59:23 INFO BlockManager: Found block rdd_2136_0 locally\r\n22/03/20 21:59:23 INFO Executor: Finished task 0.0 in stage 997.0 (TID 2277). 1328 bytes result sent to driver\r\n22/03/20 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 997.0 (TID 2277) in 20 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 997.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:23 INFO DAGScheduler: ResultStage 997 (collect at SparkHoodieBackedTableMetadataWriter.java:154) finished in 0.091 s\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 688 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 997: Stage finished\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 688 finished: collect at SparkHoodieBackedTableMetadataWriter.java:154, took 0.091996 s\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__deltacommit__COMPLETED]}\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__deltacommit__COMPLETED]}\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading Active commit timeline for file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__deltacommit__COMPLETED]}\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating View Manager with storage type :MEMORY\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating in-memory based Table View\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__deltacommit__COMPLETED]}\r\n22/03/20 21:59:23 INFO HoodieTimelineArchiver: No Instants to archive\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Marking instant complete [==>20220320215909174__commit__INFLIGHT]\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Checking for file exists ?file:/tmp/hudi_4635/.hoodie/20220320215909174.inflight\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Create new file for toInstant ?file:/tmp/hudi_4635/.hoodie/20220320215909174.commit\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Completed [==>20220320215909174__commit__INFLIGHT]\r\n22/03/20 21:59:23 INFO SparkContext: Starting job: collectAsMap at HoodieSparkEngineContext.java:148\r\n22/03/20 21:59:23 INFO DAGScheduler: Got job 689 (collectAsMap at HoodieSparkEngineContext.java:148) with 1 output partitions\r\n22/03/20 21:59:23 INFO DAGScheduler: Final stage: ResultStage 998 (collectAsMap at HoodieSparkEngineContext.java:148)\r\n22/03/20 21:59:23 INFO DAGScheduler: Parents of final stage: List()\r\n22/03/20 21:59:23 INFO DAGScheduler: Missing parents: List()\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting ResultStage 998 (MapPartitionsRDD[2144] at mapToPair at HoodieSparkEngineContext.java:145), which has no missing parents\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_860 stored as values in memory (estimated size 99.7 KiB, free 357.4 MiB)\r\n22/03/20 21:59:23 INFO MemoryStore: Block broadcast_860_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 357.4 MiB)\r\n22/03/20 21:59:23 INFO BlockManagerInfo: Added broadcast_860_piece0 in memory on rkalluri.attlocal.net:63252 (size: 35.2 KiB, free: 364.0 MiB)\r\n22/03/20 21:59:23 INFO SparkContext: Created broadcast 860 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 998 (MapPartitionsRDD[2144] at mapToPair at HoodieSparkEngineContext.java:145) (first 15 tasks are for partitions Vector(0))\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Adding task set 998.0 with 1 tasks resource profile 0\r\n22/03/20 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 998.0 (TID 2278) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4387 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:23 INFO Executor: Running task 0.0 in stage 998.0 (TID 2278)\r\n22/03/20 21:59:23 INFO Executor: Finished task 0.0 in stage 998.0 (TID 2278). 858 bytes result sent to driver\r\n22/03/20 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 998.0 (TID 2278) in 7 ms on rkalluri.attlocal.net (executor driver) (1/1)\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 998.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:23 INFO DAGScheduler: ResultStage 998 (collectAsMap at HoodieSparkEngineContext.java:148) finished in 0.026 s\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 689 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 998: Stage finished\r\n22/03/20 21:59:23 INFO DAGScheduler: Job 689 finished: collectAsMap at HoodieSparkEngineContext.java:148, took 0.026346 s\r\n22/03/20 21:59:23 INFO FSUtils: Removed directory at file:/tmp/hudi_4635/.hoodie/.temp/20220320215909174\r\n22/03/20 21:59:23 INFO BaseHoodieWriteClient: Start to clean synchronously.\r\n22/03/20 21:59:23 INFO CleanerUtils: Cleaned failed attempts if any\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading Active commit timeline for file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating View Manager with storage type :REMOTE_FIRST\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating remote first table view\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading Active commit timeline for file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating View Manager with storage type :REMOTE_FIRST\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating remote first table view\r\n22/03/20 21:59:23 INFO BaseHoodieWriteClient: Cleaner started\r\n22/03/20 21:59:23 INFO BaseHoodieWriteClient: Scheduling cleaning at instant time :20220320215923917\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading Active commit timeline for file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating View Manager with storage type :REMOTE_FIRST\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating remote first table view\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating remote view for basePath file:/tmp/hudi_4635. Server=rkalluri.attlocal.net:63594, Timeout=300\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating InMemory based view for basePath file:/tmp/hudi_4635\r\n22/03/20 21:59:23 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:23 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:23 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/refresh/?basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:23 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:23 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:23 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/compactions/pending/?basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:/tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:/tmp/hudi_4635\r\n22/03/20 21:59:23 INFO FileSystemViewManager: Creating InMemory based view for basePath file:/tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:23 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:23 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:23 INFO HoodieTableMetadataUtil: Loading latest merged file slices for metadata table partition files\r\n22/03/20 21:59:23 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__deltacommit__COMPLETED]}\r\n22/03/20 21:59:23 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:23 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:23 INFO AbstractTableFileSystemView: Building file system view for partition (files)\r\n22/03/20 21:59:23 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=15, NumFileGroups=1, FileGroupsCreationTime=1, StoreTimeTaken=0\r\n22/03/20 21:59:23 INFO CacheConfig: Created cacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=392960, freeSize=381498432, maxSize=381891392, heapSize=392960, minSize=362796832, minFactor=0.95, multiSize=181398416, multiFactor=0.5, singleSize=90699208, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false\r\n22/03/20 21:59:23 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:23 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:23 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:23 INFO HoodieBackedTableMetadata: Opened metadata base file from file:/tmp/hudi_4635/.hoodie/metadata/files/files-0000_0-966-2246_20220320215907162001.hfile at instant 20220320215907162001 in 1 ms\r\n22/03/20 21:59:24 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:24 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:24 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:24 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:24 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__deltacommit__COMPLETED]}\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Scanning log file HoodieLogFile{pathStr='file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.1_0-975-2255', fileLen=-1}\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Reading a data block from file file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.1_0-975-2255 at instant 20220320215908164\r\n22/03/20 21:59:24 INFO HoodieLogFormatReader: Moving to the next reader for logfile HoodieLogFile{pathStr='file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.2_0-991-2273', fileLen=-1}\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Scanning log file HoodieLogFile{pathStr='file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.2_0-991-2273', fileLen=-1}\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Reading a data block from file file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.2_0-991-2273 at instant 20220320215909174\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Number of remaining logblocks to merge 1\r\n22/03/20 21:59:24 INFO CacheConfig: Created cacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=392960, freeSize=381498432, maxSize=381891392, heapSize=392960, minSize=362796832, minFactor=0.95, multiSize=181398416, multiFactor=0.5, singleSize=90699208, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO ExternalSpillableMap: Estimated Payload size => 616\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Merging the final data blocks\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Number of remaining logblocks to merge 1\r\n22/03/20 21:59:24 INFO CacheConfig: Created cacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=392960, freeSize=381498432, maxSize=381891392, heapSize=392960, minSize=362796832, minFactor=0.95, multiSize=181398416, multiFactor=0.5, singleSize=90699208, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: Number of log files scanned => 2\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: MaxMemoryInBytes allowed for compaction => 1073741824\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: Number of entries in MemoryBasedMap in ExternalSpillableMap => 3\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: Total size in bytes of MemoryBasedMap in ExternalSpillableMap => 1848\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: Number of entries in BitCaskDiskMap in ExternalSpillableMap => 0\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: Size of file spilled to disk => 0\r\n22/03/20 21:59:24 INFO HoodieBackedTableMetadata: Opened 2 metadata log files (dataset instant=20220320215909174, metadata instant=20220320215909174) in 35 ms\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO BaseTableMetadata: Listed partitions from metadata: #partitions=5\r\n22/03/20 21:59:24 INFO CleanPlanner: Total Partitions to clean : 5, with policy KEEP_LATEST_COMMITS\r\n22/03/20 21:59:24 INFO CleanPlanner: Using cleanerParallelism: 5\r\n22/03/20 21:59:24 INFO SparkContext: Starting job: collect at HoodieSparkEngineContext.java:100\r\n22/03/20 21:59:24 INFO DAGScheduler: Got job 690 (collect at HoodieSparkEngineContext.java:100) with 5 output partitions\r\n22/03/20 21:59:24 INFO DAGScheduler: Final stage: ResultStage 999 (collect at HoodieSparkEngineContext.java:100)\r\n22/03/20 21:59:24 INFO DAGScheduler: Parents of final stage: List()\r\n22/03/20 21:59:24 INFO DAGScheduler: Missing parents: List()\r\n22/03/20 21:59:24 INFO DAGScheduler: Submitting ResultStage 999 (MapPartitionsRDD[2146] at map at HoodieSparkEngineContext.java:100), which has no missing parents\r\n22/03/20 21:59:24 INFO MemoryStore: Block broadcast_861 stored as values in memory (estimated size 556.0 KiB, free 356.8 MiB)\r\n22/03/20 21:59:24 INFO MemoryStore: Block broadcast_861_piece0 stored as bytes in memory (estimated size 196.7 KiB, free 356.7 MiB)\r\n22/03/20 21:59:24 INFO BlockManagerInfo: Added broadcast_861_piece0 in memory on rkalluri.attlocal.net:63252 (size: 196.7 KiB, free: 363.8 MiB)\r\n22/03/20 21:59:24 INFO SparkContext: Created broadcast 861 from broadcast at DAGScheduler.scala:1478\r\n22/03/20 21:59:24 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 999 (MapPartitionsRDD[2146] at map at HoodieSparkEngineContext.java:100) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))\r\n22/03/20 21:59:24 INFO TaskSchedulerImpl: Adding task set 999.0 with 5 tasks resource profile 0\r\n22/03/20 21:59:24 INFO TaskSetManager: Starting task 0.0 in stage 999.0 (TID 2279) (rkalluri.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 4344 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:24 INFO TaskSetManager: Starting task 1.0 in stage 999.0 (TID 2280) (rkalluri.attlocal.net, executor driver, partition 1, PROCESS_LOCAL, 4344 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:24 INFO TaskSetManager: Starting task 2.0 in stage 999.0 (TID 2281) (rkalluri.attlocal.net, executor driver, partition 2, PROCESS_LOCAL, 4344 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:24 INFO TaskSetManager: Starting task 3.0 in stage 999.0 (TID 2282) (rkalluri.attlocal.net, executor driver, partition 3, PROCESS_LOCAL, 4344 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:24 INFO TaskSetManager: Starting task 4.0 in stage 999.0 (TID 2283) (rkalluri.attlocal.net, executor driver, partition 4, PROCESS_LOCAL, 4344 bytes) taskResourceAssignments Map()\r\n22/03/20 21:59:24 INFO Executor: Running task 2.0 in stage 999.0 (TID 2281)\r\n22/03/20 21:59:24 INFO Executor: Running task 0.0 in stage 999.0 (TID 2279)\r\n22/03/20 21:59:24 INFO Executor: Running task 1.0 in stage 999.0 (TID 2280)\r\n22/03/20 21:59:24 INFO Executor: Running task 4.0 in stage 999.0 (TID 2283)\r\n22/03/20 21:59:24 INFO Executor: Running task 3.0 in stage 999.0 (TID 2282)\r\n22/03/20 21:59:24 INFO CleanPlanner: Cleaning HEF/20211215, retaining latest 10 commits.\r\n22/03/20 21:59:24 INFO CleanPlanner: Cleaning DEF/20211215, retaining latest 10 commits.\r\n22/03/20 21:59:24 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/filegroups/replaced/before/?partition=HEF%2F20211215&maxinstant=20220320215846736&basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:24 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/filegroups/replaced/before/?partition=DEF%2F20211215&maxinstant=20220320215846736&basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Building file system view for partition (HEF/20211215)\r\n22/03/20 21:59:24 INFO HoodieTableMetadataUtil: Loading latest merged file slices for metadata table partition files\r\n22/03/20 21:59:24 INFO CleanPlanner: Cleaning GEF/20211215, retaining latest 10 commits.\r\n22/03/20 21:59:24 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/filegroups/replaced/before/?partition=GEF%2F20211215&maxinstant=20220320215846736&basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Building file system view for partition (DEF/20211215)\r\n22/03/20 21:59:24 INFO HoodieTableMetadataUtil: Loading latest merged file slices for metadata table partition files\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Building file system view for partition (GEF/20211215)\r\n22/03/20 21:59:24 INFO HoodieTableMetadataUtil: Loading latest merged file slices for metadata table partition files\r\n22/03/20 21:59:24 INFO CleanPlanner: Cleaning EEF/20211215, retaining latest 10 commits.\r\n22/03/20 21:59:24 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/filegroups/replaced/before/?partition=EEF%2F20211215&maxinstant=20220320215846736&basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Building file system view for partition (EEF/20211215)\r\n22/03/20 21:59:24 INFO HoodieTableMetadataUtil: Loading latest merged file slices for metadata table partition files\r\n22/03/20 21:59:24 INFO CleanPlanner: Cleaning FEF/20211215, retaining latest 10 commits.\r\n22/03/20 21:59:24 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/filegroups/replaced/before/?partition=FEF%2F20211215&maxinstant=20220320215846736&basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Building file system view for partition (FEF/20211215)\r\n22/03/20 21:59:24 INFO HoodieTableMetadataUtil: Loading latest merged file slices for metadata table partition files\r\n22/03/20 21:59:24 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__deltacommit__COMPLETED]}\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Took 1 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Took 1 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Took 1 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Took 0 ms to read  0 instants, 0 replaced file groups\r\n22/03/20 21:59:24 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:24 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:24 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:24 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Building file system view for partition (files)\r\n22/03/20 21:59:24 INFO ClusteringUtils: Found 0 files in pending clustering operations\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Building file system view for partition (files)\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Building file system view for partition (files)\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Building file system view for partition (files)\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: Building file system view for partition (files)\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=15, NumFileGroups=1, FileGroupsCreationTime=2, StoreTimeTaken=0\r\n22/03/20 21:59:24 INFO CacheConfig: Created cacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=392960, freeSize=381498432, maxSize=381891392, heapSize=392960, minSize=362796832, minFactor=0.95, multiSize=181398416, multiFactor=0.5, singleSize=90699208, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO HoodieBackedTableMetadata: Opened metadata base file from file:/tmp/hudi_4635/.hoodie/metadata/files/files-0000_0-966-2246_20220320215907162001.hfile at instant 20220320215907162001 in 1 ms\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=15, NumFileGroups=1, FileGroupsCreationTime=3, StoreTimeTaken=0\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=15, NumFileGroups=1, FileGroupsCreationTime=3, StoreTimeTaken=0\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=15, NumFileGroups=1, FileGroupsCreationTime=3, StoreTimeTaken=0\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=15, NumFileGroups=1, FileGroupsCreationTime=3, StoreTimeTaken=0\r\n22/03/20 21:59:24 INFO BlockManagerInfo: Removed broadcast_859_piece0 on rkalluri.attlocal.net:63252 in memory (size: 156.3 KiB, free: 363.9 MiB)\r\n22/03/20 21:59:24 INFO BlockManagerInfo: Removed broadcast_857_piece0 on rkalluri.attlocal.net:63252 in memory (size: 35.1 KiB, free: 364.0 MiB)\r\n22/03/20 21:59:24 INFO BlockManagerInfo: Removed broadcast_860_piece0 on rkalluri.attlocal.net:63252 in memory (size: 35.2 KiB, free: 364.0 MiB)\r\n22/03/20 21:59:24 INFO BlockManagerInfo: Removed broadcast_858_piece0 on rkalluri.attlocal.net:63252 in memory (size: 35.2 KiB, free: 364.0 MiB)\r\n22/03/20 21:59:24 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:24 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:24 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:24 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:24 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__deltacommit__COMPLETED]}\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Scanning log file HoodieLogFile{pathStr='file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.1_0-975-2255', fileLen=-1}\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Reading a data block from file file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.1_0-975-2255 at instant 20220320215908164\r\n22/03/20 21:59:24 INFO HoodieLogFormatReader: Moving to the next reader for logfile HoodieLogFile{pathStr='file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.2_0-991-2273', fileLen=-1}\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Scanning log file HoodieLogFile{pathStr='file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.2_0-991-2273', fileLen=-1}\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Reading a data block from file file:/tmp/hudi_4635/.hoodie/metadata/files/.files-0000_20220320215907162001.log.2_0-991-2273 at instant 20220320215909174\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Number of remaining logblocks to merge 1\r\n22/03/20 21:59:24 INFO CacheConfig: Created cacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=392960, freeSize=381498432, maxSize=381891392, heapSize=392960, minSize=362796832, minFactor=0.95, multiSize=181398416, multiFactor=0.5, singleSize=90699208, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO ExternalSpillableMap: Estimated Payload size => 616\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Merging the final data blocks\r\n22/03/20 21:59:24 INFO AbstractHoodieLogRecordReader: Number of remaining logblocks to merge 1\r\n22/03/20 21:59:24 INFO CacheConfig: Created cacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=392960, freeSize=381498432, maxSize=381891392, heapSize=392960, minSize=362796832, minFactor=0.95, multiSize=181398416, multiFactor=0.5, singleSize=90699208, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: Number of log files scanned => 2\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: MaxMemoryInBytes allowed for compaction => 1073741824\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: Number of entries in MemoryBasedMap in ExternalSpillableMap => 3\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: Total size in bytes of MemoryBasedMap in ExternalSpillableMap => 1848\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: Number of entries in BitCaskDiskMap in ExternalSpillableMap => 0\r\n22/03/20 21:59:24 INFO HoodieMergedLogRecordScanner: Size of file spilled to disk => 0\r\n22/03/20 21:59:24 INFO HoodieBackedTableMetadata: Opened 2 metadata log files (dataset instant=20220320215909174, metadata instant=20220320215909174) in 36 ms\r\n22/03/20 21:59:24 INFO CodecPool: Got brand-new decompressor [.gz]\r\n22/03/20 21:59:24 INFO BaseTableMetadata: Listed file in partition from metadata: partition=GEF/20211215, #files=9\r\n22/03/20 21:59:24 INFO BaseTableMetadata: Listed file in partition from metadata: partition=HEF/20211215, #files=9\r\n22/03/20 21:59:24 INFO BaseTableMetadata: Listed file in partition from metadata: partition=FEF/20211215, #files=9\r\n22/03/20 21:59:24 INFO BaseTableMetadata: Listed file in partition from metadata: partition=EEF/20211215, #files=9\r\n22/03/20 21:59:24 INFO BaseTableMetadata: Listed file in partition from metadata: partition=DEF/20211215, #files=10\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=9, NumFileGroups=9, FileGroupsCreationTime=0, StoreTimeTaken=0\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=9, NumFileGroups=9, FileGroupsCreationTime=0, StoreTimeTaken=0\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=9, NumFileGroups=9, FileGroupsCreationTime=1, StoreTimeTaken=0\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=9, NumFileGroups=9, FileGroupsCreationTime=1, StoreTimeTaken=0\r\n22/03/20 21:59:24 INFO AbstractTableFileSystemView: addFilesToView: NumFiles=10, NumFileGroups=10, FileGroupsCreationTime=1, StoreTimeTaken=0\r\n22/03/20 21:59:24 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/filegroups/all/partition/?partition=GEF%2F20211215&basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:24 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/filegroups/all/partition/?partition=FEF%2F20211215&basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:24 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/filegroups/all/partition/?partition=DEF%2F20211215&basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:24 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/filegroups/all/partition/?partition=EEF%2F20211215&basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:24 INFO RemoteHoodieTableFileSystemView: Sending request : (http://rkalluri.attlocal.net:63594/v1/hoodie/view/filegroups/all/partition/?partition=HEF%2F20211215&basepath=file%3A%2Ftmp%2Fhudi_4635&lastinstantts=20220320215909174&timelinehash=6d633da951dc97b80f9b1ab40bb28007857d183169e822cc8b2d05907b903876)\r\n22/03/20 21:59:24 INFO CleanPlanner: 0 patterns used to delete in partition path:DEF/20211215\r\n22/03/20 21:59:24 INFO CleanPlanner: 0 patterns used to delete in partition path:GEF/20211215\r\n22/03/20 21:59:24 INFO CleanPlanner: 0 patterns used to delete in partition path:EEF/20211215\r\n22/03/20 21:59:24 INFO Executor: Finished task 0.0 in stage 999.0 (TID 2279). 931 bytes result sent to driver\r\n22/03/20 21:59:24 INFO Executor: Finished task 3.0 in stage 999.0 (TID 2282). 931 bytes result sent to driver\r\n22/03/20 21:59:24 INFO CleanPlanner: 0 patterns used to delete in partition path:HEF/20211215\r\n22/03/20 21:59:24 INFO Executor: Finished task 1.0 in stage 999.0 (TID 2280). 931 bytes result sent to driver\r\n22/03/20 21:59:24 INFO CleanPlanner: 0 patterns used to delete in partition path:FEF/20211215\r\n22/03/20 21:59:24 INFO Executor: Finished task 4.0 in stage 999.0 (TID 2283). 931 bytes result sent to driver\r\n22/03/20 21:59:24 INFO TaskSetManager: Finished task 0.0 in stage 999.0 (TID 2279) in 125 ms on rkalluri.attlocal.net (executor driver) (1/5)\r\n22/03/20 21:59:24 INFO TaskSetManager: Finished task 3.0 in stage 999.0 (TID 2282) in 125 ms on rkalluri.attlocal.net (executor driver) (2/5)\r\n22/03/20 21:59:24 INFO Executor: Finished task 2.0 in stage 999.0 (TID 2281). 931 bytes result sent to driver\r\n22/03/20 21:59:24 INFO TaskSetManager: Finished task 1.0 in stage 999.0 (TID 2280) in 125 ms on rkalluri.attlocal.net (executor driver) (3/5)\r\n22/03/20 21:59:24 INFO TaskSetManager: Finished task 4.0 in stage 999.0 (TID 2283) in 125 ms on rkalluri.attlocal.net (executor driver) (4/5)\r\n22/03/20 21:59:24 INFO TaskSetManager: Finished task 2.0 in stage 999.0 (TID 2281) in 125 ms on rkalluri.attlocal.net (executor driver) (5/5)\r\n22/03/20 21:59:24 INFO TaskSchedulerImpl: Removed TaskSet 999.0, whose tasks have all completed, from pool\r\n22/03/20 21:59:24 INFO DAGScheduler: ResultStage 999 (collect at HoodieSparkEngineContext.java:100) finished in 0.213 s\r\n22/03/20 21:59:24 INFO DAGScheduler: Job 690 is finished. Cancelling potential speculative or zombie tasks for this job\r\n22/03/20 21:59:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 999: Stage finished\r\n22/03/20 21:59:24 INFO DAGScheduler: Job 690 finished: collect at HoodieSparkEngineContext.java:100, took 0.213358 s\r\n22/03/20 21:59:24 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:24 INFO BaseHoodieWriteClient: Start to archive synchronously.\r\n22/03/20 21:59:24 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__commit__COMPLETED]}\r\n22/03/20 21:59:24 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635\r\n22/03/20 21:59:24 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/hoodie.properties\r\n22/03/20 21:59:24 INFO HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE(version=1, baseFileFormat=PARQUET) from file:///tmp/hudi_4635\r\n22/03/20 21:59:24 INFO HoodieTableMetaClient: Loading HoodieTableMetaClient from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:24 INFO HoodieTableConfig: Loading table properties from file:/tmp/hudi_4635/.hoodie/metadata/.hoodie/hoodie.properties\r\n22/03/20 21:59:24 INFO HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ(version=1, baseFileFormat=HFILE) from file:///tmp/hudi_4635/.hoodie/metadata\r\n22/03/20 21:59:24 INFO HoodieActiveTimeline: Loaded instants upto : Option{val=[20220320215909174__deltacommit__COMPLETED]}\r\n22/03/20 21:59:24 INFO HoodieTimelineArchiver: Limiting archiving of instants to latest compaction on metadata table at 20220320215907162001\r\n22/03/20 21:59:24 INFO HoodieHeartbeatClient: Stopping heartbeat for instant 20220320215909174\r\n22/03/20 21:59:24 INFO HoodieHeartbeatClient: Stopped heartbeat for instant 20220320215909174\r\n22/03/20 21:59:24 INFO HeartbeatUtils: Deleted the heartbeat for instant 20220320215909174\r\n22/03/20 21:59:24 INFO HoodieHeartbeatClient: Deleted heartbeat file for instant 20220320215909174\r\n22/03/20 21:59:24 INFO TransactionManager: Transaction ending with transaction owner Option{val=[==>20220320215909174__commit__INFLIGHT]}\r\n22/03/20 21:59:24 INFO ZookeeperBasedLockProvider: RELEASING lock atZkBasePath = /hudi, lock key = None\r\n22/03/20 21:59:24 INFO ZookeeperBasedLockProvider: RELEASED lock atZkBasePath = /hudi, lock key = None\r\n22/03/20 21:59:24 INFO TransactionManager: Transaction ended with transaction owner Option{val=[==>20220320215909174__commit__INFLIGHT]}\r\nAn error occurred while calling o1843.save.\r\n: java.lang.NullPointerException\r\n\tat org.apache.hudi.client.HoodieTimelineArchiver.lambda$getInstantsToArchive$10(HoodieTimelineArchiver.java:452)\r\n\tat java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267)\r\n\tat java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)\r\n\tat java.util.stream.SliceOps$1$1.accept(SliceOps.java:204)\r\n\tat java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)\r\n\tat java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)\r\n\tat java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)\r\n\tat java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351)\r\n\tat java.util.stream.ReferencePipeline.forEachWithCancel(ReferencePipeline.java:126)\r\n\tat java.util.stream.AbstractPipeline.copyIntoWithCancel(AbstractPipeline.java:498)\r\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:485)\r\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)\r\n\tat java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312)\r\n\tat java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743)\r\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)\r\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)\r\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\r\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\r\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)\r\n\tat org.apache.hudi.client.HoodieTimelineArchiver.archiveIfRequired(HoodieTimelineArchiver.java:147)\r\n\tat org.apache.hudi.client.BaseHoodieWriteClient.archive(BaseHoodieWriteClient.java:818)\r\n\tat org.apache.hudi.client.BaseHoodieWriteClient.autoArchiveOnCommit(BaseHoodieWriteClient.java:572)\r\n\tat org.apache.hudi.client.BaseHoodieWriteClient.postCommit(BaseHoodieWriteClient.java:477)\r\n\tat org.apache.hudi.client.BaseHoodieWriteClient.commitStats(BaseHoodieWriteClient.java:212)\r\n\tat org.apache.hudi.client.SparkRDDWriteClient.commit(SparkRDDWriteClient.java:119)\r\n\tat org.apache.hudi.HoodieSparkSqlWriter$.commitAndPerformPostOperations(HoodieSparkSqlWriter.scala:667)\r\n\tat org.apache.hudi.HoodieSparkSqlWriter$.write(HoodieSparkSqlWriter.scala:299)\r\n\tat org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:162)\r\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\r\n\tat sun.reflect.GeneratedMethodAccessor224.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\r\n22/03/20 21:59:24 INFO SparkContext: Invoking stop() from shutdown hook\r\n22/03/20 21:59:24 INFO SparkUI: Stopped Spark web UI at http://rkalluri.attlocal.net:4040\r\n22/03/20 21:59:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\r\n22/03/20 21:59:24 INFO MemoryStore: MemoryStore cleared\r\n22/03/20 21:59:24 INFO BlockManager: BlockManager stopped\r\n22/03/20 21:59:24 INFO BlockManagerMaster: BlockManagerMaster stopped\r\n22/03/20 21:59:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\r\n22/03/20 21:59:24 INFO SparkContext: Successfully stopped SparkContext\r\n22/03/20 21:59:24 INFO ShutdownHookManager: Shutdown hook called","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073440851/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073452161","html_url":"https://github.com/apache/hudi/pull/5072#issuecomment-1073452161","issue_url":"https://api.github.com/repos/apache/hudi/issues/5072","id":1073452161,"node_id":"IC_kwDOBI7nWM4_-5SB","user":{"login":"XuQianJin-Stars","id":10494131,"node_id":"MDQ6VXNlcjEwNDk0MTMx","avatar_url":"https://avatars.githubusercontent.com/u/10494131?v=4","gravatar_id":"","url":"https://api.github.com/users/XuQianJin-Stars","html_url":"https://github.com/XuQianJin-Stars","followers_url":"https://api.github.com/users/XuQianJin-Stars/followers","following_url":"https://api.github.com/users/XuQianJin-Stars/following{/other_user}","gists_url":"https://api.github.com/users/XuQianJin-Stars/gists{/gist_id}","starred_url":"https://api.github.com/users/XuQianJin-Stars/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/XuQianJin-Stars/subscriptions","organizations_url":"https://api.github.com/users/XuQianJin-Stars/orgs","repos_url":"https://api.github.com/users/XuQianJin-Stars/repos","events_url":"https://api.github.com/users/XuQianJin-Stars/events{/privacy}","received_events_url":"https://api.github.com/users/XuQianJin-Stars/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T03:36:40Z","updated_at":"2022-03-21T03:36:40Z","author_association":"CONTRIBUTOR","body":"> > hi @danny0405 `bot.yml` add the flink multi version to build?\r\n> \r\n> Yes, can you help with that ? I tried to add it but find that there would be too many builds if i add in another dimension, there are already 2 dimensions now: spark and scala\r\n\r\nWell, I'll take time to think about it. There are other things at hand.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073452161/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073478422","html_url":"https://github.com/apache/hudi/pull/5079#issuecomment-1073478422","issue_url":"https://api.github.com/repos/apache/hudi/issues/5079","id":1073478422,"node_id":"IC_kwDOBI7nWM4_-_sW","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T04:36:44Z","updated_at":"2022-03-21T04:36:44Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"3abe4abed9cd81efd54fc9b6d19458f3cfdfc4d5\",\n    \"status\" : \"PENDING\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7117\",\n    \"triggerID\" : \"3abe4abed9cd81efd54fc9b6d19458f3cfdfc4d5\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 3abe4abed9cd81efd54fc9b6d19458f3cfdfc4d5 Azure: [PENDING](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7117) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073478422/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073504190","html_url":"https://github.com/apache/hudi/pull/2438#issuecomment-1073504190","issue_url":"https://api.github.com/repos/apache/hudi/issues/2438","id":1073504190,"node_id":"IC_kwDOBI7nWM4__F--","user":{"login":"liujinhui1994","id":25769285,"node_id":"MDQ6VXNlcjI1NzY5Mjg1","avatar_url":"https://avatars.githubusercontent.com/u/25769285?v=4","gravatar_id":"","url":"https://api.github.com/users/liujinhui1994","html_url":"https://github.com/liujinhui1994","followers_url":"https://api.github.com/users/liujinhui1994/followers","following_url":"https://api.github.com/users/liujinhui1994/following{/other_user}","gists_url":"https://api.github.com/users/liujinhui1994/gists{/gist_id}","starred_url":"https://api.github.com/users/liujinhui1994/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liujinhui1994/subscriptions","organizations_url":"https://api.github.com/users/liujinhui1994/orgs","repos_url":"https://api.github.com/users/liujinhui1994/repos","events_url":"https://api.github.com/users/liujinhui1994/events{/privacy}","received_events_url":"https://api.github.com/users/liujinhui1994/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T05:43:16Z","updated_at":"2022-03-21T05:43:16Z","author_association":"CONTRIBUTOR","body":"The purpose of introducing timestamps: Mainly when users want to consume from a certain location, deltastreamer can only specify checkpoint sites in the past. For example, kafka may have 50+ partitions, and users need to manually configure the checkpoint string. Introducing this simplifies this operation\r\n\r\nRegarding your example: I think you are right and agree with your idea. Partition 2 should not be populated with this value.\r\nAt that time, the main consideration of this PR was to solve the problem of complex user configuration. It can simplify consumption data as much as possible. This example of partition 2 makes sense for some businesses. Maybe your current scenario may be a bit contradictory, and I feel like we can improve it and make it better","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073504190/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073504409","html_url":"https://github.com/apache/hudi/pull/2438#issuecomment-1073504409","issue_url":"https://api.github.com/repos/apache/hudi/issues/2438","id":1073504409,"node_id":"IC_kwDOBI7nWM4__GCZ","user":{"login":"liujinhui1994","id":25769285,"node_id":"MDQ6VXNlcjI1NzY5Mjg1","avatar_url":"https://avatars.githubusercontent.com/u/25769285?v=4","gravatar_id":"","url":"https://api.github.com/users/liujinhui1994","html_url":"https://github.com/liujinhui1994","followers_url":"https://api.github.com/users/liujinhui1994/followers","following_url":"https://api.github.com/users/liujinhui1994/following{/other_user}","gists_url":"https://api.github.com/users/liujinhui1994/gists{/gist_id}","starred_url":"https://api.github.com/users/liujinhui1994/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liujinhui1994/subscriptions","organizations_url":"https://api.github.com/users/liujinhui1994/orgs","repos_url":"https://api.github.com/users/liujinhui1994/repos","events_url":"https://api.github.com/users/liujinhui1994/events{/privacy}","received_events_url":"https://api.github.com/users/liujinhui1994/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T05:43:59Z","updated_at":"2022-03-21T05:43:59Z","author_association":"CONTRIBUTOR","body":"@pratyakshsharma ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073504409/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073526561","html_url":"https://github.com/apache/hudi/pull/5048#issuecomment-1073526561","issue_url":"https://api.github.com/repos/apache/hudi/issues/5048","id":1073526561,"node_id":"IC_kwDOBI7nWM4__Lch","user":{"login":"boneanxs","id":10115332,"node_id":"MDQ6VXNlcjEwMTE1MzMy","avatar_url":"https://avatars.githubusercontent.com/u/10115332?v=4","gravatar_id":"","url":"https://api.github.com/users/boneanxs","html_url":"https://github.com/boneanxs","followers_url":"https://api.github.com/users/boneanxs/followers","following_url":"https://api.github.com/users/boneanxs/following{/other_user}","gists_url":"https://api.github.com/users/boneanxs/gists{/gist_id}","starred_url":"https://api.github.com/users/boneanxs/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/boneanxs/subscriptions","organizations_url":"https://api.github.com/users/boneanxs/orgs","repos_url":"https://api.github.com/users/boneanxs/repos","events_url":"https://api.github.com/users/boneanxs/events{/privacy}","received_events_url":"https://api.github.com/users/boneanxs/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T06:38:48Z","updated_at":"2022-03-21T06:38:48Z","author_association":"CONTRIBUTOR","body":"@yihua Can you take a look at this issue, I think this is a common user case and could cause data lose for downstreams.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073526561/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073627475","html_url":"https://github.com/apache/hudi/issues/5053#issuecomment-1073627475","issue_url":"https://api.github.com/repos/apache/hudi/issues/5053","id":1073627475,"node_id":"IC_kwDOBI7nWM4__kFT","user":{"login":"worf0815","id":10959555,"node_id":"MDQ6VXNlcjEwOTU5NTU1","avatar_url":"https://avatars.githubusercontent.com/u/10959555?v=4","gravatar_id":"","url":"https://api.github.com/users/worf0815","html_url":"https://github.com/worf0815","followers_url":"https://api.github.com/users/worf0815/followers","following_url":"https://api.github.com/users/worf0815/following{/other_user}","gists_url":"https://api.github.com/users/worf0815/gists{/gist_id}","starred_url":"https://api.github.com/users/worf0815/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/worf0815/subscriptions","organizations_url":"https://api.github.com/users/worf0815/orgs","repos_url":"https://api.github.com/users/worf0815/repos","events_url":"https://api.github.com/users/worf0815/events{/privacy}","received_events_url":"https://api.github.com/users/worf0815/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T08:31:49Z","updated_at":"2022-03-21T08:31:49Z","author_association":"NONE","body":"@rkkalluri  I can confirm with above settings using hudi 0.10.1 everything works as expected :)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073627475/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073712400","html_url":"https://github.com/apache/hudi/issues/4635#issuecomment-1073712400","issue_url":"https://api.github.com/repos/apache/hudi/issues/4635","id":1073712400,"node_id":"IC_kwDOBI7nWM4__40Q","user":{"login":"VIKASPATID","id":6930082,"node_id":"MDQ6VXNlcjY5MzAwODI=","avatar_url":"https://avatars.githubusercontent.com/u/6930082?v=4","gravatar_id":"","url":"https://api.github.com/users/VIKASPATID","html_url":"https://github.com/VIKASPATID","followers_url":"https://api.github.com/users/VIKASPATID/followers","following_url":"https://api.github.com/users/VIKASPATID/following{/other_user}","gists_url":"https://api.github.com/users/VIKASPATID/gists{/gist_id}","starred_url":"https://api.github.com/users/VIKASPATID/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/VIKASPATID/subscriptions","organizations_url":"https://api.github.com/users/VIKASPATID/orgs","repos_url":"https://api.github.com/users/VIKASPATID/repos","events_url":"https://api.github.com/users/VIKASPATID/events{/privacy}","received_events_url":"https://api.github.com/users/VIKASPATID/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T10:08:44Z","updated_at":"2022-03-21T10:08:44Z","author_association":"NONE","body":"> sorry. could not get time to repro this. I don't have exp w/ pyspark. I just saved the script to rep.py and tried to execute the spark-submit. but running into failures.\r\n> \r\n> ```\r\n> :: resolution report :: resolve 255ms :: artifacts dl 5ms\r\n> \t:: modules in use:\r\n> \torg.apache.hudi#hudi-spark-bundle_2.11;0.10.1 from local-m2-cache in [default]\r\n> \torg.apache.spark#spark-avro_2.11;2.4.4 from local-m2-cache in [default]\r\n> \torg.spark-project.spark#unused;1.0.0 from local-m2-cache in [default]\r\n> \t---------------------------------------------------------------------\r\n> \t|                  |            modules            ||   artifacts   |\r\n> \t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\r\n> \t---------------------------------------------------------------------\r\n> \t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\r\n> \t---------------------------------------------------------------------\r\n> :: retrieving :: org.apache.spark#spark-submit-parent-a3077db6-05fc-4539-ab07-7fcdba4e85ba\r\n> \tconfs: [default]\r\n> \t0 artifacts copied, 3 already retrieved (0kB/5ms)\r\n> 22/03/19 14:05:28 WARN Utils: Your hostname, Sivabalans-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.5 instead (on interface en0)\r\n> 22/03/19 14:05:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\r\n> 22/03/19 14:05:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n>   File \"/tmp/rep.py\", line 26\r\n>     'hoodie.write.lock.zookeeper.lock_key': f\"{table_name}\",\r\n>                                                           ^\r\n> SyntaxError: invalid syntax\r\n> log4j:WARN No appenders could be found for logger (org.apache.spark.util.ShutdownHookManager).\r\n> log4j:WARN Please initialize the log4j system properly.\r\n> log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\r\n> ```\r\n> \r\n> Or should I launch pyspark and run through the commands you have given above.\r\n\r\nyeah, please launch pyspark and try.\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073712400/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073770671","html_url":"https://github.com/apache/hudi/issues/5000#issuecomment-1073770671","issue_url":"https://api.github.com/repos/apache/hudi/issues/5000","id":1073770671,"node_id":"IC_kwDOBI7nWM5AAHCv","user":{"login":"arunb2w","id":38204827,"node_id":"MDQ6VXNlcjM4MjA0ODI3","avatar_url":"https://avatars.githubusercontent.com/u/38204827?v=4","gravatar_id":"","url":"https://api.github.com/users/arunb2w","html_url":"https://github.com/arunb2w","followers_url":"https://api.github.com/users/arunb2w/followers","following_url":"https://api.github.com/users/arunb2w/following{/other_user}","gists_url":"https://api.github.com/users/arunb2w/gists{/gist_id}","starred_url":"https://api.github.com/users/arunb2w/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arunb2w/subscriptions","organizations_url":"https://api.github.com/users/arunb2w/orgs","repos_url":"https://api.github.com/users/arunb2w/repos","events_url":"https://api.github.com/users/arunb2w/events{/privacy}","received_events_url":"https://api.github.com/users/arunb2w/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T11:13:26Z","updated_at":"2022-03-21T11:15:38Z","author_association":"NONE","body":"@nsivabalan When i was searching through the internet, i came across this ticket for partial update payload https://github.com/apache/hudi/issues/2637 so i tried to use that payload class for my above usecase to see how it behaves\r\nbut am facing below error.\r\nCaused by: java.lang.ClassNotFoundException: org.apache.hudi.common.model.PartialUpdatePayload\r\nDoes this mean this payload class is not yet deployed to production?\r\nWhen i checked the old ticket it was closed so i thought it is already updated and this payload class is available already.\r\n\r\nThis is the way am running my job\r\n\r\n> spark-submit --master local --packages org.apache.hudi:hudi-spark3.1.2-bundle_2.12:0.10.1,org.apache.spark:spark-avro_2.12:3.1.2 --conf 'spark.serializer=org.apache.spark.serializer.KryoSerializer' --driver-memory 1g --executor-memory 1g main.py  -f /Users/parunkarthick/samepk_insert_mupdates.json \r\n\r\n\r\nMy hudi options:\r\n\r\n> 'hoodie.table.name': tableName,\r\n> 'hoodie.datasource.write.recordkey.field': 'KEY',\r\n> 'hoodie.datasource.write.partitionpath.field': 'partition_field',\r\n> 'hoodie.datasource.write.table.name': tableName,\r\n> 'hoodie.datasource.write.operation': 'upsert',\r\n> 'hoodie.datasource.write.payload.class': 'org.apache.hudi.common.model.PartialUpdatePayload',\r\n> 'hoodie.datasource.write.table.type': write_type,\r\n> 'hoodie.datasource.write.precombine.field': 'VERSION',\r\n> 'hoodie.upsert.shuffle.parallelism': 2,\r\n> 'hoodie.insert.shuffle.parallelism': 2\r\n\r\nPlease let me know whether am doing something wrong and why am getting the class not found exception.\r\nThanks\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073770671/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073798280","html_url":"https://github.com/apache/hudi/issues/5058#issuecomment-1073798280","issue_url":"https://api.github.com/repos/apache/hudi/issues/5058","id":1073798280,"node_id":"IC_kwDOBI7nWM5AANyI","user":{"login":"ksrihari93","id":31289318,"node_id":"MDQ6VXNlcjMxMjg5MzE4","avatar_url":"https://avatars.githubusercontent.com/u/31289318?v=4","gravatar_id":"","url":"https://api.github.com/users/ksrihari93","html_url":"https://github.com/ksrihari93","followers_url":"https://api.github.com/users/ksrihari93/followers","following_url":"https://api.github.com/users/ksrihari93/following{/other_user}","gists_url":"https://api.github.com/users/ksrihari93/gists{/gist_id}","starred_url":"https://api.github.com/users/ksrihari93/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ksrihari93/subscriptions","organizations_url":"https://api.github.com/users/ksrihari93/orgs","repos_url":"https://api.github.com/users/ksrihari93/repos","events_url":"https://api.github.com/users/ksrihari93/events{/privacy}","received_events_url":"https://api.github.com/users/ksrihari93/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T11:47:36Z","updated_at":"2022-03-21T11:48:07Z","author_association":"NONE","body":"Hi @nsivabalan ,\r\nIs there any temporary fix for this issue? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073798280/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073799596","html_url":"https://github.com/apache/hudi/issues/5058#issuecomment-1073799596","issue_url":"https://api.github.com/repos/apache/hudi/issues/5058","id":1073799596,"node_id":"IC_kwDOBI7nWM5AAOGs","user":{"login":"ksrihari93","id":31289318,"node_id":"MDQ6VXNlcjMxMjg5MzE4","avatar_url":"https://avatars.githubusercontent.com/u/31289318?v=4","gravatar_id":"","url":"https://api.github.com/users/ksrihari93","html_url":"https://github.com/ksrihari93","followers_url":"https://api.github.com/users/ksrihari93/followers","following_url":"https://api.github.com/users/ksrihari93/following{/other_user}","gists_url":"https://api.github.com/users/ksrihari93/gists{/gist_id}","starred_url":"https://api.github.com/users/ksrihari93/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ksrihari93/subscriptions","organizations_url":"https://api.github.com/users/ksrihari93/orgs","repos_url":"https://api.github.com/users/ksrihari93/repos","events_url":"https://api.github.com/users/ksrihari93/events{/privacy}","received_events_url":"https://api.github.com/users/ksrihari93/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T11:49:11Z","updated_at":"2022-03-21T11:49:11Z","author_association":"NONE","body":"> Hudi only support schema evolution when Add a new nullable column at root level at the end or inner struct (at the end). [schema_evolution](https://hudi.apache.org/docs/schema_evolution/) but you add column at the middle, in this case may need recreate hudi table?\r\n\r\n@nsivabalan  yes i can update the table ,but job it self is getting failed to write anymore data.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073799596/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073840063","html_url":"https://github.com/apache/hudi/pull/4507#issuecomment-1073840063","issue_url":"https://api.github.com/repos/apache/hudi/issues/4507","id":1073840063,"node_id":"IC_kwDOBI7nWM5AAX-_","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T12:35:51Z","updated_at":"2022-03-21T12:35:51Z","author_association":"MEMBER","body":"Key thing to verify here is that - compaction or cleaning does not affect the file slice that is part of the save point","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073840063/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073853627","html_url":"https://github.com/apache/hudi/pull/4542#issuecomment-1073853627","issue_url":"https://api.github.com/repos/apache/hudi/issues/4542","id":1073853627,"node_id":"IC_kwDOBI7nWM5AAbS7","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T12:49:20Z","updated_at":"2022-03-21T12:49:20Z","author_association":"MEMBER","body":"@xushiyan I think a better approach would be to provide a hudi-aws-bundle with all the different dependencies for aws separately? As @parisni points out as well, there are more issues here? Can we summarize how we are on master and if anything needs to be done before the release.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073853627/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073866571","html_url":"https://github.com/apache/hudi/pull/4507#issuecomment-1073866571","issue_url":"https://api.github.com/repos/apache/hudi/issues/4507","id":1073866571,"node_id":"IC_kwDOBI7nWM5AAedL","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T13:01:47Z","updated_at":"2022-03-21T13:01:47Z","author_association":"CONTRIBUTOR","body":"If we perform a savepoint from the CLI, while there are inflight writes or pending table services? \r\nA: Do you mean \"savepoint\" or \"restore\" in above question? If its \"savepoint\", savepoint can be done only on completed commit. so should not matter if there are any new write in flight. if you meant \"restore\", as we know, restore is a destructive operation and users are advised to stop all pipelines before they trigger restore. or can expect all queries to fail when they trigger restore. \r\n\r\nIn line 92, we only work with the base file view? how would this correctly restore the log data?\r\nA: yes, even I was surprised. Its mainly because of the way our cleaning and rollback works. Both works at file slice level. i..e cleaner will clean up only entire file slice(if entire file slice is eligible to be cleaned up). and rollback will remove/delete data and log files only if entire file slice is expected to be rolledback. If not, rollback will just do a append of log blocks. And so, we don't need to do any special handling for log files in general wrt savepoint and restore. \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073866571/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073869562","html_url":"https://github.com/apache/hudi/pull/4507#issuecomment-1073869562","issue_url":"https://api.github.com/repos/apache/hudi/issues/4507","id":1073869562,"node_id":"IC_kwDOBI7nWM5AAfL6","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T13:04:51Z","updated_at":"2022-03-21T13:04:51Z","author_association":"CONTRIBUTOR","body":"Key thing to verify here is that - compaction or cleaning does not affect the file slice that is part of the save point\r\nA: I understand cleaning should not affect the file slice as part of the savepoint. but don't quite get you why compaction should not ? can you please clarify. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073869562/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073995477","html_url":"https://github.com/apache/hudi/pull/5076#issuecomment-1073995477","issue_url":"https://api.github.com/repos/apache/hudi/issues/5076","id":1073995477,"node_id":"IC_kwDOBI7nWM5AA97V","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T14:50:48Z","updated_at":"2022-03-21T14:50:48Z","author_association":"MEMBER","body":"<img width=\"799\" alt=\"Screen Shot 2022-03-21 at 10 48 00 PM\" src=\"https://user-images.githubusercontent.com/2701446/159286752-3104ce31-c12d-483d-80c1-eea4ffcd7bca.png\">\r\n\r\nVerified running meta sync with `org.apache.hudi.aws.sync.AwsGlueCatalogSyncTool` and sync'ed to Glue table.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1073995477/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074049683","html_url":"https://github.com/apache/hudi/pull/4955#issuecomment-1074049683","issue_url":"https://api.github.com/repos/apache/hudi/issues/4955","id":1074049683,"node_id":"IC_kwDOBI7nWM5ABLKT","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T15:34:08Z","updated_at":"2022-03-21T15:34:08Z","author_association":"MEMBER","body":"> we should also be good to rename our spark3 bundles from hudi-spark3.2.1-bundle to hudi-spark3.2-bundles as we discussed.\r\n\r\n@xushiyan as well. let's avoid renaming bundles . It does cause some busy work and thrashing for users, when they just want to pick up a new version. e.g if they had a `HUDI_VERSION` in their build/deploy scripts, now they need to all adjust per new naming. \r\n\r\nIs the change to bundle names in this PR or a separate one? If so, can we just retain spark2, spark3, spark3.1 as bundle names? whats the plan","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074049683/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074181355","html_url":"https://github.com/apache/hudi/pull/4910#issuecomment-1074181355","issue_url":"https://api.github.com/repos/apache/hudi/issues/4910","id":1074181355,"node_id":"IC_kwDOBI7nWM5ABrTr","user":{"login":"xiarixiaoyao","id":13514703,"node_id":"MDQ6VXNlcjEzNTE0NzAz","avatar_url":"https://avatars.githubusercontent.com/u/13514703?v=4","gravatar_id":"","url":"https://api.github.com/users/xiarixiaoyao","html_url":"https://github.com/xiarixiaoyao","followers_url":"https://api.github.com/users/xiarixiaoyao/followers","following_url":"https://api.github.com/users/xiarixiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/xiarixiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/xiarixiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiarixiaoyao/subscriptions","organizations_url":"https://api.github.com/users/xiarixiaoyao/orgs","repos_url":"https://api.github.com/users/xiarixiaoyao/repos","events_url":"https://api.github.com/users/xiarixiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/xiarixiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T17:17:41Z","updated_at":"2022-03-21T17:17:41Z","author_association":"CONTRIBUTOR","body":"@bvaradar  addressed all comments,   could you pls help me review this PR again in your spare time Thank you very much.\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074181355/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074203927","html_url":"https://github.com/apache/hudi/pull/5084#issuecomment-1074203927","issue_url":"https://api.github.com/repos/apache/hudi/issues/5084","id":1074203927,"node_id":"IC_kwDOBI7nWM5ABw0X","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T17:29:45Z","updated_at":"2022-03-21T17:29:45Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"d35a58bbed6a910e8c6c8f259b7518a8386207eb\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7134\",\n    \"triggerID\" : \"d35a58bbed6a910e8c6c8f259b7518a8386207eb\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* d35a58bbed6a910e8c6c8f259b7518a8386207eb Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7134) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074203927/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074237528","html_url":"https://github.com/apache/hudi/pull/3808#issuecomment-1074237528","issue_url":"https://api.github.com/repos/apache/hudi/issues/3808","id":1074237528,"node_id":"IC_kwDOBI7nWM5AB5BY","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T18:01:42Z","updated_at":"2022-03-21T18:01:42Z","author_association":"MEMBER","body":"@bvaradar @xiarixiaoyao Please let me know if/when this is ready for a review. We plan to code freeze this friday","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074237528/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074237651","html_url":"https://github.com/apache/hudi/pull/3808#issuecomment-1074237651","issue_url":"https://api.github.com/repos/apache/hudi/issues/3808","id":1074237651,"node_id":"IC_kwDOBI7nWM5AB5DT","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T18:01:50Z","updated_at":"2022-03-21T18:01:50Z","author_association":"MEMBER","body":"cc @xushiyan ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074237651/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074444305","html_url":"https://github.com/apache/hudi/pull/4888#issuecomment-1074444305","issue_url":"https://api.github.com/repos/apache/hudi/issues/4888","id":1074444305,"node_id":"IC_kwDOBI7nWM5ACrgR","user":{"login":"alexeykudinkin","id":428277,"node_id":"MDQ6VXNlcjQyODI3Nw==","avatar_url":"https://avatars.githubusercontent.com/u/428277?v=4","gravatar_id":"","url":"https://api.github.com/users/alexeykudinkin","html_url":"https://github.com/alexeykudinkin","followers_url":"https://api.github.com/users/alexeykudinkin/followers","following_url":"https://api.github.com/users/alexeykudinkin/following{/other_user}","gists_url":"https://api.github.com/users/alexeykudinkin/gists{/gist_id}","starred_url":"https://api.github.com/users/alexeykudinkin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexeykudinkin/subscriptions","organizations_url":"https://api.github.com/users/alexeykudinkin/orgs","repos_url":"https://api.github.com/users/alexeykudinkin/repos","events_url":"https://api.github.com/users/alexeykudinkin/events{/privacy}","received_events_url":"https://api.github.com/users/alexeykudinkin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T21:35:32Z","updated_at":"2022-03-21T21:35:32Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074444305/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074445103","html_url":"https://github.com/apache/hudi/pull/4996#issuecomment-1074445103","issue_url":"https://api.github.com/repos/apache/hudi/issues/4996","id":1074445103,"node_id":"IC_kwDOBI7nWM5ACrsv","user":{"login":"alexeykudinkin","id":428277,"node_id":"MDQ6VXNlcjQyODI3Nw==","avatar_url":"https://avatars.githubusercontent.com/u/428277?v=4","gravatar_id":"","url":"https://api.github.com/users/alexeykudinkin","html_url":"https://github.com/alexeykudinkin","followers_url":"https://api.github.com/users/alexeykudinkin/followers","following_url":"https://api.github.com/users/alexeykudinkin/following{/other_user}","gists_url":"https://api.github.com/users/alexeykudinkin/gists{/gist_id}","starred_url":"https://api.github.com/users/alexeykudinkin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexeykudinkin/subscriptions","organizations_url":"https://api.github.com/users/alexeykudinkin/orgs","repos_url":"https://api.github.com/users/alexeykudinkin/repos","events_url":"https://api.github.com/users/alexeykudinkin/events{/privacy}","received_events_url":"https://api.github.com/users/alexeykudinkin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T21:36:31Z","updated_at":"2022-03-21T21:36:31Z","author_association":"CONTRIBUTOR","body":"@vinothchandar what test results are you referring to? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074445103/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074498225","html_url":"https://github.com/apache/hudi/pull/4910#issuecomment-1074498225","issue_url":"https://api.github.com/repos/apache/hudi/issues/4910","id":1074498225,"node_id":"IC_kwDOBI7nWM5AC4qx","user":{"login":"xiarixiaoyao","id":13514703,"node_id":"MDQ6VXNlcjEzNTE0NzAz","avatar_url":"https://avatars.githubusercontent.com/u/13514703?v=4","gravatar_id":"","url":"https://api.github.com/users/xiarixiaoyao","html_url":"https://github.com/xiarixiaoyao","followers_url":"https://api.github.com/users/xiarixiaoyao/followers","following_url":"https://api.github.com/users/xiarixiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/xiarixiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/xiarixiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiarixiaoyao/subscriptions","organizations_url":"https://api.github.com/users/xiarixiaoyao/orgs","repos_url":"https://api.github.com/users/xiarixiaoyao/repos","events_url":"https://api.github.com/users/xiarixiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/xiarixiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-21T22:51:18Z","updated_at":"2022-03-21T22:51:18Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074498225/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074541420","html_url":"https://github.com/apache/hudi/pull/4385#issuecomment-1074541420","issue_url":"https://api.github.com/repos/apache/hudi/issues/4385","id":1074541420,"node_id":"IC_kwDOBI7nWM5ADDNs","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T00:05:45Z","updated_at":"2022-03-22T00:05:45Z","author_association":"CONTRIBUTOR","body":"Have created a follow up patch for enhancing tests \r\nhttps://issues.apache.org/jira/browse/HUDI-3676\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074541420/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074565855","html_url":"https://github.com/apache/hudi/pull/4910#issuecomment-1074565855","issue_url":"https://api.github.com/repos/apache/hudi/issues/4910","id":1074565855,"node_id":"IC_kwDOBI7nWM5ADJLf","user":{"login":"xiarixiaoyao","id":13514703,"node_id":"MDQ6VXNlcjEzNTE0NzAz","avatar_url":"https://avatars.githubusercontent.com/u/13514703?v=4","gravatar_id":"","url":"https://api.github.com/users/xiarixiaoyao","html_url":"https://github.com/xiarixiaoyao","followers_url":"https://api.github.com/users/xiarixiaoyao/followers","following_url":"https://api.github.com/users/xiarixiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/xiarixiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/xiarixiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiarixiaoyao/subscriptions","organizations_url":"https://api.github.com/users/xiarixiaoyao/orgs","repos_url":"https://api.github.com/users/xiarixiaoyao/repos","events_url":"https://api.github.com/users/xiarixiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/xiarixiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T00:50:50Z","updated_at":"2022-03-22T00:50:50Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074565855/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074613660","html_url":"https://github.com/apache/hudi/pull/3599#issuecomment-1074613660","issue_url":"https://api.github.com/repos/apache/hudi/issues/3599","id":1074613660,"node_id":"IC_kwDOBI7nWM5ADU2c","user":{"login":"yuzhaojing","id":32435329,"node_id":"MDQ6VXNlcjMyNDM1MzI5","avatar_url":"https://avatars.githubusercontent.com/u/32435329?v=4","gravatar_id":"","url":"https://api.github.com/users/yuzhaojing","html_url":"https://github.com/yuzhaojing","followers_url":"https://api.github.com/users/yuzhaojing/followers","following_url":"https://api.github.com/users/yuzhaojing/following{/other_user}","gists_url":"https://api.github.com/users/yuzhaojing/gists{/gist_id}","starred_url":"https://api.github.com/users/yuzhaojing/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yuzhaojing/subscriptions","organizations_url":"https://api.github.com/users/yuzhaojing/orgs","repos_url":"https://api.github.com/users/yuzhaojing/repos","events_url":"https://api.github.com/users/yuzhaojing/events{/privacy}","received_events_url":"https://api.github.com/users/yuzhaojing/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T01:47:09Z","updated_at":"2022-03-22T01:47:09Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074613660/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074653488","html_url":"https://github.com/apache/hudi/pull/4996#issuecomment-1074653488","issue_url":"https://api.github.com/repos/apache/hudi/issues/4996","id":1074653488,"node_id":"IC_kwDOBI7nWM5ADekw","user":{"login":"alexeykudinkin","id":428277,"node_id":"MDQ6VXNlcjQyODI3Nw==","avatar_url":"https://avatars.githubusercontent.com/u/428277?v=4","gravatar_id":"","url":"https://api.github.com/users/alexeykudinkin","html_url":"https://github.com/alexeykudinkin","followers_url":"https://api.github.com/users/alexeykudinkin/followers","following_url":"https://api.github.com/users/alexeykudinkin/following{/other_user}","gists_url":"https://api.github.com/users/alexeykudinkin/gists{/gist_id}","starred_url":"https://api.github.com/users/alexeykudinkin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexeykudinkin/subscriptions","organizations_url":"https://api.github.com/users/alexeykudinkin/orgs","repos_url":"https://api.github.com/users/alexeykudinkin/repos","events_url":"https://api.github.com/users/alexeykudinkin/events{/privacy}","received_events_url":"https://api.github.com/users/alexeykudinkin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T02:26:10Z","updated_at":"2022-03-22T02:26:10Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074653488/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074654696","html_url":"https://github.com/apache/hudi/issues/5000#issuecomment-1074654696","issue_url":"https://api.github.com/repos/apache/hudi/issues/5000","id":1074654696,"node_id":"IC_kwDOBI7nWM5ADe3o","user":{"login":"YannByron","id":10036681,"node_id":"MDQ6VXNlcjEwMDM2Njgx","avatar_url":"https://avatars.githubusercontent.com/u/10036681?v=4","gravatar_id":"","url":"https://api.github.com/users/YannByron","html_url":"https://github.com/YannByron","followers_url":"https://api.github.com/users/YannByron/followers","following_url":"https://api.github.com/users/YannByron/following{/other_user}","gists_url":"https://api.github.com/users/YannByron/gists{/gist_id}","starred_url":"https://api.github.com/users/YannByron/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YannByron/subscriptions","organizations_url":"https://api.github.com/users/YannByron/orgs","repos_url":"https://api.github.com/users/YannByron/repos","events_url":"https://api.github.com/users/YannByron/events{/privacy}","received_events_url":"https://api.github.com/users/YannByron/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T02:26:39Z","updated_at":"2022-03-22T02:26:39Z","author_association":"CONTRIBUTOR","body":"> this falls more into dynamic schemas. https://issues.apache.org/jira/browse/HUDI-2175 we don't have support for now. @YannByron @XuQianJin-Stars : Is there a way we can achieve this via spark-sql dml.\r\n\r\n@nsivabalan spark-sql is just a wrapper to `write-core`.  we don't support this sense that apply each of the coming record to update the existing one. need to do some work for this. let me create a ticket to trace this.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074654696/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074656503","html_url":"https://github.com/apache/hudi/pull/4888#issuecomment-1074656503","issue_url":"https://api.github.com/repos/apache/hudi/issues/4888","id":1074656503,"node_id":"IC_kwDOBI7nWM5ADfT3","user":{"login":"alexeykudinkin","id":428277,"node_id":"MDQ6VXNlcjQyODI3Nw==","avatar_url":"https://avatars.githubusercontent.com/u/428277?v=4","gravatar_id":"","url":"https://api.github.com/users/alexeykudinkin","html_url":"https://github.com/alexeykudinkin","followers_url":"https://api.github.com/users/alexeykudinkin/followers","following_url":"https://api.github.com/users/alexeykudinkin/following{/other_user}","gists_url":"https://api.github.com/users/alexeykudinkin/gists{/gist_id}","starred_url":"https://api.github.com/users/alexeykudinkin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexeykudinkin/subscriptions","organizations_url":"https://api.github.com/users/alexeykudinkin/orgs","repos_url":"https://api.github.com/users/alexeykudinkin/repos","events_url":"https://api.github.com/users/alexeykudinkin/events{/privacy}","received_events_url":"https://api.github.com/users/alexeykudinkin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T02:27:19Z","updated_at":"2022-03-22T02:27:19Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074656503/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074689907","html_url":"https://github.com/apache/hudi/pull/5086#issuecomment-1074689907","issue_url":"https://api.github.com/repos/apache/hudi/issues/5086","id":1074689907,"node_id":"IC_kwDOBI7nWM5ADndz","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T03:33:34Z","updated_at":"2022-03-22T03:33:34Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"5d514cb45871d3baf3d7358f17475dd6896a3f38\",\n    \"status\" : \"PENDING\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7159\",\n    \"triggerID\" : \"5d514cb45871d3baf3d7358f17475dd6896a3f38\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 5d514cb45871d3baf3d7358f17475dd6896a3f38 Azure: [PENDING](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7159) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074689907/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074813859","html_url":"https://github.com/apache/hudi/pull/4676#issuecomment-1074813859","issue_url":"https://api.github.com/repos/apache/hudi/issues/4676","id":1074813859,"node_id":"IC_kwDOBI7nWM5AEFuj","user":{"login":"fengjian428","id":4403474,"node_id":"MDQ6VXNlcjQ0MDM0NzQ=","avatar_url":"https://avatars.githubusercontent.com/u/4403474?v=4","gravatar_id":"","url":"https://api.github.com/users/fengjian428","html_url":"https://github.com/fengjian428","followers_url":"https://api.github.com/users/fengjian428/followers","following_url":"https://api.github.com/users/fengjian428/following{/other_user}","gists_url":"https://api.github.com/users/fengjian428/gists{/gist_id}","starred_url":"https://api.github.com/users/fengjian428/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fengjian428/subscriptions","organizations_url":"https://api.github.com/users/fengjian428/orgs","repos_url":"https://api.github.com/users/fengjian428/repos","events_url":"https://api.github.com/users/fengjian428/events{/privacy}","received_events_url":"https://api.github.com/users/fengjian428/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T07:12:12Z","updated_at":"2022-03-22T07:12:12Z","author_association":"CONTRIBUTOR","body":"@nsivabalan @codope   Can anyone take a look at this?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074813859/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074893489","html_url":"https://github.com/apache/hudi/pull/4996#issuecomment-1074893489","issue_url":"https://api.github.com/repos/apache/hudi/issues/4996","id":1074893489,"node_id":"IC_kwDOBI7nWM5AEZKx","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T08:50:54Z","updated_at":"2022-03-22T08:50:54Z","author_association":"MEMBER","body":"@nsivabalan we can land this once CI passes","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074893489/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074901867","html_url":"https://github.com/apache/hudi/issues/4241#issuecomment-1074901867","issue_url":"https://api.github.com/repos/apache/hudi/issues/4241","id":1074901867,"node_id":"IC_kwDOBI7nWM5AEbNr","user":{"login":"kazdy","id":27806231,"node_id":"MDQ6VXNlcjI3ODA2MjMx","avatar_url":"https://avatars.githubusercontent.com/u/27806231?v=4","gravatar_id":"","url":"https://api.github.com/users/kazdy","html_url":"https://github.com/kazdy","followers_url":"https://api.github.com/users/kazdy/followers","following_url":"https://api.github.com/users/kazdy/following{/other_user}","gists_url":"https://api.github.com/users/kazdy/gists{/gist_id}","starred_url":"https://api.github.com/users/kazdy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kazdy/subscriptions","organizations_url":"https://api.github.com/users/kazdy/orgs","repos_url":"https://api.github.com/users/kazdy/repos","events_url":"https://api.github.com/users/kazdy/events{/privacy}","received_events_url":"https://api.github.com/users/kazdy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T09:00:05Z","updated_at":"2022-03-22T09:00:05Z","author_association":"CONTRIBUTOR","body":"For anyone looking at this question now, I see there's documentation available for \"current\" version (0.11):\r\nhttps://hudi.apache.org/docs/next/disaster_recovery","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074901867/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074924118","html_url":"https://github.com/apache/hudi/pull/5027#issuecomment-1074924118","issue_url":"https://api.github.com/repos/apache/hudi/issues/5027","id":1074924118,"node_id":"IC_kwDOBI7nWM5AEgpW","user":{"login":"boneanxs","id":10115332,"node_id":"MDQ6VXNlcjEwMTE1MzMy","avatar_url":"https://avatars.githubusercontent.com/u/10115332?v=4","gravatar_id":"","url":"https://api.github.com/users/boneanxs","html_url":"https://github.com/boneanxs","followers_url":"https://api.github.com/users/boneanxs/followers","following_url":"https://api.github.com/users/boneanxs/following{/other_user}","gists_url":"https://api.github.com/users/boneanxs/gists{/gist_id}","starred_url":"https://api.github.com/users/boneanxs/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/boneanxs/subscriptions","organizations_url":"https://api.github.com/users/boneanxs/orgs","repos_url":"https://api.github.com/users/boneanxs/repos","events_url":"https://api.github.com/users/boneanxs/events{/privacy}","received_events_url":"https://api.github.com/users/boneanxs/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T09:23:10Z","updated_at":"2022-03-22T09:23:10Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1074924118/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075018640","html_url":"https://github.com/apache/hudi/issues/5053#issuecomment-1075018640","issue_url":"https://api.github.com/repos/apache/hudi/issues/5053","id":1075018640,"node_id":"IC_kwDOBI7nWM5AE3uQ","user":{"login":"kination","id":1720209,"node_id":"MDQ6VXNlcjE3MjAyMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1720209?v=4","gravatar_id":"","url":"https://api.github.com/users/kination","html_url":"https://github.com/kination","followers_url":"https://api.github.com/users/kination/followers","following_url":"https://api.github.com/users/kination/following{/other_user}","gists_url":"https://api.github.com/users/kination/gists{/gist_id}","starred_url":"https://api.github.com/users/kination/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kination/subscriptions","organizations_url":"https://api.github.com/users/kination/orgs","repos_url":"https://api.github.com/users/kination/repos","events_url":"https://api.github.com/users/kination/events{/privacy}","received_events_url":"https://api.github.com/users/kination/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T10:50:39Z","updated_at":"2022-03-22T10:50:39Z","author_association":"CONTRIBUTOR","body":"@worf0815 you mean it works well at hudi 0.10.1?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075018640/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075101602","html_url":"https://github.com/apache/hudi/pull/3808#issuecomment-1075101602","issue_url":"https://api.github.com/repos/apache/hudi/issues/3808","id":1075101602,"node_id":"IC_kwDOBI7nWM5AFL-i","user":{"login":"xiarixiaoyao","id":13514703,"node_id":"MDQ6VXNlcjEzNTE0NzAz","avatar_url":"https://avatars.githubusercontent.com/u/13514703?v=4","gravatar_id":"","url":"https://api.github.com/users/xiarixiaoyao","html_url":"https://github.com/xiarixiaoyao","followers_url":"https://api.github.com/users/xiarixiaoyao/followers","following_url":"https://api.github.com/users/xiarixiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/xiarixiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/xiarixiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiarixiaoyao/subscriptions","organizations_url":"https://api.github.com/users/xiarixiaoyao/orgs","repos_url":"https://api.github.com/users/xiarixiaoyao/repos","events_url":"https://api.github.com/users/xiarixiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/xiarixiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T12:14:58Z","updated_at":"2022-03-22T12:14:58Z","author_association":"CONTRIBUTOR","body":"@vinothchandar  yes Thank you for your attention.  \r\ncould you pls also help me review this pr in your spare time\r\n\r\nIn this [PR](https://github.com/apache/hudi/pull/4910), bvaradar also puts forward some modification suggestions. I'm actively address those comments","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075101602/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075120254","html_url":"https://github.com/apache/hudi/pull/5091#issuecomment-1075120254","issue_url":"https://api.github.com/repos/apache/hudi/issues/5091","id":1075120254,"node_id":"IC_kwDOBI7nWM5AFQh-","user":{"login":"zhangyue19921010","id":69956021,"node_id":"MDQ6VXNlcjY5OTU2MDIx","avatar_url":"https://avatars.githubusercontent.com/u/69956021?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangyue19921010","html_url":"https://github.com/zhangyue19921010","followers_url":"https://api.github.com/users/zhangyue19921010/followers","following_url":"https://api.github.com/users/zhangyue19921010/following{/other_user}","gists_url":"https://api.github.com/users/zhangyue19921010/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangyue19921010/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangyue19921010/subscriptions","organizations_url":"https://api.github.com/users/zhangyue19921010/orgs","repos_url":"https://api.github.com/users/zhangyue19921010/repos","events_url":"https://api.github.com/users/zhangyue19921010/events{/privacy}","received_events_url":"https://api.github.com/users/zhangyue19921010/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T12:32:59Z","updated_at":"2022-03-22T12:32:59Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075120254/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075147932","html_url":"https://github.com/apache/hudi/pull/5093#issuecomment-1075147932","issue_url":"https://api.github.com/repos/apache/hudi/issues/5093","id":1075147932,"node_id":"IC_kwDOBI7nWM5AFXSc","user":{"login":"minihippo","id":17903481,"node_id":"MDQ6VXNlcjE3OTAzNDgx","avatar_url":"https://avatars.githubusercontent.com/u/17903481?v=4","gravatar_id":"","url":"https://api.github.com/users/minihippo","html_url":"https://github.com/minihippo","followers_url":"https://api.github.com/users/minihippo/followers","following_url":"https://api.github.com/users/minihippo/following{/other_user}","gists_url":"https://api.github.com/users/minihippo/gists{/gist_id}","starred_url":"https://api.github.com/users/minihippo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/minihippo/subscriptions","organizations_url":"https://api.github.com/users/minihippo/orgs","repos_url":"https://api.github.com/users/minihippo/repos","events_url":"https://api.github.com/users/minihippo/events{/privacy}","received_events_url":"https://api.github.com/users/minihippo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T12:59:20Z","updated_at":"2022-03-22T12:59:20Z","author_association":"CONTRIBUTOR","body":"@garyli1019 An improvement for HUDI-3315, please take a look.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075147932/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075180617","html_url":"https://github.com/apache/hudi/issues/5058#issuecomment-1075180617","issue_url":"https://api.github.com/repos/apache/hudi/issues/5058","id":1075180617,"node_id":"IC_kwDOBI7nWM5AFfRJ","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T13:28:38Z","updated_at":"2022-03-22T13:28:38Z","author_association":"CONTRIBUTOR","body":"nope, we don't have any fix as such. You can try to restore your table to one of the good commits and resume your pipeline. \r\nhttps://hudi.apache.org/docs/next/disaster_recovery/","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075180617/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075181507","html_url":"https://github.com/apache/hudi/issues/5053#issuecomment-1075181507","issue_url":"https://api.github.com/repos/apache/hudi/issues/5053","id":1075181507,"node_id":"IC_kwDOBI7nWM5AFffD","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T13:29:27Z","updated_at":"2022-03-22T13:29:27Z","author_association":"CONTRIBUTOR","body":"thanks @rkkalluri  for helping out. @worf0815 : will go ahead and close out the issue. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075181507/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075182524","html_url":"https://github.com/apache/hudi/issues/5047#issuecomment-1075182524","issue_url":"https://api.github.com/repos/apache/hudi/issues/5047","id":1075182524,"node_id":"IC_kwDOBI7nWM5AFfu8","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T13:30:26Z","updated_at":"2022-03-22T13:30:26Z","author_association":"CONTRIBUTOR","body":"@srinikandi : did you get a chance to try out the above config. \r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075182524/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075189962","html_url":"https://github.com/apache/hudi/issues/5036#issuecomment-1075189962","issue_url":"https://api.github.com/repos/apache/hudi/issues/5036","id":1075189962,"node_id":"IC_kwDOBI7nWM5AFhjK","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T13:37:06Z","updated_at":"2022-03-22T13:37:06Z","author_association":"CONTRIBUTOR","body":"sure, sg. thanks!","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075189962/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075191819","html_url":"https://github.com/apache/hudi/issues/5000#issuecomment-1075191819","issue_url":"https://api.github.com/repos/apache/hudi/issues/5000","id":1075191819,"node_id":"IC_kwDOBI7nWM5AFiAL","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T13:38:49Z","updated_at":"2022-03-22T13:38:49Z","author_association":"CONTRIBUTOR","body":"@arunb2w : yes, we don't have a partial update payload patch merged yet. \r\n@YannByron : sounds good. thanks!","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075191819/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075219383","html_url":"https://github.com/apache/hudi/pull/4910#issuecomment-1075219383","issue_url":"https://api.github.com/repos/apache/hudi/issues/4910","id":1075219383,"node_id":"IC_kwDOBI7nWM5AFou3","user":{"login":"xiarixiaoyao","id":13514703,"node_id":"MDQ6VXNlcjEzNTE0NzAz","avatar_url":"https://avatars.githubusercontent.com/u/13514703?v=4","gravatar_id":"","url":"https://api.github.com/users/xiarixiaoyao","html_url":"https://github.com/xiarixiaoyao","followers_url":"https://api.github.com/users/xiarixiaoyao/followers","following_url":"https://api.github.com/users/xiarixiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/xiarixiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/xiarixiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiarixiaoyao/subscriptions","organizations_url":"https://api.github.com/users/xiarixiaoyao/orgs","repos_url":"https://api.github.com/users/xiarixiaoyao/repos","events_url":"https://api.github.com/users/xiarixiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/xiarixiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T14:02:16Z","updated_at":"2022-03-22T14:02:16Z","author_association":"CONTRIBUTOR","body":"@bvaradar Thank you very much for your review.\r\n I'm redoing the cache and hope not to use metaclient as much as possible\r\nand i will addressed all comments by tomorrow night at the latest\r\nFinally, thank you again","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075219383/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075249175","html_url":"https://github.com/apache/hudi/issues/5053#issuecomment-1075249175","issue_url":"https://api.github.com/repos/apache/hudi/issues/5053","id":1075249175,"node_id":"IC_kwDOBI7nWM5AFwAX","user":{"login":"worf0815","id":10959555,"node_id":"MDQ6VXNlcjEwOTU5NTU1","avatar_url":"https://avatars.githubusercontent.com/u/10959555?v=4","gravatar_id":"","url":"https://api.github.com/users/worf0815","html_url":"https://github.com/worf0815","followers_url":"https://api.github.com/users/worf0815/followers","following_url":"https://api.github.com/users/worf0815/following{/other_user}","gists_url":"https://api.github.com/users/worf0815/gists{/gist_id}","starred_url":"https://api.github.com/users/worf0815/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/worf0815/subscriptions","organizations_url":"https://api.github.com/users/worf0815/orgs","repos_url":"https://api.github.com/users/worf0815/repos","events_url":"https://api.github.com/users/worf0815/events{/privacy}","received_events_url":"https://api.github.com/users/worf0815/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T14:25:15Z","updated_at":"2022-03-22T14:25:15Z","author_association":"NONE","body":"> @worf0815 you mean it works well at hudi 0.10.1?\r\n\r\nYes, the Jackson-Issues was solved and it is now working as expected...","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075249175/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075596631","html_url":"https://github.com/apache/hudi/pull/5095#issuecomment-1075596631","issue_url":"https://api.github.com/repos/apache/hudi/issues/5095","id":1075596631,"node_id":"IC_kwDOBI7nWM5AHE1X","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T20:16:14Z","updated_at":"2022-03-22T20:16:14Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"4e4de93986900f596cd8bba54336b617f9d5dd64\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7195\",\n    \"triggerID\" : \"4e4de93986900f596cd8bba54336b617f9d5dd64\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 4e4de93986900f596cd8bba54336b617f9d5dd64 Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7195) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075596631/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075620964","html_url":"https://github.com/apache/hudi/issues/4230#issuecomment-1075620964","issue_url":"https://api.github.com/repos/apache/hudi/issues/4230","id":1075620964,"node_id":"IC_kwDOBI7nWM5AHKxk","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-22T20:45:45Z","updated_at":"2022-03-22T20:45:45Z","author_association":"CONTRIBUTOR","body":"I think @BenjMaq is asking about how to pass the same config as an argument to the `spark-sql` command, i.e., when launching `spark-sql` before even running the queries.  @nsivabalan @xushiyan if we don't support that, we can see if it is possible to add this feature.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075620964/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075805688","html_url":"https://github.com/apache/hudi/pull/5093#issuecomment-1075805688","issue_url":"https://api.github.com/repos/apache/hudi/issues/5093","id":1075805688,"node_id":"IC_kwDOBI7nWM5AH334","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T01:10:04Z","updated_at":"2022-03-23T01:10:04Z","author_association":"MEMBER","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075805688/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075820299","html_url":"https://github.com/apache/hudi/issues/4992#issuecomment-1075820299","issue_url":"https://api.github.com/repos/apache/hudi/issues/4992","id":1075820299,"node_id":"IC_kwDOBI7nWM5AH7cL","user":{"login":"liuyaolin","id":4271067,"node_id":"MDQ6VXNlcjQyNzEwNjc=","avatar_url":"https://avatars.githubusercontent.com/u/4271067?v=4","gravatar_id":"","url":"https://api.github.com/users/liuyaolin","html_url":"https://github.com/liuyaolin","followers_url":"https://api.github.com/users/liuyaolin/followers","following_url":"https://api.github.com/users/liuyaolin/following{/other_user}","gists_url":"https://api.github.com/users/liuyaolin/gists{/gist_id}","starred_url":"https://api.github.com/users/liuyaolin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liuyaolin/subscriptions","organizations_url":"https://api.github.com/users/liuyaolin/orgs","repos_url":"https://api.github.com/users/liuyaolin/repos","events_url":"https://api.github.com/users/liuyaolin/events{/privacy}","received_events_url":"https://api.github.com/users/liuyaolin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T01:40:53Z","updated_at":"2022-03-23T01:40:53Z","author_association":"NONE","body":"@nsivabalan thank you,I've solved it\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075820299/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075835918","html_url":"https://github.com/apache/hudi/issues/5053#issuecomment-1075835918","issue_url":"https://api.github.com/repos/apache/hudi/issues/5053","id":1075835918,"node_id":"IC_kwDOBI7nWM5AH_QO","user":{"login":"kination","id":1720209,"node_id":"MDQ6VXNlcjE3MjAyMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1720209?v=4","gravatar_id":"","url":"https://api.github.com/users/kination","html_url":"https://github.com/kination","followers_url":"https://api.github.com/users/kination/followers","following_url":"https://api.github.com/users/kination/following{/other_user}","gists_url":"https://api.github.com/users/kination/gists{/gist_id}","starred_url":"https://api.github.com/users/kination/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kination/subscriptions","organizations_url":"https://api.github.com/users/kination/orgs","repos_url":"https://api.github.com/users/kination/repos","events_url":"https://api.github.com/users/kination/events{/privacy}","received_events_url":"https://api.github.com/users/kination/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T02:13:35Z","updated_at":"2022-03-23T02:13:35Z","author_association":"CONTRIBUTOR","body":"@nsivabalan @worf0815 will there be some way to make it work on older hudi version?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075835918/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075859852","html_url":"https://github.com/apache/hudi/pull/5060#issuecomment-1075859852","issue_url":"https://api.github.com/repos/apache/hudi/issues/5060","id":1075859852,"node_id":"IC_kwDOBI7nWM5AIFGM","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T02:48:38Z","updated_at":"2022-03-23T02:48:38Z","author_association":"CONTRIBUTOR","body":"@hudi-bot  run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075859852/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075861068","html_url":"https://github.com/apache/hudi/pull/5095#issuecomment-1075861068","issue_url":"https://api.github.com/repos/apache/hudi/issues/5095","id":1075861068,"node_id":"IC_kwDOBI7nWM5AIFZM","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T02:51:32Z","updated_at":"2022-03-23T02:51:32Z","author_association":"CONTRIBUTOR","body":"Which test case is failing and cased by this PR ? I see the CI is still failing.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075861068/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075861386","html_url":"https://github.com/apache/hudi/issues/1243#issuecomment-1075861386","issue_url":"https://api.github.com/repos/apache/hudi/issues/1243","id":1075861386,"node_id":"IC_kwDOBI7nWM5AIFeK","user":{"login":"Terror-LM","id":7994304,"node_id":"MDQ6VXNlcjc5OTQzMDQ=","avatar_url":"https://avatars.githubusercontent.com/u/7994304?v=4","gravatar_id":"","url":"https://api.github.com/users/Terror-LM","html_url":"https://github.com/Terror-LM","followers_url":"https://api.github.com/users/Terror-LM/followers","following_url":"https://api.github.com/users/Terror-LM/following{/other_user}","gists_url":"https://api.github.com/users/Terror-LM/gists{/gist_id}","starred_url":"https://api.github.com/users/Terror-LM/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Terror-LM/subscriptions","organizations_url":"https://api.github.com/users/Terror-LM/orgs","repos_url":"https://api.github.com/users/Terror-LM/repos","events_url":"https://api.github.com/users/Terror-LM/events{/privacy}","received_events_url":"https://api.github.com/users/Terror-LM/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T02:52:13Z","updated_at":"2022-03-23T02:52:13Z","author_association":"NONE","body":"> i face this issue in 0.5.3, for my custom jar importing hudi-client it is bringing in hbase-client/hadoop* and then old avro 1.7\r\n> \r\n> [INFO] +- org.apache.hudi:hudi-client:jar:0.5.3:compile [INFO] | +- (org.apache.hudi:hudi-common:jar:0.5.3:compile - omitted for duplicate) [INFO] | +- org.apache.hudi:hudi-timeline-service:jar:0.5.3:compile [INFO] | | +- (org.apache.hudi:hudi-common:jar:0.5.3:compile - omitted for duplicate) [INFO] | | +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate) [INFO] | | +- (com.fasterxml.jackson.core:jackson-annotations:jar:2.6.7:compile - omitted for duplicate) [INFO] | | +- (com.fasterxml.jackson.core:jackson-core:jar:2.6.7:compile - omitted for duplicate) [INFO] | | +- (com.fasterxml.jackson.core:jackson-databind:jar:2.6.7.1:compile - omitted for conflict with 2.6.7.3) [INFO] | | +- (org.apache.httpcomponents:fluent-hc:jar:4.3.2:compile - omitted for duplicate) [INFO] | | +- io.javalin:javalin:jar:2.8.0:compile [INFO] | | | +- org.jetbrains.kotlin:kotlin-stdlib-jdk8:jar:1.2.71:compile [INFO] | | | | +- org.jetbrains.kotlin:kotlin-stdlib:jar:1.2.71:compile [INFO] | | | | | +- org.jetbrains.kotlin:kotlin-stdlib-common:jar:1.2.71:compile [INFO] | | | | | - org.jetbrains:annotations:jar:13.0:compile [INFO] | | | | - org.jetbrains.kotlin:kotlin-stdlib-jdk7:jar:1.2.71:compile [INFO] | | | | - (org.jetbrains.kotlin:kotlin-stdlib:jar:1.2.71:compile - omitted for duplicate) [INFO] | | | +- (org.slf4j:slf4j-api:jar:1.7.26:compile - omitted for conflict with 1.7.28) [INFO] | | | +- org.eclipse.jetty:jetty-server:jar:9.4.15.v20190215:compile [INFO] | | | | +- javax.servlet:javax.servlet-api:jar:3.1.0:compile [INFO] | | | | +- org.eclipse.jetty:jetty-http:jar:9.4.15.v20190215:compile [INFO] | | | | | +- org.eclipse.jetty:jetty-util:jar:9.4.15.v20190215:compile [INFO] | | | | | - (org.eclipse.jetty:jetty-io:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | | - org.eclipse.jetty:jetty-io:jar:9.4.15.v20190215:compile [INFO] | | | | - (org.eclipse.jetty:jetty-util:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | +- org.eclipse.jetty:jetty-webapp:jar:9.4.15.v20190215:compile [INFO] | | | | +- org.eclipse.jetty:jetty-xml:jar:9.4.15.v20190215:compile [INFO] | | | | | - (org.eclipse.jetty:jetty-util:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | | - org.eclipse.jetty:jetty-servlet:jar:9.4.15.v20190215:compile [INFO] | | | | - org.eclipse.jetty:jetty-security:jar:9.4.15.v20190215:compile [INFO] | | | | - (org.eclipse.jetty:jetty-server:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | - org.eclipse.jetty.websocket:websocket-server:jar:9.4.15.v20190215:compile [INFO] | | | +- org.eclipse.jetty.websocket:websocket-common:jar:9.4.15.v20190215:compile [INFO] | | | | +- org.eclipse.jetty.websocket:websocket-api:jar:9.4.15.v20190215:compile [INFO] | | | | +- (org.eclipse.jetty:jetty-util:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | | - (org.eclipse.jetty:jetty-io:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | +- org.eclipse.jetty.websocket:websocket-client:jar:9.4.15.v20190215:compile [INFO] | | | | +- org.eclipse.jetty:jetty-client:jar:9.4.15.v20190215:compile [INFO] | | | | | +- (org.eclipse.jetty:jetty-http:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | | | - (org.eclipse.jetty:jetty-io:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | | +- (org.eclipse.jetty:jetty-xml:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | | +- (org.eclipse.jetty:jetty-util:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | | +- (org.eclipse.jetty:jetty-io:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | | - (org.eclipse.jetty.websocket:websocket-common:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | +- org.eclipse.jetty.websocket:websocket-servlet:jar:9.4.15.v20190215:compile [INFO] | | | | +- (org.eclipse.jetty.websocket:websocket-api:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | | - (javax.servlet:javax.servlet-api:jar:3.1.0:compile - omitted for duplicate) [INFO] | | | +- (org.eclipse.jetty:jetty-servlet:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | | - (org.eclipse.jetty:jetty-http:jar:9.4.15.v20190215:compile - omitted for duplicate) [INFO] | | +- (com.beust:jcommander:jar:1.72:compile - omitted for duplicate) [INFO] | | +- (org.rocksdb:rocksdbjni:jar:5.17.2:compile - omitted for duplicate) [INFO] | | - (org.apache.hadoop:hadoop-common:jar:tests:2.7.3:compile - omitted for duplicate) [INFO] | +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate) [INFO] | +- io.dropwizard.metrics:metrics-graphite:jar:4.1.1:compile [INFO] | | +- (io.dropwizard.metrics:metrics-core:jar:4.1.1:compile - omitted for duplicate) [INFO] | | - (org.slf4j:slf4j-api:jar:1.7.28:compile - omitted for conflict with 1.7.7) [INFO] | +- io.dropwizard.metrics:metrics-core:jar:4.1.1:compile [INFO] | | - (org.slf4j:slf4j-api:jar:1.7.28:compile - omitted for duplicate) [INFO] | +- org.apache.hadoop:hadoop-hdfs:jar:tests:2.7.3:compile [INFO] | | +- (com.google.guava:guava:jar:11.0.2:compile - omitted for duplicate) [INFO] | | +- (com.sun.jersey:jersey-core:jar:1.9:compile - omitted for duplicate) [INFO] | | +- (com.sun.jersey:jersey-server:jar:1.9:compile - omitted for duplicate) [INFO] | | +- (commons-cli:commons-cli:jar:1.2:compile - omitted for duplicate) [INFO] | | +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6) [INFO] | | +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate) [INFO] | | +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate) [INFO] | | +- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate) [INFO] | | +- (commons-daemon:commons-daemon:jar:1.0.13:compile - omitted for duplicate) [INFO] | | +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate) [INFO] | | +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate) [INFO] | | +- (org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile - omitted for duplicate) [INFO] | | +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile - omitted for duplicate) [INFO] | | +- (xmlenc:xmlenc:jar:0.52:compile - omitted for duplicate) [INFO] | | +- (io.netty:netty:jar:3.6.2.Final:compile - omitted for duplicate) [INFO] | | +- (io.netty:netty-all:jar:4.0.23.Final:compile - omitted for duplicate) [INFO] | | +- (xerces:xercesImpl:jar:2.9.1:compile - omitted for duplicate) [INFO] | | +- (org.apache.htrace:htrace-core:jar:3.1.0-incubating:compile - omitted for duplicate) [INFO] | | - (org.fusesource.leveldbjni:leveldbjni-all:jar:1.8:compile - omitted for duplicate) [INFO] | +- org.apache.hadoop:hadoop-common:jar:tests:2.7.3:compile [INFO] | | +- org.apache.hadoop:hadoop-annotations:jar:2.7.3:compile [INFO] | | | - jdk.tools:jdk.tools:jar:1.8:system [INFO] | | +- (com.google.guava:guava:jar:11.0.2:compile - omitted for duplicate) [INFO] | | +- (commons-cli:commons-cli:jar:1.2:compile - omitted for duplicate) [INFO] | | +- org.apache.commons:commons-math3:jar:3.1.1:compile [INFO] | | +- (xmlenc:xmlenc:jar:0.52:compile - omitted for duplicate) [INFO] | | +- commons-httpclient:commons-httpclient:jar:3.1:compile [INFO] | | | +- (commons-logging:commons-logging:jar:1.0.4:compile - omitted for conflict with 1.1.3) [INFO] | | | - (commons-codec:commons-codec:jar:1.2:compile - omitted for conflict with 1.6) [INFO] | | +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6) [INFO] | | +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate) [INFO] | | +- commons-net:commons-net:jar:3.1:compile [INFO] | | +- commons-collections:commons-collections:jar:3.2.2:compile [INFO] | | +- (com.sun.jersey:jersey-core:jar:1.9:compile - omitted for duplicate) [INFO] | | +- com.sun.jersey:jersey-json:jar:1.9:compile [INFO] | | | +- org.codehaus.jettison:jettison:jar:1.1:compile [INFO] | | | +- com.sun.xml.bind:jaxb-impl:jar:2.2.3-1:compile [INFO] | | | | - javax.xml.bind:jaxb-api:jar:2.2.2:compile [INFO] | | | | +- javax.xml.stream:stax-api:jar:1.0-2:compile [INFO] | | | | - (javax.activation:activation:jar:1.1:compile - omitted for duplicate) [INFO] | | | +- (org.codehaus.jackson:jackson-core-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13) [INFO] | | | +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13) [INFO] | | | +- org.codehaus.jackson:jackson-jaxrs:jar:1.8.3:compile [INFO] | | | | +- (org.codehaus.jackson:jackson-core-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13) [INFO] | | | | - (org.codehaus.jackson:jackson-mapper-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13) [INFO] | | | +- org.codehaus.jackson:jackson-xc:jar:1.8.3:compile [INFO] | | | | +- (org.codehaus.jackson:jackson-core-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13) [INFO] | | | | - (org.codehaus.jackson:jackson-mapper-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13) [INFO] | | | - (com.sun.jersey:jersey-core:jar:1.9:compile - omitted for duplicate) [INFO] | | +- (com.sun.jersey:jersey-server:jar:1.9:compile - omitted for duplicate) [INFO] | | +- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate) [INFO] | | +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate) [INFO] | | +- net.java.dev.jets3t:jets3t:jar:0.9.0:compile [INFO] | | | +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6) [INFO] | | | +- (commons-logging:commons-logging:jar:1.1.1:compile - omitted for conflict with 1.1.3) [INFO] | | | +- (org.apache.httpcomponents:httpclient:jar:4.1.2:compile - omitted for conflict with 4.3.6) [INFO] | | | +- (org.apache.httpcomponents:httpcore:jar:4.1.2:compile - omitted for conflict with 4.3.3) [INFO] | | | - com.jamesmurty.utils:java-xmlbuilder:jar:0.4:compile [INFO] | | +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate) [INFO] | | +- commons-configuration:commons-configuration:jar:1.6:compile [INFO] | | | +- (commons-collections:commons-collections:jar:3.2.1:compile - omitted for conflict with 3.2.2) [INFO] | | | +- (commons-lang:commons-lang:jar:2.4:compile - omitted for conflict with 2.6) [INFO] | | | +- (commons-logging:commons-logging:jar:1.1.1:compile - omitted for conflict with 1.1.3) [INFO] | | | +- commons-digester:commons-digester:jar:1.8:compile [INFO] | | | | +- commons-beanutils:commons-beanutils:jar:1.7.0:compile [INFO] | | | | | - (commons-logging:commons-logging:jar:1.0.3:compile - omitted for conflict with 1.1.3) [INFO] | | | | - (commons-logging:commons-logging:jar:1.1:compile - omitted for conflict with 1.1.3) [INFO] | | | - commons-beanutils:commons-beanutils-core:jar:1.8.0:compile [INFO] | | | - (commons-logging:commons-logging:jar:1.1.1:compile - omitted for conflict with 1.1.3) [INFO] | | +- (org.slf4j:slf4j-api:jar:1.7.10:compile - omitted for conflict with 1.7.28) [INFO] | | +- (org.slf4j:slf4j-log4j12:jar:1.7.10:compile - scope updated from runtime; omitted for duplicate) [INFO] | | +- (org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile - omitted for duplicate) [INFO] | | +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile - omitted for duplicate) [INFO] | | +- (org.apache.avro:avro:jar:1.7.4:compile - omitted for conflict with 1.8.2) [INFO] | | +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate) [INFO] | | +- com.google.code.gson:gson:jar:2.2.4:compile [INFO] | | +- org.apache.hadoop:hadoop-auth:jar:2.7.3:compile [INFO] | | | +- (org.slf4j:slf4j-api:jar:1.7.10:compile - omitted for conflict with 1.7.28) [INFO] | | | +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6) [INFO] | | | +- (log4j:log4j:jar:1.2.17:runtime - omitted for duplicate) [INFO] | | | +- (org.slf4j:slf4j-log4j12:jar:1.7.10:runtime - omitted for duplicate) [INFO] | | | +- (org.apache.httpcomponents:httpclient:jar:4.2.5:compile - omitted for conflict with 4.3.6) [INFO] | | | +- org.apache.directory.server:apacheds-kerberos-codec:jar:2.0.0-M15:compile [INFO] | | | | +- org.apache.directory.server:apacheds-i18n:jar:2.0.0-M15:compile [INFO] | | | | | - (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28) [INFO] | | | | +- org.apache.directory.api:api-asn1-api:jar:1.0.0-M20:compile [INFO] | | | | | - (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28) [INFO] | | | | +- org.apache.directory.api:api-util:jar:1.0.0-M20:compile [INFO] | | | | | - (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28) [INFO] | | | | - (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28) [INFO] | | | +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate) [INFO] | | | - org.apache.curator:curator-framework:jar:2.7.1:compile [INFO] | | | +- (org.apache.curator:curator-client:jar:2.7.1:compile - omitted for duplicate) [INFO] | | | +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate) [INFO] | | | - (com.google.guava:guava:jar:16.0.1:compile - omitted for conflict with 11.0.2) [INFO] | | +- com.jcraft:jsch:jar:0.1.42:compile [INFO] | | +- org.apache.curator:curator-client:jar:2.7.1:compile [INFO] | | | +- (org.slf4j:slf4j-api:jar:1.7.6:compile - omitted for conflict with 1.7.28) [INFO] | | | +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate) [INFO] | | | - (com.google.guava:guava:jar:16.0.1:compile - omitted for conflict with 11.0.2) [INFO] | | +- org.apache.curator:curator-recipes:jar:2.7.1:compile [INFO] | | | +- (org.apache.curator:curator-framework:jar:2.7.1:compile - omitted for duplicate) [INFO] | | | +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate) [INFO] | | | - (com.google.guava:guava:jar:16.0.1:compile - omitted for conflict with 11.0.2) [INFO] | | +- com.google.code.findbugs:jsr305:jar:3.0.0:compile [INFO] | | +- (org.apache.htrace:htrace-core:jar:3.1.0-incubating:compile - omitted for duplicate) [INFO] | | +- org.apache.zookeeper:zookeeper:jar:3.4.6:compile [INFO] | | | +- (org.slf4j:slf4j-api:jar:1.6.1:compile - omitted for conflict with 1.7.28) [INFO] | | | +- org.slf4j:slf4j-log4j12:jar:1.6.1:compile [INFO] | | | | +- (org.slf4j:slf4j-api:jar:1.6.1:compile - omitted for conflict with 1.7.28) [INFO] | | | | - (log4j:log4j:jar:1.2.16:compile - omitted for conflict with 1.2.17) [INFO] | | | +- (log4j:log4j:jar:1.2.16:compile - omitted for conflict with 1.2.17) [INFO] | | | - (io.netty:netty:jar:3.7.0.Final:compile - omitted for conflict with 3.6.2.Final) [INFO] | | - (org.apache.commons:commons-compress:jar:1.4.1:compile - omitted for conflict with 1.9) [INFO] | - org.apache.hbase:hbase-client:jar:1.2.3:compile [INFO] | +- org.apache.hbase:hbase-annotations:jar:1.2.3:compile [INFO] | | +- com.github.stephenc.findbugs:findbugs-annotations:jar:1.3.9-1:compile [INFO] | | +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate) [INFO] | | - (junit:junit:jar:4.12:compile - omitted for duplicate) [INFO] | +- org.apache.hbase:hbase-common:jar:1.2.3:compile [INFO] | | +- (org.apache.hbase:hbase-protocol:jar:1.2.3:compile - omitted for duplicate) [INFO] | | +- (org.apache.hbase:hbase-annotations:jar:1.2.3:compile - omitted for duplicate) [INFO] | | +- (com.google.guava:guava:jar:12.0.1:compile - omitted for conflict with 11.0.2) [INFO] | | +- (commons-logging:commons-logging:jar:1.2:compile - omitted for conflict with 1.1.3) [INFO] | | +- (commons-codec:commons-codec:jar:1.9:compile - omitted for conflict with 1.6) [INFO] | | +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate) [INFO] | | +- (commons-collections:commons-collections:jar:3.2.2:compile - omitted for duplicate) [INFO] | | +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate) [INFO] | | +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate) [INFO] | | +- (org.mortbay.jetty:jetty-util:jar:6.1.26:compile - omitted for duplicate) [INFO] | | +- (org.apache.htrace:htrace-core:jar:3.1.0-incubating:compile - omitted for duplicate) [INFO] | | +- (org.apache.hadoop:hadoop-common:jar:2.5.1:compile - omitted for duplicate) [INFO] | | +- (org.apache.hadoop:hadoop-mapreduce-client-core:jar:2.5.1:compile - omitted for duplicate) [INFO] | | +- (com.github.stephenc.findbugs:findbugs-annotations:jar:1.3.9-1:compile - omitted for duplicate) [INFO] | | +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate) [INFO] | | - (junit:junit:jar:4.12:compile - omitted for duplicate) [INFO] | +- org.apache.hbase:hbase-protocol:jar:1.2.3:compile [INFO] | | +- (org.apache.hbase:hbase-annotations:jar:1.2.3:compile - omitted for duplicate) [INFO] | | +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate) [INFO] | | +- (commons-logging:commons-logging:jar:1.2:compile - omitted for conflict with 1.1.3) [INFO] | | +- (com.github.stephenc.findbugs:findbugs-annotations:jar:1.3.9-1:compile - omitted for duplicate) [INFO] | | +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate) [INFO] | | - (junit:junit:jar:4.12:compile - omitted for duplicate) [INFO] | +- (commons-codec:commons-codec:jar:1.9:compile - omitted for conflict with 1.6) [INFO] | +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate) [INFO] | +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate) [INFO] | +- (commons-logging:commons-logging:jar:1.2:compile - omitted for conflict with 1.1.3) [INFO] | +- (com.google.guava:guava:jar:12.0.1:compile - omitted for conflict with 11.0.2) [INFO] | +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate) [INFO] | +- (io.netty:netty-all:jar:4.0.23.Final:compile - omitted for duplicate) [INFO] | +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate) [INFO] | +- (org.apache.htrace:htrace-core:jar:3.1.0-incubating:compile - omitted for duplicate) [INFO] | +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile - omitted for duplicate) [INFO] | +- org.jruby.jcodings:jcodings:jar:1.0.8:compile [INFO] | +- org.jruby.joni:joni:jar:2.1.2:compile [INFO] | | - (org.jruby.jcodings:jcodings:jar:1.0.8:compile - omitted for duplicate) [INFO] | +- com.yammer.metrics:metrics-core:jar:2.2.0:compile [INFO] | | - (org.slf4j:slf4j-api:jar:1.7.2:compile - omitted for conflict with 1.7.28) [INFO] | +- (org.apache.hadoop:hadoop-auth:jar:2.5.1:compile - omitted for conflict with 2.7.3) [INFO] | +- org.apache.hadoop:hadoop-common:jar:2.5.1:compile [INFO] | | +- (org.apache.hadoop:hadoop-annotations:jar:2.5.1:compile - omitted for conflict with 2.7.3) [INFO] | | +- (com.google.guava:guava:jar:11.0.2:compile - omitted for duplicate) [INFO] | | +- (commons-cli:commons-cli:jar:1.2:compile - omitted for duplicate) [INFO] | | +- (org.apache.commons:commons-math3:jar:3.1.1:compile - omitted for duplicate) [INFO] | | +- (xmlenc:xmlenc:jar:0.52:compile - omitted for duplicate) [INFO] | | +- (commons-httpclient:commons-httpclient:jar:3.1:compile - omitted for duplicate) [INFO] | | +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6) [INFO] | | +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate) [INFO] | | +- (commons-net:commons-net:jar:3.1:compile - omitted for duplicate) [INFO] | | +- (commons-collections:commons-collections:jar:3.2.1:compile - omitted for conflict with 3.2.2) [INFO] | | +- (org.mortbay.jetty:jetty-util:jar:6.1.26:compile - omitted for duplicate) [INFO] | | +- (commons-el:commons-el:jar:1.0:compile - scope updated from runtime; omitted for duplicate) [INFO] | | +- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate) [INFO] | | +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate) [INFO] | | +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate) [INFO] | | +- (commons-configuration:commons-configuration:jar:1.6:compile - omitted for duplicate) [INFO] | | +- (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28) [INFO] | | +- (org.slf4j:slf4j-log4j12:jar:1.7.5:runtime - omitted for conflict with 1.6.1) [INFO] | | +- (org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile - omitted for duplicate) [INFO] | | +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile - omitted for duplicate) [INFO] | | +- (org.apache.avro:avro:jar:1.7.4:compile - omitted for duplicate) [INFO] | | +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate) [INFO] | | +- (org.apache.hadoop:hadoop-auth:jar:2.5.1:compile - omitted for conflict with 2.7.3) [INFO] | | +- (com.jcraft:jsch:jar:0.1.42:compile - omitted for duplicate) [INFO] | | +- (com.google.code.findbugs:jsr305:jar:1.3.9:compile - omitted for conflict with 3.0.0) [INFO] | | +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate) [INFO] | | - (org.apache.commons:commons-compress:jar:1.4.1:compile - omitted for duplicate) [INFO] | +- org.apache.hadoop:hadoop-mapreduce-client-core:jar:2.5.1:compile [INFO] | | +- org.apache.hadoop:hadoop-yarn-common:jar:2.5.1:compile [INFO] | | | +- org.apache.hadoop:hadoop-yarn-api:jar:2.5.1:compile [INFO] | | | | +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate) [INFO] | | | | +- (com.google.guava:guava:jar:11.0.2:compile - omitted for duplicate) [INFO] | | | | +- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate) [INFO] | | | | +- (org.apache.hadoop:hadoop-annotations:jar:2.5.1:compile - omitted for conflict with 2.7.3) [INFO] | | | | - (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate) [INFO] | | | +- (javax.xml.bind:jaxb-api:jar:2.2.2:compile - omitted for duplicate) [INFO] | | | +- (org.apache.commons:commons-compress:jar:1.4.1:compile - omitted for duplicate) [INFO] | | | +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate) [INFO] | | | +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6) [INFO] | | | +- (org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile - omitted for duplicate) [INFO] | | | +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile - omitted for duplicate) [INFO] | | | +- (com.google.guava:guava:jar:11.0.2:compile - omitted for duplicate) [INFO] | | | +- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate) [INFO] | | | +- (commons-cli:commons-cli:jar:1.2:compile - omitted for duplicate) [INFO] | | | +- (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28) [INFO] | | | +- (org.apache.hadoop:hadoop-annotations:jar:2.5.1:compile - omitted for conflict with 2.7.3) [INFO] | | | +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate) [INFO] | | | +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate) [INFO] | | | - (log4j:log4j:jar:1.2.17:compile - omitted for duplicate) [INFO] | | +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate) [INFO] | | +- (org.apache.avro:avro:jar:1.7.4:compile - omitted for duplicate) [INFO] | | +- (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28) [INFO] | | +- (org.slf4j:slf4j-log4j12:jar:1.7.5:compile - omitted for conflict with 1.6.1) [INFO] | | +- (org.apache.hadoop:hadoop-annotations:jar:2.5.1:compile - omitted for conflict with 2.7.3) [INFO] | | - (io.netty:netty:jar:3.6.2.Final:compile - omitted for duplicate) [INFO] | - (junit:junit:jar:4.12:compile - omitted for duplicate)\r\n\r\nhow did you get that jar list, from yarn log, or else?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075861386/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075871635","html_url":"https://github.com/apache/hudi/issues/5000#issuecomment-1075871635","issue_url":"https://api.github.com/repos/apache/hudi/issues/5000","id":1075871635,"node_id":"IC_kwDOBI7nWM5AIH-T","user":{"login":"YannByron","id":10036681,"node_id":"MDQ6VXNlcjEwMDM2Njgx","avatar_url":"https://avatars.githubusercontent.com/u/10036681?v=4","gravatar_id":"","url":"https://api.github.com/users/YannByron","html_url":"https://github.com/YannByron","followers_url":"https://api.github.com/users/YannByron/followers","following_url":"https://api.github.com/users/YannByron/following{/other_user}","gists_url":"https://api.github.com/users/YannByron/gists{/gist_id}","starred_url":"https://api.github.com/users/YannByron/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YannByron/subscriptions","organizations_url":"https://api.github.com/users/YannByron/orgs","repos_url":"https://api.github.com/users/YannByron/repos","events_url":"https://api.github.com/users/YannByron/events{/privacy}","received_events_url":"https://api.github.com/users/YannByron/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T03:16:15Z","updated_at":"2022-03-23T03:16:15Z","author_association":"CONTRIBUTOR","body":"ticket: https://issues.apache.org/jira/browse/HUDI-3690.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075871635/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075886765","html_url":"https://github.com/apache/hudi/pull/5099#issuecomment-1075886765","issue_url":"https://api.github.com/repos/apache/hudi/issues/5099","id":1075886765,"node_id":"IC_kwDOBI7nWM5AILqt","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T03:52:17Z","updated_at":"2022-03-23T03:52:17Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075886765/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075906694","html_url":"https://github.com/apache/hudi/issues/5053#issuecomment-1075906694","issue_url":"https://api.github.com/repos/apache/hudi/issues/5053","id":1075906694,"node_id":"IC_kwDOBI7nWM5AIQiG","user":{"login":"kination","id":1720209,"node_id":"MDQ6VXNlcjE3MjAyMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1720209?v=4","gravatar_id":"","url":"https://api.github.com/users/kination","html_url":"https://github.com/kination","followers_url":"https://api.github.com/users/kination/followers","following_url":"https://api.github.com/users/kination/following{/other_user}","gists_url":"https://api.github.com/users/kination/gists{/gist_id}","starred_url":"https://api.github.com/users/kination/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kination/subscriptions","organizations_url":"https://api.github.com/users/kination/orgs","repos_url":"https://api.github.com/users/kination/repos","events_url":"https://api.github.com/users/kination/events{/privacy}","received_events_url":"https://api.github.com/users/kination/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T04:38:08Z","updated_at":"2022-03-23T04:38:08Z","author_association":"CONTRIBUTOR","body":"I'm working with scala, so can it be solved by importing `jackson` separately?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075906694/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075907228","html_url":"https://github.com/apache/hudi/pull/5095#issuecomment-1075907228","issue_url":"https://api.github.com/repos/apache/hudi/issues/5095","id":1075907228,"node_id":"IC_kwDOBI7nWM5AIQqc","user":{"login":"alexeykudinkin","id":428277,"node_id":"MDQ6VXNlcjQyODI3Nw==","avatar_url":"https://avatars.githubusercontent.com/u/428277?v=4","gravatar_id":"","url":"https://api.github.com/users/alexeykudinkin","html_url":"https://github.com/alexeykudinkin","followers_url":"https://api.github.com/users/alexeykudinkin/followers","following_url":"https://api.github.com/users/alexeykudinkin/following{/other_user}","gists_url":"https://api.github.com/users/alexeykudinkin/gists{/gist_id}","starred_url":"https://api.github.com/users/alexeykudinkin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexeykudinkin/subscriptions","organizations_url":"https://api.github.com/users/alexeykudinkin/orgs","repos_url":"https://api.github.com/users/alexeykudinkin/repos","events_url":"https://api.github.com/users/alexeykudinkin/events{/privacy}","received_events_url":"https://api.github.com/users/alexeykudinkin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T04:39:20Z","updated_at":"2022-03-23T04:39:20Z","author_association":"CONTRIBUTOR","body":"@nsivabalan we can close this one, CI failures that we observed in the PR this one is reverting were caused by CME, and has nothing to do with current failures","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075907228/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075938530","html_url":"https://github.com/apache/hudi/pull/4724#issuecomment-1075938530","issue_url":"https://api.github.com/repos/apache/hudi/issues/4724","id":1075938530,"node_id":"IC_kwDOBI7nWM5AIYTi","user":{"login":"stayrascal","id":13775334,"node_id":"MDQ6VXNlcjEzNzc1MzM0","avatar_url":"https://avatars.githubusercontent.com/u/13775334?v=4","gravatar_id":"","url":"https://api.github.com/users/stayrascal","html_url":"https://github.com/stayrascal","followers_url":"https://api.github.com/users/stayrascal/followers","following_url":"https://api.github.com/users/stayrascal/following{/other_user}","gists_url":"https://api.github.com/users/stayrascal/gists{/gist_id}","starred_url":"https://api.github.com/users/stayrascal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stayrascal/subscriptions","organizations_url":"https://api.github.com/users/stayrascal/orgs","repos_url":"https://api.github.com/users/stayrascal/repos","events_url":"https://api.github.com/users/stayrascal/events{/privacy}","received_events_url":"https://api.github.com/users/stayrascal/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T05:42:03Z","updated_at":"2022-03-23T05:42:03Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075938530/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075956587","html_url":"https://github.com/apache/hudi/pull/5097#issuecomment-1075956587","issue_url":"https://api.github.com/repos/apache/hudi/issues/5097","id":1075956587,"node_id":"IC_kwDOBI7nWM5AIctr","user":{"login":"alexeykudinkin","id":428277,"node_id":"MDQ6VXNlcjQyODI3Nw==","avatar_url":"https://avatars.githubusercontent.com/u/428277?v=4","gravatar_id":"","url":"https://api.github.com/users/alexeykudinkin","html_url":"https://github.com/alexeykudinkin","followers_url":"https://api.github.com/users/alexeykudinkin/followers","following_url":"https://api.github.com/users/alexeykudinkin/following{/other_user}","gists_url":"https://api.github.com/users/alexeykudinkin/gists{/gist_id}","starred_url":"https://api.github.com/users/alexeykudinkin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexeykudinkin/subscriptions","organizations_url":"https://api.github.com/users/alexeykudinkin/orgs","repos_url":"https://api.github.com/users/alexeykudinkin/repos","events_url":"https://api.github.com/users/alexeykudinkin/events{/privacy}","received_events_url":"https://api.github.com/users/alexeykudinkin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T06:11:33Z","updated_at":"2022-03-23T06:11:49Z","author_association":"CONTRIBUTOR","body":"After making sure `TestHoodieDeltaStreamer` shuts down all executors properly, tests are starting to hang with following exception trailing test runs:\r\n\r\n```\r\n2022-03-23T05:36:34.5915659Z 1622490 [LeaseRenewer:vsts@localhost:38427] WARN  org.apache.hadoop.hdfs.LeaseRenewer  - Failed to renew lease for [DFSClient_NONMAPREDUCE_93990013_1] for 31 seconds.  Will retry shortly ...\r\n2022-03-23T05:36:34.5917288Z java.net.ConnectException: Call From fv-az208-692/10.1.0.11 to localhost:38427 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\r\n2022-03-23T05:36:34.5918493Z \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n2022-03-23T05:36:34.5919500Z \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n2022-03-23T05:36:34.5920133Z \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n2022-03-23T05:36:34.5920667Z \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n2022-03-23T05:36:34.5921187Z \tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)\r\n2022-03-23T05:36:34.5921641Z \tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)\r\n2022-03-23T05:36:34.5922058Z \tat org.apache.hadoop.ipc.Client.call(Client.java:1479)\r\n2022-03-23T05:36:34.5922459Z \tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\r\n2022-03-23T05:36:34.5922939Z \tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\r\n2022-03-23T05:36:34.5923377Z \tat com.sun.proxy.$Proxy43.renewLease(Unknown Source)\r\n2022-03-23T05:36:34.5923898Z \tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:590)\r\n2022-03-23T05:36:34.5924434Z \tat sun.reflect.GeneratedMethodAccessor471.invoke(Unknown Source)\r\n2022-03-23T05:36:34.5924879Z \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n2022-03-23T05:36:34.5925339Z \tat java.lang.reflect.Method.invoke(Method.java:498)\r\n2022-03-23T05:36:34.5925810Z \tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\r\n2022-03-23T05:36:34.5926357Z \tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\r\n2022-03-23T05:36:34.5926807Z \tat com.sun.proxy.$Proxy44.renewLease(Unknown Source)\r\n2022-03-23T05:36:34.5927201Z \tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:892)\r\n2022-03-23T05:36:34.5927644Z \tat org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:423)\r\n2022-03-23T05:36:34.5928087Z \tat org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:448)\r\n2022-03-23T05:36:34.5928540Z \tat org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)\r\n2022-03-23T05:36:34.5929000Z \tat org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:304)\r\n2022-03-23T05:36:34.5929395Z \tat java.lang.Thread.run(Thread.java:750)\r\n2022-03-23T05:36:34.5929749Z Caused by: java.net.ConnectException: Connection refused\r\n2022-03-23T05:36:34.5930105Z \tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\r\n2022-03-23T05:36:34.5930528Z \tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\r\n2022-03-23T05:36:34.5931023Z \tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\r\n2022-03-23T05:36:34.5931487Z \tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\r\n2022-03-23T05:36:34.5931917Z \tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)\r\n2022-03-23T05:36:34.5932361Z \tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)\r\n2022-03-23T05:36:34.5932836Z \tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)\r\n2022-03-23T05:36:34.5933506Z \tat org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)\r\n2022-03-23T05:36:34.5933956Z \tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)\r\n2022-03-23T05:36:34.5934364Z \tat org.apache.hadoop.ipc.Client.call(Client.java:1451)\r\n2022-03-23T05:36:34.5934674Z \t... 16 more\r\n```\r\n\r\nSeems like thread renewing the lease from HDFS is just getting stuck in a constant loop of trying to renew the lease, while all of the other components of the test (including HDFS itself) have been shutdown.\r\n\r\nTest failure seem to occur due to following exception found in the logs right above the first occurrence of the previous exception: \r\n\r\n```\r\n2022-03-23T05:36:02.6376389Z 1590537 [pool-235-thread-7] WARN  org.apache.hadoop.hive.metastore.ObjectStore  - Falling back to ORM path due to direct SQL failure (this is not an error): See previous errors; Error executing SQL query \"SELECT \"DBS\".\"NAME\", \"TBLS\".\"TBL_NAME\", \"COLUMNS_V2\".\"COLUMN_NAME\",\"KEY_CONSTRAINTS\".\"POSITION\", \"KEY_CONSTRAINTS\".\"CONSTRAINT_NAME\", \"KEY_CONSTRAINTS\".\"ENABLE_VALIDATE_RELY\"  FROM  \"TBLS\"  INNER  JOIN \"KEY_CONSTRAINTS\" ON \"TBLS\".\"TBL_ID\" = \"KEY_CONSTRAINTS\".\"PARENT_TBL_ID\"  INNER JOIN \"DBS\" ON \"TBLS\".\"DB_ID\" = \"DBS\".\"DB_ID\"  INNER JOIN \"COLUMNS_V2\" ON \"COLUMNS_V2\".\"CD_ID\" = \"KEY_CONSTRAINTS\".\"PARENT_CD_ID\" AND  \"COLUMNS_V2\".\"INTEGER_IDX\" = \"KEY_CONSTRAINTS\".\"PARENT_INTEGER_IDX\"  WHERE \"KEY_CONSTRAINTS\".\"CONSTRAINT_TYPE\" = 0 AND \"DBS\".\"NAME\" = ? AND \"TBLS\".\"TBL_NAME\" = ?\". at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.executeWithArray(MetaStoreDirectSql.java:1762) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPrimaryKeys(MetaStoreDirectSql.java:1939) at org.apache.hadoop.hive.metastore.ObjectStore$11.getSqlResult(ObjectStore.java:8551)\r\n2022-03-23T05:36:03.4650339Z 1591360 [main] ERROR org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer  - Got error running delta sync once. Shutting down\r\n2022-03-23T05:36:03.4651433Z org.apache.hudi.exception.HoodieException: Could not sync using the meta sync class org.apache.hudi.hive.HiveSyncTool\r\n2022-03-23T05:36:03.4652199Z \tat org.apache.hudi.sync.common.util.SyncUtilHelpers.runHoodieMetaSync(SyncUtilHelpers.java:42)\r\n2022-03-23T05:36:03.4652952Z \tat org.apache.hudi.utilities.deltastreamer.DeltaSync.syncMeta(DeltaSync.java:704)\r\n2022-03-23T05:36:03.4653977Z \tat org.apache.hudi.utilities.deltastreamer.DeltaSync.writeToSink(DeltaSync.java:623)\r\n2022-03-23T05:36:03.4654597Z \tat org.apache.hudi.utilities.deltastreamer.DeltaSync.syncOnce(DeltaSync.java:327)\r\n2022-03-23T05:36:03.4655192Z \tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.lambda$sync$2(HoodieDeltaStreamer.java:193)\r\n2022-03-23T05:36:03.4655832Z \tat org.apache.hudi.common.util.Option.ifPresent(Option.java:97)\r\n2022-03-23T05:36:03.4656359Z \tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.sync(HoodieDeltaStreamer.java:191)\r\n2022-03-23T05:36:03.4657020Z \tat org.apache.hudi.utilities.functional.TestHoodieDeltaStreamer.testPayloadClassUpdateWithCOWTable(TestHoodieDeltaStreamer.java:1289)\r\n2022-03-23T05:36:03.4657584Z \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n2022-03-23T05:36:03.4658030Z \tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n2022-03-23T05:36:03.4658573Z \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n2022-03-23T05:36:03.4659033Z \tat java.lang.reflect.Method.invoke(Method.java:498)\r\n2022-03-23T05:36:03.4659481Z \tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)\r\n2022-03-23T05:36:03.4660255Z \tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)\r\n2022-03-23T05:36:03.4660960Z \tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)\r\n2022-03-23T05:36:03.4661557Z \tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)\r\n2022-03-23T05:36:03.4662114Z \tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)\r\n2022-03-23T05:36:03.4662695Z \tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)\r\n2022-03-23T05:36:03.4663396Z \tat org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)\r\n2022-03-23T05:36:03.4664018Z \tat org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)\r\n2022-03-23T05:36:03.4664656Z \tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\r\n2022-03-23T05:36:03.4665300Z \tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\r\n2022-03-23T05:36:03.4665917Z \tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\r\n2022-03-23T05:36:03.4666533Z \tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\r\n2022-03-23T05:36:03.4667089Z \tat org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)\r\n2022-03-23T05:36:03.4667615Z \tat org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)\r\n2022-03-23T05:36:03.4668213Z \tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:212)\r\n2022-03-23T05:36:03.4668824Z \tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n2022-03-23T05:36:03.4669426Z \tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:208)\r\n2022-03-23T05:36:03.4670035Z \tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:137)\r\n2022-03-23T05:36:03.4670617Z \tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:71)\r\n2022-03-23T05:36:03.4671204Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)\r\n2022-03-23T05:36:03.4671943Z \tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n2022-03-23T05:36:03.4672546Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)\r\n2022-03-23T05:36:03.4673078Z \tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\r\n2022-03-23T05:36:03.4673634Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)\r\n2022-03-23T05:36:03.4674232Z \tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n2022-03-23T05:36:03.4674797Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)\r\n2022-03-23T05:36:03.4675352Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)\r\n2022-03-23T05:36:03.4675812Z \tat java.util.ArrayList.forEach(ArrayList.java:1259)\r\n2022-03-23T05:36:03.4676378Z \tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38)\r\n2022-03-23T05:36:03.4677074Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143)\r\n2022-03-23T05:36:03.4677677Z \tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n2022-03-23T05:36:03.4678371Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)\r\n2022-03-23T05:36:03.4678913Z \tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\r\n2022-03-23T05:36:03.4679456Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)\r\n2022-03-23T05:36:03.4680043Z \tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n2022-03-23T05:36:03.4680612Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)\r\n2022-03-23T05:36:03.4681230Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)\r\n2022-03-23T05:36:03.4681697Z \tat java.util.ArrayList.forEach(ArrayList.java:1259)\r\n2022-03-23T05:36:03.4682269Z \tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38)\r\n2022-03-23T05:36:03.4682959Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143)\r\n2022-03-23T05:36:03.4683562Z \tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n2022-03-23T05:36:03.4684159Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)\r\n2022-03-23T05:36:03.4684700Z \tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\r\n2022-03-23T05:36:03.4685251Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)\r\n2022-03-23T05:36:03.4685851Z \tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n2022-03-23T05:36:03.4686419Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)\r\n2022-03-23T05:36:03.4686983Z \tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)\r\n2022-03-23T05:36:03.4687625Z \tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32)\r\n2022-03-23T05:36:03.4688303Z \tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)\r\n2022-03-23T05:36:03.4688916Z \tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:51)\r\n2022-03-23T05:36:03.4689508Z \tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)\r\n2022-03-23T05:36:03.4690103Z \tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:87)\r\n2022-03-23T05:36:03.4690714Z \tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:53)\r\n2022-03-23T05:36:03.4691355Z \tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:66)\r\n2022-03-23T05:36:03.4691970Z \tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:51)\r\n2022-03-23T05:36:03.4692502Z \tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:87)\r\n2022-03-23T05:36:03.4693008Z \tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:75)\r\n2022-03-23T05:36:03.4693494Z \tat org.junit.platform.runner.JUnitPlatform.run(JUnitPlatform.java:139)\r\n2022-03-23T05:36:03.4693905Z \tat org.junit.runners.Suite.runChild(Suite.java:128)\r\n2022-03-23T05:36:03.4694290Z \tat org.junit.runners.Suite.runChild(Suite.java:27)\r\n2022-03-23T05:36:03.4694688Z \tat org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\r\n2022-03-23T05:36:03.4695113Z \tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\r\n2022-03-23T05:36:03.4695606Z \tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\r\n2022-03-23T05:36:03.4696047Z \tat org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\r\n2022-03-23T05:36:03.4696491Z \tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\r\n2022-03-23T05:36:03.4696935Z \tat org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\r\n2022-03-23T05:36:03.4697354Z \tat org.junit.runners.ParentRunner.run(ParentRunner.java:413)\r\n2022-03-23T05:36:03.4697792Z \tat org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55)\r\n2022-03-23T05:36:03.4698308Z \tat org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137)\r\n2022-03-23T05:36:03.4698917Z \tat org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107)\r\n2022-03-23T05:36:03.4699458Z \tat org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83)\r\n2022-03-23T05:36:03.4699986Z \tat org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75)\r\n2022-03-23T05:36:03.4700522Z \tat org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158)\r\n2022-03-23T05:36:03.4701053Z \tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)\r\n2022-03-23T05:36:03.4701566Z \tat org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)\r\n2022-03-23T05:36:03.4702047Z \tat org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)\r\n2022-03-23T05:36:03.4702521Z \tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)\r\n2022-03-23T05:36:03.4703010Z Caused by: org.apache.hudi.exception.HoodieException: Got runtime exception when hive syncing hive_trips\r\n2022-03-23T05:36:03.4703494Z \tat org.apache.hudi.hive.HiveSyncTool.syncHoodieTable(HiveSyncTool.java:140)\r\n2022-03-23T05:36:03.4704004Z \tat org.apache.hudi.sync.common.util.SyncUtilHelpers.runHoodieMetaSync(SyncUtilHelpers.java:40)\r\n2022-03-23T05:36:03.4704391Z \t... 88 more\r\n2022-03-23T05:36:03.4704755Z Caused by: org.apache.hudi.hive.HoodieHiveSyncException: Failed to sync partitions for table hive_trips\r\n2022-03-23T05:36:03.4705226Z \tat org.apache.hudi.hive.HiveSyncTool.syncPartitions(HiveSyncTool.java:402)\r\n2022-03-23T05:36:03.4705700Z \tat org.apache.hudi.hive.HiveSyncTool.syncHoodieTable(HiveSyncTool.java:220)\r\n2022-03-23T05:36:03.4706160Z \tat org.apache.hudi.hive.HiveSyncTool.doSync(HiveSyncTool.java:151)\r\n2022-03-23T05:36:03.4706609Z \tat org.apache.hudi.hive.HiveSyncTool.syncHoodieTable(HiveSyncTool.java:137)\r\n2022-03-23T05:36:03.4706955Z \t... 89 more\r\n2022-03-23T05:36:03.4707376Z Caused by: java.lang.IllegalArgumentException: Partition key parts [datestr] does not match with partition values [2015, 03, 16]. Check partition strategy. \r\n2022-03-23T05:36:03.4707953Z \tat org.apache.hudi.common.util.ValidationUtils.checkArgument(ValidationUtils.java:40)\r\n2022-03-23T05:36:03.4708497Z \tat org.apache.hudi.hive.ddl.QueryBasedDDLExecutor.getPartitionClause(QueryBasedDDLExecutor.java:184)\r\n2022-03-23T05:36:03.4709078Z \tat org.apache.hudi.hive.ddl.QueryBasedDDLExecutor.constructAddPartitions(QueryBasedDDLExecutor.java:158)\r\n2022-03-23T05:36:03.4709649Z \tat org.apache.hudi.hive.ddl.QueryBasedDDLExecutor.addPartitionsToTable(QueryBasedDDLExecutor.java:115)\r\n2022-03-23T05:36:03.4710194Z \tat org.apache.hudi.hive.HoodieHiveClient.addPartitionsToTable(HoodieHiveClient.java:123)\r\n2022-03-23T05:36:03.4710693Z \tat org.apache.hudi.hive.HiveSyncTool.syncPartitions(HiveSyncTool.java:385)\r\n2022-03-23T05:36:03.4711031Z \t... 92 more\r\n```\r\nhttps://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_apis/build/builds/7211/logs/69","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075956587/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075958844","html_url":"https://github.com/apache/hudi/pull/5102#issuecomment-1075958844","issue_url":"https://api.github.com/repos/apache/hudi/issues/5102","id":1075958844,"node_id":"IC_kwDOBI7nWM5AIdQ8","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T06:14:50Z","updated_at":"2022-03-23T06:14:50Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"8311cb4ae825e75628bbc98a4d9b10bd6e52b59e\",\n    \"status\" : \"CANCELED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7217\",\n    \"triggerID\" : \"8311cb4ae825e75628bbc98a4d9b10bd6e52b59e\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 8311cb4ae825e75628bbc98a4d9b10bd6e52b59e Azure: [CANCELED](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7217) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075958844/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075996925","html_url":"https://github.com/apache/hudi/pull/5099#issuecomment-1075996925","issue_url":"https://api.github.com/repos/apache/hudi/issues/5099","id":1075996925,"node_id":"IC_kwDOBI7nWM5AImj9","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T07:07:27Z","updated_at":"2022-03-23T07:07:27Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"7ab14eac41176f70df83f40c594c72e9d78183b0\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7209\",\n    \"triggerID\" : \"7ab14eac41176f70df83f40c594c72e9d78183b0\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"9be827be3e98ed6de2a85f8ccf6a7c3ba36b4731\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7212\",\n    \"triggerID\" : \"9be827be3e98ed6de2a85f8ccf6a7c3ba36b4731\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"84180852d5ca5f128afa8972a436f5dbcdd0d3ab\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7214\",\n    \"triggerID\" : \"1075886765\",\n    \"triggerType\" : \"MANUAL\"\n  }, {\n    \"hash\" : \"84180852d5ca5f128afa8972a436f5dbcdd0d3ab\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7214\",\n    \"triggerID\" : \"84180852d5ca5f128afa8972a436f5dbcdd0d3ab\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"TBD\",\n    \"triggerID\" : \"1075886765\",\n    \"triggerType\" : \"MANUAL\"\n  }, {\n    \"hash\" : \"84180852d5ca5f128afa8972a436f5dbcdd0d3ab\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7219\",\n    \"triggerID\" : \"1075936939\",\n    \"triggerType\" : \"MANUAL\"\n  } ]\n}-->\n## CI report:\n\n* 84180852d5ca5f128afa8972a436f5dbcdd0d3ab Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7214) Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7219) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1075996925/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076039588","html_url":"https://github.com/apache/hudi/pull/5090#issuecomment-1076039588","issue_url":"https://api.github.com/repos/apache/hudi/issues/5090","id":1076039588,"node_id":"IC_kwDOBI7nWM5AIw-k","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T07:54:50Z","updated_at":"2022-03-23T07:54:50Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"13b84294fa4e9614b5010d3ccc6cc76db929a8f5\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7177\",\n    \"triggerID\" : \"13b84294fa4e9614b5010d3ccc6cc76db929a8f5\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"70482ca1b89479d37f8155baa7ec5a44c199fe5a\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7222\",\n    \"triggerID\" : \"70482ca1b89479d37f8155baa7ec5a44c199fe5a\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 70482ca1b89479d37f8155baa7ec5a44c199fe5a Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7222) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076039588/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076058350","html_url":"https://github.com/apache/hudi/pull/5099#issuecomment-1076058350","issue_url":"https://api.github.com/repos/apache/hudi/issues/5099","id":1076058350,"node_id":"IC_kwDOBI7nWM5AI1ju","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T08:07:32Z","updated_at":"2022-03-23T08:07:32Z","author_association":"MEMBER","body":"fixing this in #5103 ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076058350/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076063686","html_url":"https://github.com/apache/hudi/issues/5105#issuecomment-1076063686","issue_url":"https://api.github.com/repos/apache/hudi/issues/5105","id":1076063686,"node_id":"IC_kwDOBI7nWM5AI23G","user":{"login":"CrazyBeeline","id":25030234,"node_id":"MDQ6VXNlcjI1MDMwMjM0","avatar_url":"https://avatars.githubusercontent.com/u/25030234?v=4","gravatar_id":"","url":"https://api.github.com/users/CrazyBeeline","html_url":"https://github.com/CrazyBeeline","followers_url":"https://api.github.com/users/CrazyBeeline/followers","following_url":"https://api.github.com/users/CrazyBeeline/following{/other_user}","gists_url":"https://api.github.com/users/CrazyBeeline/gists{/gist_id}","starred_url":"https://api.github.com/users/CrazyBeeline/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CrazyBeeline/subscriptions","organizations_url":"https://api.github.com/users/CrazyBeeline/orgs","repos_url":"https://api.github.com/users/CrazyBeeline/repos","events_url":"https://api.github.com/users/CrazyBeeline/events{/privacy}","received_events_url":"https://api.github.com/users/CrazyBeeline/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T08:13:24Z","updated_at":"2022-03-23T08:13:24Z","author_association":"NONE","body":"By the way, using this configuration will stop the HoodieDeltaStreamer task\r\n--------\r\n![image](https://user-images.githubusercontent.com/25030234/159653242-06241134-fc8f-4680-bfab-6eab0b24946c.png)\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076063686/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076077724","html_url":"https://github.com/apache/hudi/issues/5053#issuecomment-1076077724","issue_url":"https://api.github.com/repos/apache/hudi/issues/5053","id":1076077724,"node_id":"IC_kwDOBI7nWM5AI6Sc","user":{"login":"worf0815","id":10959555,"node_id":"MDQ6VXNlcjEwOTU5NTU1","avatar_url":"https://avatars.githubusercontent.com/u/10959555?v=4","gravatar_id":"","url":"https://api.github.com/users/worf0815","html_url":"https://github.com/worf0815","followers_url":"https://api.github.com/users/worf0815/followers","following_url":"https://api.github.com/users/worf0815/following{/other_user}","gists_url":"https://api.github.com/users/worf0815/gists{/gist_id}","starred_url":"https://api.github.com/users/worf0815/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/worf0815/subscriptions","organizations_url":"https://api.github.com/users/worf0815/orgs","repos_url":"https://api.github.com/users/worf0815/repos","events_url":"https://api.github.com/users/worf0815/events{/privacy}","received_events_url":"https://api.github.com/users/worf0815/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T08:28:03Z","updated_at":"2022-03-23T08:28:22Z","author_association":"NONE","body":"> I'm working with scala, so can it be solved by importing `jackson` separately?\r\n\r\nIf you are using EMR, AWS-Support recommended to separately specify the AWS dependency, e.g. for pyspark (though the same should work for spark-submit as well):\r\n\r\n`pyspark --conf \"spark.serializer=org.apache.spark.serializer.KryoSerializer\" --conf \"spark.sql.hive.convertMetastoreParquet=false\" --jars /usr/share/aws/aws-java-sdk/aws-java-sdk-bundle-1.12.31.jar,/usr/lib/hudi/hudi-spark-bundle.jar,/usr/lib/spark/jars/spark-avro.jar`","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076077724/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076154652","html_url":"https://github.com/apache/hudi/pull/5096#issuecomment-1076154652","issue_url":"https://api.github.com/repos/apache/hudi/issues/5096","id":1076154652,"node_id":"IC_kwDOBI7nWM5AJNEc","user":{"login":"wangxianghu","id":49835526,"node_id":"MDQ6VXNlcjQ5ODM1NTI2","avatar_url":"https://avatars.githubusercontent.com/u/49835526?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxianghu","html_url":"https://github.com/wangxianghu","followers_url":"https://api.github.com/users/wangxianghu/followers","following_url":"https://api.github.com/users/wangxianghu/following{/other_user}","gists_url":"https://api.github.com/users/wangxianghu/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxianghu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxianghu/subscriptions","organizations_url":"https://api.github.com/users/wangxianghu/orgs","repos_url":"https://api.github.com/users/wangxianghu/repos","events_url":"https://api.github.com/users/wangxianghu/events{/privacy}","received_events_url":"https://api.github.com/users/wangxianghu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T09:39:17Z","updated_at":"2022-03-23T09:39:17Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076154652/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076171942","html_url":"https://github.com/apache/hudi/issues/4825#issuecomment-1076171942","issue_url":"https://api.github.com/repos/apache/hudi/issues/4825","id":1076171942,"node_id":"IC_kwDOBI7nWM5AJRSm","user":{"login":"CodeCooker17","id":64473732,"node_id":"MDQ6VXNlcjY0NDczNzMy","avatar_url":"https://avatars.githubusercontent.com/u/64473732?v=4","gravatar_id":"","url":"https://api.github.com/users/CodeCooker17","html_url":"https://github.com/CodeCooker17","followers_url":"https://api.github.com/users/CodeCooker17/followers","following_url":"https://api.github.com/users/CodeCooker17/following{/other_user}","gists_url":"https://api.github.com/users/CodeCooker17/gists{/gist_id}","starred_url":"https://api.github.com/users/CodeCooker17/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CodeCooker17/subscriptions","organizations_url":"https://api.github.com/users/CodeCooker17/orgs","repos_url":"https://api.github.com/users/CodeCooker17/repos","events_url":"https://api.github.com/users/CodeCooker17/events{/privacy}","received_events_url":"https://api.github.com/users/CodeCooker17/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T09:57:40Z","updated_at":"2022-03-23T09:57:40Z","author_association":"CONTRIBUTOR","body":"\r\n\r\n\r\n> > Yes, the default bundle jar does not include the hive jar but the hive class is shaded.\r\n> \r\n> How can I reference a Hudi package with hive synchronization in the local environment\r\n\r\nhi,\r\n \r\nYou can refer to the tutorial on the official website https://hudi.apache.org/docs/syncing_metastore\r\nYou can  choose the following way 'mvn install -DskipTests -Drat.skip=true -Pflink-bundle-shade-hive2' when you compile.\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076171942/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076173999","html_url":"https://github.com/apache/hudi/pull/5108#issuecomment-1076173999","issue_url":"https://api.github.com/repos/apache/hudi/issues/5108","id":1076173999,"node_id":"IC_kwDOBI7nWM5AJRyv","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T09:59:48Z","updated_at":"2022-03-23T09:59:48Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"d2cda00cfa9601ad2471ed024ed6d687b70c8d2f\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7229\",\n    \"triggerID\" : \"d2cda00cfa9601ad2471ed024ed6d687b70c8d2f\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* d2cda00cfa9601ad2471ed024ed6d687b70c8d2f Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7229) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076173999/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076190767","html_url":"https://github.com/apache/hudi/issues/5053#issuecomment-1076190767","issue_url":"https://api.github.com/repos/apache/hudi/issues/5053","id":1076190767,"node_id":"IC_kwDOBI7nWM5AJV4v","user":{"login":"rkkalluri","id":3401900,"node_id":"MDQ6VXNlcjM0MDE5MDA=","avatar_url":"https://avatars.githubusercontent.com/u/3401900?v=4","gravatar_id":"","url":"https://api.github.com/users/rkkalluri","html_url":"https://github.com/rkkalluri","followers_url":"https://api.github.com/users/rkkalluri/followers","following_url":"https://api.github.com/users/rkkalluri/following{/other_user}","gists_url":"https://api.github.com/users/rkkalluri/gists{/gist_id}","starred_url":"https://api.github.com/users/rkkalluri/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rkkalluri/subscriptions","organizations_url":"https://api.github.com/users/rkkalluri/orgs","repos_url":"https://api.github.com/users/rkkalluri/repos","events_url":"https://api.github.com/users/rkkalluri/events{/privacy}","received_events_url":"https://api.github.com/users/rkkalluri/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T10:15:00Z","updated_at":"2022-03-23T10:15:00Z","author_association":"CONTRIBUTOR","body":"spark.{driver,executor}.userClassPathFirst=true  will also hint spark to prioritize the --jars you provide","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076190767/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076246684","html_url":"https://github.com/apache/hudi/issues/5053#issuecomment-1076246684","issue_url":"https://api.github.com/repos/apache/hudi/issues/5053","id":1076246684,"node_id":"IC_kwDOBI7nWM5AJjic","user":{"login":"kination","id":1720209,"node_id":"MDQ6VXNlcjE3MjAyMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1720209?v=4","gravatar_id":"","url":"https://api.github.com/users/kination","html_url":"https://github.com/kination","followers_url":"https://api.github.com/users/kination/followers","following_url":"https://api.github.com/users/kination/following{/other_user}","gists_url":"https://api.github.com/users/kination/gists{/gist_id}","starred_url":"https://api.github.com/users/kination/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kination/subscriptions","organizations_url":"https://api.github.com/users/kination/orgs","repos_url":"https://api.github.com/users/kination/repos","events_url":"https://api.github.com/users/kination/events{/privacy}","received_events_url":"https://api.github.com/users/kination/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T11:13:39Z","updated_at":"2022-03-23T11:13:39Z","author_association":"CONTRIBUTOR","body":"@worf0815 so will it be solved by using `aws-java-sdk-bundle-1.12.31.jar, hudi-spark-bundle.jar, spark-avro.jar` jar files inside EMR?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076246684/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076264419","html_url":"https://github.com/apache/hudi/pull/5093#issuecomment-1076264419","issue_url":"https://api.github.com/repos/apache/hudi/issues/5093","id":1076264419,"node_id":"IC_kwDOBI7nWM5AJn3j","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T11:31:11Z","updated_at":"2022-03-23T11:31:11Z","author_association":"MEMBER","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076264419/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076271726","html_url":"https://github.com/apache/hudi/pull/5095#issuecomment-1076271726","issue_url":"https://api.github.com/repos/apache/hudi/issues/5095","id":1076271726,"node_id":"IC_kwDOBI7nWM5AJppu","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T11:38:22Z","updated_at":"2022-03-23T11:38:22Z","author_association":"CONTRIBUTOR","body":"sorry folks. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076271726/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076281067","html_url":"https://github.com/apache/hudi/pull/5103#issuecomment-1076281067","issue_url":"https://api.github.com/repos/apache/hudi/issues/5103","id":1076281067,"node_id":"IC_kwDOBI7nWM5AJr7r","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T11:47:44Z","updated_at":"2022-03-23T11:47:44Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076281067/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076318960","html_url":"https://github.com/apache/hudi/issues/4682#issuecomment-1076318960","issue_url":"https://api.github.com/repos/apache/hudi/issues/4682","id":1076318960,"node_id":"IC_kwDOBI7nWM5AJ1Lw","user":{"login":"tjtoll","id":56052873,"node_id":"MDQ6VXNlcjU2MDUyODcz","avatar_url":"https://avatars.githubusercontent.com/u/56052873?v=4","gravatar_id":"","url":"https://api.github.com/users/tjtoll","html_url":"https://github.com/tjtoll","followers_url":"https://api.github.com/users/tjtoll/followers","following_url":"https://api.github.com/users/tjtoll/following{/other_user}","gists_url":"https://api.github.com/users/tjtoll/gists{/gist_id}","starred_url":"https://api.github.com/users/tjtoll/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tjtoll/subscriptions","organizations_url":"https://api.github.com/users/tjtoll/orgs","repos_url":"https://api.github.com/users/tjtoll/repos","events_url":"https://api.github.com/users/tjtoll/events{/privacy}","received_events_url":"https://api.github.com/users/tjtoll/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T12:27:26Z","updated_at":"2022-03-23T12:27:26Z","author_association":"NONE","body":"Good morning,\r\n\r\nWe are experiencing the same issue with .10 and .9 (see UI below). Also using S3, but using AWS Glue not EMR. What stands out to me are the 3 consecutive 'Getting small files from partitions' stages that with 4, 20, 100 tasks respectively. The stages with 4 and 20 tasks obviously getting very poor parallelization. The identical behavior exists on my UI and [ChiehFu](https://github.com/ChiehFu)'s\r\n\r\n![image](https://user-images.githubusercontent.com/56052873/159698317-d41ff1ff-fd9d-4bbb-ac95-f3b31d875e6b.png)\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076318960/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076339572","html_url":"https://github.com/apache/hudi/pull/5111#issuecomment-1076339572","issue_url":"https://api.github.com/repos/apache/hudi/issues/5111","id":1076339572,"node_id":"IC_kwDOBI7nWM5AJ6N0","user":{"login":"miomiocat","id":11596570,"node_id":"MDQ6VXNlcjExNTk2NTcw","avatar_url":"https://avatars.githubusercontent.com/u/11596570?v=4","gravatar_id":"","url":"https://api.github.com/users/miomiocat","html_url":"https://github.com/miomiocat","followers_url":"https://api.github.com/users/miomiocat/followers","following_url":"https://api.github.com/users/miomiocat/following{/other_user}","gists_url":"https://api.github.com/users/miomiocat/gists{/gist_id}","starred_url":"https://api.github.com/users/miomiocat/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/miomiocat/subscriptions","organizations_url":"https://api.github.com/users/miomiocat/orgs","repos_url":"https://api.github.com/users/miomiocat/repos","events_url":"https://api.github.com/users/miomiocat/events{/privacy}","received_events_url":"https://api.github.com/users/miomiocat/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T12:50:57Z","updated_at":"2022-03-23T12:50:57Z","author_association":"CONTRIBUTOR","body":"@alexeykudinkin @YannByron PTAL","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076339572/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076345195","html_url":"https://github.com/apache/hudi/pull/5103#issuecomment-1076345195","issue_url":"https://api.github.com/repos/apache/hudi/issues/5103","id":1076345195,"node_id":"IC_kwDOBI7nWM5AJ7lr","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T12:57:07Z","updated_at":"2022-03-23T12:57:07Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"206cd2a2836a06b7baaf26696558ee34871d99fb\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7218\",\n    \"triggerID\" : \"206cd2a2836a06b7baaf26696558ee34871d99fb\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"3ea76b81f7cfdd482d5223658bb3ca7c9d3e4f69\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7224\",\n    \"triggerID\" : \"3ea76b81f7cfdd482d5223658bb3ca7c9d3e4f69\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"88e01022e0799c134994bbc2f6189d3c7ce18ff2\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7227\",\n    \"triggerID\" : \"88e01022e0799c134994bbc2f6189d3c7ce18ff2\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"49b9dc644810606d32302443d64dc4c83b13445c\",\n    \"status\" : \"SUCCESS\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7232\",\n    \"triggerID\" : \"49b9dc644810606d32302443d64dc4c83b13445c\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"49b9dc644810606d32302443d64dc4c83b13445c\",\n    \"status\" : \"CANCELED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7236\",\n    \"triggerID\" : \"1076281067\",\n    \"triggerType\" : \"MANUAL\"\n  }, {\n    \"hash\" : \"43579baa17c898d791a8315a11bc8a3230d8547c\",\n    \"status\" : \"PENDING\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7241\",\n    \"triggerID\" : \"43579baa17c898d791a8315a11bc8a3230d8547c\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 49b9dc644810606d32302443d64dc4c83b13445c Azure: [SUCCESS](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7232) Azure: [CANCELED](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7236) \n* 43579baa17c898d791a8315a11bc8a3230d8547c Azure: [PENDING](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7241) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076345195/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076384540","html_url":"https://github.com/apache/hudi/issues/5101#issuecomment-1076384540","issue_url":"https://api.github.com/repos/apache/hudi/issues/5101","id":1076384540,"node_id":"IC_kwDOBI7nWM5AKFMc","user":{"login":"qjqqyy","id":8439769,"node_id":"MDQ6VXNlcjg0Mzk3Njk=","avatar_url":"https://avatars.githubusercontent.com/u/8439769?v=4","gravatar_id":"","url":"https://api.github.com/users/qjqqyy","html_url":"https://github.com/qjqqyy","followers_url":"https://api.github.com/users/qjqqyy/followers","following_url":"https://api.github.com/users/qjqqyy/following{/other_user}","gists_url":"https://api.github.com/users/qjqqyy/gists{/gist_id}","starred_url":"https://api.github.com/users/qjqqyy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qjqqyy/subscriptions","organizations_url":"https://api.github.com/users/qjqqyy/orgs","repos_url":"https://api.github.com/users/qjqqyy/repos","events_url":"https://api.github.com/users/qjqqyy/events{/privacy}","received_events_url":"https://api.github.com/users/qjqqyy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T13:36:40Z","updated_at":"2022-03-23T18:36:16Z","author_association":"CONTRIBUTOR","body":"Some key generators such as ComplexKeyGenerator requires you to pass in `hoodie.datasource.write.partitionpath.field=` to indicate that the table is non-partitioned.\r\n\r\nSeems like HoodieSyncConfig will infer this setting differently <https://github.com/apache/hudi/blob/5f570ea151d0212ab1bb2d1f5693035626b76d31/hudi-sync/hudi-sync-common/src/main/java/org/apache/hudi/sync/common/HoodieSyncConfig.java#L113>\r\nand set partitionFields as a 1-length list containing \"\", which has different semantics to partitionFields = null.\r\n\r\nRelated question: is there a valid usecase for `TypedProperties#getStringList` of \"\" to return [\"\"]?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076384540/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076483733","html_url":"https://github.com/apache/hudi/pull/5110#issuecomment-1076483733","issue_url":"https://api.github.com/repos/apache/hudi/issues/5110","id":1076483733,"node_id":"IC_kwDOBI7nWM5AKdaV","user":{"login":"YuweiXiao","id":9959868,"node_id":"MDQ6VXNlcjk5NTk4Njg=","avatar_url":"https://avatars.githubusercontent.com/u/9959868?v=4","gravatar_id":"","url":"https://api.github.com/users/YuweiXiao","html_url":"https://github.com/YuweiXiao","followers_url":"https://api.github.com/users/YuweiXiao/followers","following_url":"https://api.github.com/users/YuweiXiao/following{/other_user}","gists_url":"https://api.github.com/users/YuweiXiao/gists{/gist_id}","starred_url":"https://api.github.com/users/YuweiXiao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YuweiXiao/subscriptions","organizations_url":"https://api.github.com/users/YuweiXiao/orgs","repos_url":"https://api.github.com/users/YuweiXiao/repos","events_url":"https://api.github.com/users/YuweiXiao/events{/privacy}","received_events_url":"https://api.github.com/users/YuweiXiao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T15:20:14Z","updated_at":"2022-03-23T15:20:14Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076483733/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076542458","html_url":"https://github.com/apache/hudi/pull/5109#issuecomment-1076542458","issue_url":"https://api.github.com/repos/apache/hudi/issues/5109","id":1076542458,"node_id":"IC_kwDOBI7nWM5AKrv6","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T16:30:17Z","updated_at":"2022-03-23T16:30:17Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"12da00f59a359df03e5cdfbd5523a4ce6411fc52\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7234\",\n    \"triggerID\" : \"12da00f59a359df03e5cdfbd5523a4ce6411fc52\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"cec17e2be06093234d86b6d795780664fa3660ad\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7242\",\n    \"triggerID\" : \"cec17e2be06093234d86b6d795780664fa3660ad\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"d3bd8b5dac403d27c0d8ad7a48b6090f3a50b3bf\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7245\",\n    \"triggerID\" : \"d3bd8b5dac403d27c0d8ad7a48b6090f3a50b3bf\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"aa0fa2692e057bf2406631adc8a447a56e272e67\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7247\",\n    \"triggerID\" : \"aa0fa2692e057bf2406631adc8a447a56e272e67\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* aa0fa2692e057bf2406631adc8a447a56e272e67 Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7247) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076542458/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076578264","html_url":"https://github.com/apache/hudi/pull/4910#issuecomment-1076578264","issue_url":"https://api.github.com/repos/apache/hudi/issues/4910","id":1076578264,"node_id":"IC_kwDOBI7nWM5AK0fY","user":{"login":"xiarixiaoyao","id":13514703,"node_id":"MDQ6VXNlcjEzNTE0NzAz","avatar_url":"https://avatars.githubusercontent.com/u/13514703?v=4","gravatar_id":"","url":"https://api.github.com/users/xiarixiaoyao","html_url":"https://github.com/xiarixiaoyao","followers_url":"https://api.github.com/users/xiarixiaoyao/followers","following_url":"https://api.github.com/users/xiarixiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/xiarixiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/xiarixiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiarixiaoyao/subscriptions","organizations_url":"https://api.github.com/users/xiarixiaoyao/orgs","repos_url":"https://api.github.com/users/xiarixiaoyao/repos","events_url":"https://api.github.com/users/xiarixiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/xiarixiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T17:02:32Z","updated_at":"2022-03-23T17:02:32Z","author_association":"CONTRIBUTOR","body":"@bvaradar  addressed all comments. and there are some comments that may need to be discussed.\r\ncould you pls help me review again, thank you very much.\r\n\r\nNow code freeze has been delayed for a week,  i think we have enought time to make this pr more better.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076578264/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076670859","html_url":"https://github.com/apache/hudi/pull/5113#issuecomment-1076670859","issue_url":"https://api.github.com/repos/apache/hudi/issues/5113","id":1076670859,"node_id":"IC_kwDOBI7nWM5ALLGL","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T18:21:13Z","updated_at":"2022-03-23T18:21:13Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"59abcd3f5b8d94161ead1a8a02e27da62fc5c80f\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7251\",\n    \"triggerID\" : \"59abcd3f5b8d94161ead1a8a02e27da62fc5c80f\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 59abcd3f5b8d94161ead1a8a02e27da62fc5c80f Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7251) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076670859/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076683168","html_url":"https://github.com/apache/hudi/issues/5107#issuecomment-1076683168","issue_url":"https://api.github.com/repos/apache/hudi/issues/5107","id":1076683168,"node_id":"IC_kwDOBI7nWM5ALOGg","user":{"login":"qjqqyy","id":8439769,"node_id":"MDQ6VXNlcjg0Mzk3Njk=","avatar_url":"https://avatars.githubusercontent.com/u/8439769?v=4","gravatar_id":"","url":"https://api.github.com/users/qjqqyy","html_url":"https://github.com/qjqqyy","followers_url":"https://api.github.com/users/qjqqyy/followers","following_url":"https://api.github.com/users/qjqqyy/following{/other_user}","gists_url":"https://api.github.com/users/qjqqyy/gists{/gist_id}","starred_url":"https://api.github.com/users/qjqqyy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qjqqyy/subscriptions","organizations_url":"https://api.github.com/users/qjqqyy/orgs","repos_url":"https://api.github.com/users/qjqqyy/repos","events_url":"https://api.github.com/users/qjqqyy/events{/privacy}","received_events_url":"https://api.github.com/users/qjqqyy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T18:32:24Z","updated_at":"2022-03-23T22:21:07Z","author_association":"CONTRIBUTOR","body":"On current git master, the pseudocode for `HoodieSparkUtils::createRdd` actually looks like this\r\n\r\n```scala\r\ndf.mapPartitions { rows => \r\n  val convert: InternalRow => GenericRecord = { row =>\r\n    sparkAdapter.createAvroSerializer(???).serialize(row)\r\n  }\r\n  rows.map(convert)\r\n}\r\n```\r\nwhich seems to be why an `AvroSerializer`  is created for each row.\r\n\r\nI think this patch will cause `AvroSerializer` to only be initialized once for each partition, can you help try it?\r\n```patch\r\ndiff --git a/hudi-client/hudi-spark-client/src/main/scala/org/apache/hudi/AvroConversionUtils.scala b/hudi-client/hudi-spark-client/src/main/scala/org/apache/hudi/AvroConversionUtils.scala\r\nindex 69005cd75..9c63295d6 100644\r\n--- a/hudi-client/hudi-spark-client/src/main/scala/org/apache/hudi/AvroConversionUtils.scala\r\n+++ b/hudi-client/hudi-spark-client/src/main/scala/org/apache/hudi/AvroConversionUtils.scala\r\n@@ -76,7 +76,8 @@ object AvroConversionUtils {\r\n    * @return converter accepting Catalyst payload (in the form of [[InternalRow]]) and transforming it into an Avro one\r\n    */\r\n   def createInternalRowToAvroConverter(rootCatalystType: StructType, rootAvroType: Schema, nullable: Boolean): InternalRow => GenericRecord = {\r\n-    row => sparkAdapter.createAvroSerializer(rootCatalystType, rootAvroType, nullable)\r\n+    val serializer = sparkAdapter.createAvroSerializer(rootCatalystType, rootAvroType, nullable)\r\n+    row => serializer\r\n       .serialize(row)\r\n       .asInstanceOf[GenericRecord]\r\n   }\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076683168/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076725373","html_url":"https://github.com/apache/hudi/pull/5090#issuecomment-1076725373","issue_url":"https://api.github.com/repos/apache/hudi/issues/5090","id":1076725373,"node_id":"IC_kwDOBI7nWM5ALYZ9","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-23T19:12:51Z","updated_at":"2022-03-23T19:12:51Z","author_association":"CONTRIBUTOR","body":"The CI failures are due to other issues.  Merging this now.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076725373/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076950122","html_url":"https://github.com/apache/hudi/issues/5107#issuecomment-1076950122","issue_url":"https://api.github.com/repos/apache/hudi/issues/5107","id":1076950122,"node_id":"IC_kwDOBI7nWM5AMPRq","user":{"login":"YuweiXiao","id":9959868,"node_id":"MDQ6VXNlcjk5NTk4Njg=","avatar_url":"https://avatars.githubusercontent.com/u/9959868?v=4","gravatar_id":"","url":"https://api.github.com/users/YuweiXiao","html_url":"https://github.com/YuweiXiao","followers_url":"https://api.github.com/users/YuweiXiao/followers","following_url":"https://api.github.com/users/YuweiXiao/following{/other_user}","gists_url":"https://api.github.com/users/YuweiXiao/gists{/gist_id}","starred_url":"https://api.github.com/users/YuweiXiao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YuweiXiao/subscriptions","organizations_url":"https://api.github.com/users/YuweiXiao/orgs","repos_url":"https://api.github.com/users/YuweiXiao/repos","events_url":"https://api.github.com/users/YuweiXiao/events{/privacy}","received_events_url":"https://api.github.com/users/YuweiXiao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-24T00:33:24Z","updated_at":"2022-03-24T00:33:24Z","author_association":"CONTRIBUTOR","body":"@qjqqyy Hi, I was also referring to the master branch code (removing the adapter abstraction to simplify the context). Because the implementation of `AvroSerializer ` itself is a lambda (named converter in the source code), there is still initialization cost (for internal variables in the lambda) for each row.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076950122/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076975033","html_url":"https://github.com/apache/hudi/pull/5089#issuecomment-1076975033","issue_url":"https://api.github.com/repos/apache/hudi/issues/5089","id":1076975033,"node_id":"IC_kwDOBI7nWM5AMVW5","user":{"login":"cuibo01","id":36881649,"node_id":"MDQ6VXNlcjM2ODgxNjQ5","avatar_url":"https://avatars.githubusercontent.com/u/36881649?v=4","gravatar_id":"","url":"https://api.github.com/users/cuibo01","html_url":"https://github.com/cuibo01","followers_url":"https://api.github.com/users/cuibo01/followers","following_url":"https://api.github.com/users/cuibo01/following{/other_user}","gists_url":"https://api.github.com/users/cuibo01/gists{/gist_id}","starred_url":"https://api.github.com/users/cuibo01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cuibo01/subscriptions","organizations_url":"https://api.github.com/users/cuibo01/orgs","repos_url":"https://api.github.com/users/cuibo01/repos","events_url":"https://api.github.com/users/cuibo01/events{/privacy}","received_events_url":"https://api.github.com/users/cuibo01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-24T01:23:52Z","updated_at":"2022-03-24T01:23:52Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076975033/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076991851","html_url":"https://github.com/apache/hudi/pull/4480#issuecomment-1076991851","issue_url":"https://api.github.com/repos/apache/hudi/issues/4480","id":1076991851,"node_id":"IC_kwDOBI7nWM5AMZdr","user":{"login":"YuweiXiao","id":9959868,"node_id":"MDQ6VXNlcjk5NTk4Njg=","avatar_url":"https://avatars.githubusercontent.com/u/9959868?v=4","gravatar_id":"","url":"https://api.github.com/users/YuweiXiao","html_url":"https://github.com/YuweiXiao","followers_url":"https://api.github.com/users/YuweiXiao/followers","following_url":"https://api.github.com/users/YuweiXiao/following{/other_user}","gists_url":"https://api.github.com/users/YuweiXiao/gists{/gist_id}","starred_url":"https://api.github.com/users/YuweiXiao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YuweiXiao/subscriptions","organizations_url":"https://api.github.com/users/YuweiXiao/orgs","repos_url":"https://api.github.com/users/YuweiXiao/repos","events_url":"https://api.github.com/users/YuweiXiao/events{/privacy}","received_events_url":"https://api.github.com/users/YuweiXiao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-24T02:02:32Z","updated_at":"2022-03-24T02:02:43Z","author_association":"CONTRIBUTOR","body":"@nsivabalan @alexeykudinkin @vinothchandar Hey, could it be possible that we push forward together to land this PR in the coming release 0.11?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1076991851/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1077023692","html_url":"https://github.com/apache/hudi/pull/4962#issuecomment-1077023692","issue_url":"https://api.github.com/repos/apache/hudi/issues/4962","id":1077023692,"node_id":"IC_kwDOBI7nWM5AMhPM","user":{"login":"xiarixiaoyao","id":13514703,"node_id":"MDQ6VXNlcjEzNTE0NzAz","avatar_url":"https://avatars.githubusercontent.com/u/13514703?v=4","gravatar_id":"","url":"https://api.github.com/users/xiarixiaoyao","html_url":"https://github.com/xiarixiaoyao","followers_url":"https://api.github.com/users/xiarixiaoyao/followers","following_url":"https://api.github.com/users/xiarixiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/xiarixiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/xiarixiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiarixiaoyao/subscriptions","organizations_url":"https://api.github.com/users/xiarixiaoyao/orgs","repos_url":"https://api.github.com/users/xiarixiaoyao/repos","events_url":"https://api.github.com/users/xiarixiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/xiarixiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-24T03:12:50Z","updated_at":"2022-03-24T03:12:50Z","author_association":"CONTRIBUTOR","body":"@yihua  Thank you very much for your review fixed all comments","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1077023692/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1077093180","html_url":"https://github.com/apache/hudi/issues/5021#issuecomment-1077093180","issue_url":"https://api.github.com/repos/apache/hudi/issues/5021","id":1077093180,"node_id":"IC_kwDOBI7nWM5AMyM8","user":{"login":"maddy2u","id":7676511,"node_id":"MDQ6VXNlcjc2NzY1MTE=","avatar_url":"https://avatars.githubusercontent.com/u/7676511?v=4","gravatar_id":"","url":"https://api.github.com/users/maddy2u","html_url":"https://github.com/maddy2u","followers_url":"https://api.github.com/users/maddy2u/followers","following_url":"https://api.github.com/users/maddy2u/following{/other_user}","gists_url":"https://api.github.com/users/maddy2u/gists{/gist_id}","starred_url":"https://api.github.com/users/maddy2u/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/maddy2u/subscriptions","organizations_url":"https://api.github.com/users/maddy2u/orgs","repos_url":"https://api.github.com/users/maddy2u/repos","events_url":"https://api.github.com/users/maddy2u/events{/privacy}","received_events_url":"https://api.github.com/users/maddy2u/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-24T04:47:15Z","updated_at":"2022-03-24T04:47:15Z","author_association":"NONE","body":"Hi @umehrot2  - Do you have any update on this? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1077093180/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1077101336","html_url":"https://github.com/apache/hudi/pull/5106#issuecomment-1077101336","issue_url":"https://api.github.com/repos/apache/hudi/issues/5106","id":1077101336,"node_id":"IC_kwDOBI7nWM5AM0MY","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-24T04:50:41Z","updated_at":"2022-03-24T04:50:41Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"7f5c63d29db483a30866c1586c2be7360ff8b307\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7228\",\n    \"triggerID\" : \"7f5c63d29db483a30866c1586c2be7360ff8b307\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"6ced2ef06612d67b7d06143e4f1383e722ce8727\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7265\",\n    \"triggerID\" : \"6ced2ef06612d67b7d06143e4f1383e722ce8727\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 6ced2ef06612d67b7d06143e4f1383e722ce8727 Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=7265) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1077101336/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1077261639","html_url":"https://github.com/apache/hudi/issues/5081#issuecomment-1077261639","issue_url":"https://api.github.com/repos/apache/hudi/issues/5081","id":1077261639,"node_id":"IC_kwDOBI7nWM5ANbVH","user":{"login":"Guanpx","id":29246713,"node_id":"MDQ6VXNlcjI5MjQ2NzEz","avatar_url":"https://avatars.githubusercontent.com/u/29246713?v=4","gravatar_id":"","url":"https://api.github.com/users/Guanpx","html_url":"https://github.com/Guanpx","followers_url":"https://api.github.com/users/Guanpx/followers","following_url":"https://api.github.com/users/Guanpx/following{/other_user}","gists_url":"https://api.github.com/users/Guanpx/gists{/gist_id}","starred_url":"https://api.github.com/users/Guanpx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Guanpx/subscriptions","organizations_url":"https://api.github.com/users/Guanpx/orgs","repos_url":"https://api.github.com/users/Guanpx/repos","events_url":"https://api.github.com/users/Guanpx/events{/privacy}","received_events_url":"https://api.github.com/users/Guanpx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-03-24T05:58:33Z","updated_at":"2022-03-24T05:58:33Z","author_association":"NONE","body":"set write.parquet.max.file.size = 100M that is an approximate number","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1077261639/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]