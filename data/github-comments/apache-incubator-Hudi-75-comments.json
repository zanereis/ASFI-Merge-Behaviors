[{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671298448","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671298448","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671298448,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTI5ODQ0OA==","user":{"login":"sbernauer","id":29303194,"node_id":"MDQ6VXNlcjI5MzAzMTk0","avatar_url":"https://avatars.githubusercontent.com/u/29303194?v=4","gravatar_id":"","url":"https://api.github.com/users/sbernauer","html_url":"https://github.com/sbernauer","followers_url":"https://api.github.com/users/sbernauer/followers","following_url":"https://api.github.com/users/sbernauer/following{/other_user}","gists_url":"https://api.github.com/users/sbernauer/gists{/gist_id}","starred_url":"https://api.github.com/users/sbernauer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sbernauer/subscriptions","organizations_url":"https://api.github.com/users/sbernauer/orgs","repos_url":"https://api.github.com/users/sbernauer/repos","events_url":"https://api.github.com/users/sbernauer/events{/privacy}","received_events_url":"https://api.github.com/users/sbernauer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T11:22:22Z","updated_at":"2020-08-10T11:22:22Z","author_association":"CONTRIBUTOR","body":"My setup has no access to the internet, so i downloaded the libs from mvn central and included them in my docker images. Is the version 0.8.0 correct?\r\n```\r\n$ ls simpleclient*\r\nsimpleclient-0.8.0.jar  simpleclient_common-0.8.0.jar  simpleclient_dropwizard-0.8.0.jar  simpleclient_httpserver-0.8.0.jar  simpleclient_pushgateway-0.8.0.jar","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671298448/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671298995","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671298995","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671298995,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTI5ODk5NQ==","user":{"login":"liujinhui1994","id":25769285,"node_id":"MDQ6VXNlcjI1NzY5Mjg1","avatar_url":"https://avatars.githubusercontent.com/u/25769285?v=4","gravatar_id":"","url":"https://api.github.com/users/liujinhui1994","html_url":"https://github.com/liujinhui1994","followers_url":"https://api.github.com/users/liujinhui1994/followers","following_url":"https://api.github.com/users/liujinhui1994/following{/other_user}","gists_url":"https://api.github.com/users/liujinhui1994/gists{/gist_id}","starred_url":"https://api.github.com/users/liujinhui1994/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liujinhui1994/subscriptions","organizations_url":"https://api.github.com/users/liujinhui1994/orgs","repos_url":"https://api.github.com/users/liujinhui1994/repos","events_url":"https://api.github.com/users/liujinhui1994/events{/privacy}","received_events_url":"https://api.github.com/users/liujinhui1994/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T11:23:42Z","updated_at":"2020-08-10T11:23:42Z","author_association":"CONTRIBUTOR","body":"\r\n0.8.0 correct","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671298995/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671299385","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671299385","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671299385,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTI5OTM4NQ==","user":{"login":"sbernauer","id":29303194,"node_id":"MDQ6VXNlcjI5MzAzMTk0","avatar_url":"https://avatars.githubusercontent.com/u/29303194?v=4","gravatar_id":"","url":"https://api.github.com/users/sbernauer","html_url":"https://github.com/sbernauer","followers_url":"https://api.github.com/users/sbernauer/followers","following_url":"https://api.github.com/users/sbernauer/following{/other_user}","gists_url":"https://api.github.com/users/sbernauer/gists{/gist_id}","starred_url":"https://api.github.com/users/sbernauer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sbernauer/subscriptions","organizations_url":"https://api.github.com/users/sbernauer/orgs","repos_url":"https://api.github.com/users/sbernauer/repos","events_url":"https://api.github.com/users/sbernauer/events{/privacy}","received_events_url":"https://api.github.com/users/sbernauer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T11:24:33Z","updated_at":"2020-08-10T11:24:33Z","author_association":"CONTRIBUTOR","body":"The constructor of DropwizardExports seems to be stable and I'm wondering what is going wrong here (It does not seem like a version mismatch to me). https://github.com/prometheus/client_java/blob/570f8bb70ae6f5a0a950dc563b68fb495d2f4d69/simpleclient_dropwizard/src/main/java/io/prometheus/client/dropwizard/DropwizardExports.java#L30\r\nMabye `org/apache/hudi/com/codahale/metrics/MetricRegistry` (see exception) instead of `com/codahale/metrics/MetricRegistry` is a problem?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671299385/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671301067","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671301067","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671301067,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTMwMTA2Nw==","user":{"login":"sbernauer","id":29303194,"node_id":"MDQ6VXNlcjI5MzAzMTk0","avatar_url":"https://avatars.githubusercontent.com/u/29303194?v=4","gravatar_id":"","url":"https://api.github.com/users/sbernauer","html_url":"https://github.com/sbernauer","followers_url":"https://api.github.com/users/sbernauer/followers","following_url":"https://api.github.com/users/sbernauer/following{/other_user}","gists_url":"https://api.github.com/users/sbernauer/gists{/gist_id}","starred_url":"https://api.github.com/users/sbernauer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sbernauer/subscriptions","organizations_url":"https://api.github.com/users/sbernauer/orgs","repos_url":"https://api.github.com/users/sbernauer/repos","events_url":"https://api.github.com/users/sbernauer/events{/privacy}","received_events_url":"https://api.github.com/users/sbernauer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T11:28:46Z","updated_at":"2020-08-10T11:28:46Z","author_association":"CONTRIBUTOR","body":"If i uncompress my `simpleclient_dropwizard-0.8.0.jar` and look inside the class all seems correct:\r\n```\r\n$ javap DropwizardExports.class \r\nCompiled from \"DropwizardExports.java\"\r\npublic class io.prometheus.client.dropwizard.DropwizardExports extends io.prometheus.client.Collector implements io.prometheus.client.Collector$Describable {\r\n  public io.prometheus.client.dropwizard.DropwizardExports(com.codahale.metrics.MetricRegistry);\r\n  public io.prometheus.client.dropwizard.DropwizardExports(com.codahale.metrics.MetricRegistry, io.prometheus.client.dropwizard.samplebuilder.SampleBuilder);\r\n[...]\r\n}","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671301067/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671302048","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671302048","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671302048,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTMwMjA0OA==","user":{"login":"liujinhui1994","id":25769285,"node_id":"MDQ6VXNlcjI1NzY5Mjg1","avatar_url":"https://avatars.githubusercontent.com/u/25769285?v=4","gravatar_id":"","url":"https://api.github.com/users/liujinhui1994","html_url":"https://github.com/liujinhui1994","followers_url":"https://api.github.com/users/liujinhui1994/followers","following_url":"https://api.github.com/users/liujinhui1994/following{/other_user}","gists_url":"https://api.github.com/users/liujinhui1994/gists{/gist_id}","starred_url":"https://api.github.com/users/liujinhui1994/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liujinhui1994/subscriptions","organizations_url":"https://api.github.com/users/liujinhui1994/orgs","repos_url":"https://api.github.com/users/liujinhui1994/repos","events_url":"https://api.github.com/users/liujinhui1994/events{/privacy}","received_events_url":"https://api.github.com/users/liujinhui1994/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T11:31:13Z","updated_at":"2020-08-10T11:31:13Z","author_association":"CONTRIBUTOR","body":"If you use the include tag to include the required dependencies, it should be correct. Let me see why","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671302048/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671304318","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671304318","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671304318,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTMwNDMxOA==","user":{"login":"sbernauer","id":29303194,"node_id":"MDQ6VXNlcjI5MzAzMTk0","avatar_url":"https://avatars.githubusercontent.com/u/29303194?v=4","gravatar_id":"","url":"https://api.github.com/users/sbernauer","html_url":"https://github.com/sbernauer","followers_url":"https://api.github.com/users/sbernauer/followers","following_url":"https://api.github.com/users/sbernauer/following{/other_user}","gists_url":"https://api.github.com/users/sbernauer/gists{/gist_id}","starred_url":"https://api.github.com/users/sbernauer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sbernauer/subscriptions","organizations_url":"https://api.github.com/users/sbernauer/orgs","repos_url":"https://api.github.com/users/sbernauer/repos","events_url":"https://api.github.com/users/sbernauer/events{/privacy}","received_events_url":"https://api.github.com/users/sbernauer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T11:36:52Z","updated_at":"2020-08-10T11:37:02Z","author_association":"CONTRIBUTOR","body":"I don't use the include option but instead guarantee that all drivers and executors have the libs and correctly use them via SPARK_DIST_CLASSPATH.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671304318/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671331840","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671331840","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671331840,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTMzMTg0MA==","user":{"login":"liujinhui1994","id":25769285,"node_id":"MDQ6VXNlcjI1NzY5Mjg1","avatar_url":"https://avatars.githubusercontent.com/u/25769285?v=4","gravatar_id":"","url":"https://api.github.com/users/liujinhui1994","html_url":"https://github.com/liujinhui1994","followers_url":"https://api.github.com/users/liujinhui1994/followers","following_url":"https://api.github.com/users/liujinhui1994/following{/other_user}","gists_url":"https://api.github.com/users/liujinhui1994/gists{/gist_id}","starred_url":"https://api.github.com/users/liujinhui1994/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liujinhui1994/subscriptions","organizations_url":"https://api.github.com/users/liujinhui1994/orgs","repos_url":"https://api.github.com/users/liujinhui1994/repos","events_url":"https://api.github.com/users/liujinhui1994/events{/privacy}","received_events_url":"https://api.github.com/users/liujinhui1994/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T12:44:49Z","updated_at":"2020-08-10T12:44:49Z","author_association":"CONTRIBUTOR","body":"It’s because I missed to configure less dependencies, it will be fixed soon\r\n@sbernauer ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671331840/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671334282","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671334282","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671334282,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTMzNDI4Mg==","user":{"login":"sbernauer","id":29303194,"node_id":"MDQ6VXNlcjI5MzAzMTk0","avatar_url":"https://avatars.githubusercontent.com/u/29303194?v=4","gravatar_id":"","url":"https://api.github.com/users/sbernauer","html_url":"https://github.com/sbernauer","followers_url":"https://api.github.com/users/sbernauer/followers","following_url":"https://api.github.com/users/sbernauer/following{/other_user}","gists_url":"https://api.github.com/users/sbernauer/gists{/gist_id}","starred_url":"https://api.github.com/users/sbernauer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sbernauer/subscriptions","organizations_url":"https://api.github.com/users/sbernauer/orgs","repos_url":"https://api.github.com/users/sbernauer/repos","events_url":"https://api.github.com/users/sbernauer/events{/privacy}","received_events_url":"https://api.github.com/users/sbernauer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T12:50:19Z","updated_at":"2020-08-10T12:50:19Z","author_association":"CONTRIBUTOR","body":"Thanks a lot @UZi5136225 for your fast response!","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671334282/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671336381","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671336381","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671336381,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTMzNjM4MQ==","user":{"login":"liujinhui1994","id":25769285,"node_id":"MDQ6VXNlcjI1NzY5Mjg1","avatar_url":"https://avatars.githubusercontent.com/u/25769285?v=4","gravatar_id":"","url":"https://api.github.com/users/liujinhui1994","html_url":"https://github.com/liujinhui1994","followers_url":"https://api.github.com/users/liujinhui1994/followers","following_url":"https://api.github.com/users/liujinhui1994/following{/other_user}","gists_url":"https://api.github.com/users/liujinhui1994/gists{/gist_id}","starred_url":"https://api.github.com/users/liujinhui1994/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liujinhui1994/subscriptions","organizations_url":"https://api.github.com/users/liujinhui1994/orgs","repos_url":"https://api.github.com/users/liujinhui1994/repos","events_url":"https://api.github.com/users/liujinhui1994/events{/privacy}","received_events_url":"https://api.github.com/users/liujinhui1994/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T12:55:00Z","updated_at":"2020-08-10T12:55:00Z","author_association":"CONTRIBUTOR","body":"https://github.com/apache/hudi/pull/1942 @sbernauer   You can try this PR","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671336381/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671350777","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671350777","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671350777,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTM1MDc3Nw==","user":{"login":"sbernauer","id":29303194,"node_id":"MDQ6VXNlcjI5MzAzMTk0","avatar_url":"https://avatars.githubusercontent.com/u/29303194?v=4","gravatar_id":"","url":"https://api.github.com/users/sbernauer","html_url":"https://github.com/sbernauer","followers_url":"https://api.github.com/users/sbernauer/followers","following_url":"https://api.github.com/users/sbernauer/following{/other_user}","gists_url":"https://api.github.com/users/sbernauer/gists{/gist_id}","starred_url":"https://api.github.com/users/sbernauer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sbernauer/subscriptions","organizations_url":"https://api.github.com/users/sbernauer/orgs","repos_url":"https://api.github.com/users/sbernauer/repos","events_url":"https://api.github.com/users/sbernauer/events{/privacy}","received_events_url":"https://api.github.com/users/sbernauer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T13:22:05Z","updated_at":"2020-08-10T13:22:05Z","author_association":"CONTRIBUTOR","body":"Thanks @UZi5136225, this fixed the problem!\r\nI dont understand why, because i added all the libs below in the correct version to the classpath. But it works :)\r\n```\r\nmvn dependency:tree | grep simpleclient\r\n[INFO] +- io.prometheus:simpleclient:jar:0.8.0:compile\r\n[INFO] +- io.prometheus:simpleclient_httpserver:jar:0.8.0:compile\r\n[INFO] |  \\- io.prometheus:simpleclient_common:jar:0.8.0:compile\r\n[INFO] +- io.prometheus:simpleclient_dropwizard:jar:0.8.0:compile\r\n[INFO] +- io.prometheus:simpleclient_pushgateway:jar:0.8.0:compile\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671350777/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671353265","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671353265","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671353265,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTM1MzI2NQ==","user":{"login":"sbernauer","id":29303194,"node_id":"MDQ6VXNlcjI5MzAzMTk0","avatar_url":"https://avatars.githubusercontent.com/u/29303194?v=4","gravatar_id":"","url":"https://api.github.com/users/sbernauer","html_url":"https://github.com/sbernauer","followers_url":"https://api.github.com/users/sbernauer/followers","following_url":"https://api.github.com/users/sbernauer/following{/other_user}","gists_url":"https://api.github.com/users/sbernauer/gists{/gist_id}","starred_url":"https://api.github.com/users/sbernauer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sbernauer/subscriptions","organizations_url":"https://api.github.com/users/sbernauer/orgs","repos_url":"https://api.github.com/users/sbernauer/repos","events_url":"https://api.github.com/users/sbernauer/events{/privacy}","received_events_url":"https://api.github.com/users/sbernauer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T13:26:47Z","updated_at":"2020-08-10T13:27:20Z","author_association":"CONTRIBUTOR","body":"@UZi5136225 i just noticed that i get a `java.lang.ClassNotFoundException: io.prometheus.client.exporter.common.TextFormat` when trying to access the interface. I think we should also add (i will give it a try)\r\n```\r\n<include>io.prometheus:simpleclient_common</include>\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671353265/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671354955","html_url":"https://github.com/apache/hudi/pull/1931#issuecomment-671354955","issue_url":"https://api.github.com/repos/apache/hudi/issues/1931","id":671354955,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTM1NDk1NQ==","user":{"login":"liujinhui1994","id":25769285,"node_id":"MDQ6VXNlcjI1NzY5Mjg1","avatar_url":"https://avatars.githubusercontent.com/u/25769285?v=4","gravatar_id":"","url":"https://api.github.com/users/liujinhui1994","html_url":"https://github.com/liujinhui1994","followers_url":"https://api.github.com/users/liujinhui1994/followers","following_url":"https://api.github.com/users/liujinhui1994/following{/other_user}","gists_url":"https://api.github.com/users/liujinhui1994/gists{/gist_id}","starred_url":"https://api.github.com/users/liujinhui1994/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liujinhui1994/subscriptions","organizations_url":"https://api.github.com/users/liujinhui1994/orgs","repos_url":"https://api.github.com/users/liujinhui1994/repos","events_url":"https://api.github.com/users/liujinhui1994/events{/privacy}","received_events_url":"https://api.github.com/users/liujinhui1994/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T13:30:03Z","updated_at":"2020-08-10T13:30:03Z","author_association":"CONTRIBUTOR","body":"Yes, this configuration needs to be added","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671354955/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671401411","html_url":"https://github.com/apache/hudi/pull/1870#issuecomment-671401411","issue_url":"https://api.github.com/repos/apache/hudi/issues/1870","id":671401411,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTQwMTQxMQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T14:48:49Z","updated_at":"2020-08-10T14:48:49Z","author_association":"MEMBER","body":"@zhedoubushishi @umehrot2 please review this PR carefully ! We plan to land today ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671401411/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671512191","html_url":"https://github.com/apache/hudi/issues/1813#issuecomment-671512191","issue_url":"https://api.github.com/repos/apache/hudi/issues/1813","id":671512191,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTUxMjE5MQ==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T18:20:56Z","updated_at":"2020-08-10T18:21:22Z","author_association":"NONE","body":"@bhasudha how does checkpointing work here? ie after some time of running DeltaStreamer job i need to stop the DeltaStreamer job, destroy old EC2, launch new EC2, restart DeltaStreamer job. How does DeltaStreamer job know to skip some of the raw change capture parquets (that were already processed into Hudi table) and resume from certain point of them?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671512191/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671522522","html_url":"https://github.com/apache/hudi/issues/1925#issuecomment-671522522","issue_url":"https://api.github.com/repos/apache/hudi/issues/1925","id":671522522,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTUyMjUyMg==","user":{"login":"jpugliesi","id":2141170,"node_id":"MDQ6VXNlcjIxNDExNzA=","avatar_url":"https://avatars.githubusercontent.com/u/2141170?v=4","gravatar_id":"","url":"https://api.github.com/users/jpugliesi","html_url":"https://github.com/jpugliesi","followers_url":"https://api.github.com/users/jpugliesi/followers","following_url":"https://api.github.com/users/jpugliesi/following{/other_user}","gists_url":"https://api.github.com/users/jpugliesi/gists{/gist_id}","starred_url":"https://api.github.com/users/jpugliesi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpugliesi/subscriptions","organizations_url":"https://api.github.com/users/jpugliesi/orgs","repos_url":"https://api.github.com/users/jpugliesi/repos","events_url":"https://api.github.com/users/jpugliesi/events{/privacy}","received_events_url":"https://api.github.com/users/jpugliesi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T18:42:24Z","updated_at":"2020-08-10T18:43:11Z","author_association":"NONE","body":"@bvaradar looks like this works - thanks for your help.\r\n\r\nOne follow up question about this `SchemaRegistryProvider` - is it possible to configure Hudi to use this `SchemaProvider` (specifically `SchemaRegistryProvider`) with the Datasource Writer (Spark) API to assert source/target schemas as well? (Happy to create a new ticket to track this conversation if need be)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671522522/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671523549","html_url":"https://github.com/apache/hudi/issues/1837#issuecomment-671523549","issue_url":"https://api.github.com/repos/apache/hudi/issues/1837","id":671523549,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTUyMzU0OQ==","user":{"login":"steveloughran","id":162090,"node_id":"MDQ6VXNlcjE2MjA5MA==","avatar_url":"https://avatars.githubusercontent.com/u/162090?v=4","gravatar_id":"","url":"https://api.github.com/users/steveloughran","html_url":"https://github.com/steveloughran","followers_url":"https://api.github.com/users/steveloughran/followers","following_url":"https://api.github.com/users/steveloughran/following{/other_user}","gists_url":"https://api.github.com/users/steveloughran/gists{/gist_id}","starred_url":"https://api.github.com/users/steveloughran/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/steveloughran/subscriptions","organizations_url":"https://api.github.com/users/steveloughran/orgs","repos_url":"https://api.github.com/users/steveloughran/repos","events_url":"https://api.github.com/users/steveloughran/events{/privacy}","received_events_url":"https://api.github.com/users/steveloughran/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T18:44:23Z","updated_at":"2020-08-10T18:44:23Z","author_association":"NONE","body":"The issue here is that treewalking is pathologically bad for S3. Asking for a deep listing is often more efficient; filesystem.listFiles(path, recursive=true) will do this","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671523549/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671642813","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-671642813","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":671642813,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTY0MjgxMw==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T23:40:35Z","updated_at":"2020-08-10T23:40:35Z","author_association":"CONTRIBUTOR","body":"cc @vinothchandar @bvaradar @bhasudha ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671642813/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671645321","html_url":"https://github.com/apache/hudi/issues/1940#issuecomment-671645321","issue_url":"https://api.github.com/repos/apache/hudi/issues/1940","id":671645321,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTY0NTMyMQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T23:49:38Z","updated_at":"2020-08-10T23:49:38Z","author_association":"CONTRIBUTOR","body":"Hudi supports Avro schema evolution and compatibility rules. We are also planning to rethink schema evolution in general for our next major release. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671645321/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671645896","html_url":"https://github.com/apache/hudi/issues/1941#issuecomment-671645896","issue_url":"https://api.github.com/repos/apache/hudi/issues/1941","id":671645896,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTY0NTg5Ng==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-10T23:51:44Z","updated_at":"2020-08-10T23:51:44Z","author_association":"CONTRIBUTOR","body":"@satishkotha @n3nash : Can you please chime in on this ? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671645896/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671685350","html_url":"https://github.com/apache/hudi/pull/1871#issuecomment-671685350","issue_url":"https://api.github.com/repos/apache/hudi/issues/1871","id":671685350,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTY4NTM1MA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T02:21:13Z","updated_at":"2020-08-11T02:21:13Z","author_association":"MEMBER","body":"@yanghua @xushiyan can we please hold off on these refactoring PRs until we cut RCs please. we are trying to land the last bits. the rebase efforts from these, keep stretching the timelines. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671685350/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671686601","html_url":"https://github.com/apache/hudi/issues/1925#issuecomment-671686601","issue_url":"https://api.github.com/repos/apache/hudi/issues/1925","id":671686601,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTY4NjYwMQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T02:25:42Z","updated_at":"2020-08-11T02:25:42Z","author_association":"CONTRIBUTOR","body":"@jpugliesi : With Spark DataSource write the schema is implicitly derived from the input data-frame we want to write. Is there a specific use-case you have in mind ?\r\n\r\nSince DeltaStreamer is a generic ingestion tool, it made sense to provide a framework to plugin schema providers.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671686601/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671687932","html_url":"https://github.com/apache/hudi/issues/1813#issuecomment-671687932","issue_url":"https://api.github.com/repos/apache/hudi/issues/1813","id":671687932,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTY4NzkzMg==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T02:30:40Z","updated_at":"2020-08-11T02:30:40Z","author_association":"CONTRIBUTOR","body":"@tooptoop4 : The checkpoints are stored as part of .commit files in .hoodie folder and will persist across cluster, application restarts. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671687932/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671690639","html_url":"https://github.com/apache/hudi/issues/1939#issuecomment-671690639","issue_url":"https://api.github.com/repos/apache/hudi/issues/1939","id":671690639,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTY5MDYzOQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T02:39:31Z","updated_at":"2020-08-11T02:39:31Z","author_association":"CONTRIBUTOR","body":"To understand, Are you using bulk insert for initial loading and upsert for subsequent operations ? \r\nFor records with LOBs, it is important to tune hoodie.copyonwrite.record.size.estimate during initial bootstrap to get the file sizing right.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671690639/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671719305","html_url":"https://github.com/apache/hudi/issues/1936#issuecomment-671719305","issue_url":"https://api.github.com/repos/apache/hudi/issues/1936","id":671719305,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTcxOTMwNQ==","user":{"login":"harishchanderramesh","id":46951911,"node_id":"MDQ6VXNlcjQ2OTUxOTEx","avatar_url":"https://avatars.githubusercontent.com/u/46951911?v=4","gravatar_id":"","url":"https://api.github.com/users/harishchanderramesh","html_url":"https://github.com/harishchanderramesh","followers_url":"https://api.github.com/users/harishchanderramesh/followers","following_url":"https://api.github.com/users/harishchanderramesh/following{/other_user}","gists_url":"https://api.github.com/users/harishchanderramesh/gists{/gist_id}","starred_url":"https://api.github.com/users/harishchanderramesh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harishchanderramesh/subscriptions","organizations_url":"https://api.github.com/users/harishchanderramesh/orgs","repos_url":"https://api.github.com/users/harishchanderramesh/repos","events_url":"https://api.github.com/users/harishchanderramesh/events{/privacy}","received_events_url":"https://api.github.com/users/harishchanderramesh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T04:35:22Z","updated_at":"2020-08-11T04:37:05Z","author_association":"NONE","body":"Hi @umehrot2 ,\r\n\r\nPlease find me responses below.\r\n\r\nAre you able to do a simple aws s3 ls and list or get anything from your cluster on S3 ?\r\n**_Yes,I am able to._** \r\nAre you configuring to use S3A instead of EmrFS as the filesystem or your EMR cluster ?\r\n**_No, I am not configuring any file system explicitly_**\r\nAre you running and EMR bootstrap actions that change sdk/http client versions on the cluster ?\r\n**_No, I am not._**\r\nAre you changing spark driver/executor classpaths ?\r\n**_No, I am not changing the classpaths._**\r\nIs this happening specifically for hudi tables ? Or for non-hudi tables as well ?\r\n**_Only for Hudi tables. The other Delta IO tables are working fine._**","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671719305/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671721410","html_url":"https://github.com/apache/hudi/pull/1871#issuecomment-671721410","issue_url":"https://api.github.com/repos/apache/hudi/issues/1871","id":671721410,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTcyMTQxMA==","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T04:44:13Z","updated_at":"2020-08-11T04:44:13Z","author_association":"MEMBER","body":"@vinothchandar sorry i'll make the PRs in draft state until the cut.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671721410/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671729188","html_url":"https://github.com/apache/hudi/pull/1871#issuecomment-671729188","issue_url":"https://api.github.com/repos/apache/hudi/issues/1871","id":671729188,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTcyOTE4OA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T05:12:27Z","updated_at":"2020-08-11T05:12:27Z","author_association":"CONTRIBUTOR","body":"@xushiyan @yanghua : This PR is causing lot of merge conflicts to a blocker PR which we needed to merge  by tonight and I am unable to resolve conflicts in time. I am reverting this PR for now. Can you kindly re-merge this PR once 0.6. is cut. \r\n\r\nTHanks,\r\nBalaji.V","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671729188/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671730074","html_url":"https://github.com/apache/hudi/pull/1871#issuecomment-671730074","issue_url":"https://api.github.com/repos/apache/hudi/issues/1871","id":671730074,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTczMDA3NA==","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T05:15:26Z","updated_at":"2020-08-11T05:15:26Z","author_association":"MEMBER","body":"@bvaradar no worries.. i can do another one.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671730074/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671730790","html_url":"https://github.com/apache/hudi/pull/1870#issuecomment-671730790","issue_url":"https://api.github.com/repos/apache/hudi/issues/1870","id":671730790,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTczMDc5MA==","user":{"login":"zhedoubushishi","id":31263084,"node_id":"MDQ6VXNlcjMxMjYzMDg0","avatar_url":"https://avatars.githubusercontent.com/u/31263084?v=4","gravatar_id":"","url":"https://api.github.com/users/zhedoubushishi","html_url":"https://github.com/zhedoubushishi","followers_url":"https://api.github.com/users/zhedoubushishi/followers","following_url":"https://api.github.com/users/zhedoubushishi/following{/other_user}","gists_url":"https://api.github.com/users/zhedoubushishi/gists{/gist_id}","starred_url":"https://api.github.com/users/zhedoubushishi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhedoubushishi/subscriptions","organizations_url":"https://api.github.com/users/zhedoubushishi/orgs","repos_url":"https://api.github.com/users/zhedoubushishi/repos","events_url":"https://api.github.com/users/zhedoubushishi/events{/privacy}","received_events_url":"https://api.github.com/users/zhedoubushishi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T05:17:49Z","updated_at":"2020-08-11T05:17:49Z","author_association":"CONTRIBUTOR","body":"LGTM to me. Thanks for the implementation of versioning part @bvaradar !\r\nOnly left some minor comments. I noticed that there's a conflict with another commit but it seems you just reverted that commit.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671730790/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671730869","html_url":"https://github.com/apache/hudi/pull/1871#issuecomment-671730869","issue_url":"https://api.github.com/repos/apache/hudi/issues/1871","id":671730869,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTczMDg2OQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T05:18:01Z","updated_at":"2020-08-11T05:18:01Z","author_association":"CONTRIBUTOR","body":"Thanks @xushiyan ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671730869/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671742308","html_url":"https://github.com/apache/hudi/issues/1939#issuecomment-671742308","issue_url":"https://api.github.com/repos/apache/hudi/issues/1939","id":671742308,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTc0MjMwOA==","user":{"login":"RajasekarSribalan","id":22605603,"node_id":"MDQ6VXNlcjIyNjA1NjAz","avatar_url":"https://avatars.githubusercontent.com/u/22605603?v=4","gravatar_id":"","url":"https://api.github.com/users/RajasekarSribalan","html_url":"https://github.com/RajasekarSribalan","followers_url":"https://api.github.com/users/RajasekarSribalan/followers","following_url":"https://api.github.com/users/RajasekarSribalan/following{/other_user}","gists_url":"https://api.github.com/users/RajasekarSribalan/gists{/gist_id}","starred_url":"https://api.github.com/users/RajasekarSribalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RajasekarSribalan/subscriptions","organizations_url":"https://api.github.com/users/RajasekarSribalan/orgs","repos_url":"https://api.github.com/users/RajasekarSribalan/repos","events_url":"https://api.github.com/users/RajasekarSribalan/events{/privacy}","received_events_url":"https://api.github.com/users/RajasekarSribalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T05:53:49Z","updated_at":"2020-08-11T05:53:49Z","author_association":"NONE","body":"Yes @bvaradar we do an initial bulk insert and then upsert for subsequent operations.! I configured hoodie.copyonwrite.record.size.estimate to 128 while taking initial load via bulk insert. But during subsequent upserts, we face memory issues as stated above and  streaming jobs are getting failed... But we are sure the size of 10mill records is close to 10GB and we have given sufficient executor memory(60GB per executor and 4 cores)..\r\n\r\nWe use Dstream and number of records for each micro batch is 10 mil and size of the batch is 10GB.\r\n\r\nWe persist the RDD(10GB) in disk because we reuse RDD for upsert and subsequent deletes. What i can see from storage tab in spark is, Hudi do persist the data internally in memory. I tried configuring hoodie.write.status.storage.level to Disk to leave more memory for tasks.. But Hudi always persists in memory? Any thoughts on this prop? will this be a reason for memory isue?\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671742308/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671742888","html_url":"https://github.com/apache/hudi/pull/1871#issuecomment-671742888","issue_url":"https://api.github.com/repos/apache/hudi/issues/1871","id":671742888,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTc0Mjg4OA==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T05:55:29Z","updated_at":"2020-08-11T05:55:29Z","author_association":"CONTRIBUTOR","body":"> @xushiyan @yanghua : This PR is causing lot of merge conflicts to a blocker PR which we needed to merge by tonight and I am unable to resolve conflicts in time. I am reverting this PR for now. Can you kindly re-merge this PR once 0.6. is cut.\r\n> \r\n> THanks,\r\n> Balaji.V\r\n\r\nOk, sorry for interrupting the release plan.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671742888/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671892573","html_url":"https://github.com/apache/hudi/pull/1834#issuecomment-671892573","issue_url":"https://api.github.com/repos/apache/hudi/issues/1834","id":671892573,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTg5MjU3Mw==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T11:34:12Z","updated_at":"2020-08-11T11:34:45Z","author_association":"CONTRIBUTOR","body":"https://github.com/apache/hudi/pull/1834#discussion_r461939866\r\n: bcoz, this is for Row where as existing WriteStats is for HoodieRecords. Guess we should have templatized this too.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671892573/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671970849","html_url":"https://github.com/apache/hudi/pull/1901#issuecomment-671970849","issue_url":"https://api.github.com/repos/apache/hudi/issues/1901","id":671970849,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTk3MDg0OQ==","user":{"login":"wangxianghu","id":49835526,"node_id":"MDQ6VXNlcjQ5ODM1NTI2","avatar_url":"https://avatars.githubusercontent.com/u/49835526?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxianghu","html_url":"https://github.com/wangxianghu","followers_url":"https://api.github.com/users/wangxianghu/followers","following_url":"https://api.github.com/users/wangxianghu/following{/other_user}","gists_url":"https://api.github.com/users/wangxianghu/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxianghu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxianghu/subscriptions","organizations_url":"https://api.github.com/users/wangxianghu/orgs","repos_url":"https://api.github.com/users/wangxianghu/repos","events_url":"https://api.github.com/users/wangxianghu/events{/privacy}","received_events_url":"https://api.github.com/users/wangxianghu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T14:11:18Z","updated_at":"2020-08-11T14:11:18Z","author_association":"CONTRIBUTOR","body":"@yanghua this pr is ready for review now :)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671970849/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671971132","html_url":"https://github.com/apache/hudi/pull/1900#issuecomment-671971132","issue_url":"https://api.github.com/repos/apache/hudi/issues/1900","id":671971132,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTk3MTEzMg==","user":{"login":"wangxianghu","id":49835526,"node_id":"MDQ6VXNlcjQ5ODM1NTI2","avatar_url":"https://avatars.githubusercontent.com/u/49835526?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxianghu","html_url":"https://github.com/wangxianghu","followers_url":"https://api.github.com/users/wangxianghu/followers","following_url":"https://api.github.com/users/wangxianghu/following{/other_user}","gists_url":"https://api.github.com/users/wangxianghu/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxianghu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxianghu/subscriptions","organizations_url":"https://api.github.com/users/wangxianghu/orgs","repos_url":"https://api.github.com/users/wangxianghu/repos","events_url":"https://api.github.com/users/wangxianghu/events{/privacy}","received_events_url":"https://api.github.com/users/wangxianghu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T14:11:49Z","updated_at":"2020-08-11T14:11:49Z","author_association":"CONTRIBUTOR","body":"@yanghua  this pr is ready for review now :)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/671971132/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672053354","html_url":"https://github.com/apache/hudi/pull/1760#issuecomment-672053354","issue_url":"https://api.github.com/repos/apache/hudi/issues/1760","id":672053354,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjA1MzM1NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T16:06:09Z","updated_at":"2020-08-11T16:06:09Z","author_association":"MEMBER","body":"@bschell is this tested and ready to go? would like to get it into the RC if possible\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672053354/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672067962","html_url":"https://github.com/apache/hudi/pull/1760#issuecomment-672067962","issue_url":"https://api.github.com/repos/apache/hudi/issues/1760","id":672067962,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjA2Nzk2Mg==","user":{"login":"bschell","id":8600774,"node_id":"MDQ6VXNlcjg2MDA3NzQ=","avatar_url":"https://avatars.githubusercontent.com/u/8600774?v=4","gravatar_id":"","url":"https://api.github.com/users/bschell","html_url":"https://github.com/bschell","followers_url":"https://api.github.com/users/bschell/followers","following_url":"https://api.github.com/users/bschell/following{/other_user}","gists_url":"https://api.github.com/users/bschell/gists{/gist_id}","starred_url":"https://api.github.com/users/bschell/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bschell/subscriptions","organizations_url":"https://api.github.com/users/bschell/orgs","repos_url":"https://api.github.com/users/bschell/repos","events_url":"https://api.github.com/users/bschell/events{/privacy}","received_events_url":"https://api.github.com/users/bschell/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T16:24:03Z","updated_at":"2020-08-11T16:24:03Z","author_association":"CONTRIBUTOR","body":"@vinothchandar While this works, the reflection does hurt performance as this is a frequently used path. I was looking into any better options to workaround the performance hit.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672067962/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672261179","html_url":"https://github.com/apache/hudi/pull/1951#issuecomment-672261179","issue_url":"https://api.github.com/repos/apache/hudi/issues/1951","id":672261179,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjI2MTE3OQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T20:25:15Z","updated_at":"2020-08-11T20:25:40Z","author_association":"CONTRIBUTOR","body":"Compilation error:\r\n```\r\n[ERROR] /Users/sivabala/Documents/personal/projects/siva_hudi/hudi_aug2020/hudi/hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkUtils.scala:41: error: object SparkHadoopUtil in package deploy cannot be accessed in package org.apache.spark.deploy\r\n[ERROR]       val globPaths = SparkHadoopUtil.get.globPathIfNecessary(fs, qualified)\r\n[ERROR]                       ^\r\n[ERROR] /Users/sivabala/Documents/personal/projects/siva_hudi/hudi_aug2020/hudi/hudi-spark/src/main/scala/org/apache/hudi/MergeOnReadSnapshotRelation.scala:118: error: not found: value SparkHadoopUtil\r\n[ERROR]     SparkHadoopUtil.get.addCredentials(jobConf)\r\n[ERROR]     ^\r\n[WARNING] three warnings found\r\n[ERROR] two errors found\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672261179/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672262343","html_url":"https://github.com/apache/hudi/pull/1760#issuecomment-672262343","issue_url":"https://api.github.com/repos/apache/hudi/issues/1760","id":672262343,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjI2MjM0Mw==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T20:27:59Z","updated_at":"2020-08-11T20:29:14Z","author_association":"CONTRIBUTOR","body":"@bschell @vinothchandar : I gave it a shot on this. I don't have permission to push to your branch to update this PR. \r\nDiff1: adding support to spark 3. but does not upgrade spark version in pom.xml : https://github.com/apache/hudi/pull/1950\r\nDiff2: also upgrades spark version to 3.0.0 : https://github.com/apache/hudi/pull/1951\r\nDiff2 results in [compilation failure](https://github.com/apache/hudi/pull/1951#issuecomment-672261179) as one of the classes that Hoodie uses(SparkHadoopUtil) is not accessible anymore.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672262343/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672288068","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-672288068","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":672288068,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjI4ODA2OA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T21:26:20Z","updated_at":"2020-08-11T21:26:20Z","author_association":"MEMBER","body":"in some sense, due to the bundling changes, this feel very last minute to validate more. We have to rely on 1-2 rounds of RC testing to weed things out.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672288068/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672306115","html_url":"https://github.com/apache/hudi/issues/1902#issuecomment-672306115","issue_url":"https://api.github.com/repos/apache/hudi/issues/1902","id":672306115,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjMwNjExNQ==","user":{"login":"rubenssoto","id":36298331,"node_id":"MDQ6VXNlcjM2Mjk4MzMx","avatar_url":"https://avatars.githubusercontent.com/u/36298331?v=4","gravatar_id":"","url":"https://api.github.com/users/rubenssoto","html_url":"https://github.com/rubenssoto","followers_url":"https://api.github.com/users/rubenssoto/followers","following_url":"https://api.github.com/users/rubenssoto/following{/other_user}","gists_url":"https://api.github.com/users/rubenssoto/gists{/gist_id}","starred_url":"https://api.github.com/users/rubenssoto/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rubenssoto/subscriptions","organizations_url":"https://api.github.com/users/rubenssoto/orgs","repos_url":"https://api.github.com/users/rubenssoto/repos","events_url":"https://api.github.com/users/rubenssoto/events{/privacy}","received_events_url":"https://api.github.com/users/rubenssoto/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T22:05:50Z","updated_at":"2020-08-11T22:05:50Z","author_association":"NONE","body":"Thank you so much for your help, it worked.\r\n\r\nLast question, Hudi organized data very well by files, but created some small files, is there any way to solve?\r\n\r\n<img width=\"1680\" alt=\"Captura de Tela 2020-08-11 às 19 01 56\" src=\"https://user-images.githubusercontent.com/36298331/89953414-6bd09380-dc05-11ea-8fe9-8167ac6a91b9.png\">\r\n\r\n{\r\n   \"hoodie.datasource.write.recordkey.field\":\"created_date_brt,id\",\r\n   \"hoodie.datasource.write.table.name\":\"order\",\r\n   \"hoodie.datasource.write.operation\":\"bulk_insert\",\r\n   \"hoodie.datasource.write.partitionpath.field\":\"partitionpath\",\r\n   \"hoodie.datasource.write.hive_style_partitioning\":\"true\",\r\n   \"hoodie.combine.before.insert\":\"true\",\r\n   \"hoodie.combine.before.upsert\":\"false\",\r\n   \"hoodie.datasource.write.precombine.field\":\"LineCreatedTimestamp\",\r\n   \"hoodie.datasource.write.keygenerator.class\":\"org.apache.hudi.keygen.ComplexKeyGenerator\",\r\n   \"hoodie.parquet.small.file.limit\":943718400,\r\n   \"hoodie.parquet.max.file.size\":1073741824,\r\n   \"hoodie.parquet.block.size\":1073741824,\r\n   \"hoodie.copyonwrite.record.size.estimate\":512,\r\n   \"hoodie.cleaner.commits.retained\":5,\r\n   \"hoodie.datasource.hive_sync.enable\":\"true\",\r\n   \"hoodie.datasource.hive_sync.database\":\"datalake_raw\",\r\n   \"hoodie.datasource.hive_sync.table\":\"order\",\r\n   \"hoodie.datasource.hive_sync.partition_fields\":\"partitionpath\",\r\n   \"hoodie.datasource.hive_sync.partition_extractor_class\":\"org.apache.hudi.hive.MultiPartKeysValueExtractor\",\r\n   \"hoodie.datasource.hive_sync.jdbcurl\":\"jdbc:hive2://ip-10-0-82-196.us-west-2.compute.internal:1000\",\r\n   \"hoodie.insert.shuffle.parallelism\":1500,\r\n   \"hoodie.bulkinsert.shuffle.parallelism\":8,\r\n   \"hoodie.upsert.shuffle.parallelism\":1500\r\n}","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672306115/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672374251","html_url":"https://github.com/apache/hudi/issues/1936#issuecomment-672374251","issue_url":"https://api.github.com/repos/apache/hudi/issues/1936","id":672374251,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjM3NDI1MQ==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-11T23:59:31Z","updated_at":"2020-08-11T23:59:31Z","author_association":"CONTRIBUTOR","body":"@harishchanderramesh What is the configured s3 path or your hudi table ? does it start with `s3a://` or `s3://` ? If it starts with `s3a` you may want to try using `s3://` once.\r\n\r\nIf that's not the cause this would need deeper investigation by AWS support and its not something that we can or should drive over here, as this most likely does not have to do with Hudi. Please open an AWS support ticket and they should be able to drive the investigation over this issue.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672374251/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672378827","html_url":"https://github.com/apache/hudi/issues/1902#issuecomment-672378827","issue_url":"https://api.github.com/repos/apache/hudi/issues/1902","id":672378827,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjM3ODgyNw==","user":{"login":"rubenssoto","id":36298331,"node_id":"MDQ6VXNlcjM2Mjk4MzMx","avatar_url":"https://avatars.githubusercontent.com/u/36298331?v=4","gravatar_id":"","url":"https://api.github.com/users/rubenssoto","html_url":"https://github.com/rubenssoto","followers_url":"https://api.github.com/users/rubenssoto/followers","following_url":"https://api.github.com/users/rubenssoto/following{/other_user}","gists_url":"https://api.github.com/users/rubenssoto/gists{/gist_id}","starred_url":"https://api.github.com/users/rubenssoto/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rubenssoto/subscriptions","organizations_url":"https://api.github.com/users/rubenssoto/orgs","repos_url":"https://api.github.com/users/rubenssoto/repos","events_url":"https://api.github.com/users/rubenssoto/events{/privacy}","received_events_url":"https://api.github.com/users/rubenssoto/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T00:07:06Z","updated_at":"2020-08-12T00:07:06Z","author_association":"NONE","body":"Hi,\r\nWith bulk_insert my data was organized very well, so I started a streaming job with upsert on the same data.\r\n\r\n<img width=\"1229\" alt=\"Captura de Tela 2020-08-11 às 21 03 07\" src=\"https://user-images.githubusercontent.com/36298331/89960776-4f892280-dc16-11ea-9ab7-843f67e5961b.png\">\r\n\r\n\r\nWhy upsert didn't keep files organized? Its the same Hudi Options I only changed \r\nhoodie.datasource.write.operation","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672378827/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672406725","html_url":"https://github.com/apache/hudi/issues/1902#issuecomment-672406725","issue_url":"https://api.github.com/repos/apache/hudi/issues/1902","id":672406725,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjQwNjcyNQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T00:46:51Z","updated_at":"2020-08-12T00:46:51Z","author_association":"CONTRIBUTOR","body":"With bulk insert, the parallelism configuration determines the lower bound on the number of files. Since, you started with bulk insert, you are seeing that many number of files. Hudi upsert/insert will route \"new records\" (with new record keys) to these small files. So, If there are new records on the same partition, you will see those smalll files growing.\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672406725/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672430487","html_url":"https://github.com/apache/hudi/issues/1837#issuecomment-672430487","issue_url":"https://api.github.com/repos/apache/hudi/issues/1837","id":672430487,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjQzMDQ4Nw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T01:26:11Z","updated_at":"2020-08-12T01:26:11Z","author_association":"CONTRIBUTOR","body":"Thanks @steveloughran : Good to know. We are looking at an approach using consolidated metadata to avoid file listing (RFC-15) in the first place. @umehrot2 : What are your thoughts on this ? Do you think this would significantly help S3 case in the interim ? We do list all partitions for compaction scheduling  currently.  I am wondering if this is worth looking at 0.6.1 timeframe. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672430487/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672433664","html_url":"https://github.com/apache/hudi/issues/1813#issuecomment-672433664","issue_url":"https://api.github.com/repos/apache/hudi/issues/1813","id":672433664,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjQzMzY2NA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T01:31:48Z","updated_at":"2020-08-12T01:31:48Z","author_association":"CONTRIBUTOR","body":"@jcunhafonte : @bschell confirmed it works in master. Can you try using master or wait for 0.6 (Release should happen in a weeks time).","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672433664/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672555379","html_url":"https://github.com/apache/hudi/issues/827#issuecomment-672555379","issue_url":"https://api.github.com/repos/apache/hudi/issues/827","id":672555379,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjU1NTM3OQ==","user":{"login":"saumyasuhagiya","id":2899428,"node_id":"MDQ6VXNlcjI4OTk0Mjg=","avatar_url":"https://avatars.githubusercontent.com/u/2899428?v=4","gravatar_id":"","url":"https://api.github.com/users/saumyasuhagiya","html_url":"https://github.com/saumyasuhagiya","followers_url":"https://api.github.com/users/saumyasuhagiya/followers","following_url":"https://api.github.com/users/saumyasuhagiya/following{/other_user}","gists_url":"https://api.github.com/users/saumyasuhagiya/gists{/gist_id}","starred_url":"https://api.github.com/users/saumyasuhagiya/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/saumyasuhagiya/subscriptions","organizations_url":"https://api.github.com/users/saumyasuhagiya/orgs","repos_url":"https://api.github.com/users/saumyasuhagiya/repos","events_url":"https://api.github.com/users/saumyasuhagiya/events{/privacy}","received_events_url":"https://api.github.com/users/saumyasuhagiya/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T03:45:56Z","updated_at":"2020-08-12T03:46:15Z","author_association":"NONE","body":"@malanb5 @n3nash I have tried that as well still its failing. I am using hudi spark bundle and above dependency on databricks cluster.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672555379/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672558523","html_url":"https://github.com/apache/hudi/issues/827#issuecomment-672558523","issue_url":"https://api.github.com/repos/apache/hudi/issues/827","id":672558523,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjU1ODUyMw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T03:59:23Z","updated_at":"2020-08-12T03:59:23Z","author_association":"CONTRIBUTOR","body":"@saumyasuhagiya : This is a very old ticket about hudi 0.4.x version. Are you using 0.4.x or 0.5.x. If it is newer, please open a new ticket with complete context.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672558523/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672560925","html_url":"https://github.com/apache/hudi/issues/1837#issuecomment-672560925","issue_url":"https://api.github.com/repos/apache/hudi/issues/1837","id":672560925,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjU2MDkyNQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T04:09:35Z","updated_at":"2020-08-12T04:09:35Z","author_association":"MEMBER","body":"and this is the last such place. (cleaner, rollback are all incremental now) . cc @prashantwason to the rescue ;)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672560925/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672595024","html_url":"https://github.com/apache/hudi/issues/1813#issuecomment-672595024","issue_url":"https://api.github.com/repos/apache/hudi/issues/1813","id":672595024,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjU5NTAyNA==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T05:32:39Z","updated_at":"2020-08-12T07:46:08Z","author_association":"NONE","body":"@bschell @bvaradar  which PR fixes it?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672595024/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672783166","html_url":"https://github.com/apache/hudi/issues/1936#issuecomment-672783166","issue_url":"https://api.github.com/repos/apache/hudi/issues/1936","id":672783166,"node_id":"MDEyOklzc3VlQ29tbWVudDY3Mjc4MzE2Ng==","user":{"login":"harishchanderramesh","id":46951911,"node_id":"MDQ6VXNlcjQ2OTUxOTEx","avatar_url":"https://avatars.githubusercontent.com/u/46951911?v=4","gravatar_id":"","url":"https://api.github.com/users/harishchanderramesh","html_url":"https://github.com/harishchanderramesh","followers_url":"https://api.github.com/users/harishchanderramesh/followers","following_url":"https://api.github.com/users/harishchanderramesh/following{/other_user}","gists_url":"https://api.github.com/users/harishchanderramesh/gists{/gist_id}","starred_url":"https://api.github.com/users/harishchanderramesh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harishchanderramesh/subscriptions","organizations_url":"https://api.github.com/users/harishchanderramesh/orgs","repos_url":"https://api.github.com/users/harishchanderramesh/repos","events_url":"https://api.github.com/users/harishchanderramesh/events{/privacy}","received_events_url":"https://api.github.com/users/harishchanderramesh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T10:11:43Z","updated_at":"2020-08-12T10:11:43Z","author_association":"NONE","body":"tried with both. No difference.\r\nHave reached out to aws support. Thanks @umehrot2 ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672783166/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672828200","html_url":"https://github.com/apache/hudi/issues/1936#issuecomment-672828200","issue_url":"https://api.github.com/repos/apache/hudi/issues/1936","id":672828200,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjgyODIwMA==","user":{"login":"harishchanderramesh","id":46951911,"node_id":"MDQ6VXNlcjQ2OTUxOTEx","avatar_url":"https://avatars.githubusercontent.com/u/46951911?v=4","gravatar_id":"","url":"https://api.github.com/users/harishchanderramesh","html_url":"https://github.com/harishchanderramesh","followers_url":"https://api.github.com/users/harishchanderramesh/followers","following_url":"https://api.github.com/users/harishchanderramesh/following{/other_user}","gists_url":"https://api.github.com/users/harishchanderramesh/gists{/gist_id}","starred_url":"https://api.github.com/users/harishchanderramesh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harishchanderramesh/subscriptions","organizations_url":"https://api.github.com/users/harishchanderramesh/orgs","repos_url":"https://api.github.com/users/harishchanderramesh/repos","events_url":"https://api.github.com/users/harishchanderramesh/events{/privacy}","received_events_url":"https://api.github.com/users/harishchanderramesh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T11:59:49Z","updated_at":"2020-08-12T11:59:49Z","author_association":"NONE","body":"Just a question before we close this issue.\r\n@umehrot2 When is EMR going to support latest version of Hudi?\r\nI think it is still supporting only 0.5.2. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672828200/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672831272","html_url":"https://github.com/apache/hudi/issues/1954#issuecomment-672831272","issue_url":"https://api.github.com/repos/apache/hudi/issues/1954","id":672831272,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MjgzMTI3Mg==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T12:07:11Z","updated_at":"2020-08-12T12:07:11Z","author_association":"NONE","body":"even with NonPartitionedExtractor getting same issue","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672831272/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672843556","html_url":"https://github.com/apache/hudi/issues/1954#issuecomment-672843556","issue_url":"https://api.github.com/repos/apache/hudi/issues/1954","id":672843556,"node_id":"MDEyOklzc3VlQ29tbWVudDY3Mjg0MzU1Ng==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T12:33:52Z","updated_at":"2020-08-12T12:33:52Z","author_association":"NONE","body":"got a bit further with the below, now hudi/spark job succeeds but the hive ddl is pointing at wrong s3 location, so doing select from hive/presto gives error. But when i manually alter the s3 location in the table ddl via hiveserver2 then it works (ie change LOCATION 's3a://redact/my2/multpk7' to LOCATION 's3a://redact/my2/multpk7/default'), so i think there should be some code change to make it create table at proper s3 location.\r\n\r\n```\r\n/home/ec2-user/spark_home/bin/spark-submit --conf \"spark.hadoop.fs.s3a.proxy.host=redact\" --conf \"spark.hadoop.fs.s3a.proxy.port=redact\" --conf \"spark.driver.extraClassPath=/home/ec2-user/json-20090211.jar\" --conf \"spark.executor.extraClassPath=/home/ec2-user/json-20090211.jar\" --class org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer --jars \"/home/ec2-user/spark-avro_2.11-2.4.6.jar\" --master spark://redact:7077 --deploy-mode client /home/ec2-user/hudi-utilities-bundle_2.11-0.5.3-1.jar --table-type COPY_ON_WRITE --source-ordering-field TimeCreated --source-class org.apache.hudi.utilities.sources.ParquetDFSSource --enable-hive-sync --hoodie-conf hoodie.datasource.hive_sync.database=redact --hoodie-conf hoodie.datasource.hive_sync.table=dmstest_multpk7 --hoodie-conf hoodie.datasource.hive_sync.partition_extractor_class=org.apache.hudi.hive.NonPartitionedExtractor --hoodie-conf  hoodie.datasource.hive_sync.use_jdbc=false --target-base-path s3a://redact/my2/multpk7 --target-table dmstest_multpk7 --transformer-class org.apache.hudi.utilities.transform.AWSDmsTransformer --payload-class org.apache.hudi.payload.AWSDmsAvroPayload --hoodie-conf hoodie.datasource.write.keygenerator.class=org.apache.hudi.keygen.ComplexKeyGenerator --hoodie-conf hoodie.datasource.write.recordkey.field=version_no,group_company --hoodie-conf \"hoodie.datasource.write.partitionpath.field=\" --hoodie-conf hoodie.deltastreamer.source.dfs.root=s3a://redact/dbo/tbl > multpk7.log\r\nOK\r\n```\r\n\r\ncat multpk7.log\r\n```\r\n2020-08-12 12:18:15,375 [main] WARN  org.apache.hudi.utilities.deltastreamer.SchedulerConfGenerator - Job Scheduling Configs will not be in effect as spark.scheduler.mode is not set to FAIR at instantiation time. Continuing without scheduling configs\r\n2020-08-12 12:18:16,386 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Connected to Spark cluster with app ID app-20200812121816-0086\r\n2020-08-12 12:18:17,199 [main] INFO  com.amazonaws.http.AmazonHttpClient - Configuring Proxy. redact\r\n2020-08-12 12:18:18,154 [main] INFO  org.apache.spark.scheduler.EventLoggingListener - Logging events to s3a://redact/sparkevents/app-20200812121816-0086\r\n2020-08-12 12:18:18,171 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Granted executor ID app-20200812121816-0086/0 on hostPort redact:19629 with 4 core(s), 7.9 GB RAM\r\n2020-08-12 12:18:18,195 [main] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\r\n2020-08-12 12:18:18,427 [main] WARN  org.apache.spark.SparkContext - Using an existing SparkContext; some configuration may not take effect.\r\n2020-08-12 12:18:18,526 [main] ERROR org.apache.hudi.common.util.DFSPropertiesConfiguration - Error reading in properies from dfs\r\njava.io.FileNotFoundException: File file:/home/ec2-user/http_listener/logs/src/test/resources/delta-streamer-config/dfs-source.properties does not exist\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:635)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:861)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:625)\r\n        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:442)\r\n        at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:146)\r\n        at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:347)\r\n        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\r\n        at org.apache.hudi.common.util.DFSPropertiesConfiguration.visitFile(DFSPropertiesConfiguration.java:87)\r\n        at org.apache.hudi.common.util.DFSPropertiesConfiguration.<init>(DFSPropertiesConfiguration.java:60)\r\n        at org.apache.hudi.common.util.DFSPropertiesConfiguration.<init>(DFSPropertiesConfiguration.java:64)\r\n        at org.apache.hudi.utilities.UtilHelpers.readConfig(UtilHelpers.java:118)\r\n        at org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer$DeltaSyncService.<init>(HoodieDeltaStreamer.java:451)\r\n        at org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.<init>(HoodieDeltaStreamer.java:97)\r\n        at org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.<init>(HoodieDeltaStreamer.java:91)\r\n        at org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.main(HoodieDeltaStreamer.java:380)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)\r\n        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)\r\n        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)\r\n        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)\r\n        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)\r\n        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)\r\n        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2020-08-12 12:18:18,528 [main] WARN  org.apache.hudi.utilities.UtilHelpers - Unexpected error read props file at :file:/home/ec2-user/http_listener/logs/src/test/resources/delta-streamer-config/dfs-source.properties\r\njava.lang.IllegalArgumentException: Cannot read properties from dfs\r\n        at org.apache.hudi.common.util.DFSPropertiesConfiguration.visitFile(DFSPropertiesConfiguration.java:91)\r\n        at org.apache.hudi.common.util.DFSPropertiesConfiguration.<init>(DFSPropertiesConfiguration.java:60)\r\n        at org.apache.hudi.common.util.DFSPropertiesConfiguration.<init>(DFSPropertiesConfiguration.java:64)\r\n        at org.apache.hudi.utilities.UtilHelpers.readConfig(UtilHelpers.java:118)\r\n        at org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer$DeltaSyncService.<init>(HoodieDeltaStreamer.java:451)\r\n        at org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.<init>(HoodieDeltaStreamer.java:97)\r\n        at org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.<init>(HoodieDeltaStreamer.java:91)\r\n        at org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.main(HoodieDeltaStreamer.java:380)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)\r\n        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)\r\n        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)\r\n        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)\r\n        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)\r\n        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)\r\n        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: File file:/home/ec2-user/http_listener/logs/src/test/resources/delta-streamer-config/dfs-source.properties does not exist\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:635)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:861)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:625)\r\n        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:442)\r\n        at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:146)\r\n        at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:347)\r\n        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\r\n        at org.apache.hudi.common.util.DFSPropertiesConfiguration.visitFile(DFSPropertiesConfiguration.java:87)\r\n        ... 19 more\r\n2020-08-12 12:18:18,528 [main] INFO  org.apache.hudi.utilities.UtilHelpers - Adding overridden properties to file properties.\r\n2020-08-12 12:18:18,529 [main] INFO  org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer - Creating delta streamer with configs : {hoodie.datasource.hive_sync.use_jdbc=false, hoodie.datasource.write.recordkey.field=version_no,group_company, hoodie.datasource.write.partitionpath.field=, hoodie.datasource.write.keygenerator.class=org.apache.hudi.keygen.ComplexKeyGenerator, hoodie.datasource.hive_sync.partition_extractor_class=org.apache.hudi.hive.NonPartitionedExtractor, hoodie.datasource.hive_sync.table=dmstest_multpk7, hoodie.deltastreamer.source.dfs.root=s3a://redact/dbo/tbl, hoodie.datasource.hive_sync.database=redact}\r\n2020-08-12 12:18:18,533 [main] INFO  org.apache.hudi.utilities.deltastreamer.DeltaSync - Creating delta streamer with configs : {hoodie.datasource.hive_sync.use_jdbc=false, hoodie.datasource.write.recordkey.field=version_no,group_company, hoodie.datasource.write.partitionpath.field=, hoodie.datasource.write.keygenerator.class=org.apache.hudi.keygen.ComplexKeyGenerator, hoodie.datasource.hive_sync.partition_extractor_class=org.apache.hudi.hive.NonPartitionedExtractor, hoodie.datasource.hive_sync.table=dmstest_multpk7, hoodie.deltastreamer.source.dfs.root=s3a://redact/dbo/tbl, hoodie.datasource.hive_sync.database=redact}\r\n2020-08-12 12:18:19,798 [main] INFO  org.apache.hudi.utilities.deltastreamer.DeltaSync - Setting up Hoodie Write Client\r\n2020-08-12 12:18:19,799 [main] INFO  org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer - Delta Streamer running only single round\r\n2020-08-12 12:18:20,218 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants []\r\n2020-08-12 12:18:20,222 [main] INFO  org.apache.hudi.utilities.deltastreamer.DeltaSync - Checkpoint to resume from : Option{val=null}\r\n2020-08-12 12:18:42,136 [main] INFO  org.apache.hudi.utilities.deltastreamer.DeltaSync - Setting up Hoodie Write Client\r\n2020-08-12 12:18:42,156 [main] INFO  org.apache.hudi.utilities.deltastreamer.DeltaSync - Registering Schema :[{\"type\":\"record\",\"name\":\"hoodie_source\",\"namespace\":\"hoodie.source\",\"fields\":[{\"name\":\"Op\",\"type\":[\"string\",\"null\"]},{\"name\":\"Id\",\"type\":[\"int\",\"null\"]},{\"name\":\"AuditProcessHistoryId\",\"type\":[\"int\",\"null\"]},{\"name\":\"org_id\",\"type\":[\"int\",\"null\"]},{\"name\":\"org_name\",\"type\":[\"string\",\"null\"]},{\"name\":\"org_sname\",\"type\":[\"string\",\"null\"]},{\"name\":\"org_mnem\",\"type\":[\"string\",\"null\"]},{\"name\":\"org_parent\",\"type\":[\"int\",\"null\"]},{\"name\":\"percent_holding\",\"type\":[\"double\",\"null\"]},{\"name\":\"group_company\",\"type\":[\"string\",\"null\"]},{\"name\":\"grp_ord_for_cln\",\"type\":[\"string\",\"null\"]},{\"name\":\"mkt_only\",\"type\":[\"string\",\"null\"]},{\"name\":\"pro_rate_ind\",\"type\":[\"string\",\"null\"]},{\"name\":\"show_shapes\",\"type\":[\"string\",\"null\"]},{\"name\":\"sec_code_pref\",\"type\":[\"string\",\"null\"]},{\"name\":\"alert_org_ref\",\"type\":[\"string\",\"null\"]},{\"name\":\"swift_bic\",\"type\":[\"string\",\"null\"]},{\"name\":\"exec_breakdown\",\"type\":[\"string\",\"null\"]},{\"name\":\"notes\",\"type\":[\"string\",\"null\"]},{\"name\":\"active\",\"type\":[\"string\",\"null\"]},{\"name\":\"version_no\",\"type\":[\"int\",\"null\"]},{\"name\":\"sys_date\",\"type\":[{\"type\":\"long\",\"logicalType\":\"timestamp-micros\"},\"null\"]},{\"name\":\"sys_user\",\"type\":[\"string\",\"null\"]},{\"name\":\"create_date\",\"type\":[{\"type\":\"long\",\"logicalType\":\"timestamp-micros\"},\"null\"]},{\"name\":\"cntry_of_dom\",\"type\":[\"string\",\"null\"]},{\"name\":\"client\",\"type\":[\"string\",\"null\"]},{\"name\":\"alert_acronym\",\"type\":[\"string\",\"null\"]},{\"name\":\"oneoff_client\",\"type\":[\"string\",\"null\"]},{\"name\":\"booking_domicile\",\"type\":[\"string\",\"null\"]},{\"name\":\"booking_dom_list\",\"type\":[\"string\",\"null\"]},{\"name\":\"TimeCreated\",\"type\":[{\"type\":\"long\",\"logicalType\":\"timestamp-micros\"},\"null\"]},{\"name\":\"UserCreated\",\"type\":[\"string\",\"null\"]}]}, {\"type\":\"record\",\"name\":\"hoodie_source\",\"namespace\":\"hoodie.source\",\"fields\":[{\"name\":\"Op\",\"type\":[\"string\",\"null\"]},{\"name\":\"Id\",\"type\":[\"int\",\"null\"]},{\"name\":\"AuditProcessHistoryId\",\"type\":[\"int\",\"null\"]},{\"name\":\"org_id\",\"type\":[\"int\",\"null\"]},{\"name\":\"org_name\",\"type\":[\"string\",\"null\"]},{\"name\":\"org_sname\",\"type\":[\"string\",\"null\"]},{\"name\":\"org_mnem\",\"type\":[\"string\",\"null\"]},{\"name\":\"org_parent\",\"type\":[\"int\",\"null\"]},{\"name\":\"percent_holding\",\"type\":[\"double\",\"null\"]},{\"name\":\"group_company\",\"type\":[\"string\",\"null\"]},{\"name\":\"grp_ord_for_cln\",\"type\":[\"string\",\"null\"]},{\"name\":\"mkt_only\",\"type\":[\"string\",\"null\"]},{\"name\":\"pro_rate_ind\",\"type\":[\"string\",\"null\"]},{\"name\":\"show_shapes\",\"type\":[\"string\",\"null\"]},{\"name\":\"sec_code_pref\",\"type\":[\"string\",\"null\"]},{\"name\":\"alert_org_ref\",\"type\":[\"string\",\"null\"]},{\"name\":\"swift_bic\",\"type\":[\"string\",\"null\"]},{\"name\":\"exec_breakdown\",\"type\":[\"string\",\"null\"]},{\"name\":\"notes\",\"type\":[\"string\",\"null\"]},{\"name\":\"active\",\"type\":[\"string\",\"null\"]},{\"name\":\"version_no\",\"type\":[\"int\",\"null\"]},{\"name\":\"sys_date\",\"type\":[{\"type\":\"long\",\"logicalType\":\"timestamp-micros\"},\"null\"]},{\"name\":\"sys_user\",\"type\":[\"string\",\"null\"]},{\"name\":\"create_date\",\"type\":[{\"type\":\"long\",\"logicalType\":\"timestamp-micros\"},\"null\"]},{\"name\":\"cntry_of_dom\",\"type\":[\"string\",\"null\"]},{\"name\":\"client\",\"type\":[\"string\",\"null\"]},{\"name\":\"alert_acronym\",\"type\":[\"string\",\"null\"]},{\"name\":\"oneoff_client\",\"type\":[\"string\",\"null\"]},{\"name\":\"booking_domicile\",\"type\":[\"string\",\"null\"]},{\"name\":\"booking_dom_list\",\"type\":[\"string\",\"null\"]},{\"name\":\"TimeCreated\",\"type\":[{\"type\":\"long\",\"logicalType\":\"timestamp-micros\"},\"null\"]},{\"name\":\"UserCreated\",\"type\":[\"string\",\"null\"]}]}]\r\n2020-08-12 12:18:50,361 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants []\r\n2020-08-12 12:18:50,934 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants []\r\n2020-08-12 12:18:50,937 [main] INFO  org.apache.hudi.client.HoodieWriteClient - Generate a new instant time 20200812121850\r\n2020-08-12 12:18:51,226 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants []\r\n2020-08-12 12:18:51,234 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Creating a new instant [==>20200812121850__commit__REQUESTED]\r\n2020-08-12 12:18:51,415 [main] INFO  org.apache.hudi.utilities.deltastreamer.DeltaSync - Starting commit  : 20200812121850\r\n2020-08-12 12:18:51,699 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[==>20200812121850__commit__REQUESTED]]\r\n2020-08-12 12:18:51,982 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[==>20200812121850__commit__REQUESTED]]\r\n2020-08-12 12:19:21,501 [main] INFO  org.apache.hudi.index.bloom.HoodieBloomIndex - InputParallelism: ${1500}, IndexParallelism: ${0}\r\n2020-08-12 12:19:32,817 [main] INFO  org.apache.hudi.client.HoodieWriteClient - Workload profile :WorkloadProfile {globalStat=WorkloadStat {numInserts=103, numUpdates=0}, partitionStat={default=WorkloadStat {numInserts=103, numUpdates=0}}}\r\n2020-08-12 12:19:32,841 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Checking for file exists ?s3a://redact/my2/multpk7/.hoodie/20200812121850.commit.requested\r\n2020-08-12 12:19:33,081 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Create new file for toInstant ?s3a://redact/my2/multpk7/.hoodie/20200812121850.inflight\r\n2020-08-12 12:19:33,082 [main] INFO  org.apache.hudi.table.HoodieCopyOnWriteTable - AvgRecordSize => 1024\r\n2020-08-12 12:19:33,184 [main] INFO  org.apache.hudi.table.HoodieCopyOnWriteTable - For partitionPath : default Small Files => []\r\n2020-08-12 12:19:33,184 [main] INFO  org.apache.hudi.table.HoodieCopyOnWriteTable - After small file assignment: unassignedInserts => 103, totalInsertBuckets => 1, recordsPerBucket => 122880\r\n2020-08-12 12:19:33,185 [main] INFO  org.apache.hudi.table.HoodieCopyOnWriteTable - Total insert buckets for partition path default => [WorkloadStat {bucketNumber=0, weight=1.0}]\r\n2020-08-12 12:19:33,186 [main] INFO  org.apache.hudi.table.HoodieCopyOnWriteTable - Total Buckets :1, buckets info => {0=BucketInfo {bucketType=INSERT, fileIdPrefix=a9ab6f7a-4def-490a-aac0-49e15ee9d742}},\r\nPartition to insert buckets => {default=[WorkloadStat {bucketNumber=0, weight=1.0}]},\r\nUpdateLocations mapped to buckets =>{}\r\n2020-08-12 12:19:33,206 [main] INFO  org.apache.hudi.client.AbstractHoodieWriteClient - Auto commit disabled for 20200812121850\r\n2020-08-12 12:19:41,179 [main] INFO  org.apache.hudi.client.AbstractHoodieWriteClient - Commiting 20200812121850\r\n2020-08-12 12:19:41,502 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[==>20200812121850__commit__INFLIGHT]]\r\n2020-08-12 12:19:41,777 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[==>20200812121850__commit__INFLIGHT]]\r\n2020-08-12 12:19:42,140 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[==>20200812121850__commit__INFLIGHT]]\r\n2020-08-12 12:19:42,479 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[==>20200812121850__commit__INFLIGHT]]\r\n2020-08-12 12:19:42,706 [main] INFO  org.apache.hudi.table.HoodieTable - Removing marker directory=s3a://redact/my2/multpk7/.hoodie/.temp/20200812121850\r\n2020-08-12 12:19:43,027 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Marking instant complete [==>20200812121850__commit__INFLIGHT]\r\n2020-08-12 12:19:43,027 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Checking for file exists ?s3a://redact/my2/multpk7/.hoodie/20200812121850.inflight\r\n2020-08-12 12:19:43,356 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Create new file for toInstant ?s3a://redact/my2/multpk7/.hoodie/20200812121850.commit\r\n2020-08-12 12:19:43,357 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Completed [==>20200812121850__commit__INFLIGHT]\r\n2020-08-12 12:19:43,745 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[20200812121850__commit__COMPLETED]]\r\n2020-08-12 12:19:44,010 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[20200812121850__commit__COMPLETED]]\r\n2020-08-12 12:19:44,084 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[==>20200812121850__commit__REQUESTED], [==>20200812121850__commit__INFLIGHT], [20200812121850__commit__COMPLETED]]\r\n2020-08-12 12:19:44,085 [main] INFO  org.apache.hudi.table.HoodieCommitArchiveLog - No Instants to archive\r\n2020-08-12 12:19:44,086 [main] INFO  org.apache.hudi.client.HoodieWriteClient - Auto cleaning is enabled. Running cleaner now\r\n2020-08-12 12:19:44,356 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[20200812121850__commit__COMPLETED]]\r\n2020-08-12 12:19:44,629 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[20200812121850__commit__COMPLETED]]\r\n2020-08-12 12:19:44,912 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[20200812121850__commit__COMPLETED]]\r\n2020-08-12 12:19:45,321 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[20200812121850__commit__COMPLETED]]\r\n2020-08-12 12:19:45,337 [main] INFO  org.apache.hudi.table.CleanHelper - No earliest commit to retain. No need to scan partitions !!\r\n2020-08-12 12:19:45,337 [main] INFO  org.apache.hudi.table.HoodieCopyOnWriteTable - Nothing to clean here. It is already clean\r\n2020-08-12 12:19:45,374 [main] INFO  org.apache.hudi.client.AbstractHoodieWriteClient - Committed 20200812121850\r\n2020-08-12 12:19:45,374 [main] INFO  org.apache.hudi.utilities.deltastreamer.DeltaSync - Commit 20200812121850 successful!\r\n2020-08-12 12:19:45,375 [main] INFO  org.apache.hudi.utilities.deltastreamer.DeltaSync - Syncing target hoodie table with hive table(dmstest_multpk7). Hive metastore URL :jdbc:hive2://localhost:10000, basePath :s3a://redact/my2/multpk7\r\n2020-08-12 12:19:45,636 [main] INFO  org.apache.hudi.common.table.timeline.HoodieActiveTimeline - Loaded instants [[20200812121850__commit__COMPLETED]]\r\n2020-08-12 12:19:46,806 [main] INFO  org.apache.hudi.hive.HiveSyncTool - Trying to sync hoodie table dmstest_multpk7 with base path s3a://redact/my2/multpk7 of type COPY_ON_WRITE\r\n2020-08-12 12:19:46,864 [main] INFO  org.apache.hudi.hive.HoodieHiveClient - Reading schema from s3a://redact/my2/multpk7/default/a9ab6f7a-4def-490a-aac0-49e15ee9d742-0_0-25-15010_20200812121850.parquet\r\n2020-08-12 12:19:47,064 [main] INFO  org.apache.hudi.hive.HiveSyncTool - Hive table dmstest_multpk7 is not found. Creating it\r\n2020-08-12 12:19:47,070 [main] INFO  org.apache.hudi.hive.HoodieHiveClient - Creating table with CREATE EXTERNAL TABLE  IF NOT EXISTS `redact`.`dmstest_multpk7`( `_hoodie_commit_time` string, `_hoodie_commit_seqno` string, `_hoodie_record_key` string, `_hoodie_partition_path` string, `_hoodie_file_name` string, `Op` string, `Id` int, `AuditProcessHistoryId` int, `org_id` int, `org_name` string, `org_sname` string, `org_mnem` string, `org_parent` int, `percent_holding` double, `group_company` string, `grp_ord_for_cln` string, `mkt_only` string, `pro_rate_ind` string, `show_shapes` string, `sec_code_pref` string, `alert_org_ref` string, `swift_bic` string, `exec_breakdown` string, `notes` string, `active` string, `version_no` int, `sys_date` bigint, `sys_user` string, `create_date` bigint, `cntry_of_dom` string, `client` string, `alert_acronym` string, `oneoff_client` string, `booking_domicile` string, `booking_dom_list` string, `TimeCreated` bigint, `UserCreated` string) ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe' STORED AS INPUTFORMAT 'org.apache.hudi.hadoop.HoodieParquetInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat' LOCATION 's3a://redact/my2/multpk7'\r\n2020-08-12 12:19:47,151 [main] INFO  org.apache.hudi.hive.HoodieHiveClient - Time taken to start SessionState and create Driver: 81 ms\r\n2020-08-12 12:19:47,186 [main] INFO  hive.ql.parse.ParseDriver - Parsing command: CREATE EXTERNAL TABLE  IF NOT EXISTS `redact`.`dmstest_multpk7`( `_hoodie_commit_time` string, `_hoodie_commit_seqno` string, `_hoodie_record_key` string, `_hoodie_partition_path` string, `_hoodie_file_name` string, `Op` string, `Id` int, `AuditProcessHistoryId` int, `org_id` int, `org_name` string, `org_sname` string, `org_mnem` string, `org_parent` int, `percent_holding` double, `group_company` string, `grp_ord_for_cln` string, `mkt_only` string, `pro_rate_ind` string, `show_shapes` string, `sec_code_pref` string, `alert_org_ref` string, `swift_bic` string, `exec_breakdown` string, `notes` string, `active` string, `version_no` int, `sys_date` bigint, `sys_user` string, `create_date` bigint, `cntry_of_dom` string, `client` string, `alert_acronym` string, `oneoff_client` string, `booking_domicile` string, `booking_dom_list` string, `TimeCreated` bigint, `UserCreated` string) ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe' STORED AS INPUTFORMAT 'org.apache.hudi.hadoop.HoodieParquetInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat' LOCATION 's3a://redact/my2/multpk7'\r\n2020-08-12 12:19:47,874 [main] INFO  hive.ql.parse.ParseDriver - Parse Completed\r\n2020-08-12 12:19:48,323 [main] INFO  org.apache.hudi.hive.HoodieHiveClient - Time taken to execute [CREATE EXTERNAL TABLE  IF NOT EXISTS `redact`.`dmstest_multpk7`( `_hoodie_commit_time` string, `_hoodie_commit_seqno` string, `_hoodie_record_key` string, `_hoodie_partition_path` string, `_hoodie_file_name` string, `Op` string, `Id` int, `AuditProcessHistoryId` int, `org_id` int, `org_name` string, `org_sname` string, `org_mnem` string, `org_parent` int, `percent_holding` double, `group_company` string, `grp_ord_for_cln` string, `mkt_only` string, `pro_rate_ind` string, `show_shapes` string, `sec_code_pref` string, `alert_org_ref` string, `swift_bic` string, `exec_breakdown` string, `notes` string, `active` string, `version_no` int, `sys_date` bigint, `sys_user` string, `create_date` bigint, `cntry_of_dom` string, `client` string, `alert_acronym` string, `oneoff_client` string, `booking_domicile` string, `booking_dom_list` string, `TimeCreated` bigint, `UserCreated` string) ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe' STORED AS INPUTFORMAT 'org.apache.hudi.hadoop.HoodieParquetInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat' LOCATION 's3a://redact/my2/multpk7']: 1171 ms\r\n2020-08-12 12:19:48,329 [main] INFO  org.apache.hudi.hive.HiveSyncTool - Schema sync complete. Syncing partitions for dmstest_multpk7\r\n2020-08-12 12:19:48,329 [main] INFO  org.apache.hudi.hive.HiveSyncTool - Last commit time synced was found to be null\r\n2020-08-12 12:19:48,330 [main] INFO  org.apache.hudi.hive.HoodieHiveClient - Last commit time synced is not known, listing all partitions in s3a://redact/my2/multpk7,FS :S3AFileSystem{uri=s3a://redact, workingDir=s3a://redact/user/ec2-user, inputPolicy=normal, partSize=104857600, enableMultiObjectsDelete=true, maxKeys=5000, readAhead=65536, blockSize=33554432, multiPartThreshold=2147483647, serverSideEncryptionAlgorithm='AES256', blockFactory=org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory@62765aec, boundedExecutor=BlockingThreadPoolExecutorService{SemaphoredDelegatingExecutor{permitCount=2405, available=2405, waiting=0}, activeCount=0}, unboundedExecutor=java.util.concurrent.ThreadPoolExecutor@6f5bd362[Running, pool size = 6, active threads = 0, queued tasks = 0, completed tasks = 6], statistics {445890 bytes read, 4324 bytes written, 172 read ops, 0 large read ops, 31 write ops}, metrics {{Context=S3AFileSystem} {FileSystemId=aad8f6ce-2b40-4ddb-9b9b-4e82033cb193-redact} {fsURI=s3a://redact/sparkevents} {files_created=5} {files_copied=0} {files_copied_bytes=0} {files_deleted=1} {fake_directories_deleted=0} {directories_created=6} {directories_deleted=0} {ignored_errors=4} {op_copy_from_local_file=0} {op_exists=53} {op_get_file_status=145} {op_glob_status=0} {op_is_directory=38} {op_is_file=0} {op_list_files=1} {op_list_located_status=0} {op_list_status=19} {op_mkdirs=5} {op_rename=0} {object_copy_requests=0} {object_delete_requests=5} {object_list_requests=140} {object_continue_list_requests=0} {object_metadata_requests=265} {object_multipart_aborted=0} {object_put_bytes=4324} {object_put_requests=10} {object_put_requests_completed=10} {stream_write_failures=0} {stream_write_block_uploads=0} {stream_write_block_uploads_committed=0} {stream_write_block_uploads_aborted=0} {stream_write_total_time=0} {stream_write_total_data=4324} {object_put_requests_active=0} {object_put_bytes_pending=0} {stream_write_block_uploads_active=0} {stream_write_block_uploads_pending=4} {stream_write_block_uploads_data_pending=0} {stream_read_fully_operations=0} {stream_opened=22} {stream_bytes_skipped_on_seek=0} {stream_closed=22} {stream_bytes_backwards_on_seek=438082} {stream_bytes_read=445890} {stream_read_operations_incomplete=71} {stream_bytes_discarded_in_abort=0} {stream_close_operations=22} {stream_read_operations=2764} {stream_aborted=0} {stream_forward_seek_operations=0} {stream_backward_seek_operations=1} {stream_seek_operations=1} {stream_bytes_read_in_close=8} {stream_read_exceptions=0} }}\r\n2020-08-12 12:19:48,584 [main] INFO  org.apache.hudi.hive.HiveSyncTool - Storage partitions scan complete. Found 1\r\n2020-08-12 12:19:48,613 [main] INFO  org.apache.hudi.hive.HiveSyncTool - New Partitions []\r\n2020-08-12 12:19:48,614 [main] INFO  org.apache.hudi.hive.HoodieHiveClient - No partitions to add for dmstest_multpk7\r\n2020-08-12 12:19:48,614 [main] INFO  org.apache.hudi.hive.HiveSyncTool - Changed Partitions []\r\n2020-08-12 12:19:48,614 [main] INFO  org.apache.hudi.hive.HoodieHiveClient - No partitions to change for dmstest_multpk7\r\n2020-08-12 12:19:49,002 [main] INFO  org.apache.hudi.hive.HiveSyncTool - Sync complete for dmstest_multpk7\r\n2020-08-12 12:19:49,031 [main] INFO  org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer - Shut down deltastreamer\r\n2020-08-12 12:19:49,044 [main] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Shutting down all executors\r\n```\r\n\r\n```\r\naws s3 ls s3://redact/my2/multpk7/\r\n                           PRE .hoodie/\r\n                           PRE default/\r\n                           \r\naws s3 ls s3://redact/my2/multpk7/default/\r\n2020-08-12 12:19:39         93 .hoodie_partition_metadata\r\n2020-08-12 12:19:41     452644 a9ab6f7a-4def-490a-aac0-49e15ee9d742-0_0-25-15010_20200812121850.parquet\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672843556/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672853435","html_url":"https://github.com/apache/hudi/issues/1955#issuecomment-672853435","issue_url":"https://api.github.com/repos/apache/hudi/issues/1955","id":672853435,"node_id":"MDEyOklzc3VlQ29tbWVudDY3Mjg1MzQzNQ==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T12:55:55Z","updated_at":"2020-08-12T12:55:55Z","author_association":"NONE","body":"--hoodie-conf hoodie.index.type=GLOBAL_BLOOM --hoodie-conf hoodie.bloom.index.update.partition.path=true   adding those 2 flags seems to get the right row count in the target but can you confirm it will take the latest row by source-ordering-field ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/672853435/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673019518","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673019518","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673019518,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzAxOTUxOA==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T17:49:39Z","updated_at":"2020-08-12T17:49:39Z","author_association":"CONTRIBUTOR","body":"> in some sense, due to the bundling changes, this feel very last minute to validate more. We have to rely on 1-2 rounds of RC testing to weed things out.\r\n\r\nI understand Vinoth. So are we planning to include this ? It will unblock the contribution on presto side for the bootstrapped table work.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673019518/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673051331","html_url":"https://github.com/apache/hudi/pull/1760#issuecomment-673051331","issue_url":"https://api.github.com/repos/apache/hudi/issues/1760","id":673051331,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzA1MTMzMQ==","user":{"login":"bschell","id":8600774,"node_id":"MDQ6VXNlcjg2MDA3NzQ=","avatar_url":"https://avatars.githubusercontent.com/u/8600774?v=4","gravatar_id":"","url":"https://api.github.com/users/bschell","html_url":"https://github.com/bschell","followers_url":"https://api.github.com/users/bschell/followers","following_url":"https://api.github.com/users/bschell/following{/other_user}","gists_url":"https://api.github.com/users/bschell/gists{/gist_id}","starred_url":"https://api.github.com/users/bschell/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bschell/subscriptions","organizations_url":"https://api.github.com/users/bschell/orgs","repos_url":"https://api.github.com/users/bschell/repos","events_url":"https://api.github.com/users/bschell/events{/privacy}","received_events_url":"https://api.github.com/users/bschell/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T18:56:56Z","updated_at":"2020-08-12T18:56:56Z","author_association":"CONTRIBUTOR","body":"@nsivabalan Looks like a recent commit made this Class private: https://github.com/apache/spark/commit/ce2cdc36e29742dda22200963cfd3f9876170455 \r\n\r\nHowever I think we can workaround this by porting the code for those methods over to Hudi (it's not too long).\r\nFor example:\r\n\r\n\r\n[spark3.txt](https://github.com/apache/hudi/files/5065062/spark3.txt)\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673051331/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673054126","html_url":"https://github.com/apache/hudi/issues/1902#issuecomment-673054126","issue_url":"https://api.github.com/repos/apache/hudi/issues/1902","id":673054126,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzA1NDEyNg==","user":{"login":"rubenssoto","id":36298331,"node_id":"MDQ6VXNlcjM2Mjk4MzMx","avatar_url":"https://avatars.githubusercontent.com/u/36298331?v=4","gravatar_id":"","url":"https://api.github.com/users/rubenssoto","html_url":"https://github.com/rubenssoto","followers_url":"https://api.github.com/users/rubenssoto/followers","following_url":"https://api.github.com/users/rubenssoto/following{/other_user}","gists_url":"https://api.github.com/users/rubenssoto/gists{/gist_id}","starred_url":"https://api.github.com/users/rubenssoto/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rubenssoto/subscriptions","organizations_url":"https://api.github.com/users/rubenssoto/orgs","repos_url":"https://api.github.com/users/rubenssoto/repos","events_url":"https://api.github.com/users/rubenssoto/events{/privacy}","received_events_url":"https://api.github.com/users/rubenssoto/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T19:02:49Z","updated_at":"2020-08-12T19:02:49Z","author_association":"NONE","body":"Thank you so much for your help!","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673054126/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673096439","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673096439","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673096439,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzA5NjQzOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T20:33:14Z","updated_at":"2020-08-12T20:33:14Z","author_association":"MEMBER","body":"I am kind of torn. On one hand, this completes the bootstrap story and lets us stabilize things. Given the later versions of presto anyway take hudi as a compile depedency, I think it may be ok?\r\n\r\ncc @bhasudha does prestoDB depend on the bundle or the hoodie-hadoop-mr jars? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673096439/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673096742","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673096742","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673096742,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzA5Njc0Mg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T20:34:00Z","updated_at":"2020-08-12T20:34:00Z","author_association":"MEMBER","body":"cc @bvaradar wdyt? if there is little impact to presto integration, we could just do it and iterate.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673096742/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673100458","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673100458","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673100458,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEwMDQ1OA==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T20:42:01Z","updated_at":"2020-08-12T20:42:01Z","author_association":"CONTRIBUTOR","body":"> I am kind of torn. On one hand, this completes the bootstrap story and lets us stabilize things. Given the later versions of presto anyway take hudi as a compile depedency, I think it may be ok?\r\n> \r\n> cc @bhasudha does prestoDB depend on the bundle or the hoodie-hadoop-mr jars?\r\n\r\nYes this is a good question. Should we really depend on `hud-hadoop-mr` in presto or the `presto-bundle` ? The bundle gives us the advantages of shading the dependencies to avoid such conflicts. Without bundle we would have to do the shading in `hudi-hadoop-mr` which does not seem right.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673100458/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673100564","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673100564","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673100564,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEwMDU2NA==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T20:42:14Z","updated_at":"2020-08-12T20:42:14Z","author_association":"CONTRIBUTOR","body":"> I am kind of torn. On one hand, this completes the bootstrap story and lets us stabilize things. Given the later versions of presto anyway take hudi as a compile depedency, I think it may be ok?\r\n> \r\n> cc @bhasudha does prestoDB depend on the bundle or the hoodie-hadoop-mr jars?\r\n\r\n@vinothchandar @umehrot2  Starting from version 0.233, Presto depends on hudi-hadoop-mr during compile time. Prior to that we needed to drop bundle jars into the plugin directory.  \r\n@umehrot2  If this fix is for 0.232 would this go away when picking up 0.233 ? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673100564/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673102081","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673102081","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673102081,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEwMjA4MQ==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T20:45:51Z","updated_at":"2020-08-12T20:45:51Z","author_association":"CONTRIBUTOR","body":"> > I am kind of torn. On one hand, this completes the bootstrap story and lets us stabilize things. Given the later versions of presto anyway take hudi as a compile depedency, I think it may be ok?\r\n> > cc @bhasudha does prestoDB depend on the bundle or the hoodie-hadoop-mr jars?\r\n> \r\n> @vinothchandar @umehrot2 Starting from version 0.233, Presto depends on hudi-hadoop-mr during compile time. Prior to that we needed to drop bundle jars into the plugin directory.\r\n> @umehrot2 If this fix is for 0.232 would this go away when picking up 0.233 ?\r\n\r\nYeah this is based on my testing for presto 0.232. I did not know the `presto-bundle` would be deprecated going forward. But I am wondering if this was the right decision to depend on `hudi-hadoop-mr` in `presto`. How would we avoid version conflicts like the ones that came up with hbase here ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673102081/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673102805","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673102805","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673102805,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEwMjgwNQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T20:47:33Z","updated_at":"2020-08-12T20:47:33Z","author_association":"MEMBER","body":"@bhasudha @bschell the MOR support in presto as well, works using the compile time dependency? \r\n\r\nseems, then to make presto generally work with bootstrap, we need to rethink that for higher presto versions at-least. How's athena working now, with the bundle or the compile-time dependency? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673102805/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673103082","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673103082","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673103082,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEwMzA4Mg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T20:48:10Z","updated_at":"2020-08-12T20:48:10Z","author_association":"MEMBER","body":"@umehrot2 I think we can control the shading by a flag for now. and move on for now? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673103082/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673103276","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673103276","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673103276,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEwMzI3Ng==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T20:48:35Z","updated_at":"2020-08-12T20:48:35Z","author_association":"CONTRIBUTOR","body":"> > I am kind of torn. On one hand, this completes the bootstrap story and lets us stabilize things. Given the later versions of presto anyway take hudi as a compile depedency, I think it may be ok?\r\n> > cc @bhasudha does prestoDB depend on the bundle or the hoodie-hadoop-mr jars?\r\n> \r\n> Yes this is a good question. Should we really depend on `hud-hadoop-mr` in presto or the `presto-bundle` ? The bundle gives us the advantages of shading the dependencies to avoid such conflicts. Without bundle we would have to do the shading in `hudi-hadoop-mr` which does not seem right.\r\n\r\nI agree that doing shading in the `hudi-hadoop-mr` is not right. As far depending on bundle itself, we would need to test the shading in both s3 and HDFS environments to include all right shading if we went that route. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673103276/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673103896","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673103896","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673103896,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEwMzg5Ng==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T20:50:02Z","updated_at":"2020-08-12T20:50:02Z","author_association":"CONTRIBUTOR","body":"> @bhasudha @bschell the MOR support in presto as well, works using the compile time dependency?\r\n> \r\n> seems, then to make presto generally work with bootstrap, we need to rethink that for higher presto versions at-least. How's athena working now, with the bundle or the compile-time dependency?\r\n\r\nAthena is using very old version of Presto I believe. And definitely using the bundle jar.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673103896/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673107178","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673107178","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673107178,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEwNzE3OA==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T20:57:50Z","updated_at":"2020-08-12T20:57:50Z","author_association":"CONTRIBUTOR","body":"> @bhasudha @bschell the MOR support in presto as well, works using the compile time dependency?\r\n> \r\n> seems, then to make presto generally work with bootstrap, we need to rethink that for higher presto versions at-least. How's athena working now, with the bundle or the compile-time dependency?\r\n\r\n\r\n\r\n> > I am kind of torn. On one hand, this completes the bootstrap story and lets us stabilize things. Given the later versions of presto anyway take hudi as a compile depedency, I think it may be ok?\r\n> > cc @bhasudha does prestoDB depend on the bundle or the hoodie-hadoop-mr jars?\r\n> \r\n> Yes this is a good question. Should we really depend on `hud-hadoop-mr` in presto or the `presto-bundle` ? The bundle gives us the advantages of shading the dependencies to avoid such conflicts. Without bundle we would have to do the shading in `hudi-hadoop-mr` which does not seem right.   \r\n\r\nThere is no strong reason for why we would need to depend on `hudi-hadoop-mr` from Presto.  I guess at that time, we were not yet thinking about how other use case would be supported in Presto and the dependencies that come along. We could certainly depend on the bundle instead. From my interactions, the presto community does not recommend dropping jars into plugin. So if we could instead take compile time dependency on the `presto-bundle`, that could work for all situations here. \r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673107178/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673112695","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673112695","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673112695,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzExMjY5NQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T21:09:44Z","updated_at":"2020-08-12T21:09:44Z","author_association":"MEMBER","body":">So if we could instead take compile time dependency on the presto-bundle, that could work for all situations here.\r\n\r\nlet's raise a JIRA for this. the thing is sometimes its weird to depend on compile time on a bundle, because you cannot selectively exclude dependencies. but if we rework prestoDB to depend on presto-bundle and shade it, it would fix all issues. \r\n\r\nI ll let the aws folks chime in here. so we can make a call. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673112695/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673114587","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673114587","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673114587,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzExNDU4Nw==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T21:14:27Z","updated_at":"2020-08-12T21:14:27Z","author_association":"CONTRIBUTOR","body":"> > So if we could instead take compile time dependency on the presto-bundle, that could work for all situations here.\r\n> \r\n> let's raise a JIRA for this. the thing is sometimes its weird to depend on compile time on a bundle, because you cannot selectively exclude dependencies. but if we rework prestoDB to depend on presto-bundle and shade it, it would fix all issues.\r\n> \r\n> I ll let the aws folks chime in here. so we can make a call.\r\n\r\nI agree that its weird to have compile time dependency on bundle jars, but that seems like the way forward here to me.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673114587/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673115616","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673115616","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673115616,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzExNTYxNg==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T21:17:06Z","updated_at":"2020-08-12T21:17:06Z","author_association":"CONTRIBUTOR","body":"> > > So if we could instead take compile time dependency on the presto-bundle, that could work for all situations here.\r\n> > \r\n> > \r\n> > let's raise a JIRA for this. the thing is sometimes its weird to depend on compile time on a bundle, because you cannot selectively exclude dependencies. but if we rework prestoDB to depend on presto-bundle and shade it, it would fix all issues.\r\n> > I ll let the aws folks chime in here. so we can make a call.\r\n> \r\n> I agree that its weird to have compile time dependency on bundle jars, but that seems like the way forward here to me.\r\n\r\nhttps://issues.apache.org/jira/browse/HUDI-1183 I created a jira here to track this. @umehrot2 feel free to add more details to that. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673115616/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673119515","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673119515","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673119515,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzExOTUxNQ==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T21:26:54Z","updated_at":"2020-08-12T21:26:54Z","author_association":"CONTRIBUTOR","body":"> @umehrot2 I think we can control the shading by a flag for now. and move on for now?\r\n\r\nLet me do this.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673119515/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673120694","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673120694","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673120694,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEyMDY5NA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T21:29:52Z","updated_at":"2020-08-12T21:29:52Z","author_association":"CONTRIBUTOR","body":"> cc @bvaradar wdyt? if there is little impact to presto integration, we could just do it and iterate.\r\n\r\n@vinothchandar : Since this is essential for Presto support for bootstrapped tables and we are shading, I think we can get this in and iterate. A flag to control the inclusion of dependent  packages makes sense as we will have a way to tell users what to do if we find issues post launch.  \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673120694/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673131428","html_url":"https://github.com/apache/hudi/issues/1947#issuecomment-673131428","issue_url":"https://api.github.com/repos/apache/hudi/issues/1947","id":673131428,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEzMTQyOA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T21:59:14Z","updated_at":"2020-08-12T21:59:14Z","author_association":"CONTRIBUTOR","body":"@xushiyan : Can you please chime in here ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673131428/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673133768","html_url":"https://github.com/apache/hudi/issues/1958#issuecomment-673133768","issue_url":"https://api.github.com/repos/apache/hudi/issues/1958","id":673133768,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEzMzc2OA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T22:05:39Z","updated_at":"2020-08-12T22:05:39Z","author_association":"CONTRIBUTOR","body":"@nsivabalan : Can you please look at this and respond ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673133768/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673138395","html_url":"https://github.com/apache/hudi/issues/1956#issuecomment-673138395","issue_url":"https://api.github.com/repos/apache/hudi/issues/1956","id":673138395,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzEzODM5NQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T22:19:17Z","updated_at":"2020-08-12T22:19:17Z","author_association":"CONTRIBUTOR","body":"@tooptoop4 : Can you add the exceptions you are getting. With 0.5.3, We handle null columns in record-key  https://github.com/apache/hudi/blob/release-0.5.3/hudi-spark/src/main/java/org/apache/hudi/keygen/ComplexKeyGenerator.java#L71 \r\nCurious, what the exception is ? \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673138395/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673165008","html_url":"https://github.com/apache/hudi/pull/1916#issuecomment-673165008","issue_url":"https://api.github.com/repos/apache/hudi/issues/1916","id":673165008,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzE2NTAwOA==","user":{"login":"modi95","id":6784567,"node_id":"MDQ6VXNlcjY3ODQ1Njc=","avatar_url":"https://avatars.githubusercontent.com/u/6784567?v=4","gravatar_id":"","url":"https://api.github.com/users/modi95","html_url":"https://github.com/modi95","followers_url":"https://api.github.com/users/modi95/followers","following_url":"https://api.github.com/users/modi95/following{/other_user}","gists_url":"https://api.github.com/users/modi95/gists{/gist_id}","starred_url":"https://api.github.com/users/modi95/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/modi95/subscriptions","organizations_url":"https://api.github.com/users/modi95/orgs","repos_url":"https://api.github.com/users/modi95/repos","events_url":"https://api.github.com/users/modi95/events{/privacy}","received_events_url":"https://api.github.com/users/modi95/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-12T23:51:34Z","updated_at":"2020-08-12T23:51:34Z","author_association":"CONTRIBUTOR","body":"Updated the diff. Thanks for the review @leesf :D ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673165008/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673169459","html_url":"https://github.com/apache/hudi/pull/1944#issuecomment-673169459","issue_url":"https://api.github.com/repos/apache/hudi/issues/1944","id":673169459,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzE2OTQ1OQ==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T00:08:04Z","updated_at":"2020-08-13T00:08:04Z","author_association":"CONTRIBUTOR","body":"> A flag to control the inclusion of dependent packages makes sense as we will have a way to tell users what to do if we find issues post launch.\r\n\r\nUpdated the PR by adding a flag that can control if we want to not shade these.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673169459/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673197133","html_url":"https://github.com/apache/hudi/pull/1242#issuecomment-673197133","issue_url":"https://api.github.com/repos/apache/hudi/issues/1242","id":673197133,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzE5NzEzMw==","user":{"login":"hddong","id":17537134,"node_id":"MDQ6VXNlcjE3NTM3MTM0","avatar_url":"https://avatars.githubusercontent.com/u/17537134?v=4","gravatar_id":"","url":"https://api.github.com/users/hddong","html_url":"https://github.com/hddong","followers_url":"https://api.github.com/users/hddong/followers","following_url":"https://api.github.com/users/hddong/following{/other_user}","gists_url":"https://api.github.com/users/hddong/gists{/gist_id}","starred_url":"https://api.github.com/users/hddong/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hddong/subscriptions","organizations_url":"https://api.github.com/users/hddong/orgs","repos_url":"https://api.github.com/users/hddong/repos","events_url":"https://api.github.com/users/hddong/events{/privacy}","received_events_url":"https://api.github.com/users/hddong/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T01:33:39Z","updated_at":"2020-08-13T01:33:39Z","author_association":"CONTRIBUTOR","body":"@n3nash : had rebase this again, please have a review when free.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673197133/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673206288","html_url":"https://github.com/apache/hudi/issues/1958#issuecomment-673206288","issue_url":"https://api.github.com/repos/apache/hudi/issues/1958","id":673206288,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzIwNjI4OA==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T02:08:14Z","updated_at":"2020-08-13T02:08:14Z","author_association":"CONTRIBUTOR","body":"We have to make some fixes to HbaseIndex in this regards. Guess its a bug. We have a fix in all implicit global indexes, where a upsert record to a different partition will upsert to new partition and also delete from old partition. Don't think we have this fix in HbaseIndex. \r\nI have create a ticket to track this https://issues.apache.org/jira/browse/HUDI-1184","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673206288/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673209399","html_url":"https://github.com/apache/hudi/pull/1916#issuecomment-673209399","issue_url":"https://api.github.com/repos/apache/hudi/issues/1916","id":673209399,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzIwOTM5OQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T02:20:06Z","updated_at":"2020-08-13T02:20:06Z","author_association":"MEMBER","body":"Seems innocuous. Would not cause conflicts with any blocker PRs per se. We can land if you are comfortable. \r\n\r\ncc @bvaradar notice how CI passes on all the PRs. (udit's presto bootstrap PR also for e.g,) . This branch for e,g has upto the bootstrap PR merge that I did :| .is this some travis/bad box issue,for master branch only?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673209399/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673211582","html_url":"https://github.com/apache/hudi/issues/1911#issuecomment-673211582","issue_url":"https://api.github.com/repos/apache/hudi/issues/1911","id":673211582,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzIxMTU4Mg==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T02:28:18Z","updated_at":"2020-08-13T02:28:18Z","author_association":"CONTRIBUTOR","body":"@mingujotemp : is it possible to try with latest hoodie version. I vaguely remember a fix was put in for a similar bug/issue. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673211582/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673274582","html_url":"https://github.com/apache/hudi/issues/1958#issuecomment-673274582","issue_url":"https://api.github.com/repos/apache/hudi/issues/1958","id":673274582,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzI3NDU4Mg==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T05:46:21Z","updated_at":"2020-08-13T05:46:21Z","author_association":"CONTRIBUTOR","body":"@n3nash : Is this a valid issue in Hbase ? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673274582/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673284248","html_url":"https://github.com/apache/hudi/issues/1956#issuecomment-673284248","issue_url":"https://api.github.com/repos/apache/hudi/issues/1956","id":673284248,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzI4NDI0OA==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T06:14:56Z","updated_at":"2020-08-13T06:14:56Z","author_association":"NONE","body":"so on single column table it was https://github.com/apache/hudi/blob/release-0.5.3/hudi-spark/src/main/java/org/apache/hudi/keygen/SimpleKeyGenerator.java#L58\r\n\r\ncan I use complexkey class even for single column table ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673284248/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673310364","html_url":"https://github.com/apache/hudi/issues/827#issuecomment-673310364","issue_url":"https://api.github.com/repos/apache/hudi/issues/827","id":673310364,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzMxMDM2NA==","user":{"login":"saumyasuhagiya","id":2899428,"node_id":"MDQ6VXNlcjI4OTk0Mjg=","avatar_url":"https://avatars.githubusercontent.com/u/2899428?v=4","gravatar_id":"","url":"https://api.github.com/users/saumyasuhagiya","html_url":"https://github.com/saumyasuhagiya","followers_url":"https://api.github.com/users/saumyasuhagiya/followers","following_url":"https://api.github.com/users/saumyasuhagiya/following{/other_user}","gists_url":"https://api.github.com/users/saumyasuhagiya/gists{/gist_id}","starred_url":"https://api.github.com/users/saumyasuhagiya/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/saumyasuhagiya/subscriptions","organizations_url":"https://api.github.com/users/saumyasuhagiya/orgs","repos_url":"https://api.github.com/users/saumyasuhagiya/repos","events_url":"https://api.github.com/users/saumyasuhagiya/events{/privacy}","received_events_url":"https://api.github.com/users/saumyasuhagiya/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T07:25:07Z","updated_at":"2020-08-13T07:25:07Z","author_association":"NONE","body":"Thanks @bvaradar. Currently I have resolved it by putting as external jar using --jars. I will open new issue if required","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673310364/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673310825","html_url":"https://github.com/apache/hudi/pull/1834#issuecomment-673310825","issue_url":"https://api.github.com/repos/apache/hudi/issues/1834","id":673310825,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzMxMDgyNQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T07:26:12Z","updated_at":"2020-08-13T07:26:12Z","author_association":"MEMBER","body":"@nsivabalan this is ready. I am going ahead and merging. I also re-ran the benchmark again . Seems to clock the same 30 mins against spark.write.parquet. \r\n\r\nPlease carefully go over the changes I have made in the last commits here.. and see if anything needs follow on fixing. Our timelines are tight. we need to do it tomorrow, if at all ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673310825/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673322896","html_url":"https://github.com/apache/hudi/issues/1947#issuecomment-673322896","issue_url":"https://api.github.com/repos/apache/hudi/issues/1947","id":673322896,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzMyMjg5Ng==","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T07:53:12Z","updated_at":"2020-08-13T07:53:12Z","author_association":"MEMBER","body":"hi i haven't tried this myself but a cursory look gives that `option(\"hoodie.metrics.on\",true)` may be a problem as it takes a `boolean` for value. can you try `option(\"hoodie.metrics.on\",\"true\")`? and have you tried the settings with other metrics reporter?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673322896/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673336838","html_url":"https://github.com/apache/hudi/issues/1960#issuecomment-673336838","issue_url":"https://api.github.com/repos/apache/hudi/issues/1960","id":673336838,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzMzNjgzOA==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T08:22:10Z","updated_at":"2020-08-13T08:23:42Z","author_association":"CONTRIBUTOR","body":"@brandon-stanley  the `hoodie.datasource.write.precombine.field` is a mandatory field. If not specified a default field name `ts` is assumed. Since your table does not have this field you are seeing the above error.  The payload class invocation is not an issue since the stack trace you are pointing to here is happening way before the payload class is being invoked. You might want to point the `hoodie.datasource.write.precombine.field` to a valid column in the table and then also pass in a payload class that would ignore the precombine field. You can try that way. \r\n\r\nBut this aside,  does your dataset not have duplicates ? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673336838/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673341610","html_url":"https://github.com/apache/hudi/issues/1956#issuecomment-673341610","issue_url":"https://api.github.com/repos/apache/hudi/issues/1956","id":673341610,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzM0MTYxMA==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T08:31:36Z","updated_at":"2020-08-13T08:31:36Z","author_association":"CONTRIBUTOR","body":"> so on single column table it was https://github.com/apache/hudi/blob/release-0.5.3/hudi-spark/src/main/java/org/apache/hudi/keygen/SimpleKeyGenerator.java#L58\r\n> \r\n> can I use complexkey class even for single column table ?\r\n\r\nIt should be possible. It would split record keys separated by comma (in case of multiple columns) into a list. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673341610/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673347421","html_url":"https://github.com/apache/hudi/issues/1948#issuecomment-673347421","issue_url":"https://api.github.com/repos/apache/hudi/issues/1948","id":673347421,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzM0NzQyMQ==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T08:43:09Z","updated_at":"2020-08-13T08:43:09Z","author_association":"CONTRIBUTOR","body":"You would need to set the `--props` config for DeltaStreamer with a valid property file - https://github.com/apache/hudi/blob/379cf0786fe9fea94ec8c0da7d467ae2fb30dd0b/hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java#L217/ . Or pass in the props individually using `--hoodie-conf `. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673347421/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673462785","html_url":"https://github.com/apache/hudi/issues/1960#issuecomment-673462785","issue_url":"https://api.github.com/repos/apache/hudi/issues/1960","id":673462785,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzQ2Mjc4NQ==","user":{"login":"brandon-stanley","id":38012877,"node_id":"MDQ6VXNlcjM4MDEyODc3","avatar_url":"https://avatars.githubusercontent.com/u/38012877?v=4","gravatar_id":"","url":"https://api.github.com/users/brandon-stanley","html_url":"https://github.com/brandon-stanley","followers_url":"https://api.github.com/users/brandon-stanley/followers","following_url":"https://api.github.com/users/brandon-stanley/following{/other_user}","gists_url":"https://api.github.com/users/brandon-stanley/gists{/gist_id}","starred_url":"https://api.github.com/users/brandon-stanley/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brandon-stanley/subscriptions","organizations_url":"https://api.github.com/users/brandon-stanley/orgs","repos_url":"https://api.github.com/users/brandon-stanley/repos","events_url":"https://api.github.com/users/brandon-stanley/events{/privacy}","received_events_url":"https://api.github.com/users/brandon-stanley/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T12:58:37Z","updated_at":"2020-08-13T18:48:45Z","author_association":"NONE","body":"@bhasudha Thanks for the response. Does the precombine field have to be a non-nullable field/column as well? My dataset may have duplicates but I have implemented custom logic to deduplicate since there are two columns within my dataset that are used to determine which is the latest record: COALESCE(update_date, create_date). I implemented it this way because it is an [SCD type 2 table.](https://en.wikipedia.org/wiki/Slowly_changing_dimension#Type_2:_add_new_row)\r\n\r\nAlso, how would I specify the payload class that would ignore the precombine field? I receive the following error when specifying the `hoodie.datasource.write.payload.class` configuration property as `org.apache.hudi.common.model.HoodieAvroPayload`. Do I need to create a custom class that implements the [HoodieRecordPayload interface](https://github.com/apache/hudi/blob/release-0.5.2/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java)?\r\n\r\n```\r\npy4j.protocol.Py4JJavaError: An error occurred while calling o152.save.\r\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 21.0 failed 1 times, most recent failure: Lost task 1.0 in stage 21.0 (TID 529, localhost, executor driver): java.io.IOException: Could not create payload for class: org.apache.hudi.common.model.HoodieAvroPayload\r\n        at org.apache.hudi.DataSourceUtils.createPayload(DataSourceUtils.java:128)\r\n        at org.apache.hudi.DataSourceUtils.createHoodieRecord(DataSourceUtils.java:181)\r\n        at org.apache.hudi.HoodieSparkSqlWriter$$anonfun$1.apply(HoodieSparkSqlWriter.scala:103)\r\n        at org.apache.hudi.HoodieSparkSqlWriter$$anonfun$1.apply(HoodieSparkSqlWriter.scala:100)\r\n        at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)\r\n        at scala.collection.Iterator$$anon$10.next(Iterator.scala:347)\r\n        at scala.collection.Iterator$class.foreach(Iterator.scala:743)\r\n        at scala.collection.AbstractIterator.foreach(Iterator.scala:1174)\r\n        at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\r\n        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\r\n        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\r\n        at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:296)\r\n        at scala.collection.AbstractIterator.to(Iterator.scala:1174)\r\n        at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:288)\r\n        at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1174)\r\n        at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:275)\r\n        at scala.collection.AbstractIterator.toArray(Iterator.scala:1174)\r\n        at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\r\n        at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\r\n        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n        at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.hudi.exception.HoodieException: Unable to instantiate class\r\n        at org.apache.hudi.common.util.ReflectionUtils.loadClass(ReflectionUtils.java:80)\r\n        at org.apache.hudi.DataSourceUtils.createPayload(DataSourceUtils.java:125)\r\n        ... 28 more\r\nCaused by: java.lang.NoSuchMethodException: org.apache.hudi.common.model.HoodieAvroPayload.<init>(org.apache.avro.generic.GenericRecord, java.lang.Comparable)\r\n        at java.lang.Class.getConstructor0(Class.java:3082)\r\n        at java.lang.Class.getConstructor(Class.java:1825)\r\n        at org.apache.hudi.common.util.ReflectionUtils.loadClass(ReflectionUtils.java:78)\r\n        ... 29 more\r\n\r\nDriver stacktrace:\r\n        at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n        at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n        at scala.Option.foreach(Option.scala:245)\r\n        at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n        at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n        at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n        at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n        at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n        at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n        at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)\r\n        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n        at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n        at org.apache.spark.rdd.RDD.take(RDD.scala:1337)\r\n        at org.apache.spark.rdd.RDD$$anonfun$isEmpty$1.apply$mcZ$sp(RDD.scala:1472)\r\n        at org.apache.spark.rdd.RDD$$anonfun$isEmpty$1.apply(RDD.scala:1472)\r\n        at org.apache.spark.rdd.RDD$$anonfun$isEmpty$1.apply(RDD.scala:1472)\r\n        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n        at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n        at org.apache.spark.rdd.RDD.isEmpty(RDD.scala:1471)\r\n        at org.apache.spark.api.java.JavaRDDLike$class.isEmpty(JavaRDDLike.scala:544)\r\n        at org.apache.spark.api.java.AbstractJavaRDDLike.isEmpty(JavaRDDLike.scala:45)\r\n        at org.apache.hudi.HoodieSparkSqlWriter$.write(HoodieSparkSqlWriter.scala:142)\r\n        at org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:91)\r\n        at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\r\n        at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\r\n        at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\r\n        at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\r\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n        at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\r\n        at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\r\n        at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\r\n        at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\r\n        at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n        at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n        at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n        at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\r\n        at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\r\n        at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\r\n        at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n        at py4j.Gateway.invoke(Gateway.java:282)\r\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n        at py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.IOException: Could not create payload for class: org.apache.hudi.common.model.HoodieAvroPayload\r\n        at org.apache.hudi.DataSourceUtils.createPayload(DataSourceUtils.java:128)\r\n        at org.apache.hudi.DataSourceUtils.createHoodieRecord(DataSourceUtils.java:181)\r\n        at org.apache.hudi.HoodieSparkSqlWriter$$anonfun$1.apply(HoodieSparkSqlWriter.scala:103)\r\n        at org.apache.hudi.HoodieSparkSqlWriter$$anonfun$1.apply(HoodieSparkSqlWriter.scala:100)\r\n        at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)\r\n        at scala.collection.Iterator$$anon$10.next(Iterator.scala:347)\r\n        at scala.collection.Iterator$class.foreach(Iterator.scala:743)\r\n        at scala.collection.AbstractIterator.foreach(Iterator.scala:1174)\r\n        at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\r\n        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\r\n        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\r\n        at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:296)\r\n        at scala.collection.AbstractIterator.to(Iterator.scala:1174)\r\n        at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:288)\r\n        at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1174)\r\n        at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:275)\r\n        at scala.collection.AbstractIterator.toArray(Iterator.scala:1174)\r\n        at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\r\n        at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\r\n        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n        at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        ... 1 more\r\nCaused by: org.apache.hudi.exception.HoodieException: Unable to instantiate class\r\n        at org.apache.hudi.common.util.ReflectionUtils.loadClass(ReflectionUtils.java:80)\r\n        at org.apache.hudi.DataSourceUtils.createPayload(DataSourceUtils.java:125)\r\n        ... 28 more\r\nCaused by: java.lang.NoSuchMethodException: org.apache.hudi.common.model.HoodieAvroPayload.<init>(org.apache.avro.generic.GenericRecord, java.lang.Comparable)\r\n        at java.lang.Class.getConstructor0(Class.java:3082)\r\n        at java.lang.Class.getConstructor(Class.java:1825)\r\n        at org.apache.hudi.common.util.ReflectionUtils.loadClass(ReflectionUtils.java:78)\r\n        ... 29 more\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673462785/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673519517","html_url":"https://github.com/apache/hudi/issues/1948#issuecomment-673519517","issue_url":"https://api.github.com/repos/apache/hudi/issues/1948","id":673519517,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzUxOTUxNw==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T14:41:44Z","updated_at":"2020-08-13T14:41:44Z","author_association":"NONE","body":"I use hoodie-conf as shown in the description, but is property file mandatory?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673519517/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673694878","html_url":"https://github.com/apache/hudi/issues/1962#issuecomment-673694878","issue_url":"https://api.github.com/repos/apache/hudi/issues/1962","id":673694878,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzY5NDg3OA==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T20:29:46Z","updated_at":"2020-08-13T20:29:46Z","author_association":"CONTRIBUTOR","body":"Did you set hive input format ? Also can you confirm you settings given [here](https://hudi.apache.org/docs/docker_demo.html#step-4-a-run-hive-queries) are set. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673694878/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673696662","html_url":"https://github.com/apache/hudi/issues/1961#issuecomment-673696662","issue_url":"https://api.github.com/repos/apache/hudi/issues/1961","id":673696662,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzY5NjY2Mg==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T20:33:47Z","updated_at":"2020-08-13T20:34:36Z","author_association":"CONTRIBUTOR","body":"I don't have any exp in Azure databricks. Can you post it in [hudi's slack channel](https://github.com/apache/hudi/issues/1961#issuecomment-673696662). someone with experience might help.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673696662/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673747835","html_url":"https://github.com/apache/hudi/issues/1911#issuecomment-673747835","issue_url":"https://api.github.com/repos/apache/hudi/issues/1911","id":673747835,"node_id":"MDEyOklzc3VlQ29tbWVudDY3Mzc0NzgzNQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-13T22:50:08Z","updated_at":"2020-08-13T22:50:08Z","author_association":"CONTRIBUTOR","body":"Can you try w/ spark datasource, as you see in quick start utils and let us know if you could reproduce the issue. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673747835/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673855323","html_url":"https://github.com/apache/hudi/pull/1868#issuecomment-673855323","issue_url":"https://api.github.com/repos/apache/hudi/issues/1868","id":673855323,"node_id":"MDEyOklzc3VlQ29tbWVudDY3Mzg1NTMyMw==","user":{"login":"shenh062326","id":9527867,"node_id":"MDQ6VXNlcjk1Mjc4Njc=","avatar_url":"https://avatars.githubusercontent.com/u/9527867?v=4","gravatar_id":"","url":"https://api.github.com/users/shenh062326","html_url":"https://github.com/shenh062326","followers_url":"https://api.github.com/users/shenh062326/followers","following_url":"https://api.github.com/users/shenh062326/following{/other_user}","gists_url":"https://api.github.com/users/shenh062326/gists{/gist_id}","starred_url":"https://api.github.com/users/shenh062326/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shenh062326/subscriptions","organizations_url":"https://api.github.com/users/shenh062326/orgs","repos_url":"https://api.github.com/users/shenh062326/repos","events_url":"https://api.github.com/users/shenh062326/events{/privacy}","received_events_url":"https://api.github.com/users/shenh062326/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-14T02:56:55Z","updated_at":"2020-08-14T02:56:55Z","author_association":"CONTRIBUTOR","body":"@nsivabalan Can you take a look at this PR?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673855323/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673890895","html_url":"https://github.com/apache/hudi/issues/1961#issuecomment-673890895","issue_url":"https://api.github.com/repos/apache/hudi/issues/1961","id":673890895,"node_id":"MDEyOklzc3VlQ29tbWVudDY3Mzg5MDg5NQ==","user":{"login":"saumyasuhagiya","id":2899428,"node_id":"MDQ6VXNlcjI4OTk0Mjg=","avatar_url":"https://avatars.githubusercontent.com/u/2899428?v=4","gravatar_id":"","url":"https://api.github.com/users/saumyasuhagiya","html_url":"https://github.com/saumyasuhagiya","followers_url":"https://api.github.com/users/saumyasuhagiya/followers","following_url":"https://api.github.com/users/saumyasuhagiya/following{/other_user}","gists_url":"https://api.github.com/users/saumyasuhagiya/gists{/gist_id}","starred_url":"https://api.github.com/users/saumyasuhagiya/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/saumyasuhagiya/subscriptions","organizations_url":"https://api.github.com/users/saumyasuhagiya/orgs","repos_url":"https://api.github.com/users/saumyasuhagiya/repos","events_url":"https://api.github.com/users/saumyasuhagiya/events{/privacy}","received_events_url":"https://api.github.com/users/saumyasuhagiya/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-14T05:24:20Z","updated_at":"2020-08-14T05:24:20Z","author_association":"NONE","body":"Not able to join the channel as I don't have any email id with the mentioned domain. Can you help me to get in? @nsivabalan ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673890895/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673892377","html_url":"https://github.com/apache/hudi/issues/1961#issuecomment-673892377","issue_url":"https://api.github.com/repos/apache/hudi/issues/1961","id":673892377,"node_id":"MDEyOklzc3VlQ29tbWVudDY3Mzg5MjM3Nw==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-14T05:29:37Z","updated_at":"2020-08-14T05:29:37Z","author_association":"CONTRIBUTOR","body":"> Not able to join the channel as I don't have any email id with the mentioned domain. Can you help me to get in? @nsivabalan\r\n\r\nhttps://hudi.apache.org/community.html#engage-with-us There are some resources here. Can you please give this a try ? If that doesn't work, please send your email id.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673892377/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673905819","html_url":"https://github.com/apache/hudi/issues/1961#issuecomment-673905819","issue_url":"https://api.github.com/repos/apache/hudi/issues/1961","id":673905819,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzkwNTgxOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-14T06:10:44Z","updated_at":"2020-08-14T06:10:44Z","author_association":"MEMBER","body":"@saumyasuhagiya https://github.com/apache/hudi/blob/master/README.md has the auto signup link. I just opened a PR to update the site to using this, instead","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673905819/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673908103","html_url":"https://github.com/apache/hudi/pull/1963#issuecomment-673908103","issue_url":"https://api.github.com/repos/apache/hudi/issues/1963","id":673908103,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzkwODEwMw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-14T06:17:53Z","updated_at":"2020-08-14T06:17:53Z","author_association":"MEMBER","body":"@n3nash can you please review this. (we can land after the release branch is cut) ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673908103/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673910051","html_url":"https://github.com/apache/hudi/issues/1960#issuecomment-673910051","issue_url":"https://api.github.com/repos/apache/hudi/issues/1960","id":673910051,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MzkxMDA1MQ==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-14T06:24:14Z","updated_at":"2020-08-14T06:24:14Z","author_association":"CONTRIBUTOR","body":"@brandon-stanley Based on your description above, you could try this:\r\n\r\nInstead of skipping the precombine field, you could add the COALESCE(update_date, create_date) as new column before writing to Hudi and pass in that new column as the precombine field. I think you could use withColumn() in Spark to do this. Here duplicates are handled based on the latest value of the precombine field which is the COALESCE() described above. You wouldn't need to worry about Payload class then. \r\n\r\nPlease correct me if I am missing something.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/673910051/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]