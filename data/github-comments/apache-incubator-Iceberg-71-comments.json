[{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757058872","html_url":"https://github.com/apache/iceberg/issues/2043#issuecomment-757058872","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2043","id":757058872,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzA1ODg3Mg==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-09T00:18:36Z","updated_at":"2021-01-09T00:18:36Z","author_association":"CONTRIBUTOR","body":"`DataFiles.fillFromPath` is only available as a convenience for importing Hive data files. It does not parse values from Iceberg paths on purpose because paths should not be parsed in Iceberg. Iceberg metadata contains the actual values that should be used instead of parsing from a String. Converting a partition data tuple to a path component is considered one-way.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757058872/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757072100","html_url":"https://github.com/apache/iceberg/issues/170#issuecomment-757072100","issue_url":"https://api.github.com/repos/apache/iceberg/issues/170","id":757072100,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzA3MjEwMA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-09T01:26:11Z","updated_at":"2021-01-09T01:26:11Z","author_association":"CONTRIBUTOR","body":"I agree, this is mostly done now and this is also not very specific. We should open more specific issues for any other gaps where we intend to add features, like a non-Hive OutputFormat.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757072100/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757072379","html_url":"https://github.com/apache/iceberg/issues/1832#issuecomment-757072379","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1832","id":757072379,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzA3MjM3OQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-09T01:27:51Z","updated_at":"2021-01-09T01:27:51Z","author_association":"CONTRIBUTOR","body":"I think I agree that the two features are separate. We probably won't use the same format for partition-level data and file-level indexes. Sorry I haven't had a chance to take a look at these proposals in detail yet. I should have some time once the MERGE INTO support is about finished, as that's a high priority for the community.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757072379/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757092648","html_url":"https://github.com/apache/iceberg/pull/2052#issuecomment-757092648","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2052","id":757092648,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzA5MjY0OA==","user":{"login":"qphien","id":17759741,"node_id":"MDQ6VXNlcjE3NzU5NzQx","avatar_url":"https://avatars.githubusercontent.com/u/17759741?v=4","gravatar_id":"","url":"https://api.github.com/users/qphien","html_url":"https://github.com/qphien","followers_url":"https://api.github.com/users/qphien/followers","following_url":"https://api.github.com/users/qphien/following{/other_user}","gists_url":"https://api.github.com/users/qphien/gists{/gist_id}","starred_url":"https://api.github.com/users/qphien/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qphien/subscriptions","organizations_url":"https://api.github.com/users/qphien/orgs","repos_url":"https://api.github.com/users/qphien/repos","events_url":"https://api.github.com/users/qphien/events{/privacy}","received_events_url":"https://api.github.com/users/qphien/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-09T04:16:18Z","updated_at":"2021-01-09T04:16:18Z","author_association":"CONTRIBUTOR","body":"I'm not sure whether these failure tests are related to this PR. I tested locally and all test cases were passed.\r\n```\r\norg.apache.iceberg.spark.extensions.TestCopyOnWriteDelete > testDeleteWithSerializableIsolation[catalogName = spark_catalog, implementation = org.apache.iceberg.spark.SparkSessionCatalog, config = {type=hive, default-namespace=default, clients=1, parquet-enabled=false, cache-enabled=false}, format = avro, vectorized = false] FAILED\r\n    java.lang.RuntimeException: Failed to get table info from metastore default.table\r\n\r\n        Caused by:\r\n        org.apache.thrift.transport.TTransportException: java.net.SocketException: Broken pipe (Write failed)\r\n\r\n            Caused by:\r\n            java.net.SocketException: Broken pipe (Write failed)\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757092648/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757136222","html_url":"https://github.com/apache/iceberg/issues/2057#issuecomment-757136222","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2057","id":757136222,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzEzNjIyMg==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-09T11:33:55Z","updated_at":"2021-01-09T11:33:55Z","author_association":"CONTRIBUTOR","body":"I think maybe jar conflict，could you describe your environment  more detail? For example,  the flink cluster is yarn session or standalone? Have you put iceberg-flink-runtime-xxx.jar and flink-sql-connector-hive-xxx.jar on the classpath? Currently the hive version integrated by iceberg is 2.3.6. Can you test whether there is a problem with this version?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757136222/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757393325","html_url":"https://github.com/apache/iceberg/pull/2058#issuecomment-757393325","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2058","id":757393325,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzM5MzMyNQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-10T01:02:54Z","updated_at":"2021-01-10T01:02:54Z","author_association":"CONTRIBUTOR","body":"This came up while working on this issue: https://github.com/apache/iceberg/issues/1952","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757393325/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757567574","html_url":"https://github.com/apache/iceberg/pull/2061#issuecomment-757567574","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2061","id":757567574,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzU2NzU3NA==","user":{"login":"jun-he","id":12246263,"node_id":"MDQ6VXNlcjEyMjQ2MjYz","avatar_url":"https://avatars.githubusercontent.com/u/12246263?v=4","gravatar_id":"","url":"https://api.github.com/users/jun-he","html_url":"https://github.com/jun-he","followers_url":"https://api.github.com/users/jun-he/followers","following_url":"https://api.github.com/users/jun-he/following{/other_user}","gists_url":"https://api.github.com/users/jun-he/gists{/gist_id}","starred_url":"https://api.github.com/users/jun-he/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jun-he/subscriptions","organizations_url":"https://api.github.com/users/jun-he/orgs","repos_url":"https://api.github.com/users/jun-he/repos","events_url":"https://api.github.com/users/jun-he/events{/privacy}","received_events_url":"https://api.github.com/users/jun-he/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T00:03:23Z","updated_at":"2021-01-11T00:03:23Z","author_association":"COLLABORATOR","body":"@rdblue  can you please take a look? Thanks.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757567574/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757573819","html_url":"https://github.com/apache/iceberg/issues/1912#issuecomment-757573819","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1912","id":757573819,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzU3MzgxOQ==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T00:40:19Z","updated_at":"2021-01-11T00:40:19Z","author_association":"CONTRIBUTOR","body":"@borislitvak \r\nI'd suggest closing the issue, as the answer is already provided and no further discussion is expected.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757573819/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757574016","html_url":"https://github.com/apache/iceberg/issues/1931#issuecomment-757574016","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1931","id":757574016,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzU3NDAxNg==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T00:41:31Z","updated_at":"2021-01-11T00:41:31Z","author_association":"CONTRIBUTOR","body":"@cccs-jc \r\nCould you please close the issue explicitly? Thanks in advance!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757574016/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757582135","html_url":"https://github.com/apache/iceberg/issues/2057#issuecomment-757582135","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2057","id":757582135,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzU4MjEzNQ==","user":{"login":"dixingxing0","id":1303530,"node_id":"MDQ6VXNlcjEzMDM1MzA=","avatar_url":"https://avatars.githubusercontent.com/u/1303530?v=4","gravatar_id":"","url":"https://api.github.com/users/dixingxing0","html_url":"https://github.com/dixingxing0","followers_url":"https://api.github.com/users/dixingxing0/followers","following_url":"https://api.github.com/users/dixingxing0/following{/other_user}","gists_url":"https://api.github.com/users/dixingxing0/gists{/gist_id}","starred_url":"https://api.github.com/users/dixingxing0/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dixingxing0/subscriptions","organizations_url":"https://api.github.com/users/dixingxing0/orgs","repos_url":"https://api.github.com/users/dixingxing0/repos","events_url":"https://api.github.com/users/dixingxing0/events{/privacy}","received_events_url":"https://api.github.com/users/dixingxing0/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T01:24:23Z","updated_at":"2021-01-11T01:24:23Z","author_association":"CONTRIBUTOR","body":"Maybe you can check your JDK version, we use HotSpot 1.8.0_202 which works fine.\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757582135/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757657248","html_url":"https://github.com/apache/iceberg/issues/2057#issuecomment-757657248","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2057","id":757657248,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzY1NzI0OA==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T06:43:59Z","updated_at":"2021-01-11T06:43:59Z","author_association":"CONTRIBUTOR","body":"I see: `org/apache/hadoop/hive/metastore/api/NoSuchObjectException` in the logs. Is it possible that the db is not created?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757657248/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757674907","html_url":"https://github.com/apache/iceberg/issues/2063#issuecomment-757674907","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2063","id":757674907,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzY3NDkwNw==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T07:30:47Z","updated_at":"2021-01-11T07:30:47Z","author_association":"CONTRIBUTOR","body":"@deadwind4: If your question is about having a Hive SQL command which could alter an EXTERNAL Hive table which is backed by an Iceberg table then sadly the answer is no. With some further development we can make it possible with the use the Hive 3.1.2 API to update the table properties, but with the current API I do not see a way for schema evolution.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757674907/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757677682","html_url":"https://github.com/apache/iceberg/issues/2063#issuecomment-757677682","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2063","id":757677682,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzY3NzY4Mg==","user":{"login":"a49a","id":12015546,"node_id":"MDQ6VXNlcjEyMDE1NTQ2","avatar_url":"https://avatars.githubusercontent.com/u/12015546?v=4","gravatar_id":"","url":"https://api.github.com/users/a49a","html_url":"https://github.com/a49a","followers_url":"https://api.github.com/users/a49a/followers","following_url":"https://api.github.com/users/a49a/following{/other_user}","gists_url":"https://api.github.com/users/a49a/gists{/gist_id}","starred_url":"https://api.github.com/users/a49a/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/a49a/subscriptions","organizations_url":"https://api.github.com/users/a49a/orgs","repos_url":"https://api.github.com/users/a49a/repos","events_url":"https://api.github.com/users/a49a/events{/privacy}","received_events_url":"https://api.github.com/users/a49a/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T07:37:28Z","updated_at":"2021-01-11T07:37:28Z","author_association":"CONTRIBUTOR","body":"So, it is not supported to add a column to INTERNAL Hive table with hive current API, right?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757677682/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757757783","html_url":"https://github.com/apache/iceberg/issues/2063#issuecomment-757757783","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2063","id":757757783,"node_id":"MDEyOklzc3VlQ29tbWVudDc1Nzc1Nzc4Mw==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T09:02:13Z","updated_at":"2021-01-11T09:02:13Z","author_association":"CONTRIBUTOR","body":"MANAGED and EXTERNAL tables should behave the same way in respect of the ALTER TABLE commands.\r\n\r\nBy my current understanding the current SerDe API does not provide methods to handle ALTER TABLE commands.\r\nThe 3.1.2 version of the API contains this method which is added by [HIVE-19049](https://issues.apache.org/jira/browse/HIVE-19049) in Hive 3.0.0:\r\n```\r\n  /**\r\n   * Called before a table is altered in the metastore\r\n   * during ALTER TABLE.\r\n   *\r\n   * @param table new table definition\r\n   */\r\n  public default void preAlterTable(Table table, EnvironmentContext context) throws MetaException {\r\n    String alterOpType = (context == null || context.getProperties() == null) ?\r\n        null : context.getProperties().get(ALTER_TABLE_OPERATION_TYPE);\r\n    // By default allow only ADDPROPS and DROPPROPS.\r\n    // alterOpType is null in case of stats update.\r\n    if (alterOpType != null && !allowedAlterTypes.contains(alterOpType)){\r\n      throw new MetaException(\r\n          \"ALTER TABLE can not be used for \" + alterOpType + \" to a non-native table \");\r\n    }\r\n  }\r\n```\r\nThis could be implemented to do schema evoulution, but this is not present in Hive 2.3.7.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757757783/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757877001","html_url":"https://github.com/apache/iceberg/issues/2065#issuecomment-757877001","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2065","id":757877001,"node_id":"MDEyOklzc3VlQ29tbWVudDc1Nzg3NzAwMQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T11:02:18Z","updated_at":"2021-01-11T11:05:14Z","author_association":"CONTRIBUTOR","body":"You know I was actually just working on this PR https://github.com/apache/iceberg/pull/2062 where I encountered this and was debating whether or not we should be allowing zero length when it came up during my work (but I didn't want to pack too much into an admittedly large PR already).\r\n\r\nI have a fix stashed away that I can push if you'd like. 👍 ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757877001/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757878033","html_url":"https://github.com/apache/iceberg/issues/2065#issuecomment-757878033","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2065","id":757878033,"node_id":"MDEyOklzc3VlQ29tbWVudDc1Nzg3ODAzMw==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T11:04:12Z","updated_at":"2021-01-11T11:04:12Z","author_association":"CONTRIBUTOR","body":"Though if you'd like to submit a patch, by all means let me know 🙂 . Otherwise, I can take this.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757878033/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757885743","html_url":"https://github.com/apache/iceberg/issues/2043#issuecomment-757885743","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2043","id":757885743,"node_id":"MDEyOklzc3VlQ29tbWVudDc1Nzg4NTc0Mw==","user":{"login":"boroknagyz","id":12861880,"node_id":"MDQ6VXNlcjEyODYxODgw","avatar_url":"https://avatars.githubusercontent.com/u/12861880?v=4","gravatar_id":"","url":"https://api.github.com/users/boroknagyz","html_url":"https://github.com/boroknagyz","followers_url":"https://api.github.com/users/boroknagyz/followers","following_url":"https://api.github.com/users/boroknagyz/following{/other_user}","gists_url":"https://api.github.com/users/boroknagyz/gists{/gist_id}","starred_url":"https://api.github.com/users/boroknagyz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/boroknagyz/subscriptions","organizations_url":"https://api.github.com/users/boroknagyz/orgs","repos_url":"https://api.github.com/users/boroknagyz/repos","events_url":"https://api.github.com/users/boroknagyz/events{/privacy}","received_events_url":"https://api.github.com/users/boroknagyz/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T11:18:30Z","updated_at":"2021-01-11T11:18:30Z","author_association":"CONTRIBUTOR","body":"Thanks for your reply, @rdblue.\r\nIn Impala we also use Builder.withPartitionPath, because we generate the partition path already in our C++ backend, so this was the easiest way to transfer partition data from C++ to Java.\r\n\r\nI see that Iceberg  unit test code also uses withPartitionPath to conveniently create partition data, so for Iceberg this conversion could be useful for unit tests at least.\r\n\r\nWith that said, if you think two-way conversion could be useful for Iceberg, then I'll happily contribute code. If not, that's also OK for me, I can add partition path -> partition data conversion to Impala's code base.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757885743/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757902440","html_url":"https://github.com/apache/iceberg/pull/1793#issuecomment-757902440","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1793","id":757902440,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzkwMjQ0MA==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T11:51:41Z","updated_at":"2021-01-11T11:51:41Z","author_association":"MEMBER","body":"@rdblue ,   After talked with some flink users from Asia. They have strong demand for this feature because it's necessary for building a classic data pipeline : (kafka) -> (flink) -> (iceberg) -> (flink) -> (iceberg) -> ...   .  I think it's good to merge this before iceberg 0.11.0 release,  would you like to take another look when you have time ?  Thanks.  ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757902440/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757912157","html_url":"https://github.com/apache/iceberg/pull/2031#issuecomment-757912157","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2031","id":757912157,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzkxMjE1Nw==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T12:10:35Z","updated_at":"2021-01-11T12:10:35Z","author_association":"MEMBER","body":"Apache flink will load those catalog factory classes whose __required properties__ are matched,  and check whether there's only one matched factory ( If more than one or no factory,  it will throw exception, means we're failing to load catalog). ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757912157/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757922726","html_url":"https://github.com/apache/iceberg/pull/2046#issuecomment-757922726","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2046","id":757922726,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzkyMjcyNg==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T12:32:16Z","updated_at":"2021-01-11T12:32:16Z","author_association":"MEMBER","body":"@pvary I skimmed this PR,  seems I need more background to understand this change. Let me see the previous committed PRs. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757922726/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757924934","html_url":"https://github.com/apache/iceberg/issues/1994#issuecomment-757924934","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1994","id":757924934,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzkyNDkzNA==","user":{"login":"carmhuo","id":9296411,"node_id":"MDQ6VXNlcjkyOTY0MTE=","avatar_url":"https://avatars.githubusercontent.com/u/9296411?v=4","gravatar_id":"","url":"https://api.github.com/users/carmhuo","html_url":"https://github.com/carmhuo","followers_url":"https://api.github.com/users/carmhuo/followers","following_url":"https://api.github.com/users/carmhuo/following{/other_user}","gists_url":"https://api.github.com/users/carmhuo/gists{/gist_id}","starred_url":"https://api.github.com/users/carmhuo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/carmhuo/subscriptions","organizations_url":"https://api.github.com/users/carmhuo/orgs","repos_url":"https://api.github.com/users/carmhuo/repos","events_url":"https://api.github.com/users/carmhuo/events{/privacy}","received_events_url":"https://api.github.com/users/carmhuo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T12:36:55Z","updated_at":"2021-01-11T12:36:55Z","author_association":"CONTRIBUTOR","body":"Sorry for replying so late @pvary .\r\nRunning the liveliness test on every established HMS Client is a solution.  \r\nI will try to implement it and submit a PR.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757924934/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757929023","html_url":"https://github.com/apache/iceberg/pull/2046#issuecomment-757929023","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2046","id":757929023,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzkyOTAyMw==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T12:45:14Z","updated_at":"2021-01-11T12:45:14Z","author_association":"CONTRIBUTOR","body":"> @pvary I skimmed this PR, seems I need more background to understand this change. Let me see the previous committed PRs.\r\n\r\nThanks @openinx for taking the time to check the PR!\r\nFeel free to ask any questions here/or on slack/or in email if you feel it is easier than digging up everything, I would be happy to answer them!\r\n\r\nI would like to give some context - hope this helps:\r\nWith Hive, and maybe even for other execution engines too, the query compilation and the query execution happens on different nodes and we are only sending serialized data between the them. The execution also could happen in a distributed mode and it is unnecessary (and even problematic) for every executor node to look-up the table data from the Catalogs. If during the compilation we read the table data from the Catalog and then serialize, then the executor nodes do not have to have access to the Catalog, and it could be enough for them to have S3 access to read the snapshot data themselves.\r\n\r\nIn nutshell what we are trying to archive here to have a way to Serialize/Deserialize not only BaseTable-s, but every MetadataTable as well.\r\n\r\nThanks,\r\nPeter","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757929023/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757936750","html_url":"https://github.com/apache/iceberg/pull/1825#issuecomment-757936750","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1825","id":757936750,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzkzNjc1MA==","user":{"login":"rymurr","id":2022305,"node_id":"MDQ6VXNlcjIwMjIzMDU=","avatar_url":"https://avatars.githubusercontent.com/u/2022305?v=4","gravatar_id":"","url":"https://api.github.com/users/rymurr","html_url":"https://github.com/rymurr","followers_url":"https://api.github.com/users/rymurr/followers","following_url":"https://api.github.com/users/rymurr/following{/other_user}","gists_url":"https://api.github.com/users/rymurr/gists{/gist_id}","starred_url":"https://api.github.com/users/rymurr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymurr/subscriptions","organizations_url":"https://api.github.com/users/rymurr/orgs","repos_url":"https://api.github.com/users/rymurr/repos","events_url":"https://api.github.com/users/rymurr/events{/privacy}","received_events_url":"https://api.github.com/users/rymurr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T13:01:06Z","updated_at":"2021-01-11T13:01:06Z","author_association":"CONTRIBUTOR","body":"I've just rebased and I think all comments have been addressed. Any chance we can close this one out?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757936750/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757941189","html_url":"https://github.com/apache/iceberg/pull/2054#issuecomment-757941189","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2054","id":757941189,"node_id":"MDEyOklzc3VlQ29tbWVudDc1Nzk0MTE4OQ==","user":{"login":"marton-bod","id":19599214,"node_id":"MDQ6VXNlcjE5NTk5MjE0","avatar_url":"https://avatars.githubusercontent.com/u/19599214?v=4","gravatar_id":"","url":"https://api.github.com/users/marton-bod","html_url":"https://github.com/marton-bod","followers_url":"https://api.github.com/users/marton-bod/followers","following_url":"https://api.github.com/users/marton-bod/following{/other_user}","gists_url":"https://api.github.com/users/marton-bod/gists{/gist_id}","starred_url":"https://api.github.com/users/marton-bod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marton-bod/subscriptions","organizations_url":"https://api.github.com/users/marton-bod/orgs","repos_url":"https://api.github.com/users/marton-bod/repos","events_url":"https://api.github.com/users/marton-bod/events{/privacy}","received_events_url":"https://api.github.com/users/marton-bod/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T13:09:52Z","updated_at":"2021-01-11T13:09:52Z","author_association":"COLLABORATOR","body":"Once done, we should also update the Hive docs with this new property/behaviour.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757941189/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757961378","html_url":"https://github.com/apache/iceberg/issues/1994#issuecomment-757961378","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1994","id":757961378,"node_id":"MDEyOklzc3VlQ29tbWVudDc1Nzk2MTM3OA==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T13:47:01Z","updated_at":"2021-01-11T13:47:01Z","author_association":"CONTRIBUTOR","body":"Thanks @Jecarm!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757961378/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757983330","html_url":"https://github.com/apache/iceberg/pull/2031#issuecomment-757983330","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2031","id":757983330,"node_id":"MDEyOklzc3VlQ29tbWVudDc1Nzk4MzMzMA==","user":{"login":"rymurr","id":2022305,"node_id":"MDQ6VXNlcjIwMjIzMDU=","avatar_url":"https://avatars.githubusercontent.com/u/2022305?v=4","gravatar_id":"","url":"https://api.github.com/users/rymurr","html_url":"https://github.com/rymurr","followers_url":"https://api.github.com/users/rymurr/followers","following_url":"https://api.github.com/users/rymurr/following{/other_user}","gists_url":"https://api.github.com/users/rymurr/gists{/gist_id}","starred_url":"https://api.github.com/users/rymurr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymurr/subscriptions","organizations_url":"https://api.github.com/users/rymurr/orgs","repos_url":"https://api.github.com/users/rymurr/repos","events_url":"https://api.github.com/users/rymurr/events{/privacy}","received_events_url":"https://api.github.com/users/rymurr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T14:23:43Z","updated_at":"2021-01-11T14:23:43Z","author_association":"CONTRIBUTOR","body":"> Apache flink will load those catalog factory classes whose **required properties** are matched, and check whether there's only one matched factory ( If more than one or no factory, it will throw exception, means we're failing to load catalog).\r\n\r\nThanks @openinx just a bit of clarification. What do you mean by **required properties**. Is there a way to set properties in `WITH` clauses to have required/not-required fields? If I can pass non-required fields through to the catalog w/o this PR I would be very happy :-)\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/757983330/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758112474","html_url":"https://github.com/apache/iceberg/pull/2056#issuecomment-758112474","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2056","id":758112474,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODExMjQ3NA==","user":{"login":"CodingCat","id":678008,"node_id":"MDQ6VXNlcjY3ODAwOA==","avatar_url":"https://avatars.githubusercontent.com/u/678008?v=4","gravatar_id":"","url":"https://api.github.com/users/CodingCat","html_url":"https://github.com/CodingCat","followers_url":"https://api.github.com/users/CodingCat/followers","following_url":"https://api.github.com/users/CodingCat/following{/other_user}","gists_url":"https://api.github.com/users/CodingCat/gists{/gist_id}","starred_url":"https://api.github.com/users/CodingCat/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CodingCat/subscriptions","organizations_url":"https://api.github.com/users/CodingCat/orgs","repos_url":"https://api.github.com/users/CodingCat/repos","events_url":"https://api.github.com/users/CodingCat/events{/privacy}","received_events_url":"https://api.github.com/users/CodingCat/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T17:43:46Z","updated_at":"2021-01-11T17:43:46Z","author_association":"CONTRIBUTOR","body":"ping for review? @shangxinli @rdblue ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758112474/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758128397","html_url":"https://github.com/apache/iceberg/pull/1825#issuecomment-758128397","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1825","id":758128397,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODEyODM5Nw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T18:10:49Z","updated_at":"2021-01-11T18:10:49Z","author_association":"CONTRIBUTOR","body":"I'll try to get time to review this in the next few days. I'm wary of adding code that interprets timestamps from user strings, though. I'm just not sure it is a good idea to do this before Spark SQL can support `AS OF TIMESTAMP` or `AS OF VERSION` clauses.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758128397/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758135990","html_url":"https://github.com/apache/iceberg/pull/2056#issuecomment-758135990","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2056","id":758135990,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODEzNTk5MA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T18:23:43Z","updated_at":"2021-01-11T18:23:43Z","author_association":"CONTRIBUTOR","body":"Looks reasonable to me. Thanks, @CodingCat!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758135990/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758138564","html_url":"https://github.com/apache/iceberg/pull/2058#issuecomment-758138564","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2058","id":758138564,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODEzODU2NA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T18:28:29Z","updated_at":"2021-01-11T18:28:29Z","author_association":"CONTRIBUTOR","body":"I appreciate taking the time to keep the code clean, but I generally like to avoid commits that could cause conflicts simply to fix whitespace. It isn't unclear what the comment applies to, so I don't think that we should make this change.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758138564/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758192028","html_url":"https://github.com/apache/iceberg/pull/2048#issuecomment-758192028","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2048","id":758192028,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODE5MjAyOA==","user":{"login":"holdenk","id":59893,"node_id":"MDQ6VXNlcjU5ODkz","avatar_url":"https://avatars.githubusercontent.com/u/59893?v=4","gravatar_id":"","url":"https://api.github.com/users/holdenk","html_url":"https://github.com/holdenk","followers_url":"https://api.github.com/users/holdenk/followers","following_url":"https://api.github.com/users/holdenk/following{/other_user}","gists_url":"https://api.github.com/users/holdenk/gists{/gist_id}","starred_url":"https://api.github.com/users/holdenk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/holdenk/subscriptions","organizations_url":"https://api.github.com/users/holdenk/orgs","repos_url":"https://api.github.com/users/holdenk/repos","events_url":"https://api.github.com/users/holdenk/events{/privacy}","received_events_url":"https://api.github.com/users/holdenk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T20:06:07Z","updated_at":"2021-01-11T20:06:07Z","author_association":"CONTRIBUTOR","body":"I think I've addressed the comments, although it's possible the hooks I've chosen are not the best places but it seems to cover the right areas with the tests. Let me know if there is a better place to put the hooks for validation.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758192028/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758203253","html_url":"https://github.com/apache/iceberg/pull/1793#issuecomment-758203253","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1793","id":758203253,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODIwMzI1Mw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T20:27:34Z","updated_at":"2021-01-11T20:27:34Z","author_association":"CONTRIBUTOR","body":"@openinx, I will take a look. Sorry I didn't get a chance to finish the review I started a few days ago. I agree that this is important to get in and will make some time for it this week.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758203253/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758208367","html_url":"https://github.com/apache/iceberg/pull/2067#issuecomment-758208367","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2067","id":758208367,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODIwODM2Nw==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T20:37:40Z","updated_at":"2021-01-11T20:37:40Z","author_association":"MEMBER","body":"@aokolnychyi + @rdblue  Some docs for stored procedures","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758208367/reactions","total_count":2,"+1":0,"-1":0,"laugh":0,"hooray":2,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758276738","html_url":"https://github.com/apache/iceberg/issues/2065#issuecomment-758276738","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2065","id":758276738,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODI3NjczOA==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T22:56:22Z","updated_at":"2021-01-11T22:58:24Z","author_association":"CONTRIBUTOR","body":"@changquanyou Is it possible that you could share the individual row where this occurred, as well as the table's partition spec?\r\n\r\nAs I mentioned, I have a patch for it, but I'd like to be sure that I understand the situation under which it occurred.\r\n\r\nFor example, I imagine we want to be sure that we aren't allowing people to create partition specs for columns as `truncate[0]` (which I'd have to check to see if that's even possible). But it seems like an individual row with an empty string is what caused this... I'm guessing either pubDayStr or title, where maybe non-parseable values / values of the incorrect type in in the raw data are possibly being stored in an empty string partition.\r\n\r\nOr I should say, where the bounds store an empty string in the metrics.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758276738/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758281167","html_url":"https://github.com/apache/iceberg/issues/2043#issuecomment-758281167","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2043","id":758281167,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODI4MTE2Nw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-11T23:07:34Z","updated_at":"2021-01-11T23:07:34Z","author_association":"CONTRIBUTOR","body":"Conversion to and from string for partition data has caused a lot of bugs in Hive and other projects that use Hive tables. I do not think that it is a good idea to do it in general. Avoiding those bugs is the reason why Iceberg always keeps track of the partition values as a struct or row and serializes it as data. I think it is a bad idea to add this to the Iceberg library because it would encourage a bad practice.\r\n\r\nIf you need to do that for Impala in the short term, then let's keep the implementation there; hopefully with a note to fix it later.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758281167/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758318980","html_url":"https://github.com/apache/iceberg/pull/2056#issuecomment-758318980","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2056","id":758318980,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODMxODk4MA==","user":{"login":"shangxinli","id":31421745,"node_id":"MDQ6VXNlcjMxNDIxNzQ1","avatar_url":"https://avatars.githubusercontent.com/u/31421745?v=4","gravatar_id":"","url":"https://api.github.com/users/shangxinli","html_url":"https://github.com/shangxinli","followers_url":"https://api.github.com/users/shangxinli/followers","following_url":"https://api.github.com/users/shangxinli/following{/other_user}","gists_url":"https://api.github.com/users/shangxinli/gists{/gist_id}","starred_url":"https://api.github.com/users/shangxinli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shangxinli/subscriptions","organizations_url":"https://api.github.com/users/shangxinli/orgs","repos_url":"https://api.github.com/users/shangxinli/repos","events_url":"https://api.github.com/users/shangxinli/events{/privacy}","received_events_url":"https://api.github.com/users/shangxinli/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T00:48:27Z","updated_at":"2021-01-12T00:48:27Z","author_association":"CONTRIBUTOR","body":"LGTM","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758318980/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758373894","html_url":"https://github.com/apache/iceberg/issues/2065#issuecomment-758373894","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2065","id":758373894,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODM3Mzg5NA==","user":{"login":"changquanyou","id":9205633,"node_id":"MDQ6VXNlcjkyMDU2MzM=","avatar_url":"https://avatars.githubusercontent.com/u/9205633?v=4","gravatar_id":"","url":"https://api.github.com/users/changquanyou","html_url":"https://github.com/changquanyou","followers_url":"https://api.github.com/users/changquanyou/followers","following_url":"https://api.github.com/users/changquanyou/following{/other_user}","gists_url":"https://api.github.com/users/changquanyou/gists{/gist_id}","starred_url":"https://api.github.com/users/changquanyou/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/changquanyou/subscriptions","organizations_url":"https://api.github.com/users/changquanyou/orgs","repos_url":"https://api.github.com/users/changquanyou/repos","events_url":"https://api.github.com/users/changquanyou/events{/privacy}","received_events_url":"https://api.github.com/users/changquanyou/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T03:37:58Z","updated_at":"2021-01-12T03:40:39Z","author_association":"NONE","body":"@kbendick  thanks for your reply, I will explain in detail：\r\n\r\n- Table Schema:\r\n  `CREATE TABLE mf_data (\r\n    urlHash STRING,\r\n    titleSimHash STRING,\r\n    docId STRING,\r\n    title STRING,\r\n    content STRING,\r\n    pubTime LONG,\r\n    pubDayStr STRING\r\n    ) using iceberg PARTITIONED BY (pubDayStr);` \r\n   The Service assurance that  **partition key**  is not empty. the title may be empty. \r\n- Data Source：\r\n  Consume from Kafka Topic, And sink to IceBerg Table. At once, the data is normal。  \r\n- Experiments:\r\n 1. use like query on the  **title** field\r\n     `select title from mf_data where pubDayStr = '2021-01-09' and title like '喜讯%'  limit 1;`\r\n      **java.lang.IllegalArgumentException**: Truncate length should be positive occurred\r\n 2. use like query on the **content** field:\r\n     `select title from mf_data where pubDayStr = '2021-01-09' and content like '喜讯%'  limit 1;`\r\n       The result is normal, None Exception occurred\r\n 3.  use Spark SQL client insert:\r\n      `insert into mf_data values('7a1ab0138b535572ff346801c8b61ec0','778ec08c0e9930a64fa3ea03de1334aa','bfd_c68722c6-2224-41f8-82bd-675f0b81f0cd','房东整租霍营小区二层两居室','房东整租霍营小区二层两居室',1607912994000,'2020-12-14');`\r\n`select title from mf_data where pubDayStr = '2020-12-14' and content like '房东%'  limit 1;`\r\nThe above result is normal, of course  I Insert another data（**the title is empty**） :\r\n  `insert into mf_data values('testb0138b535572ff346801c8b61ec0','test08c0e9930a64fa3ea03de1334aa','bfd_c68722c6-2224-41f8-82bd-675f0b81test1','','Test房东整租霍营小区二层两居室',1607912994001,'2020-12-14');` \r\n Use The Same Spark Sql Query, **Truncate length should be positive**  is occurred.\r\n- TODO:\r\n   Due to the huge table, It‘s not easy to confirm the empty title exists. then I will append the title length flag to the table.\r\n\r\nFrom the Experiment Result, if the field size is zero, It does happen  IllegalArgumentException. I hope that will help you.\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758373894/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758417138","html_url":"https://github.com/apache/iceberg/issues/2071#issuecomment-758417138","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2071","id":758417138,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODQxNzEzOA==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T05:40:41Z","updated_at":"2021-01-12T05:40:41Z","author_association":"CONTRIBUTOR","body":"Little bit afraid that I am stating the obvious, but seems like a problem with the parquet library version to me. What version or versions of parquet is on your classparh?\r\n\r\nThanks, Peter ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758417138/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758438596","html_url":"https://github.com/apache/iceberg/issues/2057#issuecomment-758438596","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2057","id":758438596,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODQzODU5Ng==","user":{"login":"zhengqiangtan","id":12029814,"node_id":"MDQ6VXNlcjEyMDI5ODE0","avatar_url":"https://avatars.githubusercontent.com/u/12029814?v=4","gravatar_id":"","url":"https://api.github.com/users/zhengqiangtan","html_url":"https://github.com/zhengqiangtan","followers_url":"https://api.github.com/users/zhengqiangtan/followers","following_url":"https://api.github.com/users/zhengqiangtan/following{/other_user}","gists_url":"https://api.github.com/users/zhengqiangtan/gists{/gist_id}","starred_url":"https://api.github.com/users/zhengqiangtan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhengqiangtan/subscriptions","organizations_url":"https://api.github.com/users/zhengqiangtan/orgs","repos_url":"https://api.github.com/users/zhengqiangtan/repos","events_url":"https://api.github.com/users/zhengqiangtan/events{/privacy}","received_events_url":"https://api.github.com/users/zhengqiangtan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T06:32:47Z","updated_at":"2021-01-12T06:32:47Z","author_association":"NONE","body":"> I think maybe jar conflict，could you describe your environment more detail? For example, the flink cluster is yarn session or standalone? Have you put iceberg-flink-runtime-xxx.jar and flink-sql-connector-hive-xxx.jar on the classpath? Currently the hive version integrated by iceberg is 2.3.6. Can you test whether there is a problem with this version?\r\n\r\nthanks a lot, there is have two jars（iceberg-flink-runtime-0.10.0.jar，iceberg-hive-0.9.1.jar） in the flink lib directory，when i move  the iceberg-hive-0.9.1.jar  out and run `bin/sql-client.sh embedded shell` that is ok for me , hive catalog can be created success as follow :\r\n```shell\r\nFlink SQL> CREATE CATALOG hive_catalog WITH (\r\n>   'type'='iceberg',\r\n>   'catalog-type'='hive',\r\n>   'uri'='thrift://zmbd-uat03:9083',\r\n>   'clients'='3',\r\n>   'property-version'='1',\r\n>   'warehouse'='hdfs://nameservice1/user/hive/warehouse'\r\n> );\r\n2021-01-12 14:26:56,009 WARN  org.apache.hadoop.hive.conf.HiveConf                         [] - HiveConf of name hive.vectorized.use.checked.expressions does not exist\r\n2021-01-12 14:26:56,009 WARN  org.apache.hadoop.hive.conf.HiveConf                         [] - HiveConf of name hive.strict.checks.no.partition.filter does not exist\r\n2021-01-12 14:26:56,010 WARN  org.apache.hadoop.hive.conf.HiveConf                         [] - HiveConf of name hive.strict.checks.orderby.no.limit does not exist\r\n2021-01-12 14:26:56,010 WARN  org.apache.hadoop.hive.conf.HiveConf                         [] - HiveConf of name hive.vectorized.input.format.excludes does not exist\r\n2021-01-12 14:26:56,010 WARN  org.apache.hadoop.hive.conf.HiveConf                         [] - HiveConf of name hive.strict.checks.bucketing does not exist\r\n[INFO] Catalog has been created.\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758438596/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758439653","html_url":"https://github.com/apache/iceberg/issues/2057#issuecomment-758439653","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2057","id":758439653,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODQzOTY1Mw==","user":{"login":"zhengqiangtan","id":12029814,"node_id":"MDQ6VXNlcjEyMDI5ODE0","avatar_url":"https://avatars.githubusercontent.com/u/12029814?v=4","gravatar_id":"","url":"https://api.github.com/users/zhengqiangtan","html_url":"https://github.com/zhengqiangtan","followers_url":"https://api.github.com/users/zhengqiangtan/followers","following_url":"https://api.github.com/users/zhengqiangtan/following{/other_user}","gists_url":"https://api.github.com/users/zhengqiangtan/gists{/gist_id}","starred_url":"https://api.github.com/users/zhengqiangtan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhengqiangtan/subscriptions","organizations_url":"https://api.github.com/users/zhengqiangtan/orgs","repos_url":"https://api.github.com/users/zhengqiangtan/repos","events_url":"https://api.github.com/users/zhengqiangtan/events{/privacy}","received_events_url":"https://api.github.com/users/zhengqiangtan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T06:35:13Z","updated_at":"2021-01-12T06:35:13Z","author_association":"NONE","body":"> Maybe you can check your JDK version, we use HotSpot 1.8.0_202 which works fine.\r\n\r\nthanks~，The reason is JAR conflict, as described above","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758439653/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758457506","html_url":"https://github.com/apache/iceberg/issues/2065#issuecomment-758457506","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2065","id":758457506,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODQ1NzUwNg==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T07:14:28Z","updated_at":"2021-01-12T07:14:28Z","author_association":"CONTRIBUTOR","body":"Oh thank you so much. This is wonderful information. And I completely understand that the table could be too large to determine any single row that would cause this issue.\r\n\r\nI've discussed with @RussellSpitzer on this and I'm not going to include this in my current open PR that I mentioned where I first encountered this issue, as that PR is already large enough and I don't want to block it from getting merged. But I will take a look. I believe that I have a relatively simple fix for this and I will use these characters you've provided as test cases if you don't mind. I don't speak any languages that don't use the normal latin alphabet, with the exception of characters found in Romance languages like like ñ, œ, ü, ç, etc so it's helpful to have sample data like this. To me, it's important to have more test cases with much more extended code points from utf-8 and non-ascii letters.\r\n\r\nHowever, I think that your issue can be solved relatively easily and likely does not relate to the non-ascii characters. But I'll take a look at the non-ascii characters to verify as well, while prioritizing your issue first given that it's affecting what appears to be production queries.\r\n\r\nI'll work on this and should have something ready in the next few days. Luckily, I'm off this week so I've got time. Thanks again for the report!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758457506/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758486900","html_url":"https://github.com/apache/iceberg/issues/2071#issuecomment-758486900","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2071","id":758486900,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODQ4NjkwMA==","user":{"login":"a49a","id":12015546,"node_id":"MDQ6VXNlcjEyMDE1NTQ2","avatar_url":"https://avatars.githubusercontent.com/u/12015546?v=4","gravatar_id":"","url":"https://api.github.com/users/a49a","html_url":"https://github.com/a49a","followers_url":"https://api.github.com/users/a49a/followers","following_url":"https://api.github.com/users/a49a/following{/other_user}","gists_url":"https://api.github.com/users/a49a/gists{/gist_id}","starred_url":"https://api.github.com/users/a49a/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/a49a/subscriptions","organizations_url":"https://api.github.com/users/a49a/orgs","repos_url":"https://api.github.com/users/a49a/repos","events_url":"https://api.github.com/users/a49a/events{/privacy}","received_events_url":"https://api.github.com/users/a49a/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T08:15:44Z","updated_at":"2021-01-12T08:15:44Z","author_association":"CONTRIBUTOR","body":"![image](https://user-images.githubusercontent.com/12015546/104287423-64cdea00-54f1-11eb-85bc-88237abe9dae.png)\r\nmy parquet version","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758486900/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758491736","html_url":"https://github.com/apache/iceberg/issues/2071#issuecomment-758491736","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2071","id":758491736,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODQ5MTczNg==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T08:24:46Z","updated_at":"2021-01-12T08:24:46Z","author_association":"CONTRIBUTOR","body":"I think maybe version conflict","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758491736/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758499304","html_url":"https://github.com/apache/iceberg/issues/2071#issuecomment-758499304","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2071","id":758499304,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODQ5OTMwNA==","user":{"login":"a49a","id":12015546,"node_id":"MDQ6VXNlcjEyMDE1NTQ2","avatar_url":"https://avatars.githubusercontent.com/u/12015546?v=4","gravatar_id":"","url":"https://api.github.com/users/a49a","html_url":"https://github.com/a49a","followers_url":"https://api.github.com/users/a49a/followers","following_url":"https://api.github.com/users/a49a/following{/other_user}","gists_url":"https://api.github.com/users/a49a/gists{/gist_id}","starred_url":"https://api.github.com/users/a49a/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/a49a/subscriptions","organizations_url":"https://api.github.com/users/a49a/orgs","repos_url":"https://api.github.com/users/a49a/repos","events_url":"https://api.github.com/users/a49a/events{/privacy}","received_events_url":"https://api.github.com/users/a49a/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T08:39:40Z","updated_at":"2021-01-12T08:39:40Z","author_association":"CONTRIBUTOR","body":"I resolved this problem. This reason is the conflict between iceberg-parquet and flink-sql-connector-hive-${hive.version}_${scala.version}.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758499304/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758538209","html_url":"https://github.com/apache/iceberg/issues/2033#issuecomment-758538209","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2033","id":758538209,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODUzODIwOQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T09:48:11Z","updated_at":"2021-01-12T09:48:11Z","author_association":"CONTRIBUTOR","body":"I have been thinking about this, and I have some questions related to the bucket being used for versioning.\r\n\r\nIt's not an uncommon situation to have a versioned s3 bucket which does not have a policy which removes expired object deletion markers or a policy to expire non-current versions. By default, versioned buckets do not hav this. In such a situation, it's not uncommon to either have a very large number of object deletion markers or to have a single key with a very high number of versions (sometimes in the millions), which can greatly affect your S3 throughput.\r\n\r\nI have personally encountered this issue when using a versioned bucket with Flink (without using iceberg) for storing checkpoint and savepoint data for jobs. For Flink, it's typical for the job manager to delete checkpoints depending on how many are configured to be saved. With regular checkpointing, it's very easy to then get a very large number of object deletion markers that are never expired. Additionally, it's not uncommon to setup a Flink job to checkpoint to a bucket where much of the data has a very similar prefix for the key (and therefore likely winds up in the same physical partition). For example, when using a per job cluster, where the job ids are always 0000000000000000, it's easy to have your checkpoint data and savepoint data wind up with a long, consistent prefix in the key name (Flink provides a configuration to add randomness wherever desired in the checkpoint path).\r\n\r\nAdditionally, I know that for RocksDB state backend in Flink there is a `/shared` directory when using incremental checkpointing that I have observed grow pretty much indefinitely. We have special logic in place to remove this folder when a valid savepoint is taken (amongst other criteria) at my work.\r\n\r\n**TLDR**: For a versioned S3 buckets, particularly for `PUT` and `DELETE` requests, the likelihood of getting a 503-slow down response increases quite a lot, due to the problem of so many object versions / a very large number of retained object deletion markers, and per partition throughput limitations. **When using Apache Flink, without having a policy in place to aggressively remove expired object versions and object deletion markers, it's not uncommon in my experience to run into 503-slow down issues in my personal experience.**\r\n\r\n**What you can do to debug this issue**: First and foremost, if you have access to the console (or if you're the one managing the bucket), I'd be sure that when enabling versioning that the required lifecycle policies are in place. That would be expiring noncurrent versions, removing object deletion markers, and removing stale / failed parts of multipart uploads (more on that below). Some things you can do to debug your current bucket, without having to create additional buckets just for testing etc, is to enable logs for your S3 bucket. You can enable basic server access logs, which do not have added cost beyond the writes to the S3 bucket according to the instructions here: https://docs.aws.amazon.com/AmazonS3/latest/user-guide/server-access-logging.html. Additionally, you can enable lifecycle logging and checking for the relevant lifecycle logs in cloudtrail to see what's happening with versions in your bucket: https://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-and-other-bucket-config.html\r\n\r\nYou can read some about it at the bottom of this page https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html. I've written the relevant part here. It does not mention it, but not having a bucket policy in place to remove expired object deletion markers will also cause this issue (I believe that the underlying issue is that it affects HEAD requests, which are needed for both PUT and DELETE on versioned buckets).\r\n\r\n```\r\nIf you notice a significant increase in the number of HTTP 503-slow down responses received for Amazon S3 PUT or DELETE object requests to a bucket that has S3 Versioning enabled, you might have one or more objects in the bucket for which there are millions of versions. For more information, see Troubleshooting Amazon S3.\r\n```\r\n\r\nI would also be interested if you have any error logs @elkhand, as Iceberg retries requests but will eventually error out. So error logs would be helpful.\r\n\r\nHave you tested this using a fresh bucket, with no preexisting object keys? And did any transactions ever complete once versioning was enabled, or did it only happen after some time? Additionally, have you observed this issue with a bucket that started its life as a versioned bucket (or at the least, did not have any non-versioned keys in it). I've also encountered instances where version policies are placed on buckets after the fact, and a large number of objects remain in the bucket indefinitely because I've forgotten to remove them.\r\n\r\nSome things you can do to test this out, without having to create additional buckets just for testing etc, is to enable logs for your S3 bucket. You can enable basic server access logs, which do not have added cost beyond the writes to the S3 bucket according to the instructions here: https://docs.aws.amazon.com/AmazonS3/latest/user-guide/server-access-logging.html. Additionally, you can enable lifecycle logging and checking for the relevant lifecycle logs in cloudtrail to see what's happening with versions in your bucket: https://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-and-other-bucket-config.html\r\n\r\nLastly, and perhaps _most importantly_, here is the documentation on lifecycle rules. I personally have experienced issues when using writing Flink savepoints and checkpoints to S3 buckets that were versioned, mostly because of the high frequency with which Flink can create and delete objects and then not having the proper lifecycle rules to handle expiring old versions, removing object deletion markers, as well as removing failed inflight multipart uploads (parts of a multipart upload that has never successfully completed - while there's not exactly a definitive way for the bucket to know fi the upload has failed or not, it's common to simply decide on a large enough time frame to then remove parts of a multipart upload if the upload does not complete - I typically use 24 hours or even 7 days - the most important thing is just having the policy in place, which AWS does not add by default). https://docs.aws.amazon.com/AmazonS3/latest/dev/intro-lifecycle-rules.html\r\n\r\nIf one does not explicitly add these policies to the bucket, these objects and their metadata will remain forever and severely impact S3 performance on versioned buckets. Additionally, there is cost associated with storing all of this useless (or potentially useless data, such as very old object versions) as AWS still bills you for them. So it's extra important to ensure that these are all in place.\r\n\r\nWithout error logs, I'm not sure I can be of much more help. But I've been thinking about this issue recently and thought I'd add my personal experience with using versioned S3 buckets with Flink. I have been able to use Flink to read and write checkpoint data as well as data files to versioned S3 buckets, so I don't personally think that alone is the issue. However, I have experienced a lot of headaches when writing to versioned buckets without having aggressive policies in place to remove files with S3 lifecycle policies, as well as having a separate process in place for removing files from the `/shared` directory for rocksdb incremental checkpoints stored on S3. Having a large number of objects (which include different object versions as well as object deletion markers) is relatively easy to do with Flink without a good lifecycle policy in place.\r\n\r\nLastly, it might also be important to note that if you've enabled versioning on a bucket, it can never technically be reverted to a non-versioned bucket. When turning off versioning on a versioned S3 bucket, it technically becomes a version-suspended S3 bucket. This means that your old files, including object deletion markers and non-current object versions, still exist and that only going forward will the changes take place. So if you've enabled versioning for some time and then turned it off, it's important to ensure that any unneeded non-current object versions / deleted object markers are removed.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758538209/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758545399","html_url":"https://github.com/apache/iceberg/issues/2033#issuecomment-758545399","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2033","id":758545399,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODU0NTM5OQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T10:00:53Z","updated_at":"2021-01-12T10:02:06Z","author_association":"CONTRIBUTOR","body":"Sorry for the large wall of text, but I've personally dealt with some weird issues on versioned S3 buckets (particularly when using Flink), and I thought I'd share what information I have. I try not to use them if possible due to performance issues, but with strong bucket policies in place they're manageable.\r\n\r\n@openinx As you've assigned this issue to yourself, and since I've written a small essay already in this issue, feel free to reach out on the ASF slack and I'd be happy to help in any way that I can (though I imagine you know more about S3 buckets than I do, but perhaps you're more accustomed to traditional HDFS). I'm not sure what investigation can be done, beyond testing writing to an empty versioned bucket, without error logs. As @elkhand mentioned that the issue occurred after enabling versioning on an existing bucket, it's quite possible that there are a large number of writers / many small files and that 503-slow down exceptions accrued before the transaction could be completed, especially if there are other jobs writing to this same bucket (like with a smaller checkpoint time or a shorter interval between Iceberg commits). As I mentioned, I've personally encountered this situation when I first started using Flink on S3 as the number of jobs, with varying checkpoint intervals, writing to the same bucket increased. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758545399/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758550459","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758550459","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758550459,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODU1MDQ1OQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T10:09:01Z","updated_at":"2021-01-12T10:09:01Z","author_association":"CONTRIBUTOR","body":"This sounds particularly important to users on S3, especially users with older data that do not necessarily want to commit to migrating all of their older files (and having to copy them, which can get quite expensive). And given that there are no renames without copying on S3, many users are hesitant to move large parts of their data lake around.\r\n\r\nI think this could help drive adoption of Iceberg for users with current Hive warehouses on S3.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758550459/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758583064","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758583064","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758583064,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODU4MzA2NA==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T11:06:46Z","updated_at":"2021-01-12T11:07:37Z","author_association":"CONTRIBUTOR","body":"I think it is particularly interesting with CREATE TABLE LIKE or similar commands. It is kind of close to IMPORT of Hive partitions. We can follow that and support appending or overriding all files in a path. If we want, we can make this procedure to accept a single file too (but I don't think it is a common use case).\r\n\r\n@RussellSpitzer, could you suggest how this procedure should look like? What input and output params will it have?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758583064/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758602457","html_url":"https://github.com/apache/iceberg/issues/2015#issuecomment-758602457","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2015","id":758602457,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODYwMjQ1Nw==","user":{"login":"dixingxing0","id":1303530,"node_id":"MDQ6VXNlcjEzMDM1MzA=","avatar_url":"https://avatars.githubusercontent.com/u/1303530?v=4","gravatar_id":"","url":"https://api.github.com/users/dixingxing0","html_url":"https://github.com/dixingxing0","followers_url":"https://api.github.com/users/dixingxing0/followers","following_url":"https://api.github.com/users/dixingxing0/following{/other_user}","gists_url":"https://api.github.com/users/dixingxing0/gists{/gist_id}","starred_url":"https://api.github.com/users/dixingxing0/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dixingxing0/subscriptions","organizations_url":"https://api.github.com/users/dixingxing0/orgs","repos_url":"https://api.github.com/users/dixingxing0/repos","events_url":"https://api.github.com/users/dixingxing0/events{/privacy}","received_events_url":"https://api.github.com/users/dixingxing0/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T11:44:10Z","updated_at":"2021-01-12T11:44:10Z","author_association":"CONTRIBUTOR","body":"It looks like same as this:\r\nhttps://github.com/apache/iceberg/issues/2057","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758602457/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758640122","html_url":"https://github.com/apache/iceberg/pull/2077#issuecomment-758640122","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2077","id":758640122,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODY0MDEyMg==","user":{"login":"lcspinter","id":47777102,"node_id":"MDQ6VXNlcjQ3Nzc3MTAy","avatar_url":"https://avatars.githubusercontent.com/u/47777102?v=4","gravatar_id":"","url":"https://api.github.com/users/lcspinter","html_url":"https://github.com/lcspinter","followers_url":"https://api.github.com/users/lcspinter/followers","following_url":"https://api.github.com/users/lcspinter/following{/other_user}","gists_url":"https://api.github.com/users/lcspinter/gists{/gist_id}","starred_url":"https://api.github.com/users/lcspinter/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lcspinter/subscriptions","organizations_url":"https://api.github.com/users/lcspinter/orgs","repos_url":"https://api.github.com/users/lcspinter/repos","events_url":"https://api.github.com/users/lcspinter/events{/privacy}","received_events_url":"https://api.github.com/users/lcspinter/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T13:00:43Z","updated_at":"2021-01-12T13:00:43Z","author_association":"CONTRIBUTOR","body":"@pvary @marton-bod If you have some spare time, could you please have a look at this PR? Thanks","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758640122/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758704781","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758704781","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758704781,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODcwNDc4MQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T14:47:24Z","updated_at":"2021-01-12T15:58:38Z","author_association":"MEMBER","body":"I was thinking something like\r\n\r\n**add_files**.(**table** => \"db.sample\", **directory** => \"/some/dir/files/\", **format** => \"parquet\")\r\n\r\n**Table** = \"The iceberg table we are adding files to\"\r\n**Directory** = \"The source directory where the files are located\"\r\n**Format** = \"The reader used with these files (parquet, orc, avro ...)\r\n\r\nI believe the output should be something like\r\n\r\n| Partition | Files Added |\r\n| --------------  | ------------|\r\n| \"Foo\", \"1\"          | 5                 |\r\n| \"Foo\", \"2\"         |  6               |\r\n\r\nThis command would basically go through all of the files under the provided directory, and add them all directly to the table. The files would not be read of scanned so it would be up to the user to only add files with correct columns or to adjust the table column mapping to match. \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758704781/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758714296","html_url":"https://github.com/apache/iceberg/pull/2048#issuecomment-758714296","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2048","id":758714296,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODcxNDI5Ng==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T15:02:23Z","updated_at":"2021-01-12T15:03:24Z","author_association":"CONTRIBUTOR","body":"@rdblue @shardulm94 @RussellSpitzer, not related to this PR but a general question: the metrics config relies on column names instead of column ids as it is controlled through table properties. I was wondering whether it is safe to do so.\r\n\r\nI considered the following cases:\r\n- While writing new data, it should be always OK to follow the name-based approach if the config is up-to-date.\r\n- While importing data (assuming we have a correct name mapping), we will assign correct ids to columns, use the ids to find the current aliases in the schema, so this should work.\r\n- When fixing (re-importing) metadata (assuming we have renamed a column with a reliable id), we will just use the column id in the file to find the current name, so this should work.\r\n\r\nOverall, it seems safe to me. Any cases I missed?\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758714296/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758734891","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758734891","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758734891,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODczNDg5MQ==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T15:30:16Z","updated_at":"2021-01-12T15:30:16Z","author_association":"CONTRIBUTOR","body":"I agree with most of your points, @RussellSpitzer.\r\n\r\nI'd probably consider naming it `import_files` or `import_data` or `load_data` and add a flag whether it should overwrite the existing data or not.\r\n\r\n```\r\ncat.system.import_data(table => 'db.tbl', path => 'path/to/dir or file', format => 'orc', overwrite => true) \r\n```\r\n\r\nThen `path` can be either a root table location, a partition path or a path to an individual file (if we want to support that).","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758734891/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758737314","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758737314","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758737314,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODczNzMxNA==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T15:32:32Z","updated_at":"2021-01-12T15:32:32Z","author_association":"CONTRIBUTOR","body":"Thoughts on this one, @kbendick @rdblue @raptond @RussellSpitzer @holdenk @rymurr @shardulm94?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758737314/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758738846","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758738846","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758738846,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODczODg0Ng==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T15:34:53Z","updated_at":"2021-01-12T15:34:53Z","author_association":"CONTRIBUTOR","body":"I'd be also curious to hear thoughts from people who work on other query engines as well.\r\n\r\ncc @openinx @Parth-Brahmbhatt @electrum @jackye1995 ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758738846/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758740890","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758740890","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758740890,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODc0MDg5MA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T15:37:48Z","updated_at":"2021-01-12T15:37:48Z","author_association":"MEMBER","body":"> I agree with most of your points, @RussellSpitzer.\r\n> \r\n> I'd probably consider naming it `import_files` or `import_data` or `load_data` and add a flag whether it should overwrite the existing data or not.\r\n> \r\n> ```\r\n> cat.system.import_data(table => 'db.tbl', path => 'path/to/dir or file', format => 'orc', overwrite => true) \r\n> ```\r\n> \r\n> Then `path` can be either a root table location, a partition path or a path to an individual file (if we want to support that).\r\n\r\nI was wondering around overwrite, I feel like it would be safer to do that in two user operations rather than having this operation delete information. Since a user may not know which partitions will be touched in a given import","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758740890/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758743089","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758743089","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758743089,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODc0MzA4OQ==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T15:40:56Z","updated_at":"2021-01-12T15:40:56Z","author_association":"CONTRIBUTOR","body":"> I was wondering around overwrite, I feel like it would be safer to do that in two user operations rather than having this operation delete information. Since a user may not know which partitions will be touched in a given import\r\n\r\nI can go either way. I was coming more from `LOAD DATA INPATH ... INTO TABLE t` perspective that is supported by Spark for Hive tables.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758743089/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758826705","html_url":"https://github.com/apache/iceberg/pull/2031#issuecomment-758826705","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2031","id":758826705,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODgyNjcwNQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T17:45:38Z","updated_at":"2021-01-12T17:45:38Z","author_association":"CONTRIBUTOR","body":"The problem with using a prefix like `custom-catalog` is that it makes the configuration differ between engines. For Flink, you would need to use `custom-catalog.property`, and for others you'd use just `property`. That will confuse users that use the wrong property for an engine and expect it to work.\r\n\r\nI think that we should allow all properties if we don't think that we can enumerate the set of catalog properties that we need.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758826705/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758829503","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758829503","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758829503,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODgyOTUwMw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T17:50:27Z","updated_at":"2021-01-12T17:50:27Z","author_association":"CONTRIBUTOR","body":"I like the idea of importing data files using a stored procedure. We would need to be careful about partition specs because we do not parse values from path strings in most cases. We do it for importing from Hive tables, but we should not allow it for importing from another Iceberg table.\r\n\r\nI'm also not sure what `overwrite` would do. Dynamic partition overwrite?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758829503/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758850624","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758850624","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758850624,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODg1MDYyNA==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T18:27:05Z","updated_at":"2021-01-12T18:28:46Z","author_association":"CONTRIBUTOR","body":"> I'm also not sure what overwrite would do. Dynamic partition overwrite?\r\n\r\nYeah, the use case for this may be as follows: the user imports a partition and then more files are added to that partition through a non-Iceberg path. So he/she may want to reimport the partition overriding the current set of files in that partition. \r\n\r\nIt may be used for snapshot tables or tables to which files are promoted after they are written. For example, we have a customer who writes Parquet files using Java and at some point registers them as a partition.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758850624/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758851376","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758851376","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758851376,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODg1MTM3Ng==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T18:28:30Z","updated_at":"2021-01-12T18:28:30Z","author_association":"MEMBER","body":"IMHO, I think you should do an explicit delete or drop partition if you want that to happen but I don't have strong feelings about that. I'm not a big fan of the INSERT OVERWRITE behavior","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758851376/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758852713","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758852713","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758852713,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODg1MjcxMw==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T18:30:53Z","updated_at":"2021-01-12T18:30:53Z","author_association":"CONTRIBUTOR","body":"Don't feel strongly here but we will need a solution like that internally. Offering a separate procedure for that is also fine. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758852713/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758853336","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758853336","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758853336,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODg1MzMzNg==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T18:32:05Z","updated_at":"2021-01-12T18:32:22Z","author_association":"CONTRIBUTOR","body":"There is some sense in offering `add_files` and `replace_partitions` (or whatever we want to call them) too.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758853336/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758858143","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758858143","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758858143,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODg1ODE0Mw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T18:40:38Z","updated_at":"2021-01-12T18:40:38Z","author_association":"CONTRIBUTOR","body":"+1 for separate operations to remove files. There is no need for an atomic swap when you're working with file lists, so it should be sufficient to delete the data and re-append the files.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758858143/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758861786","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-758861786","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":758861786,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODg2MTc4Ng==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T18:47:28Z","updated_at":"2021-01-12T18:47:28Z","author_association":"CONTRIBUTOR","body":"We may not need a separate procedure. Just use DELETE FROM with a partition predicate. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758861786/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758989389","html_url":"https://github.com/apache/iceberg/pull/2058#issuecomment-758989389","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2058","id":758989389,"node_id":"MDEyOklzc3VlQ29tbWVudDc1ODk4OTM4OQ==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T21:04:40Z","updated_at":"2021-01-12T21:04:40Z","author_association":"CONTRIBUTOR","body":"> I appreciate taking the time to keep the code clean, but I generally like to avoid commits that could cause conflicts simply to fix whitespace. It isn't unclear what the comment applies to, so I don't think that we should make this change.\r\n\r\n@yyanyy can you include this change in one of your commits? I think you added that comment line","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/758989389/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759036441","html_url":"https://github.com/apache/iceberg/issues/2033#issuecomment-759036441","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2033","id":759036441,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTAzNjQ0MQ==","user":{"login":"elkhand","id":4366998,"node_id":"MDQ6VXNlcjQzNjY5OTg=","avatar_url":"https://avatars.githubusercontent.com/u/4366998?v=4","gravatar_id":"","url":"https://api.github.com/users/elkhand","html_url":"https://github.com/elkhand","followers_url":"https://api.github.com/users/elkhand/followers","following_url":"https://api.github.com/users/elkhand/following{/other_user}","gists_url":"https://api.github.com/users/elkhand/gists{/gist_id}","starred_url":"https://api.github.com/users/elkhand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/elkhand/subscriptions","organizations_url":"https://api.github.com/users/elkhand/orgs","repos_url":"https://api.github.com/users/elkhand/repos","events_url":"https://api.github.com/users/elkhand/events{/privacy}","received_events_url":"https://api.github.com/users/elkhand/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T21:36:43Z","updated_at":"2021-01-13T18:15:38Z","author_association":"CONTRIBUTOR","body":"@openinx Thanks for clarifying the Flink specific manifest file - being different from Iceberg manifest file. \r\n\r\n**Correction on the issue based on observations:**\r\n- this is not related to S3 bucket versioning.\r\n- this is not related to the S3 bucket policy setup.\r\n\r\nUnfortunately, there is nothing in logs, and no failover has happened, Job continues running normally, and producing data files and Flink specific manifest files. But it is not creating Iceberg manifest file, manifest list file, or metadata file.\r\n\r\nI'm still investigating the root cause on and off for this Flink job, will share the finding on this issue.\r\n\r\n**Few characteristics of this job:**\r\n- Checkpointing frequency is every hour.\r\n- Each Iceberg table has date/hour partitioning.\r\n\r\n**The issue can be reproduced**\r\nHere is the way how to reproduce the failure scenario @openinx : \r\nThe issue (having only Flink specific manifest files, and missing Iceberg specific files) occurs :\r\n- after the job completes several checkpoints successfully\r\n- job is suspended (via savepoint) after a few minutes since the last checkpoint.\r\n- Before the job is shut down and savepoint is completed (during the suspension flow), Flink will produce Iceberg specific files that were missing for the last checkpoints since the job started and remove Flink specific files.\r\n- But when you start the job next time from the saved savepoint, Flink only produces Flink specific manifest files, and does not create Iceberg specific files. You need to suspend the job so Flink can create Iceberg specific files, and remove Flink specific manifest files.\r\n\r\nThanks.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759036441/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759069297","html_url":"https://github.com/apache/iceberg/pull/2058#issuecomment-759069297","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2058","id":759069297,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTA2OTI5Nw==","user":{"login":"yyanyy","id":71906210,"node_id":"MDQ6VXNlcjcxOTA2MjEw","avatar_url":"https://avatars.githubusercontent.com/u/71906210?v=4","gravatar_id":"","url":"https://api.github.com/users/yyanyy","html_url":"https://github.com/yyanyy","followers_url":"https://api.github.com/users/yyanyy/followers","following_url":"https://api.github.com/users/yyanyy/following{/other_user}","gists_url":"https://api.github.com/users/yyanyy/gists{/gist_id}","starred_url":"https://api.github.com/users/yyanyy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yyanyy/subscriptions","organizations_url":"https://api.github.com/users/yyanyy/orgs","repos_url":"https://api.github.com/users/yyanyy/repos","events_url":"https://api.github.com/users/yyanyy/events{/privacy}","received_events_url":"https://api.github.com/users/yyanyy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T22:13:11Z","updated_at":"2021-01-12T22:13:11Z","author_association":"CONTRIBUTOR","body":"> > I appreciate taking the time to keep the code clean, but I generally like to avoid commits that could cause conflicts simply to fix whitespace. It isn't unclear what the comment applies to, so I don't think that we should make this change.\r\n> \r\n> @yyanyy can you include this change in one of your commits? I think you added that comment line\r\n\r\nYes, sorry I introduced this. I think currently I don't have any PR that touches this file though, and I think #2062 will likely modify this class; should we do it there instead so that we won't have conflict when either PR got merged? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759069297/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759101873","html_url":"https://github.com/apache/iceberg/pull/1979#issuecomment-759101873","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1979","id":759101873,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTEwMTg3Mw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T23:28:02Z","updated_at":"2021-01-12T23:28:02Z","author_association":"CONTRIBUTOR","body":"Thanks, @cccs-jc! The tests are passing after a restart, so I'll merge this.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759101873/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759107248","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-759107248","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":759107248,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTEwNzI0OA==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T23:42:07Z","updated_at":"2021-01-12T23:42:07Z","author_association":"CONTRIBUTOR","body":"I'm in support of this. I have several Airflow DAGs that write parquet files with python etc that need to be added to tables, like @aokolnychyi mentioned.\r\n\r\n> This command would basically go through all of the files under the provided directory, and add them all directly to the table. The files would not be read of scanned so it would be up to the user to only add files with correct columns or to adjust the table column mapping to match.\r\n\r\nI do somewhat worry about not having the ability to perform checks on the files to ensure that they have the correct columns and abide by the partition spec. Particularly I would worry about people importing data that is partitioned by say `date` but the table spec has multiple partition specs, on other columns etc. I don't currently have a strong opinion about this either way, but it would seem beneficial to have something similar to spark's `spark.sql.parquet.mergeSchema`. Meaning that it would be nice to optionally allow for the file footers to be read and either update the table schema or error out if the files are incompatible. Though I guess that's already offered via a full import and most likely the use case for this would be something like importing from a directory that's already partitioned by date etc.\r\n\r\nI know the parquet merge schemas is a rather expensive option and not typically used, but there are some clusters that I've helped administer where setting that by default is reasonable for that cluster's users if they've historically run into issues with changing schemas in their Java / Python process without updating the metastore.\r\n\r\nBut I suppose this would probably be something that users would have on a regular schedule such as the case of writing parquet files from other tools (where the schema doesn't typically change very often), or would be a one off thing where hopefully the users know what they're doing. At the least, logging the appropriate warnings would be important.\r\n\r\nSo long as users could roll back, then I don't have a strong opinion about supporting the option to verify schema compatibility. Anybody who is truly concerned about that should be retaining a long enough snapshot history to rollback in that case.\r\n\r\nI'm also +1 on not deleting files in the same operation, as that does seem likely to cause somebody data loss.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759107248/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759109163","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-759109163","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":759109163,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTEwOTE2Mw==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T23:47:19Z","updated_at":"2021-01-12T23:47:19Z","author_association":"CONTRIBUTOR","body":"Actually, thinking about it further, reading just the footers wouldn't handle the case for partition spec updates if the table has several partition specs. So it does seem that users would either need to ensure on their own, or that we'd have to parse the values from path strings to at least ensure that the paths appear to be partitioned in a similar manner and then leaving it up to the user to be sure that all of the data matches the partition that it's in.\r\n\r\nI think it's a useful option to support, even if it depends on users ensuring the data is correctly partitioned etc.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759109163/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759110037","html_url":"https://github.com/apache/iceberg/pull/2058#issuecomment-759110037","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2058","id":759110037,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTExMDAzNw==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-12T23:49:43Z","updated_at":"2021-01-12T23:49:43Z","author_association":"CONTRIBUTOR","body":"> I appreciate taking the time to keep the code clean, but I generally like to avoid commits that could cause conflicts simply to fix whitespace. It isn't unclear what the comment applies to, so I don't think that we should make this change.\r\n\r\nThat makes sense to me. I can update the formatting in https://github.com/apache/iceberg/pull/2062 if we'd like.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759110037/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759116091","html_url":"https://github.com/apache/iceberg/pull/1627#issuecomment-759116091","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1627","id":759116091,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTExNjA5MQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T00:08:12Z","updated_at":"2021-01-13T00:08:12Z","author_association":"CONTRIBUTOR","body":"I'm closing this PR as my understanding is that @jerryshao was going to continue to work on this (and the work might have been finished by now). This is to make it easier for the release managers to know which PRs need to be included or that the release needs to be blocked on waiting for this (which it does not).","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759116091/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759119938","html_url":"https://github.com/apache/iceberg/pull/2058#issuecomment-759119938","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2058","id":759119938,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTExOTkzOA==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T00:19:35Z","updated_at":"2021-01-13T00:19:35Z","author_association":"CONTRIBUTOR","body":"> > I appreciate taking the time to keep the code clean, but I generally like to avoid commits that could cause conflicts simply to fix whitespace. It isn't unclear what the comment applies to, so I don't think that we should make this change.\r\n> \r\n> That makes sense to me. I can update the formatting in #2062 if we'd like.\r\n\r\nI pushed this change in https://github.com/apache/iceberg/pull/2062 as it already touches this file, so I'm closing this PR.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759119938/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759123091","html_url":"https://github.com/apache/iceberg/issues/2080#issuecomment-759123091","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2080","id":759123091,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTEyMzA5MQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T00:29:01Z","updated_at":"2021-01-13T00:29:01Z","author_association":"CONTRIBUTOR","body":"I'm including a screenshot that I took of the issue in action.\r\n\r\nHere, you can see that I pushed twice to the same branch, but the CI tests continued to run for the older commit. In this screenshot, the popup showing the checks that are running is for the older commit. \r\n![image](https://user-images.githubusercontent.com/9833362/104390496-b460e580-54f2-11eb-8efd-08ef0fde8086.png)\r\n\r\nIn this screenshot, the popup is referring to the newer commit where the CI tests were running in parallel. I took it about 5 minutes later and both were still running.\r\n\r\n![image](https://user-images.githubusercontent.com/9833362/104390737-3bae5900-54f3-11eb-893f-a9378777977c.png)\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759123091/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759135813","html_url":"https://github.com/apache/iceberg/pull/1648#issuecomment-759135813","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1648","id":759135813,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTEzNTgxMw==","user":{"login":"shardulm94","id":6961317,"node_id":"MDQ6VXNlcjY5NjEzMTc=","avatar_url":"https://avatars.githubusercontent.com/u/6961317?v=4","gravatar_id":"","url":"https://api.github.com/users/shardulm94","html_url":"https://github.com/shardulm94","followers_url":"https://api.github.com/users/shardulm94/followers","following_url":"https://api.github.com/users/shardulm94/following{/other_user}","gists_url":"https://api.github.com/users/shardulm94/gists{/gist_id}","starred_url":"https://api.github.com/users/shardulm94/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shardulm94/subscriptions","organizations_url":"https://api.github.com/users/shardulm94/orgs","repos_url":"https://api.github.com/users/shardulm94/repos","events_url":"https://api.github.com/users/shardulm94/events{/privacy}","received_events_url":"https://api.github.com/users/shardulm94/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T01:06:33Z","updated_at":"2021-01-13T01:06:33Z","author_association":"CONTRIBUTOR","body":"@Fokko I see the Spark tests are failing with this error\r\n```\r\n    java.lang.ExceptionInInitializerError\r\n\r\n        Caused by:\r\n        com.fasterxml.jackson.databind.JsonMappingException: Scala module 2.10.2 requires Jackson Databind version >= 2.10.0 and < 2.11.0\r\n```\r\n\r\nThis happens because Jackson expects `com.fasterxml.jackson.core` versions to match `com.fasterxml.jackson.module` and that doesn't seem to be the case here. I ran a gradle build scan and seems like `jackson-databind` version is being upgraded to 2.11 [because of Avro 1.10.0](https://issues.apache.org/jira/browse/AVRO-2853) which is causing this issue.\r\n[Gradle build scan link](https://scans.gradle.com/s/77u6s7hbyyqak/dependencies?configurationFilter=WyJ0ZXN0UnVudGltZUNsYXNzcGF0aCJd&dependencies=jackson&expandAll&focusedDependency=WzIxLDcsNzUsWzAsMCxbNl1dXQ&focusedDependencyView=versions&projectFilter=WyI6aWNlYmVyZy1zcGFyazMiXQ)\r\n\r\nI think we may need to bump Iceberg's jackson version in [`version.props`](https://github.com/apache/iceberg/blob/01fca3d0a3c5653fe5a4a2a88c29aeaffca33f1d/versions.props#L14) and in [`build.gradle`](https://github.com/apache/iceberg/blob/01fca3d0a3c5653fe5a4a2a88c29aeaffca33f1d/build.gradle#L97)\r\n\r\n@rdblue I am not a 100% sure if this is the right thing to do. I know Spark can be finicky about the Jackson version. Do you have any insights here?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759135813/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759139464","html_url":"https://github.com/apache/iceberg/pull/1648#issuecomment-759139464","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1648","id":759139464,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTEzOTQ2NA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T01:17:34Z","updated_at":"2021-01-13T01:17:34Z","author_association":"CONTRIBUTOR","body":"@shardulm94, our Jackson version should be okay to update. We shade and relocate it in the runtime Jars to avoid conflicts with Spark.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759139464/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759139749","html_url":"https://github.com/apache/iceberg/pull/2031#issuecomment-759139749","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2031","id":759139749,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTEzOTc0OQ==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T01:18:28Z","updated_at":"2021-01-13T01:18:28Z","author_association":"CONTRIBUTOR","body":"> I think that we should allow all properties if we don't think that we can enumerate the set of catalog properties that we need.\r\n\r\nIf we are fine with that, simply use the following can work:\r\n\r\n```\r\n@Override\r\npublic List<String> supportedProperties() {\r\n    return ImmutableList.of(\"*\");\r\n}","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759139749/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759165160","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-759165160","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":759165160,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTE2NTE2MA==","user":{"login":"electrum","id":9230,"node_id":"MDQ6VXNlcjkyMzA=","avatar_url":"https://avatars.githubusercontent.com/u/9230?v=4","gravatar_id":"","url":"https://api.github.com/users/electrum","html_url":"https://github.com/electrum","followers_url":"https://api.github.com/users/electrum/followers","following_url":"https://api.github.com/users/electrum/following{/other_user}","gists_url":"https://api.github.com/users/electrum/gists{/gist_id}","starred_url":"https://api.github.com/users/electrum/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/electrum/subscriptions","organizations_url":"https://api.github.com/users/electrum/orgs","repos_url":"https://api.github.com/users/electrum/repos","events_url":"https://api.github.com/users/electrum/events{/privacy}","received_events_url":"https://api.github.com/users/electrum/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T02:38:14Z","updated_at":"2021-01-13T02:38:14Z","author_association":"CONTRIBUTOR","body":"This feature sounds troublesome, as it seems to mix two requirements:\r\n\r\n* Import existing files without **rewriting** them, because writing and storing multiple copies is expensive.\r\n* Import existing files without **reading** them, because reading is expensive.\r\n\r\nUsers constantly run into issues due to metadata/schema in the Hive world, due to a combination of the Hive metadata model and because they are using different tools to write and manage files and metadata. One of the things I love about Iceberg is that it has a strong specification for metadata and tools to enforce it. Not having all sorts of random software writing raw files to disk in different ways is a feature.\r\n\r\nI strongly oppose anything that makes it easy for users to create broken tables. Anything that is *\"up to the user\"* to get right is broken by design in my opinion. Users will always get it wrong. I wouldn't even trust myself to get it right. That's why our software has extensive tests and verification checks at runtime.\r\n\r\nReading data is not particularly expensive. You're presumably converting the data to Iceberg to query it, so query it once up front to make sure it's right. If you hide it behind an advanced, *\"go fast flag for people who know what they're doing\"*, guess what, everyone wants to go fast and thinks they know what they're doing.\r\n\r\nGetting metadata wrong doesn't just cause future queries to fail. If the stats or partitioning are wrong, the queries can silently return wrong answers. In my opinion, that's the worst thing a data system can do.\r\n\r\nSpeaking of stats, another great feature of Iceberg compared to Hive is that we can guarantee that we have stats, and that they're correct. At a minimum, we have to read the file footers to get the stats.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759165160/reactions","total_count":5,"+1":4,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759169871","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-759169871","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":759169871,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTE2OTg3MQ==","user":{"login":"electrum","id":9230,"node_id":"MDQ6VXNlcjkyMzA=","avatar_url":"https://avatars.githubusercontent.com/u/9230?v=4","gravatar_id":"","url":"https://api.github.com/users/electrum","html_url":"https://github.com/electrum","followers_url":"https://api.github.com/users/electrum/followers","following_url":"https://api.github.com/users/electrum/following{/other_user}","gists_url":"https://api.github.com/users/electrum/gists{/gist_id}","starred_url":"https://api.github.com/users/electrum/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/electrum/subscriptions","organizations_url":"https://api.github.com/users/electrum/orgs","repos_url":"https://api.github.com/users/electrum/repos","events_url":"https://api.github.com/users/electrum/events{/privacy}","received_events_url":"https://api.github.com/users/electrum/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T02:53:16Z","updated_at":"2021-01-13T02:53:16Z","author_association":"CONTRIBUTOR","body":"Another concern is that the migrated files will violate the Iceberg specification, since they won't have the required Iceberg column IDs, and may also be missing the identity partitioning columns. If migrated files are officially supported in Iceberg, then exactly what is allowed and how to read them should be covered by the specification.\r\n\r\nWe have this problem today for Hive migrated tables. They are, at least in theory, supported in Trino (formerly PrestoSQL), but as second class citizen, since there are no tests or specification to know it's correct. I only know about this because @Parth-Brahmbhatt originally wrote the connector based on Netflix's internal usage and told me about how it's supposed to work. Any future Iceberg implementations are likely to miss this detail.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759169871/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759197518","html_url":"https://github.com/apache/iceberg/issues/2080#issuecomment-759197518","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2080","id":759197518,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTE5NzUxOA==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T04:28:42Z","updated_at":"2021-01-13T04:28:42Z","author_association":"CONTRIBUTOR","body":"I'm investigating various Github actions that handle this situation. In particular, any that gracefully handle the case of a PR coming from a forked branch would be benificial as that's how all of the Apache repos work.\r\n\r\nSome interesting options I've found so far:\r\n- https://github.com/marketplace/actions/skip-duplicate-actions\r\n- https://github.com/styfle/cancel-workflow-action","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759197518/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759202849","html_url":"https://github.com/apache/iceberg/issues/2080#issuecomment-759202849","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2080","id":759202849,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTIwMjg0OQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T04:48:01Z","updated_at":"2021-01-13T04:48:01Z","author_association":"CONTRIBUTOR","body":"This one appears to have a large number of options for PRs that come from forked repos: https://github.com/potiuk/cancel-workflow-runs#repositories-that-use-pull-requests-from-forks\r\n\r\nIf anybody has any input or knows of any Apache repo or other OSS repo currently doing this with Github Actions, please feel free to comment on this ticket.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759202849/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759207669","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-759207669","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":759207669,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTIwNzY2OQ==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T05:04:42Z","updated_at":"2021-01-13T05:04:42Z","author_association":"CONTRIBUTOR","body":"> One of the things I love about Iceberg is that it has a strong specification for metadata and tools to enforce it. Not having all sorts of random software writing raw files to disk in different ways is a feature.\r\n\r\n+1 for the comment. Internally we have an operation called bootstrap that serves this purpose, and it is always only done by a very small set of people who know exactly what is going on. The data quality guaranteed by Iceberg is a very valuable aspect. But it is always tempting to have these features that are very fast and useful by taking a shortcut. \r\n\r\nOn the other hand, I do see the value of this, especially for people who want a quick try of Iceberg with an existing set of files. There are also some legit use cases where a set of data files cannot be rewritten and has to be added in this way. So if we think this is a valuable thing to add, this will definitely need a lot of explicit documentation and warning. Maybe a post-operation verification can be performed by reading certain amount of imported data to verify the table continues to work. If the verification fails, it is at least a simple command to rollback to the previous version without going too far.\r\n\r\n@RussellSpitzer something I do not fully understand is that, how does the procedure know the partition of each file? Does it read a line of the file to figure out? Does it assume a Hive layout to try map the path name into partition tuples?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759207669/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759231509","html_url":"https://github.com/apache/iceberg/issues/2076#issuecomment-759231509","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2076","id":759231509,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTIzMTUwOQ==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T06:16:01Z","updated_at":"2021-01-13T06:16:01Z","author_association":"CONTRIBUTOR","body":"No too familiar with Flink error messages, but could this be similar to #2057?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759231509/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759304104","html_url":"https://github.com/apache/iceberg/pull/1648#issuecomment-759304104","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1648","id":759304104,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTMwNDEwNA==","user":{"login":"Fokko","id":1134248,"node_id":"MDQ6VXNlcjExMzQyNDg=","avatar_url":"https://avatars.githubusercontent.com/u/1134248?v=4","gravatar_id":"","url":"https://api.github.com/users/Fokko","html_url":"https://github.com/Fokko","followers_url":"https://api.github.com/users/Fokko/followers","following_url":"https://api.github.com/users/Fokko/following{/other_user}","gists_url":"https://api.github.com/users/Fokko/gists{/gist_id}","starred_url":"https://api.github.com/users/Fokko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Fokko/subscriptions","organizations_url":"https://api.github.com/users/Fokko/orgs","repos_url":"https://api.github.com/users/Fokko/repos","events_url":"https://api.github.com/users/Fokko/events{/privacy}","received_events_url":"https://api.github.com/users/Fokko/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T08:55:38Z","updated_at":"2021-01-13T09:56:24Z","author_association":"CONTRIBUTOR","body":"Not 100% sure if this is the case. The Jackson module in Avro isn't shaded, so that might cause issues with Spark 2. Avro 1.10.1 uses Jackson 2.11, and 1.9 is still on 2.10.\r\n\r\nSpark 3.0.1 is still on Jackson 2.10:\r\n```\r\n+--- org.apache.spark:spark-hive_2.12 -> 3.0.1\r\n|    +--- org.apache.spark:spark-core_2.12:3.0.1\r\n|    |    +--- com.fasterxml.jackson.module:jackson-module-scala_2.12:2.10.0 -> 2.10.2\r\n|    |    |    +--- org.scala-lang:scala-library:2.12.10\r\n|    |    |    +--- com.fasterxml.jackson.core:jackson-core:2.10.2\r\n|    |    |    +--- com.fasterxml.jackson.core:jackson-annotations:2.10.2\r\n|    |    |    +--- com.fasterxml.jackson.core:jackson-databind:2.10.2 (*)\r\n|    |    |    \\--- com.fasterxml.jackson.module:jackson-module-paranamer:2.10.2\r\n|    |    |         +--- com.fasterxml.jackson.core:jackson-databind:2.10.2 (*)\r\n|    |    |         \\--- com.thoughtworks.paranamer:paranamer:2.8\r\n```\r\nhttps://github.com/apache/spark/blob/v3.0.1/pom.xml#L175\r\n\r\nPulling a newer version into the classpath will create a mismatch between the Jackson versions.\r\n\r\nThey've bumped Jackson in Spark 3.1, for exactly the issue that we're running into: https://github.com/apache/spark/commit/01b73ae6388279514d61c14a9dc9718a34dad465","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759304104/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759310803","html_url":"https://github.com/apache/iceberg/issues/2080#issuecomment-759310803","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2080","id":759310803,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTMxMDgwMw==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T09:07:43Z","updated_at":"2021-01-13T09:07:43Z","author_association":"CONTRIBUTOR","body":"Due to my lack of write access, I'm not exactly the best person to take this on. However, I'll be researching it and can give it a shot as I've handled a few of our other github actions. But by all means, please feel free to get involved with this issue. 👍 ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759310803/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759323889","html_url":"https://github.com/apache/iceberg/pull/2081#issuecomment-759323889","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2081","id":759323889,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTMyMzg4OQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T09:30:19Z","updated_at":"2021-01-13T09:30:19Z","author_association":"CONTRIBUTOR","body":"> This looks fine to me, given the tests all passed. But I wonder why empty string was not handled and added for testing from the very beginning, I may lack some context here. I see @aokolnychyi added the check for `length > 0`, was there any particular reason for that? Do you expect `length == 0` to be handled before the pushdown?\r\n\r\nYes I would also be very interested to hear if there's any reason to not allow for the truncation function to alter the precondition. I'm open to there being something I didn't catch.\r\n\r\nFor reference, I checked and the only place that `truncateBinary` is used is in metrics evaluation - namely for `startsWith` (and soon to be notStartsWith).\r\n\r\nTo be exact, in `InclusiveMetricsEvaluator`,  `ManifestEvaluator`, and `ParquetMetricsRowGroupFilter` (all of them in the visitor and exclusively with startsWith - which is where the bug occurs presumably due to a row with an empty string). It's also used in updating the lower bounds and upper bounds for min/max parquet metrics for `FIXED` and `BINARY` types (in `ParquetUtils`). So it's only used with metrics and literals and it's overall relatively well tested. I can add more tests as a follow up on the binary and fixed types if we feel it necessary, but overall those are all decently well covered in the tests - especially after I add my tests from the `NOT_STARTS_WITH` PR, which covers it further: https://github.com/apache/iceberg/pull/2062.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759323889/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759346637","html_url":"https://github.com/apache/iceberg/pull/2084#issuecomment-759346637","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2084","id":759346637,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTM0NjYzNw==","user":{"login":"Fokko","id":1134248,"node_id":"MDQ6VXNlcjExMzQyNDg=","avatar_url":"https://avatars.githubusercontent.com/u/1134248?v=4","gravatar_id":"","url":"https://api.github.com/users/Fokko","html_url":"https://github.com/Fokko","followers_url":"https://api.github.com/users/Fokko/followers","following_url":"https://api.github.com/users/Fokko/following{/other_user}","gists_url":"https://api.github.com/users/Fokko/gists{/gist_id}","starred_url":"https://api.github.com/users/Fokko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Fokko/subscriptions","organizations_url":"https://api.github.com/users/Fokko/orgs","repos_url":"https://api.github.com/users/Fokko/repos","events_url":"https://api.github.com/users/Fokko/events{/privacy}","received_events_url":"https://api.github.com/users/Fokko/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T10:10:15Z","updated_at":"2021-01-13T10:10:15Z","author_association":"CONTRIBUTOR","body":"Same issue as https://github.com/apache/iceberg/pull/1648#issuecomment-759304104","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759346637/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759369189","html_url":"https://github.com/apache/iceberg/pull/2081#issuecomment-759369189","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2081","id":759369189,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTM2OTE4OQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T10:51:41Z","updated_at":"2021-01-13T11:04:20Z","author_association":"CONTRIBUTOR","body":"> I see [Anton] added the check for `length > 0`, was there any particular reason for that? Do you expect `length == 0` to be handled before the pushdown?\r\n\r\nAs for whether or not length == 0 should be handled before the pushdown, it should be if I understand correctly. By the time that this function is invoked in the places I listed elsewhere, all expressions should have been rewritten to remove NOT nodes, and then been bound (both the term to the correct id or predicate id as well as the literal used for comparison in the literal expressions).\r\n\r\nGiven that this is always called either in metrics evaluation or row value evaluation against a predicate - typically START_WITH or soon to be NOT_STARTS_WITH - the expressions being evaluated are all `BoundLiteralPredicates` and the input of an empty predicate in that situation (e.g. `data not like '%'`) is not necessarily an invalid expression (nor are empty rows such as `title = ''` showing up in a row that must be evaluated once the `title = 'apple%'` predicate needs to be evaluated at the row level, which is where the precondition causes problems and which is what's most likely causing the user's error).\r\n\r\nThough for that particular query, it does get rewritten to be `data != ''` or both `title is not null and title like 'apple%'` as well as `title != 'apple'` in strict metrics evaluation at one point via parsing, binding, and rewriting.\r\n\r\nI'm not as closely familiar with the `min` and `max` functions, but my understanding after spending a decent period of time working with it when implementing NOT_STARTS_WITH,  is that they too should be under these same conditions and only applied to parquet metadata after expressions have also become rewritten into some kind of `BoundPredicate` that can be applied on parquet `Binary` type lower and upper bounds metrics.\r\n\r\nPlease correct me if I am mistaken 🙂 .\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759369189/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759407796","html_url":"https://github.com/apache/iceberg/pull/796#issuecomment-759407796","issue_url":"https://api.github.com/repos/apache/iceberg/issues/796","id":759407796,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTQwNzc5Ng==","user":{"login":"XuQianJin-Stars","id":10494131,"node_id":"MDQ6VXNlcjEwNDk0MTMx","avatar_url":"https://avatars.githubusercontent.com/u/10494131?v=4","gravatar_id":"","url":"https://api.github.com/users/XuQianJin-Stars","html_url":"https://github.com/XuQianJin-Stars","followers_url":"https://api.github.com/users/XuQianJin-Stars/followers","following_url":"https://api.github.com/users/XuQianJin-Stars/following{/other_user}","gists_url":"https://api.github.com/users/XuQianJin-Stars/gists{/gist_id}","starred_url":"https://api.github.com/users/XuQianJin-Stars/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/XuQianJin-Stars/subscriptions","organizations_url":"https://api.github.com/users/XuQianJin-Stars/orgs","repos_url":"https://api.github.com/users/XuQianJin-Stars/repos","events_url":"https://api.github.com/users/XuQianJin-Stars/events{/privacy}","received_events_url":"https://api.github.com/users/XuQianJin-Stars/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T12:09:37Z","updated_at":"2021-01-13T12:09:37Z","author_association":"CONTRIBUTOR","body":"hi @rdblue @jerryshao Sorry for taking so long to reply.  Because this PR is too big to be review and update, I want to split this PR into some small PRs to merge.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759407796/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759416101","html_url":"https://github.com/apache/iceberg/pull/2078#issuecomment-759416101","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2078","id":759416101,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTQxNjEwMQ==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T12:26:45Z","updated_at":"2021-01-13T12:26:45Z","author_association":"CONTRIBUTOR","body":"@marton-bod, @lcspinter: Could you please review?\r\nThanks,\r\nPeter","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759416101/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759434430","html_url":"https://github.com/apache/iceberg/issues/1922#issuecomment-759434430","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1922","id":759434430,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTQzNDQzMA==","user":{"login":"lcspinter","id":47777102,"node_id":"MDQ6VXNlcjQ3Nzc3MTAy","avatar_url":"https://avatars.githubusercontent.com/u/47777102?v=4","gravatar_id":"","url":"https://api.github.com/users/lcspinter","html_url":"https://github.com/lcspinter","followers_url":"https://api.github.com/users/lcspinter/followers","following_url":"https://api.github.com/users/lcspinter/following{/other_user}","gists_url":"https://api.github.com/users/lcspinter/gists{/gist_id}","starred_url":"https://api.github.com/users/lcspinter/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lcspinter/subscriptions","organizations_url":"https://api.github.com/users/lcspinter/orgs","repos_url":"https://api.github.com/users/lcspinter/repos","events_url":"https://api.github.com/users/lcspinter/events{/privacy}","received_events_url":"https://api.github.com/users/lcspinter/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T13:02:34Z","updated_at":"2021-01-13T13:02:34Z","author_association":"CONTRIBUTOR","body":"The NotNullConstraines are stored separately from the HMS Table. To get a list of not null columns we would need to call the HMS API from the HiveIcebergMetaHook, which is not straight forward.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759434430/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759466345","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-759466345","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":759466345,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTQ2NjM0NQ==","user":{"login":"rymurr","id":2022305,"node_id":"MDQ6VXNlcjIwMjIzMDU=","avatar_url":"https://avatars.githubusercontent.com/u/2022305?v=4","gravatar_id":"","url":"https://api.github.com/users/rymurr","html_url":"https://github.com/rymurr","followers_url":"https://api.github.com/users/rymurr/followers","following_url":"https://api.github.com/users/rymurr/following{/other_user}","gists_url":"https://api.github.com/users/rymurr/gists{/gist_id}","starred_url":"https://api.github.com/users/rymurr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymurr/subscriptions","organizations_url":"https://api.github.com/users/rymurr/orgs","repos_url":"https://api.github.com/users/rymurr/repos","events_url":"https://api.github.com/users/rymurr/events{/privacy}","received_events_url":"https://api.github.com/users/rymurr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T13:59:38Z","updated_at":"2021-01-13T14:02:42Z","author_association":"CONTRIBUTOR","body":"I agree with @electrum that a huge strength of iceberg is its strong specification, I would be reluctant to do anything that could weaken that or give users a footgun wrt to metadata strength. Likewise I agree that reading the files is probably required to do this safely.\r\n\r\nHowever, we are currently working on our own version of the 'make these files an iceberg table' function. It sounds like several of these already exist in other places. From the comments this is being driven by the desire to avoid copying files around, especially on S3. Our use case is the same and the conversion to iceberg will be done primarily by users (as opposed to a super-user), though it will likely be facilitated by a Nessie branch so there is a safeguard in case of misuse.\r\n\r\nI would be interested in helping to derive/implement a spec that defines the canonical Iceberg approach to importing a set of files without moving/copying/renaming (I guess this is similar to the MIGRATE Spark action?). At the very least this is likely going to have to read the footers and to verify the schema and partition spec. I see a lot of value in this function working (at least partially) across engines so that all users/systems can take advantage of it.\r\n\r\ncc @vvellanki","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759466345/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759492779","html_url":"https://github.com/apache/iceberg/pull/2086#issuecomment-759492779","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2086","id":759492779,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTQ5Mjc3OQ==","user":{"login":"lcspinter","id":47777102,"node_id":"MDQ6VXNlcjQ3Nzc3MTAy","avatar_url":"https://avatars.githubusercontent.com/u/47777102?v=4","gravatar_id":"","url":"https://api.github.com/users/lcspinter","html_url":"https://github.com/lcspinter","followers_url":"https://api.github.com/users/lcspinter/followers","following_url":"https://api.github.com/users/lcspinter/following{/other_user}","gists_url":"https://api.github.com/users/lcspinter/gists{/gist_id}","starred_url":"https://api.github.com/users/lcspinter/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lcspinter/subscriptions","organizations_url":"https://api.github.com/users/lcspinter/orgs","repos_url":"https://api.github.com/users/lcspinter/repos","events_url":"https://api.github.com/users/lcspinter/events{/privacy}","received_events_url":"https://api.github.com/users/lcspinter/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T14:42:15Z","updated_at":"2021-01-13T14:42:15Z","author_association":"CONTRIBUTOR","body":"@marton-bod @pvary Could you please have a look at this change? Thank you","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759492779/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759539641","html_url":"https://github.com/apache/iceberg/pull/2067#issuecomment-759539641","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2067","id":759539641,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTUzOTY0MQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T15:53:44Z","updated_at":"2021-01-13T15:53:44Z","author_association":"MEMBER","body":"Thanks @jackye1995 ! Changes made ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759539641/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759601028","html_url":"https://github.com/apache/iceberg/pull/2084#issuecomment-759601028","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2084","id":759601028,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTYwMTAyOA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T17:27:43Z","updated_at":"2021-01-13T17:27:43Z","author_association":"CONTRIBUTOR","body":"I think the test problem might be that we have some Jackson Scala dependencies forced in `build.gradle`:\r\n\r\n```\r\n      resolutionStrategy {\r\n        force 'com.fasterxml.jackson.module:jackson-module-scala_2.11:2.10.2'\r\n        force 'com.fasterxml.jackson.module:jackson-module-scala_2.12:2.10.2'\r\n        force 'com.fasterxml.jackson.module:jackson-module-paranamer:2.10.2'\r\n      }\r\n```\r\n\r\n@aokolnychyi, do you have more context on that?\r\n\r\nI'm not sure that those are even used. I don't see dependencies on `jackson-module-scala_*` in iceberg-spark3-extensions.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759601028/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759616650","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-759616650","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":759616650,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTYxNjY1MA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T17:55:43Z","updated_at":"2021-01-13T17:55:43Z","author_association":"MEMBER","body":"I think one thing to note is that it is always possible for files to not match the Iceberg spec which makes the checking for validity of added files a bit difficult. I definitely do think we should end up doing at least a footer read for getting metadata but I'm not sure we can/should require that the schemas match exactly. For example if a file has additional columns not in the spec should it be rejected?\r\n\r\nIn our internal code we just make a Mapping based on the icebergTable (MappingUtil.create(icebergTable.schema) and then just apply that.\r\n\r\n@karuppayya \r\nActually was discussing an issue with our current Migrate/Snapshot code that has a similar issue. For example if you create a file with a column \"iD\" and create an external hive table referring to that column with \"id\", that table can be read by Spark but when converting such a table to Iceberg we would look for \"id\" and not \"iD\" so the column would not be mapped correctly.\r\n\r\n@jackye1995 \r\nWe currently use the SparkTableUtil's listPartition function. It has custom code for parquet, orc, and avro and uses the directory structure to determine which files belong to which partitions. After that it's just a getFile, table.append.appendFile. Internally we also provide an option for specifying a specific partition to import.\r\n\r\nI agree that this is a bit of a low level method but for systems where rewrite is impossible or expensive I think it may be a good way to move files (or remake metadata for files).","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759616650/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759628824","html_url":"https://github.com/apache/iceberg/issues/2068#issuecomment-759628824","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2068","id":759628824,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTYyODgyNA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T18:16:30Z","updated_at":"2021-01-13T18:16:48Z","author_association":"MEMBER","body":"I should also note a workaround that I've given for users trying to do something similar to this is to create a Hive External Table referring to the files, then to migrate that into an iceberg table.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759628824/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759633809","html_url":"https://github.com/apache/iceberg/pull/1956#issuecomment-759633809","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1956","id":759633809,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTYzMzgwOQ==","user":{"login":"stevenzwu","id":1545663,"node_id":"MDQ6VXNlcjE1NDU2NjM=","avatar_url":"https://avatars.githubusercontent.com/u/1545663?v=4","gravatar_id":"","url":"https://api.github.com/users/stevenzwu","html_url":"https://github.com/stevenzwu","followers_url":"https://api.github.com/users/stevenzwu/followers","following_url":"https://api.github.com/users/stevenzwu/following{/other_user}","gists_url":"https://api.github.com/users/stevenzwu/gists{/gist_id}","starred_url":"https://api.github.com/users/stevenzwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stevenzwu/subscriptions","organizations_url":"https://api.github.com/users/stevenzwu/orgs","repos_url":"https://api.github.com/users/stevenzwu/repos","events_url":"https://api.github.com/users/stevenzwu/events{/privacy}","received_events_url":"https://api.github.com/users/stevenzwu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T18:25:29Z","updated_at":"2021-01-13T18:25:29Z","author_association":"CONTRIBUTOR","body":"I looked at the Beam's approach (gradle magic to copy version specific code + shim/compat layer) that @tweise suggested. It seems to be the most flexible and can work here. It does add some complexity though, mainly on the gradle setup initially. Anyone is more familiar with gradle likes to take it up?\r\n\r\nFLIP-27 source implementation can live in the 1.12 sub module (with gradle trick to copying code during build). HiveShim approach in Flink probably won't work with the FLIP-27 source implementation, which requires Flink 1.12 dep.\r\n\r\n@tweise any drawbacks of the Beam approach on supporting different Flink versions that we should be aware? like how does it work with IDE?\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759633809/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759641805","html_url":"https://github.com/apache/iceberg/pull/1956#issuecomment-759641805","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1956","id":759641805,"node_id":"MDEyOklzc3VlQ29tbWVudDc1OTY0MTgwNQ==","user":{"login":"tweise","id":263695,"node_id":"MDQ6VXNlcjI2MzY5NQ==","avatar_url":"https://avatars.githubusercontent.com/u/263695?v=4","gravatar_id":"","url":"https://api.github.com/users/tweise","html_url":"https://github.com/tweise","followers_url":"https://api.github.com/users/tweise/followers","following_url":"https://api.github.com/users/tweise/following{/other_user}","gists_url":"https://api.github.com/users/tweise/gists{/gist_id}","starred_url":"https://api.github.com/users/tweise/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tweise/subscriptions","organizations_url":"https://api.github.com/users/tweise/orgs","repos_url":"https://api.github.com/users/tweise/repos","events_url":"https://api.github.com/users/tweise/events{/privacy}","received_events_url":"https://api.github.com/users/tweise/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-13T18:40:08Z","updated_at":"2021-01-13T18:40:08Z","author_association":"NONE","body":"@stevenzwu if Flink 1.12 is required to for the source implementation, then it should be fine to make that the minimum Flink version for the next release. Flink 1.12.1 voting is underway and the X.Y.1 version is typically what gets adopted downstream, X.Y.0 would be a bit premature for this purpose IMO.\r\n\r\nIs the long term plan to contribute the connector to Flink? If so, the versioning problem goes away and maybe does not need to be addressed within Iceberg (depending how long it will take to contribute to Flink).\r\n\r\nThe Beam Flink version support approach has worked generally well. Even if only one of the versions is available in the IDE, that is normally sufficient for development. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/759641805/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]