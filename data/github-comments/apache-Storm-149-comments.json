[{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685297","html_url":"https://github.com/apache/storm/issues/5207#issuecomment-2612685297","issue_url":"https://api.github.com/repos/apache/storm/issues/5207","id":2612685297,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODUyOTc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:50:50Z","updated_at":"2025-01-24T14:37:56Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/945#issuecomment-164540466\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/945#issuecomment-164540466</a></p>\n\n<p>    Minor nit picks, +1 after the changes.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685297/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685307","html_url":"https://github.com/apache/storm/issues/5207#issuecomment-2612685307","issue_url":"https://api.github.com/repos/apache/storm/issues/5207","id":2612685307,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODUzMDc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:51:46Z","updated_at":"2025-01-24T14:37:56Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/945#discussion_r47548283\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/945#discussion_r47548283</a></p>\n\n<p>    &#8212; Diff: docs/documentation/distcache-blobstore.md &#8212;<br/>\n    @@ -0,0 +1,733 @@<br/>\n    +# Storm Distributed Cache API<br/>\n    +<br/>\n    +The distributed cache feature in storm is used to efficiently distribute files<br/>\n    +(or blobs, which is the equivalent terminology for a file in the distributed<br/>\n    +cache and is used interchangeably in this document) that are large and can<br/>\n    +change during the lifetime of a topology, such as geo-location data,<br/>\n    +dictionaries, etc. Typical use cases include phrase recognition, entity<br/>\n    +extraction, document classification, URL re-writing, location/address detection<br/>\n    +and so forth. Such files may be several KB to several GB in size. For small<br/>\n    +datasets that don't need dynamic updates, including them in the topology jar<br/>\n    +could be fine. But for large files, the startup times could become very large.<br/>\n    +In these cases, the distributed cache feature can provide fast topology startup,<br/>\n    +especially if the files were previously downloaded for the same submitter and<br/>\n    +are still in the cache. This is useful with frequent deployments, sometimes few<br/>\n    +times a day with updated jars, because the large cached files will remain available<br/>\n    +without changes. The large cached blobs that do not change frequently will<br/>\n    +remain available in the distributed cache.<br/>\n    +<br/>\n    +At the starting time of a topology, the user specifies the set of files the<br/>\n    +topology needs. Once a topology is running, the user at any time can request for<br/>\n    +any file in the distributed cache to be updated with a newer version. The<br/>\n    +updating of blobs happens in an eventual consistency model. If the topology<br/>\n    +needs to know what version of a file it has access to, it is the responsibility<br/>\n    +of the user to find this information out. The files are stored in a cache with<br/>\n    +Least-Recently Used (LRU) eviction policy, where the supervisor decides which<br/>\n    +cached files are no longer needed and can delete them to free disk space. The<br/>\n    +blobs can be compressed, and the user can request the blobs to be uncompressed<br/>\n    +before it accesses them.<br/>\n    +<br/>\n    +## Motivation for Distributed Cache<br/>\n    +* Allows sharing blobs among topologies.<br/>\n    +* Allows updating the blobs from the command line.<br/>\n    +<br/>\n    +## Distributed Cache Implementations<br/>\n    +The current BlobStore interface has the following two implementations<br/>\n    +* LocalFsBlobStore<br/>\n    +* HdfsBlobStore<br/>\n    +<br/>\n    +Appendix A contains the interface for blob store implementation.<br/>\n    +<br/>\n    +## LocalFsBlobStore<br/>\n    +!<span class=\"error\">&#91;LocalFsBlobStore&#93;</span>(images/local_blobstore.png)<br/>\n    +<br/>\n    +Local file system implementation of Blobstore can be depicted in the above timeline diagram.<br/>\n    +<br/>\n    +There are several stages from blob creation to blob download and corresponding execution of a topology. <br/>\n    +The main stages can be depicted as follows<br/>\n    +<br/>\n    +### Blob Creation Command<br/>\n    +Blobs in the blobstore can be created through command line using the following command.<br/>\n    +storm blobstore create --file README.txt --acl o::rwa --repl-fctr 4 key1<br/>\n    +The above command creates a blob with a key name “key1” corresponding to the file README.txt. <br/>\n    +The access given to all users being read, write and admin with a replication factor of 4.<br/>\n    +<br/>\n    +### Topology Submission and Blob Mapping<br/>\n    +Users can submit their topology with the following command. The command includes the <br/>\n    +topology map configuration. The configuration holds two keys “key1” and “key2” with the <br/>\n    +key “key1” having a local file name mapping named “blob_file” and it is not compressed.<br/>\n    +<br/>\n    +```<br/>\n    +storm jar /home/y/lib/storm-starter/current/storm-starter-jar-with-dependencies.jar <br/>\n    +storm.starter.clj.word_count test_topo -c topology.blobstore.map='{\"key1\":</p>\n{\"localname\":\"blob_file\", \"uncompress\":\"false\"}\n<p>,\"key2\":{}}'<br/>\n    +```<br/>\n    +<br/>\n    +### Blob Creation Process<br/>\n    +The creation of the blob takes place through the interface “ClientBlobStore”. Appendix B contains the “ClientBlobStore” interface. <br/>\n    +The concrete implementation of this interface is the  “NimbusBlobStore”. In the case of local file system the client makes a <br/>\n    +call to the nimbus to create the blobs within the local file system. The nimbus uses the local file system implementation to create these blobs. <br/>\n    +When a user submits a topology, the jar, configuration and code files are uploaded as blobs with the help of blob store. <br/>\n    +Also, all the other blobs specified by the topology are mapped to it with the help of topology.blobstore.map configuration.<br/>\n    +<br/>\n    +### Blob Download by the Supervisor<br/>\n    +Finally, the blobs corresponding to a topology are downloaded by the supervisor once it receives the assignments from the nimbus through <br/>\n    +the same “NimbusBlobStore” thrift client that uploaded the blobs. The supervisor downloads the code, jar and conf blobs by calling the <br/>\n    +“NimbusBlobStore” client directly while the blobs specified in the topology.blobstore.map are downloaded and mapped locally with the help <br/>\n    +of the Localizer. The Localizer talks to the “NimbusBlobStore” thrift client to download the blobs and adds the blob compression and local <br/>\n    +blob name mapping logic to suit the implementation of a topology. Once all the blobs have been downloaded the workers are launched to run <br/>\n    +the topologies.<br/>\n    +<br/>\n    +## HdfsBlobStore<br/>\n    +!<span class=\"error\">&#91;HdfsBlobStore&#93;</span>(images/hdfs_blobstore.png)<br/>\n    +<br/>\n    +The HdfsBlobStore functionality has a similar implementation and blob creation and download procedure barring how the replication <br/>\n    +is handled in the two blob store implementations. The replication in HDFS blob store is obvious as HDFS is equipped to handle replication <br/>\n    +and it requires no state to be stored inside the zookeeper. On the other hand, the local file system blobstore requires the state to be <br/>\n    +stored on the zookeeper in order for it to work with nimbus HA. Nimbus HA allows the local filesystem to implement the replication feature <br/>\n    +seamlessly by storing the state in the zookeeper about the running topologies and syncing the blobs on various nimbodes. On the supervisor’s <br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    We should probably just be consistent and use nimbuses everywhere like with the nimbus HA documentation.</p>\n\n<p>    ```<br/>\n    $ find ./ -type f -iname &#42;.md | xargs grep -c nimbuses | grep -v ':0$'<br/>\n    ./docs/documentation/nimbus-ha-design.md:3<br/>\n    ./docs/documentation/ui-rest-api.md:1<br/>\n    ```</p>\n\n<p>    nimbodes and nimbii do not show up at all.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685307/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685691","html_url":"https://github.com/apache/storm/issues/5208#issuecomment-2612685691","issue_url":"https://api.github.com/repos/apache/storm/issues/5208","id":2612685691,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODU2OTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:52:04Z","updated_at":"2025-01-24T14:38:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/934#discussion_r47548325\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/934#discussion_r47548325</a></p>\n\n<p>    &#8212; Diff: examples/storm-starter/src/jvm/storm/starter/BlobStoreAPIWordCountTopology.java &#8212;<br/>\n    @@ -0,0 +1,246 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package storm.starter;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import backtype.storm.StormSubmitter;<br/>\n    +import backtype.storm.LocalCluster;<br/>\n    +import backtype.storm.blobstore.AtomicOutputStream;<br/>\n    +import backtype.storm.blobstore.ClientBlobStore;<br/>\n    +import backtype.storm.blobstore.InputStreamWithMeta;<br/>\n    +import backtype.storm.blobstore.NimbusBlobStore;<br/>\n    +<br/>\n    +import backtype.storm.generated.AccessControl;<br/>\n    +import backtype.storm.generated.AccessControlType;<br/>\n    +import backtype.storm.generated.AlreadyAliveException;<br/>\n    +import backtype.storm.generated.AuthorizationException;<br/>\n    +import backtype.storm.generated.InvalidTopologyException;<br/>\n    +import backtype.storm.generated.KeyAlreadyExistsException;<br/>\n    +import backtype.storm.generated.KeyNotFoundException;<br/>\n    +import backtype.storm.generated.SettableBlobMeta;<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.ShellBolt;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.BasicOutputCollector;<br/>\n    +import backtype.storm.topology.IRichBolt;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.TopologyBuilder;<br/>\n    +import backtype.storm.topology.base.BaseBasicBolt;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.blobstore.BlobStoreAclHandler;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +import backtype.storm.tuple.Tuple;<br/>\n    +import backtype.storm.tuple.Values;<br/>\n    +import backtype.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.BufferedReader;<br/>\n    +import java.io.IOException;<br/>\n    +import java.io.InputStreamReader;<br/>\n    +import java.util.Arrays;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Random;<br/>\n    +<br/>\n    +public class BlobStoreAPIWordCountTopology {<br/>\n    +    private static NimbusBlobStore store = new NimbusBlobStore(); // Client API to invoke blob store API functionality<br/>\n    +    private static String key = \"key1\";<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(BlobStoreAPIWordCountTopology.class);<br/>\n    +    private static final List<AccessControl> WORLD_EVERYTHING = Arrays.asList(new AccessControl(AccessControlType.OTHER,<br/>\n    +    BlobStoreAclHandler.READ | BlobStoreAclHandler.WRITE | BlobStoreAclHandler.ADMIN));<br/>\n    +<br/>\n    +    // Spout implementation<br/>\n    +    public static class BlobStoreSpout extends BaseRichSpout {<br/>\n    +SpoutOutputCollector _collector;<br/>\n    +BlobStoreAPIWordCountTopology wc;<br/>\n    +String key;<br/>\n    +NimbusBlobStore store;<br/>\n    +<br/>\n    +<br/>\n    +@Override<br/>\n    +public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) </p>\n{\n    +    _collector = collector;\n    +    wc = new BlobStoreAPIWordCountTopology();\n    +    key = \"key1\";\n    +    store = new NimbusBlobStore();\n    +    store.prepare(Utils.readStormConfig());\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void nextTuple() {<br/>\n    +    Utils.sleep(100);<br/>\n    +    try </p>\n{\n    + _collector.emit(new Values(wc.getBlobContent(key, store)));\n    +    }\n<p> catch (AuthorizationException | KeyNotFoundException | IOException exp) </p>\n{\n    +throw new RuntimeException(exp);\n    +    }\n<p>    +}<br/>\n    +<br/>\n    +@Override<br/>\n    +public void ack(Object id) </p>\n{\n    +}<br/>\n    +<br/>\n    +@Override<br/>\n    +public void fail(Object id) {    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void declareOutputFields(OutputFieldsDeclarer declarer) </p>\n{\n    +    declarer.declare(new Fields(\"sentence\"));\n    +}\n<p>    +<br/>\n    +    }<br/>\n    +<br/>\n    +    // Bolt implementation<br/>\n    +    public static class SplitSentence extends ShellBolt implements IRichBolt {<br/>\n    +<br/>\n    +public SplitSentence() </p>\n{\n    +    super(\"python\", \"splitsentence.py\");\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void declareOutputFields(OutputFieldsDeclarer declarer) </p>\n{\n    +    declarer.declare(new Fields(\"word\"));\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public Map<String, Object> getComponentConfiguration() </p>\n{\n    +    return null;\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    public static class WordCount extends BaseBasicBolt {<br/>\n    +Map<String, Integer> counts = new HashMap<String, Integer>();<br/>\n    +<br/>\n    +@Override<br/>\n    +public void execute(Tuple tuple, BasicOutputCollector collector) </p>\n{\n    +    String word = tuple.getString(0);\n    +    Integer count = counts.get(word);\n    +    if (count == null)\n    +count = 0;\n    +    count++;\n    +    counts.put(word, count);\n    +    collector.emit(new Values(word, count));\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void declareOutputFields(OutputFieldsDeclarer declarer) </p>\n{\n    +    declarer.declare(new Fields(\"word\", \"count\"));\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    public void buildAndLaunchWordCountTopology(String[] args) {<br/>\n    +<br/>\n    +TopologyBuilder builder = new TopologyBuilder();<br/>\n    +<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    remove the empty line?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685691/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685695","html_url":"https://github.com/apache/storm/issues/5208#issuecomment-2612685695","issue_url":"https://api.github.com/repos/apache/storm/issues/5208","id":2612685695,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODU2OTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:52:09Z","updated_at":"2025-01-24T14:38:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/934#discussion_r47548343\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/934#discussion_r47548343</a></p>\n\n<p>    &#8212; Diff: examples/storm-starter/src/jvm/storm/starter/BlobStoreAPIWordCountTopology.java &#8212;<br/>\n    @@ -0,0 +1,246 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package storm.starter;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import backtype.storm.StormSubmitter;<br/>\n    +import backtype.storm.LocalCluster;<br/>\n    +import backtype.storm.blobstore.AtomicOutputStream;<br/>\n    +import backtype.storm.blobstore.ClientBlobStore;<br/>\n    +import backtype.storm.blobstore.InputStreamWithMeta;<br/>\n    +import backtype.storm.blobstore.NimbusBlobStore;<br/>\n    +<br/>\n    +import backtype.storm.generated.AccessControl;<br/>\n    +import backtype.storm.generated.AccessControlType;<br/>\n    +import backtype.storm.generated.AlreadyAliveException;<br/>\n    +import backtype.storm.generated.AuthorizationException;<br/>\n    +import backtype.storm.generated.InvalidTopologyException;<br/>\n    +import backtype.storm.generated.KeyAlreadyExistsException;<br/>\n    +import backtype.storm.generated.KeyNotFoundException;<br/>\n    +import backtype.storm.generated.SettableBlobMeta;<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.ShellBolt;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.BasicOutputCollector;<br/>\n    +import backtype.storm.topology.IRichBolt;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.TopologyBuilder;<br/>\n    +import backtype.storm.topology.base.BaseBasicBolt;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.blobstore.BlobStoreAclHandler;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +import backtype.storm.tuple.Tuple;<br/>\n    +import backtype.storm.tuple.Values;<br/>\n    +import backtype.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.BufferedReader;<br/>\n    +import java.io.IOException;<br/>\n    +import java.io.InputStreamReader;<br/>\n    +import java.util.Arrays;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Random;<br/>\n    +<br/>\n    +public class BlobStoreAPIWordCountTopology {<br/>\n    +    private static NimbusBlobStore store = new NimbusBlobStore(); // Client API to invoke blob store API functionality<br/>\n    +    private static String key = \"key1\";<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(BlobStoreAPIWordCountTopology.class);<br/>\n    +    private static final List<AccessControl> WORLD_EVERYTHING = Arrays.asList(new AccessControl(AccessControlType.OTHER,<br/>\n    +    BlobStoreAclHandler.READ | BlobStoreAclHandler.WRITE | BlobStoreAclHandler.ADMIN));<br/>\n    +<br/>\n    +    // Spout implementation<br/>\n    +    public static class BlobStoreSpout extends BaseRichSpout {<br/>\n    +SpoutOutputCollector _collector;<br/>\n    +BlobStoreAPIWordCountTopology wc;<br/>\n    +String key;<br/>\n    +NimbusBlobStore store;<br/>\n    +<br/>\n    +<br/>\n    +@Override<br/>\n    +public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) </p>\n{\n    +    _collector = collector;\n    +    wc = new BlobStoreAPIWordCountTopology();\n    +    key = \"key1\";\n    +    store = new NimbusBlobStore();\n    +    store.prepare(Utils.readStormConfig());\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void nextTuple() {<br/>\n    +    Utils.sleep(100);<br/>\n    +    try </p>\n{\n    + _collector.emit(new Values(wc.getBlobContent(key, store)));\n    +    }\n<p> catch (AuthorizationException | KeyNotFoundException | IOException exp) </p>\n{\n    +throw new RuntimeException(exp);\n    +    }\n<p>    +}<br/>\n    +<br/>\n    +@Override<br/>\n    +public void ack(Object id) </p>\n{\n    +}<br/>\n    +<br/>\n    +@Override<br/>\n    +public void fail(Object id) {    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void declareOutputFields(OutputFieldsDeclarer declarer) </p>\n{\n    +    declarer.declare(new Fields(\"sentence\"));\n    +}\n<p>    +<br/>\n    +    }<br/>\n    +<br/>\n    +    // Bolt implementation<br/>\n    +    public static class SplitSentence extends ShellBolt implements IRichBolt {<br/>\n    +<br/>\n    +public SplitSentence() </p>\n{\n    +    super(\"python\", \"splitsentence.py\");\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void declareOutputFields(OutputFieldsDeclarer declarer) </p>\n{\n    +    declarer.declare(new Fields(\"word\"));\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public Map<String, Object> getComponentConfiguration() </p>\n{\n    +    return null;\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    public static class WordCount extends BaseBasicBolt {<br/>\n    +Map<String, Integer> counts = new HashMap<String, Integer>();<br/>\n    +<br/>\n    +@Override<br/>\n    +public void execute(Tuple tuple, BasicOutputCollector collector) </p>\n{\n    +    String word = tuple.getString(0);\n    +    Integer count = counts.get(word);\n    +    if (count == null)\n    +count = 0;\n    +    count++;\n    +    counts.put(word, count);\n    +    collector.emit(new Values(word, count));\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void declareOutputFields(OutputFieldsDeclarer declarer) </p>\n{\n    +    declarer.declare(new Fields(\"word\", \"count\"));\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    public void buildAndLaunchWordCountTopology(String[] args) {<br/>\n    +<br/>\n    +TopologyBuilder builder = new TopologyBuilder();<br/>\n    +<br/>\n    +builder.setSpout(\"spout\", new BlobStoreSpout(), 5);<br/>\n    +<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    remove the empty line?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685695/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685700","html_url":"https://github.com/apache/storm/issues/5208#issuecomment-2612685700","issue_url":"https://api.github.com/repos/apache/storm/issues/5208","id":2612685700,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODU3MDA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:52:38Z","updated_at":"2025-01-24T14:38:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/934#discussion_r47548412\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/934#discussion_r47548412</a></p>\n\n<p>    &#8212; Diff: examples/storm-starter/src/jvm/storm/starter/BlobStoreAPIWordCountTopology.java &#8212;<br/>\n    @@ -0,0 +1,246 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package storm.starter;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import backtype.storm.StormSubmitter;<br/>\n    +import backtype.storm.LocalCluster;<br/>\n    +import backtype.storm.blobstore.AtomicOutputStream;<br/>\n    +import backtype.storm.blobstore.ClientBlobStore;<br/>\n    +import backtype.storm.blobstore.InputStreamWithMeta;<br/>\n    +import backtype.storm.blobstore.NimbusBlobStore;<br/>\n    +<br/>\n    +import backtype.storm.generated.AccessControl;<br/>\n    +import backtype.storm.generated.AccessControlType;<br/>\n    +import backtype.storm.generated.AlreadyAliveException;<br/>\n    +import backtype.storm.generated.AuthorizationException;<br/>\n    +import backtype.storm.generated.InvalidTopologyException;<br/>\n    +import backtype.storm.generated.KeyAlreadyExistsException;<br/>\n    +import backtype.storm.generated.KeyNotFoundException;<br/>\n    +import backtype.storm.generated.SettableBlobMeta;<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.ShellBolt;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.BasicOutputCollector;<br/>\n    +import backtype.storm.topology.IRichBolt;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.TopologyBuilder;<br/>\n    +import backtype.storm.topology.base.BaseBasicBolt;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.blobstore.BlobStoreAclHandler;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +import backtype.storm.tuple.Tuple;<br/>\n    +import backtype.storm.tuple.Values;<br/>\n    +import backtype.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.BufferedReader;<br/>\n    +import java.io.IOException;<br/>\n    +import java.io.InputStreamReader;<br/>\n    +import java.util.Arrays;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Random;<br/>\n    +<br/>\n    +public class BlobStoreAPIWordCountTopology {<br/>\n    +    private static NimbusBlobStore store = new NimbusBlobStore(); // Client API to invoke blob store API functionality<br/>\n    +    private static String key = \"key1\";<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(BlobStoreAPIWordCountTopology.class);<br/>\n    +    private static final List<AccessControl> WORLD_EVERYTHING = Arrays.asList(new AccessControl(AccessControlType.OTHER,<br/>\n    +    BlobStoreAclHandler.READ | BlobStoreAclHandler.WRITE | BlobStoreAclHandler.ADMIN));<br/>\n    +<br/>\n    +    // Spout implementation<br/>\n    +    public static class BlobStoreSpout extends BaseRichSpout {<br/>\n    +SpoutOutputCollector _collector;<br/>\n    +BlobStoreAPIWordCountTopology wc;<br/>\n    +String key;<br/>\n    +NimbusBlobStore store;<br/>\n    +<br/>\n    +<br/>\n    +@Override<br/>\n    +public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) </p>\n{\n    +    _collector = collector;\n    +    wc = new BlobStoreAPIWordCountTopology();\n    +    key = \"key1\";\n    +    store = new NimbusBlobStore();\n    +    store.prepare(Utils.readStormConfig());\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void nextTuple() {<br/>\n    +    Utils.sleep(100);<br/>\n    +    try </p>\n{\n    + _collector.emit(new Values(wc.getBlobContent(key, store)));\n    +    }\n<p> catch (AuthorizationException | KeyNotFoundException | IOException exp) </p>\n{\n    +throw new RuntimeException(exp);\n    +    }\n<p>    +}<br/>\n    +<br/>\n    +@Override<br/>\n    +public void ack(Object id) </p>\n{\n    +}<br/>\n    +<br/>\n    +@Override<br/>\n    +public void fail(Object id) {    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void declareOutputFields(OutputFieldsDeclarer declarer) </p>\n{\n    +    declarer.declare(new Fields(\"sentence\"));\n    +}\n<p>    +<br/>\n    +    }<br/>\n    +<br/>\n    +    // Bolt implementation<br/>\n    +    public static class SplitSentence extends ShellBolt implements IRichBolt {<br/>\n    +<br/>\n    +public SplitSentence() </p>\n{\n    +    super(\"python\", \"splitsentence.py\");\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void declareOutputFields(OutputFieldsDeclarer declarer) </p>\n{\n    +    declarer.declare(new Fields(\"word\"));\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public Map<String, Object> getComponentConfiguration() </p>\n{\n    +    return null;\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    public static class WordCount extends BaseBasicBolt {<br/>\n    +Map<String, Integer> counts = new HashMap<String, Integer>();<br/>\n    +<br/>\n    +@Override<br/>\n    +public void execute(Tuple tuple, BasicOutputCollector collector) </p>\n{\n    +    String word = tuple.getString(0);\n    +    Integer count = counts.get(word);\n    +    if (count == null)\n    +count = 0;\n    +    count++;\n    +    counts.put(word, count);\n    +    collector.emit(new Values(word, count));\n    +}\n<p>    +<br/>\n    +@Override<br/>\n    +public void declareOutputFields(OutputFieldsDeclarer declarer) </p>\n{\n    +    declarer.declare(new Fields(\"word\", \"count\"));\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    public void buildAndLaunchWordCountTopology(String[] args) {<br/>\n    +<br/>\n    +TopologyBuilder builder = new TopologyBuilder();<br/>\n    +<br/>\n    +builder.setSpout(\"spout\", new BlobStoreSpout(), 5);<br/>\n    +<br/>\n    +builder.setBolt(\"split\", new SplitSentence(), 8).shuffleGrouping(\"spout\");<br/>\n    +builder.setBolt(\"count\", new WordCount(), 12).fieldsGrouping(\"split\", new Fields(\"word\"));<br/>\n    +<br/>\n    +Config conf = new Config();<br/>\n    +conf.setDebug(true);<br/>\n    +<br/>\n    +try {<br/>\n    +    if (args != null && args.length > 0) </p>\n{\n    +conf.setNumWorkers(3);\n    +StormSubmitter.submitTopologyWithProgressBar(args[0], conf, builder.createTopology());\n    +    }\n<p> else {<br/>\n    +conf.setMaxTaskParallelism(3);<br/>\n    +<br/>\n    +LocalCluster cluster = new LocalCluster();<br/>\n    +cluster.submitTopology(\"word-count\", conf, builder.createTopology());<br/>\n    +<br/>\n    +Thread.sleep(10000);<br/>\n    +<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    remove the empty lines (a couple lines above too)?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685700/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164541059","html_url":"https://github.com/apache/storm/pull/945#issuecomment-164541059","issue_url":"https://api.github.com/repos/apache/storm/issues/945","id":164541059,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0MTA1OQ==","user":{"login":"ppoulosk","id":4550393,"node_id":"MDQ6VXNlcjQ1NTAzOTM=","avatar_url":"https://avatars.githubusercontent.com/u/4550393?v=4","gravatar_id":"","url":"https://api.github.com/users/ppoulosk","html_url":"https://github.com/ppoulosk","followers_url":"https://api.github.com/users/ppoulosk/followers","following_url":"https://api.github.com/users/ppoulosk/following{/other_user}","gists_url":"https://api.github.com/users/ppoulosk/gists{/gist_id}","starred_url":"https://api.github.com/users/ppoulosk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ppoulosk/subscriptions","organizations_url":"https://api.github.com/users/ppoulosk/orgs","repos_url":"https://api.github.com/users/ppoulosk/repos","events_url":"https://api.github.com/users/ppoulosk/events{/privacy}","received_events_url":"https://api.github.com/users/ppoulosk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:53:15Z","updated_at":"2015-12-14T19:53:59Z","author_association":"CONTRIBUTOR","body":"+1 NB\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164541059/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685313","html_url":"https://github.com/apache/storm/issues/5207#issuecomment-2612685313","issue_url":"https://api.github.com/repos/apache/storm/issues/5207","id":2612685313,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODUzMTM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:53:16Z","updated_at":"2025-01-24T14:37:56Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user ppoulosk commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/945#issuecomment-164541059\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/945#issuecomment-164541059</a></p>\n\n<p>    +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685313/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686337","html_url":"https://github.com/apache/storm/issues/5211#issuecomment-2612686337","issue_url":"https://api.github.com/repos/apache/storm/issues/5211","id":2612686337,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODYzMzc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:54:56Z","updated_at":"2025-01-24T14:38:19Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/933#discussion_r47548775\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/933#discussion_r47548775</a></p>\n\n<p>    &#8212; Diff: conf/defaults.yaml &#8212;<br/>\n    @@ -179,7 +179,7 @@ task.refresh.poll.secs: 10<br/>\n     task.credentials.poll.secs: 30</p>\n\n<ol>\n\t<li>now should be null by default<br/>\n    -topology.backpressure.enable: true<br/>\n    +topology.backpressure.enable: false<br/>\n     backpressure.disruptor.high.watermark: 0.9<br/>\n     backpressure.disruptor.low.watermark: 0.4\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ol>\n\n\n<p>    How about adding a comment describing why the choice of 0.4 and 0.9?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686337/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164541535","html_url":"https://github.com/apache/storm/pull/943#issuecomment-164541535","issue_url":"https://api.github.com/repos/apache/storm/issues/943","id":164541535,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0MTUzNQ==","user":{"login":"jerrypeng","id":3613359,"node_id":"MDQ6VXNlcjM2MTMzNTk=","avatar_url":"https://avatars.githubusercontent.com/u/3613359?v=4","gravatar_id":"","url":"https://api.github.com/users/jerrypeng","html_url":"https://github.com/jerrypeng","followers_url":"https://api.github.com/users/jerrypeng/followers","following_url":"https://api.github.com/users/jerrypeng/following{/other_user}","gists_url":"https://api.github.com/users/jerrypeng/gists{/gist_id}","starred_url":"https://api.github.com/users/jerrypeng/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jerrypeng/subscriptions","organizations_url":"https://api.github.com/users/jerrypeng/orgs","repos_url":"https://api.github.com/users/jerrypeng/repos","events_url":"https://api.github.com/users/jerrypeng/events{/privacy}","received_events_url":"https://api.github.com/users/jerrypeng/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:55:07Z","updated_at":"2015-12-14T19:55:07Z","author_association":"CONTRIBUTOR","body":"+1\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164541535/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688326","html_url":"https://github.com/apache/storm/issues/5223#issuecomment-2612688326","issue_url":"https://api.github.com/repos/apache/storm/issues/5223","id":2612688326,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODgzMjY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:55:09Z","updated_at":"2025-01-24T14:39:11Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user jerrypeng commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/943#issuecomment-164541535\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/943#issuecomment-164541535</a></p>\n\n<p>    +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688326/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164541757","html_url":"https://github.com/apache/storm/pull/882#issuecomment-164541757","issue_url":"https://api.github.com/repos/apache/storm/issues/882","id":164541757,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0MTc1Nw==","user":{"login":"jerrypeng","id":3613359,"node_id":"MDQ6VXNlcjM2MTMzNTk=","avatar_url":"https://avatars.githubusercontent.com/u/3613359?v=4","gravatar_id":"","url":"https://api.github.com/users/jerrypeng","html_url":"https://github.com/jerrypeng","followers_url":"https://api.github.com/users/jerrypeng/followers","following_url":"https://api.github.com/users/jerrypeng/following{/other_user}","gists_url":"https://api.github.com/users/jerrypeng/gists{/gist_id}","starred_url":"https://api.github.com/users/jerrypeng/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jerrypeng/subscriptions","organizations_url":"https://api.github.com/users/jerrypeng/orgs","repos_url":"https://api.github.com/users/jerrypeng/repos","events_url":"https://api.github.com/users/jerrypeng/events{/privacy}","received_events_url":"https://api.github.com/users/jerrypeng/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:56:02Z","updated_at":"2015-12-14T19:56:02Z","author_association":"CONTRIBUTOR","body":"+1\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164541757/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612593791","html_url":"https://github.com/apache/storm/issues/4847#issuecomment-2612593791","issue_url":"https://api.github.com/repos/apache/storm/issues/4847","id":2612593791,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1OTM3OTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:56:03Z","updated_at":"2025-01-24T13:58:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user jerrypeng commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/882#issuecomment-164541757\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/882#issuecomment-164541757</a></p>\n\n<p>    +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612593791/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164541974","html_url":"https://github.com/apache/storm/pull/943#issuecomment-164541974","issue_url":"https://api.github.com/repos/apache/storm/issues/943","id":164541974,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0MTk3NA==","user":{"login":"ppoulosk","id":4550393,"node_id":"MDQ6VXNlcjQ1NTAzOTM=","avatar_url":"https://avatars.githubusercontent.com/u/4550393?v=4","gravatar_id":"","url":"https://api.github.com/users/ppoulosk","html_url":"https://github.com/ppoulosk","followers_url":"https://api.github.com/users/ppoulosk/followers","following_url":"https://api.github.com/users/ppoulosk/following{/other_user}","gists_url":"https://api.github.com/users/ppoulosk/gists{/gist_id}","starred_url":"https://api.github.com/users/ppoulosk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ppoulosk/subscriptions","organizations_url":"https://api.github.com/users/ppoulosk/orgs","repos_url":"https://api.github.com/users/ppoulosk/repos","events_url":"https://api.github.com/users/ppoulosk/events{/privacy}","received_events_url":"https://api.github.com/users/ppoulosk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:56:53Z","updated_at":"2015-12-14T19:56:53Z","author_association":"CONTRIBUTOR","body":"LGTM +1, NB\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164541974/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688330","html_url":"https://github.com/apache/storm/issues/5223#issuecomment-2612688330","issue_url":"https://api.github.com/repos/apache/storm/issues/5223","id":2612688330,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODgzMzA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:56:54Z","updated_at":"2025-01-24T14:39:11Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user ppoulosk commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/943#issuecomment-164541974\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/943#issuecomment-164541974</a></p>\n\n<p>    LGTM +1, NB</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688330/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686340","html_url":"https://github.com/apache/storm/issues/5211#issuecomment-2612686340","issue_url":"https://api.github.com/repos/apache/storm/issues/5211","id":2612686340,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODYzNDA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:57:17Z","updated_at":"2025-01-24T14:38:19Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/933#discussion_r47549090\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/933#discussion_r47549090</a></p>\n\n<p>    &#8212; Diff: storm-core/test/clj/backtype/storm/nimbus_test.clj &#8212;<br/>\n    @@ -1238,10 +1238,11 @@<br/>\n       (testing \"nimbus-data uses correct ACLs\"<br/>\n (let [scheme \"digest\"<br/>\n       digest \"storm:thisisapoorpassword\"</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>auth-conf \n<div class=\"error\"><span class=\"error\">Unknown macro: {STORM-ZOOKEEPER-AUTH-SCHEME scheme    +  auth-conf (merge (read-storm-config)    +    {STORM-ZOOKEEPER-AUTH-SCHEME scheme\n  STORM-ZOOKEEPER-AUTH-PAYLOAD digest\n  STORM-PRINCIPAL-TO-LOCAL-PLUGIN \"backtype.storm.security.auth.DefaultPrincipalToLocal\"\n    -     NIMBUS-THRIFT-PORT 6666}    +     NIMBUS-THRIFT-PORT 6666}</span> </div>\n<p>)</p>\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    Ditto.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686340/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164542182","html_url":"https://github.com/apache/storm/pull/880#issuecomment-164542182","issue_url":"https://api.github.com/repos/apache/storm/issues/880","id":164542182,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0MjE4Mg==","user":{"login":"jerrypeng","id":3613359,"node_id":"MDQ6VXNlcjM2MTMzNTk=","avatar_url":"https://avatars.githubusercontent.com/u/3613359?v=4","gravatar_id":"","url":"https://api.github.com/users/jerrypeng","html_url":"https://github.com/jerrypeng","followers_url":"https://api.github.com/users/jerrypeng/followers","following_url":"https://api.github.com/users/jerrypeng/following{/other_user}","gists_url":"https://api.github.com/users/jerrypeng/gists{/gist_id}","starred_url":"https://api.github.com/users/jerrypeng/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jerrypeng/subscriptions","organizations_url":"https://api.github.com/users/jerrypeng/orgs","repos_url":"https://api.github.com/users/jerrypeng/repos","events_url":"https://api.github.com/users/jerrypeng/events{/privacy}","received_events_url":"https://api.github.com/users/jerrypeng/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:57:43Z","updated_at":"2015-12-14T19:57:43Z","author_association":"CONTRIBUTOR","body":"can we close this dup PR now?\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164542182/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612593795","html_url":"https://github.com/apache/storm/issues/4847#issuecomment-2612593795","issue_url":"https://api.github.com/repos/apache/storm/issues/4847","id":2612593795,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1OTM3OTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:57:44Z","updated_at":"2025-01-24T13:58:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user jerrypeng commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/880#issuecomment-164542182\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/880#issuecomment-164542182</a></p>\n\n<p>    can we close this dup PR now?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612593795/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685324","html_url":"https://github.com/apache/storm/issues/5207#issuecomment-2612685324","issue_url":"https://api.github.com/repos/apache/storm/issues/5207","id":2612685324,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODUzMjQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:58:00Z","updated_at":"2025-01-24T14:37:56Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/945#discussion_r47549186\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/945#discussion_r47549186</a></p>\n\n<p>    &#8212; Diff: docs/documentation/distcache-blobstore.md &#8212;<br/>\n    @@ -0,0 +1,732 @@<br/>\n    +# Storm Distributed Cache API<br/>\n    +<br/>\n    +The distributed cache feature in storm is used to efficiently distribute files<br/>\n    +(or blobs, which is the equivalent terminology for a file in the distributed<br/>\n    +cache and is used interchangeably in this document) that are large and can<br/>\n    +change during the lifetime of a topology, such as geo-location data,<br/>\n    +dictionaries, etc. Typical use cases include phrase recognition, entity<br/>\n    +extraction, document classification, URL re-writing, location/address detection<br/>\n    +and so forth. Such files may be several KB to several GB in size. For small<br/>\n    +datasets that don't need dynamic updates, including them in the topology jar<br/>\n    +could be fine. But for large files, the startup times could become very large.<br/>\n    +In these cases, the distributed cache feature can provide fast topology startup,<br/>\n    +especially if the files were previously downloaded for the same submitter and<br/>\n    +are still in the cache. This is useful with frequent deployments, sometimes few<br/>\n    +times a day with updated jars, because the large cached files will remain available<br/>\n    +without changes. The large cached blobs that do not change frequently will<br/>\n    +remain available in the distributed cache.<br/>\n    +<br/>\n    +At the starting time of a topology, the user specifies the set of files the<br/>\n    +topology needs. Once a topology is running, the user at any time can request for<br/>\n    +any file in the distributed cache to be updated with a newer version. The<br/>\n    +updating of blobs happens in an eventual consistency model. If the topology<br/>\n    +needs to know what version of a file it has access to, it is the responsibility<br/>\n    +of the user to find this information out. The files are stored in a cache with<br/>\n    +Least-Recently Used (LRU) eviction policy, where the supervisor decides which<br/>\n    +cached files are no longer needed and can delete them to free disk space. The<br/>\n    +blobs can be compressed, and the user can request the blobs to be uncompressed<br/>\n    +before it accesses them.<br/>\n    +<br/>\n    +## Motivation for Distributed Cache<br/>\n    +* Allows sharing blobs among topologies.<br/>\n    +* Allows updating the blobs from the command line.<br/>\n    +<br/>\n    +## Distributed Cache Implementations<br/>\n    +The current BlobStore interface has the following two implementations<br/>\n    +* LocalFsBlobStore<br/>\n    +* HdfsBlobStore<br/>\n    +<br/>\n    +Appendix A contains the interface for blob store implementation.<br/>\n    +<br/>\n    +## LocalFsBlobStore<br/>\n    +!<span class=\"error\">&#91;LocalFsBlobStore&#93;</span>(images/local_blobstore.png)<br/>\n    +<br/>\n    +Local file system implementation of Blobstore can be depicted in the above timeline diagram.<br/>\n    +<br/>\n    +There are several stages from blob creation to blob download and corresponding execution of a topology. <br/>\n    +The main stages can be depicted as follows<br/>\n    +<br/>\n    +### Blob Creation Command<br/>\n    +Blobs in the blobstore can be created through command line using the following command.<br/>\n    +storm blobstore create --file README.txt --acl o::rwa --repl-fctr 4 key1<br/>\n    +The above command creates a blob with a key name “key1” corresponding to the file README.txt. <br/>\n    +The access given to all users being read, write and admin with a replication factor of 4.<br/>\n    +<br/>\n    +### Topology Submission and Blob Mapping<br/>\n    +Users can submit their topology with the following command. The command includes the <br/>\n    +topology map configuration. The configuration holds two keys “key1” and “key2” with the <br/>\n    +key “key1” having a local file name mapping named “blob_file” and it is not compressed.<br/>\n    +<br/>\n    +```<br/>\n    +storm jar /home/y/lib/storm-starter/current/storm-starter-jar-with-dependencies.jar <br/>\n    +storm.starter.clj.word_count test_topo -c topology.blobstore.map='{\"key1\":</p>\n{\"localname\":\"blob_file\", \"uncompress\":\"false\"}\n<p>,\"key2\":{}}'<br/>\n    +```<br/>\n    +<br/>\n    +### Blob Creation Process<br/>\n    +The creation of the blob takes place through the interface “ClientBlobStore”. Appendix B contains the “ClientBlobStore” interface. <br/>\n    +The concrete implementation of this interface is the  “NimbusBlobStore”. In the case of local file system the client makes a <br/>\n    +call to the nimbus to create the blobs within the local file system. The nimbus uses the local file system implementation to create these blobs. <br/>\n    +When a user submits a topology, the jar, configuration and code files are uploaded as blobs with the help of blob store. <br/>\n    +Also, all the other blobs specified by the topology are mapped to it with the help of topology.blobstore.map configuration.<br/>\n    +<br/>\n    +### Blob Download by the Supervisor<br/>\n    +Finally, the blobs corresponding to a topology are downloaded by the supervisor once it receives the assignments from the nimbus through <br/>\n    +the same “NimbusBlobStore” thrift client that uploaded the blobs. The supervisor downloads the code, jar and conf blobs by calling the <br/>\n    +“NimbusBlobStore” client directly while the blobs specified in the topology.blobstore.map are downloaded and mapped locally with the help <br/>\n    +of the Localizer. The Localizer talks to the “NimbusBlobStore” thrift client to download the blobs and adds the blob compression and local <br/>\n    +blob name mapping logic to suit the implementation of a topology. Once all the blobs have been downloaded the workers are launched to run <br/>\n    +the topologies.<br/>\n    +<br/>\n    +## HdfsBlobStore<br/>\n    +!<span class=\"error\">&#91;HdfsBlobStore&#93;</span>(images/hdfs_blobstore.png)<br/>\n    +<br/>\n    +The HdfsBlobStore functionality has a similar implementation and blob creation and download procedure barring how the replication <br/>\n    +is handled in the two blob store implementations. The replication in HDFS blob store is obvious as HDFS is equipped to handle replication <br/>\n    +and it requires no state to be stored inside the zookeeper. On the other hand, the local file system blobstore requires the state to be <br/>\n    +stored on the zookeeper in order for it to work with nimbus HA. Nimbus HA allows the local filesystem to implement the replication feature <br/>\n    +seamlessly by storing the state in the zookeeper about the running topologies and syncing the blobs on various nimbodes. On the supervisor’s <br/>\n    +end, the supervisor and localizer talks to HdfsBlobStore through “HdfsClientBlobStore” implementation.<br/>\n    +<br/>\n    +## Additional Features and Documentation<br/>\n    +```<br/>\n    +storm jar /home/y/lib/storm-starter/current/storm-starter-jar-with-dependencies.jar storm.starter.clj.word_count test_topo <br/>\n    +-c topology.blobstore.map='{\"key1\":</p>\n{\"localname\":\"blob_file\", \"uncompress\":\"false\"}\n<p>,\"key2\":{}}'<br/>\n    +```<br/>\n    + <br/>\n    +### Compression<br/>\n    +The blob store allows the user to specify the “uncompress” configuration to true or false. This configuration can be specified <br/>\n    +in the topology.blobstore.map mentioned in the above command. This allows the user to upload a compressed file like a tarball/zip. <br/>\n    +In local file system blob store, the compressed blobs are stored on the nimbus node. The localizer code takes the responsibility to <br/>\n    +uncompress the blob and store it on the supervisor node. Symbolic links to the blobs on the supervisor node are created within the worker <br/>\n    +before the execution starts.<br/>\n    +<br/>\n    +### Local File Name Mapping<br/>\n    +Apart from compression the blobstore helps to give the blob a name that can be used by the workers. The localizer takes <br/>\n    +the responsibility of mapping the blob to a local name on the supervisor node.<br/>\n    +<br/>\n    +## Additional Blob Store Implementation Details<br/>\n    +Blob store uses a hashing function to create the blobs based on the key. The blobs are generally stored inside the directory specified by <br/>\n    +the blobstore.dir configuration. By default, it is stored under “storm.local.dir/nimbus/blobs” for local file system and a similar path on <br/>\n    +hdfs file system.<br/>\n    +<br/>\n    +Once a file is submitted, the blob store reads the configs and creates a metadata for the blob with all the access control details. The metadata <br/>\n    +is generally used for authorization while accessing the blobs. The blob key and version contribute to the hash code and there by the directory <br/>\n    +under “storm.local.dir/nimbus/blobs/data” where the data is placed. The blobs are generally placed in a positive number directory like 193,822 etc.<br/>\n    +<br/>\n    +Once the topology is launched and the relevant blobs have been created the supervisor downloads blobs related to the storm.conf, storm.ser <br/>\n    +and storm.code first and all the blobs uploaded by the command line separately using the localizer to uncompress and map them to a local name <br/>\n    +specified in the topology.blobstore.map configuration. The supervisor periodically updates blobs by checking for the change of version. <br/>\n    +This allows updating the blobs on the fly and thereby making it a very useful feature.<br/>\n    +<br/>\n    +For a local file system, the distributed cache on the supervisor node is set to 10240 MB as a soft limit and the clean up code attempts <br/>\n    +to clean anything over the soft limit every 600 seconds based on LRU policy.<br/>\n    +<br/>\n    +The HDFS blob store implementation handles load better by removing the burden on the nimbus to store the blobs, which avoids it becoming a bottleneck. Moreover, it provides seamless replication of blobs. On the other hand, the local file system blob store is not very efficient in <br/>\n    +replicating the blobs and is limited by the number of nimbuses. Moreover, the supervisor talks to the HDFS blob store directly without the <br/>\n    +involvement of the nimbus and thereby reduces the load and dependency on nimbus.<br/>\n    +<br/>\n    +## Highly Available Nimbus<br/>\n    +### Problem Statement:<br/>\n    +Currently the storm master aka nimbus, is a process that runs on a single machine under supervision. In most cases the <br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    That is not really the current state, because we are adding the blob store to nimbus HA.  Perhaps we can just point to the HA documentation instead of summarizing it here.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685324/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686603","html_url":"https://github.com/apache/storm/issues/5212#issuecomment-2612686603","issue_url":"https://api.github.com/repos/apache/storm/issues/5212","id":2612686603,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODY2MDM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:58:45Z","updated_at":"2025-01-24T14:38:26Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user ppoulosk commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/941#discussion_r47549323\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/941#discussion_r47549323</a></p>\n\n<p>    &#8212; Diff: storm-core/test/clj/backtype/storm/security/auth/ThriftClient_test.clj &#8212;<br/>\n    @@ -20,26 +20,26 @@<br/>\n       (:import <span class=\"error\">&#91;org.apache.thrift.transport TTransportException&#93;</span>)<br/>\n     )</p>\n\n<p>    +(def TIMEOUT (Integer. (* 3 1000)))<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Are we going from 30 seconds to 3000 miliseconds here?  Shouldn't it be 30000?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686603/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686609","html_url":"https://github.com/apache/storm/issues/5212#issuecomment-2612686609","issue_url":"https://api.github.com/repos/apache/storm/issues/5212","id":2612686609,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODY2MDk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T19:59:29Z","updated_at":"2025-01-24T14:38:26Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/941#discussion_r47549426\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/941#discussion_r47549426</a></p>\n\n<p>    &#8212; Diff: storm-core/test/clj/backtype/storm/security/auth/ThriftClient_test.clj &#8212;<br/>\n    @@ -20,26 +20,26 @@<br/>\n       (:import <span class=\"error\">&#91;org.apache.thrift.transport TTransportException&#93;</span>)<br/>\n     )</p>\n\n<p>    +(def TIMEOUT (Integer. (* 3 1000)))<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    How about adding a comment describing why the choice of 3000 in this particular test?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686609/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164543211","html_url":"https://github.com/apache/storm/pull/938#issuecomment-164543211","issue_url":"https://api.github.com/repos/apache/storm/issues/938","id":164543211,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0MzIxMQ==","user":{"login":"rfarivar","id":8742608,"node_id":"MDQ6VXNlcjg3NDI2MDg=","avatar_url":"https://avatars.githubusercontent.com/u/8742608?v=4","gravatar_id":"","url":"https://api.github.com/users/rfarivar","html_url":"https://github.com/rfarivar","followers_url":"https://api.github.com/users/rfarivar/followers","following_url":"https://api.github.com/users/rfarivar/following{/other_user}","gists_url":"https://api.github.com/users/rfarivar/gists{/gist_id}","starred_url":"https://api.github.com/users/rfarivar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rfarivar/subscriptions","organizations_url":"https://api.github.com/users/rfarivar/orgs","repos_url":"https://api.github.com/users/rfarivar/repos","events_url":"https://api.github.com/users/rfarivar/events{/privacy}","received_events_url":"https://api.github.com/users/rfarivar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:02:08Z","updated_at":"2015-12-14T20:02:08Z","author_association":"CONTRIBUTOR","body":"+1\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164543211/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687517","html_url":"https://github.com/apache/storm/issues/5218#issuecomment-2612687517","issue_url":"https://api.github.com/repos/apache/storm/issues/5218","id":2612687517,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODc1MTc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:02:09Z","updated_at":"2025-01-24T14:38:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/938#issuecomment-164543211\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/938#issuecomment-164543211</a></p>\n\n<p>    +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687517/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685329","html_url":"https://github.com/apache/storm/issues/5207#issuecomment-2612685329","issue_url":"https://api.github.com/repos/apache/storm/issues/5207","id":2612685329,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODUzMjk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:02:41Z","updated_at":"2025-01-24T14:37:56Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/945#discussion_r47549837\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/945#discussion_r47549837</a></p>\n\n<p>    &#8212; Diff: docs/documentation/distcache-blobstore.md &#8212;<br/>\n    @@ -0,0 +1,732 @@<br/>\n    +# Storm Distributed Cache API<br/>\n    +<br/>\n    +The distributed cache feature in storm is used to efficiently distribute files<br/>\n    +(or blobs, which is the equivalent terminology for a file in the distributed<br/>\n    +cache and is used interchangeably in this document) that are large and can<br/>\n    +change during the lifetime of a topology, such as geo-location data,<br/>\n    +dictionaries, etc. Typical use cases include phrase recognition, entity<br/>\n    +extraction, document classification, URL re-writing, location/address detection<br/>\n    +and so forth. Such files may be several KB to several GB in size. For small<br/>\n    +datasets that don't need dynamic updates, including them in the topology jar<br/>\n    +could be fine. But for large files, the startup times could become very large.<br/>\n    +In these cases, the distributed cache feature can provide fast topology startup,<br/>\n    +especially if the files were previously downloaded for the same submitter and<br/>\n    +are still in the cache. This is useful with frequent deployments, sometimes few<br/>\n    +times a day with updated jars, because the large cached files will remain available<br/>\n    +without changes. The large cached blobs that do not change frequently will<br/>\n    +remain available in the distributed cache.<br/>\n    +<br/>\n    +At the starting time of a topology, the user specifies the set of files the<br/>\n    +topology needs. Once a topology is running, the user at any time can request for<br/>\n    +any file in the distributed cache to be updated with a newer version. The<br/>\n    +updating of blobs happens in an eventual consistency model. If the topology<br/>\n    +needs to know what version of a file it has access to, it is the responsibility<br/>\n    +of the user to find this information out. The files are stored in a cache with<br/>\n    +Least-Recently Used (LRU) eviction policy, where the supervisor decides which<br/>\n    +cached files are no longer needed and can delete them to free disk space. The<br/>\n    +blobs can be compressed, and the user can request the blobs to be uncompressed<br/>\n    +before it accesses them.<br/>\n    +<br/>\n    +## Motivation for Distributed Cache<br/>\n    +* Allows sharing blobs among topologies.<br/>\n    +* Allows updating the blobs from the command line.<br/>\n    +<br/>\n    +## Distributed Cache Implementations<br/>\n    +The current BlobStore interface has the following two implementations<br/>\n    +* LocalFsBlobStore<br/>\n    +* HdfsBlobStore<br/>\n    +<br/>\n    +Appendix A contains the interface for blob store implementation.<br/>\n    +<br/>\n    +## LocalFsBlobStore<br/>\n    +!<span class=\"error\">&#91;LocalFsBlobStore&#93;</span>(images/local_blobstore.png)<br/>\n    +<br/>\n    +Local file system implementation of Blobstore can be depicted in the above timeline diagram.<br/>\n    +<br/>\n    +There are several stages from blob creation to blob download and corresponding execution of a topology. <br/>\n    +The main stages can be depicted as follows<br/>\n    +<br/>\n    +### Blob Creation Command<br/>\n    +Blobs in the blobstore can be created through command line using the following command.<br/>\n    +storm blobstore create --file README.txt --acl o::rwa --repl-fctr 4 key1<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Please quite this with '`' characters so the formatting looks correct.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685329/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630914","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630914","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630914,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5MTQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:02:47Z","updated_at":"2025-01-24T14:14:03Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user arunmahadevan commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47549853\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47549853</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -0,0 +1,654 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +import java.io.IOException;<br/>\n    +import java.lang.reflect.Constructor;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Timer;<br/>\n    +import java.util.TimerTask;<br/>\n    +import java.util.concurrent.LinkedBlockingQueue;<br/>\n    +import java.util.concurrent.atomic.AtomicBoolean;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import org.apache.hadoop.conf.Configuration;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.storm.hdfs.common.HdfsUtils;<br/>\n    +import org.apache.storm.hdfs.common.security.HdfsSecurityUtil;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +<br/>\n    +public class HdfsSpout extends BaseRichSpout {<br/>\n    +<br/>\n    +  private static final Logger LOG = LoggerFactory.getLogger(HdfsSpout.class);<br/>\n    +<br/>\n    +  private Path sourceDirPath;<br/>\n    +  private Path archiveDirPath;<br/>\n    +  private Path badFilesDirPath;<br/>\n    +  private Path lockDirPath;<br/>\n    +<br/>\n    +  private int commitFrequencyCount = Configs.DEFAULT_COMMIT_FREQ_COUNT;<br/>\n    +  private int commitFrequencySec = Configs.DEFAULT_COMMIT_FREQ_SEC;<br/>\n    +  private int maxDuplicates = Configs.DEFAULT_MAX_DUPLICATES;<br/>\n    +  private int lockTimeoutSec = Configs.DEFAULT_LOCK_TIMEOUT;<br/>\n    +  private boolean clocksInSync = true;<br/>\n    +<br/>\n    +  private ProgressTracker tracker = new ProgressTracker();<br/>\n    +<br/>\n    +  private FileSystem hdfs;<br/>\n    +  private FileReader reader;<br/>\n    +<br/>\n    +  private SpoutOutputCollector collector;<br/>\n    +  HashMap<MessageId, List<Object> > inflight = new HashMap<>();<br/>\n    +  LinkedBlockingQueue<HdfsUtils.Pair<MessageId, List<Object>>> retryList = new LinkedBlockingQueue<>();<br/>\n    +<br/>\n    +  private String inprogress_suffix = \".inprogress\";<br/>\n    +  private String ignoreSuffix = \".ignore\";<br/>\n    +<br/>\n    +  private Configuration hdfsConfig;<br/>\n    +  private String readerType;<br/>\n    +<br/>\n    +  private Map conf = null;<br/>\n    +  private FileLock lock;<br/>\n    +  private String spoutId = null;<br/>\n    +<br/>\n    +  HdfsUtils.Pair<Path,FileLock.LogEntry> lastExpiredLock = null;<br/>\n    +  private long lastExpiredLockTime = 0;<br/>\n    +<br/>\n    +  private long tupleCounter = 0;<br/>\n    +  private boolean ackEnabled = false;<br/>\n    +  private int acksSinceLastCommit = 0 ;<br/>\n    +  private final AtomicBoolean commitTimeElapsed = new AtomicBoolean(false);<br/>\n    +  private final Timer commitTimer = new Timer();<br/>\n    +  private boolean fileReadCompletely = false;<br/>\n    +<br/>\n    +  private String configKey = Configs.DEFAULT_HDFS_CONFIG_KEY; // key for hdfs kerberos configs<br/>\n    +<br/>\n    +  public HdfsSpout() </p>\n{\n    +  }\n<p>    +<br/>\n    +  public Path getLockDirPath() </p>\n{\n    +    return lockDirPath;\n    +  }\n<p>    +<br/>\n    +  public SpoutOutputCollector getCollector() </p>\n{\n    +    return collector;\n    +  }\n<p>    +<br/>\n    +  public HdfsSpout withConfigKey(String configKey)</p>\n{\n    +    this.configKey = configKey;\n    +    return this;\n    +  }\n<p>    +<br/>\n    +  public void nextTuple() {<br/>\n    +    LOG.debug(\"Next Tuple\");<br/>\n    +    // 1) First re-emit any previously failed tuples (from retryList)<br/>\n    +    if (!retryList.isEmpty()) </p>\n{\n    +      LOG.debug(\"Sending from retry list\");\n    +      HdfsUtils.Pair<MessageId, List<Object>> pair = retryList.remove();\n    +      emitData(pair.getValue(), pair.getKey());\n    +      return;\n    +    }\n<p>    +<br/>\n    +    if( ackEnabled  &&  tracker.size()>=maxDuplicates ) {<br/>\n    +      LOG.warn(\"Waiting for more ACKs before generating new tuples. \" +<br/>\n    +       \"Progress tracker size has reached limit {}\"<br/>\n    +      , maxDuplicates);<br/>\n    +      // Don't emit anything .. allow configured spout wait strategy to kick in<br/>\n    +      return;<br/>\n    +    }<br/>\n    +<br/>\n    +    // 2) If no failed tuples, then send tuples from hdfs<br/>\n    +    while (true) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    `nextTuple` is already called in a tight loop, so another loop is not required here.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630914/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164543714","html_url":"https://github.com/apache/storm/pull/945#issuecomment-164543714","issue_url":"https://api.github.com/repos/apache/storm/issues/945","id":164543714,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0MzcxNA==","user":{"login":"revans2","id":3441321,"node_id":"MDQ6VXNlcjM0NDEzMjE=","avatar_url":"https://avatars.githubusercontent.com/u/3441321?v=4","gravatar_id":"","url":"https://api.github.com/users/revans2","html_url":"https://github.com/revans2","followers_url":"https://api.github.com/users/revans2/followers","following_url":"https://api.github.com/users/revans2/following{/other_user}","gists_url":"https://api.github.com/users/revans2/gists{/gist_id}","starred_url":"https://api.github.com/users/revans2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/revans2/subscriptions","organizations_url":"https://api.github.com/users/revans2/orgs","repos_url":"https://api.github.com/users/revans2/repos","events_url":"https://api.github.com/users/revans2/events{/privacy}","received_events_url":"https://api.github.com/users/revans2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:03:40Z","updated_at":"2015-12-14T20:03:40Z","author_association":"CONTRIBUTOR","body":"Done with my first pass through the doc.  Most things look good.  A few minor issues.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164543714/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685345","html_url":"https://github.com/apache/storm/issues/5207#issuecomment-2612685345","issue_url":"https://api.github.com/repos/apache/storm/issues/5207","id":2612685345,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODUzNDU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:03:41Z","updated_at":"2025-01-24T14:37:56Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/945#issuecomment-164543714\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/945#issuecomment-164543714</a></p>\n\n<p>    Done with my first pass through the doc.  Most things look good.  A few minor issues.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685345/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164546402","html_url":"https://github.com/apache/storm/pull/648#issuecomment-164546402","issue_url":"https://api.github.com/repos/apache/storm/issues/648","id":164546402,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0NjQwMg==","user":{"login":"ppoulosk","id":4550393,"node_id":"MDQ6VXNlcjQ1NTAzOTM=","avatar_url":"https://avatars.githubusercontent.com/u/4550393?v=4","gravatar_id":"","url":"https://api.github.com/users/ppoulosk","html_url":"https://github.com/ppoulosk","followers_url":"https://api.github.com/users/ppoulosk/followers","following_url":"https://api.github.com/users/ppoulosk/following{/other_user}","gists_url":"https://api.github.com/users/ppoulosk/gists{/gist_id}","starred_url":"https://api.github.com/users/ppoulosk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ppoulosk/subscriptions","organizations_url":"https://api.github.com/users/ppoulosk/orgs","repos_url":"https://api.github.com/users/ppoulosk/repos","events_url":"https://api.github.com/users/ppoulosk/events{/privacy}","received_events_url":"https://api.github.com/users/ppoulosk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:13:22Z","updated_at":"2015-12-14T20:13:22Z","author_association":"CONTRIBUTOR","body":"+1 NB\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164546402/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612482521","html_url":"https://github.com/apache/storm/issues/4282#issuecomment-2612482521","issue_url":"https://api.github.com/repos/apache/storm/issues/4282","id":2612482521,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI0ODI1MjE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:13:24Z","updated_at":"2025-01-24T13:02:34Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user ppoulosk commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/648#issuecomment-164546402\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/648#issuecomment-164546402</a></p>\n\n<p>    +1 NB</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612482521/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164547193","html_url":"https://github.com/apache/storm/pull/934#issuecomment-164547193","issue_url":"https://api.github.com/repos/apache/storm/issues/934","id":164547193,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0NzE5Mw==","user":{"login":"revans2","id":3441321,"node_id":"MDQ6VXNlcjM0NDEzMjE=","avatar_url":"https://avatars.githubusercontent.com/u/3441321?v=4","gravatar_id":"","url":"https://api.github.com/users/revans2","html_url":"https://github.com/revans2","followers_url":"https://api.github.com/users/revans2/followers","following_url":"https://api.github.com/users/revans2/following{/other_user}","gists_url":"https://api.github.com/users/revans2/gists{/gist_id}","starred_url":"https://api.github.com/users/revans2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/revans2/subscriptions","organizations_url":"https://api.github.com/users/revans2/orgs","repos_url":"https://api.github.com/users/revans2/repos","events_url":"https://api.github.com/users/revans2/events{/privacy}","received_events_url":"https://api.github.com/users/revans2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:16:40Z","updated_at":"2015-12-14T20:16:40Z","author_association":"CONTRIBUTOR","body":"@redsanket I don't like this example.   I really would prefer to see an example that is realistic to how we want users to interact with the blob storm.  A blob store spout is something I would discourage people from using.\n\nCould we do something like a blacklist file that is added to the blob store at the beginning of the run.  Then a filter bolt would read in the file every n seconds from off of disk and throw away any words/tuples that appeared in the file.  In the middle of the example we can have code that updates the blob, like you have to show the blacklist changing part way through.\n\nIn the examples that interact with the blob store we could show the command line that would do the same thing, so they don't have to write code if they don't want to.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164547193/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685708","html_url":"https://github.com/apache/storm/issues/5208#issuecomment-2612685708","issue_url":"https://api.github.com/repos/apache/storm/issues/5208","id":2612685708,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODU3MDg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:16:41Z","updated_at":"2025-01-24T14:38:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/934#issuecomment-164547193\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/934#issuecomment-164547193</a></p>\n\n<p>    @redsanket I don't like this example.   I really would prefer to see an example that is realistic to how we want users to interact with the blob storm.  A blob store spout is something I would discourage people from using.</p>\n\n<p>    Could we do something like a blacklist file that is added to the blob store at the beginning of the run.  Then a filter bolt would read in the file every n seconds from off of disk and throw away any words/tuples that appeared in the file.  In the middle of the example we can have code that updates the blob, like you have to show the blacklist changing part way through.</p>\n\n<p>    In the examples that interact with the blob store we could show the command line that would do the same thing, so they don't have to write code if they don't want to.</p>\n\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685708/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164547338","html_url":"https://github.com/apache/storm/pull/946#issuecomment-164547338","issue_url":"https://api.github.com/repos/apache/storm/issues/946","id":164547338,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0NzMzOA==","user":{"login":"ppoulosk","id":4550393,"node_id":"MDQ6VXNlcjQ1NTAzOTM=","avatar_url":"https://avatars.githubusercontent.com/u/4550393?v=4","gravatar_id":"","url":"https://api.github.com/users/ppoulosk","html_url":"https://github.com/ppoulosk","followers_url":"https://api.github.com/users/ppoulosk/followers","following_url":"https://api.github.com/users/ppoulosk/following{/other_user}","gists_url":"https://api.github.com/users/ppoulosk/gists{/gist_id}","starred_url":"https://api.github.com/users/ppoulosk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ppoulosk/subscriptions","organizations_url":"https://api.github.com/users/ppoulosk/orgs","repos_url":"https://api.github.com/users/ppoulosk/repos","events_url":"https://api.github.com/users/ppoulosk/events{/privacy}","received_events_url":"https://api.github.com/users/ppoulosk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:17:19Z","updated_at":"2015-12-14T20:17:19Z","author_association":"CONTRIBUTOR","body":"+1, NB\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164547338/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688439","html_url":"https://github.com/apache/storm/issues/5224#issuecomment-2612688439","issue_url":"https://api.github.com/repos/apache/storm/issues/5224","id":2612688439,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODg0Mzk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:17:20Z","updated_at":"2025-01-24T14:39:15Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user ppoulosk commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/946#issuecomment-164547338\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/946#issuecomment-164547338</a></p>\n\n<p>    +1, NB</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688439/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612482525","html_url":"https://github.com/apache/storm/issues/4282#issuecomment-2612482525","issue_url":"https://api.github.com/repos/apache/storm/issues/4282","id":2612482525,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI0ODI1MjU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:23:19Z","updated_at":"2025-01-24T13:02:34Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/648#discussion_r47552355\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/648#discussion_r47552355</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/backtype/storm/utils/NimbusClient.java &#8212;<br/>\n    @@ -30,11 +30,18 @@<br/>\n private Nimbus.Client _client;<br/>\n private static final Logger LOG = LoggerFactory.getLogger(NimbusClient.class);</p>\n\n<p>    +    public static NimbusClient getConfiguredClient() </p>\n{\n    +      return getConfiguredClient(null);\n    +    }\n\n<p> public static NimbusClient getConfiguredClient(Map conf) {</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>try {</li>\n\t<li>String nimbusHost = (String) conf.get(Config.NIMBUS_HOST);</li>\n\t<li>return new NimbusClient(conf, nimbusHost);<br/>\n    +      try {<br/>\n    +Map fullConf = Utils.readStormConfig();<br/>\n    +if (conf != null) \n{\n    + fullConf.putAll(conf);\n    +}\n<p>    +String nimbusHost = (String) fullConf.get(Config.NIMBUS_HOST);<br/>\n    +      return new NimbusClient(fullConf, nimbusHost);</p>\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    very minor, spacing issue.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612482525/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164548714","html_url":"https://github.com/apache/storm/pull/648#issuecomment-164548714","issue_url":"https://api.github.com/repos/apache/storm/issues/648","id":164548714,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0ODcxNA==","user":{"login":"revans2","id":3441321,"node_id":"MDQ6VXNlcjM0NDEzMjE=","avatar_url":"https://avatars.githubusercontent.com/u/3441321?v=4","gravatar_id":"","url":"https://api.github.com/users/revans2","html_url":"https://github.com/revans2","followers_url":"https://api.github.com/users/revans2/followers","following_url":"https://api.github.com/users/revans2/following{/other_user}","gists_url":"https://api.github.com/users/revans2/gists{/gist_id}","starred_url":"https://api.github.com/users/revans2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/revans2/subscriptions","organizations_url":"https://api.github.com/users/revans2/orgs","repos_url":"https://api.github.com/users/revans2/repos","events_url":"https://api.github.com/users/revans2/events{/privacy}","received_events_url":"https://api.github.com/users/revans2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:23:29Z","updated_at":"2015-12-14T20:23:29Z","author_association":"CONTRIBUTOR","body":"+1 needs to be upmerged though.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164548714/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612482532","html_url":"https://github.com/apache/storm/issues/4282#issuecomment-2612482532","issue_url":"https://api.github.com/repos/apache/storm/issues/4282","id":2612482532,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI0ODI1MzI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:23:30Z","updated_at":"2025-01-24T13:02:34Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/648#issuecomment-164548714\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/648#issuecomment-164548714</a></p>\n\n<p>    +1 needs to be upmerged though.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612482532/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164549893","html_url":"https://github.com/apache/storm/pull/623#issuecomment-164549893","issue_url":"https://api.github.com/repos/apache/storm/issues/623","id":164549893,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU0OTg5Mw==","user":{"login":"ppoulosk","id":4550393,"node_id":"MDQ6VXNlcjQ1NTAzOTM=","avatar_url":"https://avatars.githubusercontent.com/u/4550393?v=4","gravatar_id":"","url":"https://api.github.com/users/ppoulosk","html_url":"https://github.com/ppoulosk","followers_url":"https://api.github.com/users/ppoulosk/followers","following_url":"https://api.github.com/users/ppoulosk/following{/other_user}","gists_url":"https://api.github.com/users/ppoulosk/gists{/gist_id}","starred_url":"https://api.github.com/users/ppoulosk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ppoulosk/subscriptions","organizations_url":"https://api.github.com/users/ppoulosk/orgs","repos_url":"https://api.github.com/users/ppoulosk/repos","events_url":"https://api.github.com/users/ppoulosk/events{/privacy}","received_events_url":"https://api.github.com/users/ppoulosk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:28:31Z","updated_at":"2015-12-14T20:28:31Z","author_association":"CONTRIBUTOR","body":"I'm don't understand why this change is necessary, and why we would want to enable DEBUG in this script for all users.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164549893/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612577608","html_url":"https://github.com/apache/storm/issues/4765#issuecomment-2612577608","issue_url":"https://api.github.com/repos/apache/storm/issues/4765","id":2612577608,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1Nzc2MDg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:28:33Z","updated_at":"2025-01-24T13:50:35Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user ppoulosk commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/623#issuecomment-164549893\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/623#issuecomment-164549893</a></p>\n\n<p>    I'm don't understand why this change is necessary, and why we would want to enable DEBUG in this script for all users.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612577608/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164550849","html_url":"https://github.com/apache/storm/pull/623#issuecomment-164550849","issue_url":"https://api.github.com/repos/apache/storm/issues/623","id":164550849,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU1MDg0OQ==","user":{"login":"DevInsanity","id":906231,"node_id":"MDQ6VXNlcjkwNjIzMQ==","avatar_url":"https://avatars.githubusercontent.com/u/906231?v=4","gravatar_id":"","url":"https://api.github.com/users/DevInsanity","html_url":"https://github.com/DevInsanity","followers_url":"https://api.github.com/users/DevInsanity/followers","following_url":"https://api.github.com/users/DevInsanity/following{/other_user}","gists_url":"https://api.github.com/users/DevInsanity/gists{/gist_id}","starred_url":"https://api.github.com/users/DevInsanity/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DevInsanity/subscriptions","organizations_url":"https://api.github.com/users/DevInsanity/orgs","repos_url":"https://api.github.com/users/DevInsanity/repos","events_url":"https://api.github.com/users/DevInsanity/events{/privacy}","received_events_url":"https://api.github.com/users/DevInsanity/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:32:38Z","updated_at":"2015-12-14T20:32:38Z","author_association":"NONE","body":"@ppoulosk Without the quotes, debug mode doesn't work if java is in a path with spaces. Debug mode is being forced for the jar subcommand only, since it makes it possible to use it from other scripts (as otherwise, the act of deploying the topology gets backgrounded and you can't check return values from it).\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164550849/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612577609","html_url":"https://github.com/apache/storm/issues/4765#issuecomment-2612577609","issue_url":"https://api.github.com/repos/apache/storm/issues/4765","id":2612577609,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1Nzc2MDk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:32:39Z","updated_at":"2025-01-24T13:50:35Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user DevInsanity commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/623#issuecomment-164550849\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/623#issuecomment-164550849</a></p>\n\n<p>    @ppoulosk Without the quotes, debug mode doesn't work if java is in a path with spaces. Debug mode is being forced for the jar subcommand only, since it makes it possible to use it from other scripts (as otherwise, the act of deploying the topology gets backgrounded and you can't check return values from it).</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612577609/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164551153","html_url":"https://github.com/apache/storm/pull/885#issuecomment-164551153","issue_url":"https://api.github.com/repos/apache/storm/issues/885","id":164551153,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU1MTE1Mw==","user":{"login":"ppoulosk","id":4550393,"node_id":"MDQ6VXNlcjQ1NTAzOTM=","avatar_url":"https://avatars.githubusercontent.com/u/4550393?v=4","gravatar_id":"","url":"https://api.github.com/users/ppoulosk","html_url":"https://github.com/ppoulosk","followers_url":"https://api.github.com/users/ppoulosk/followers","following_url":"https://api.github.com/users/ppoulosk/following{/other_user}","gists_url":"https://api.github.com/users/ppoulosk/gists{/gist_id}","starred_url":"https://api.github.com/users/ppoulosk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ppoulosk/subscriptions","organizations_url":"https://api.github.com/users/ppoulosk/orgs","repos_url":"https://api.github.com/users/ppoulosk/repos","events_url":"https://api.github.com/users/ppoulosk/events{/privacy}","received_events_url":"https://api.github.com/users/ppoulosk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:34:00Z","updated_at":"2015-12-14T20:34:00Z","author_association":"CONTRIBUTOR","body":"+1, NB\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164551153/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612632827","html_url":"https://github.com/apache/storm/issues/5048#issuecomment-2612632827","issue_url":"https://api.github.com/repos/apache/storm/issues/5048","id":2612632827,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzI4Mjc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:34:01Z","updated_at":"2025-01-24T14:14:53Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user ppoulosk commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/885#issuecomment-164551153\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/885#issuecomment-164551153</a></p>\n\n<p>    +1, NB</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612632827/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164551230","html_url":"https://github.com/apache/storm/pull/938#issuecomment-164551230","issue_url":"https://api.github.com/repos/apache/storm/issues/938","id":164551230,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU1MTIzMA==","user":{"login":"revans2","id":3441321,"node_id":"MDQ6VXNlcjM0NDEzMjE=","avatar_url":"https://avatars.githubusercontent.com/u/3441321?v=4","gravatar_id":"","url":"https://api.github.com/users/revans2","html_url":"https://github.com/revans2","followers_url":"https://api.github.com/users/revans2/followers","following_url":"https://api.github.com/users/revans2/following{/other_user}","gists_url":"https://api.github.com/users/revans2/gists{/gist_id}","starred_url":"https://api.github.com/users/revans2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/revans2/subscriptions","organizations_url":"https://api.github.com/users/revans2/orgs","repos_url":"https://api.github.com/users/revans2/repos","events_url":"https://api.github.com/users/revans2/events{/privacy}","received_events_url":"https://api.github.com/users/revans2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:34:23Z","updated_at":"2015-12-14T20:34:23Z","author_association":"CONTRIBUTOR","body":"@d2r The basic change to handling exceptions when nimbus is not available seems good, but I am not convinced of adding in the NimbusLeaderNotFoundException.  This breaks API compatibility, but oddly enough not binary compatibility.  I just want to be 100% sure that this is the change we want to make before we do this. The main reason I ask is because internally the only way we handle this differently from before is either we catch it and wrap it in a RuntimeException, or we log it, similar to what we did before, but with a bit more text specific to the exception.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164551230/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687522","html_url":"https://github.com/apache/storm/issues/5218#issuecomment-2612687522","issue_url":"https://api.github.com/repos/apache/storm/issues/5218","id":2612687522,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODc1MjI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:34:25Z","updated_at":"2025-01-24T14:38:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/938#issuecomment-164551230\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/938#issuecomment-164551230</a></p>\n\n<p>    @d2r The basic change to handling exceptions when nimbus is not available seems good, but I am not convinced of adding in the NimbusLeaderNotFoundException.  This breaks API compatibility, but oddly enough not binary compatibility.  I just want to be 100% sure that this is the change we want to make before we do this. The main reason I ask is because internally the only way we handle this differently from before is either we catch it and wrap it in a RuntimeException, or we log it, similar to what we did before, but with a bit more text specific to the exception.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687522/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164554443","html_url":"https://github.com/apache/storm/pull/938#issuecomment-164554443","issue_url":"https://api.github.com/repos/apache/storm/issues/938","id":164554443,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU1NDQ0Mw==","user":{"login":"d2r","id":905298,"node_id":"MDQ6VXNlcjkwNTI5OA==","avatar_url":"https://avatars.githubusercontent.com/u/905298?v=4","gravatar_id":"","url":"https://api.github.com/users/d2r","html_url":"https://github.com/d2r","followers_url":"https://api.github.com/users/d2r/followers","following_url":"https://api.github.com/users/d2r/following{/other_user}","gists_url":"https://api.github.com/users/d2r/gists{/gist_id}","starred_url":"https://api.github.com/users/d2r/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/d2r/subscriptions","organizations_url":"https://api.github.com/users/d2r/orgs","repos_url":"https://api.github.com/users/d2r/repos","events_url":"https://api.github.com/users/d2r/events{/privacy}","received_events_url":"https://api.github.com/users/d2r/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:46:04Z","updated_at":"2015-12-14T20:46:04Z","author_association":"NONE","body":"> This breaks API compatibility, but oddly enough not binary compatibility.\n\nHadn't thought about breaking compilation in user code that was using the nimbus client.  I will make the new exception a RuntimeException.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164554443/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687526","html_url":"https://github.com/apache/storm/issues/5218#issuecomment-2612687526","issue_url":"https://api.github.com/repos/apache/storm/issues/5218","id":2612687526,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODc1MjY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:46:06Z","updated_at":"2025-01-24T14:38:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user d2r commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/938#issuecomment-164554443\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/938#issuecomment-164554443</a></p>\n\n<p>    > This breaks API compatibility, but oddly enough not binary compatibility.</p>\n\n<p>    Hadn't thought about breaking compilation in user code that was using the nimbus client.  I will make the new exception a RuntimeException.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687526/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164554611","html_url":"https://github.com/apache/storm/pull/938#issuecomment-164554611","issue_url":"https://api.github.com/repos/apache/storm/issues/938","id":164554611,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU1NDYxMQ==","user":{"login":"revans2","id":3441321,"node_id":"MDQ6VXNlcjM0NDEzMjE=","avatar_url":"https://avatars.githubusercontent.com/u/3441321?v=4","gravatar_id":"","url":"https://api.github.com/users/revans2","html_url":"https://github.com/revans2","followers_url":"https://api.github.com/users/revans2/followers","following_url":"https://api.github.com/users/revans2/following{/other_user}","gists_url":"https://api.github.com/users/revans2/gists{/gist_id}","starred_url":"https://api.github.com/users/revans2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/revans2/subscriptions","organizations_url":"https://api.github.com/users/revans2/orgs","repos_url":"https://api.github.com/users/revans2/repos","events_url":"https://api.github.com/users/revans2/events{/privacy}","received_events_url":"https://api.github.com/users/revans2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:46:52Z","updated_at":"2015-12-14T20:46:52Z","author_association":"CONTRIBUTOR","body":"@d2r +1 for that modification. \n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164554611/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687533","html_url":"https://github.com/apache/storm/issues/5218#issuecomment-2612687533","issue_url":"https://api.github.com/repos/apache/storm/issues/5218","id":2612687533,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODc1MzM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T20:46:52Z","updated_at":"2025-01-24T14:38:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/938#issuecomment-164554611\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/938#issuecomment-164554611</a></p>\n\n<p>    @d2r +1 for that modification. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687533/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628644","html_url":"https://github.com/apache/storm/issues/5025#issuecomment-2612628644","issue_url":"https://api.github.com/repos/apache/storm/issues/5025","id":2612628644,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2Mjg2NDQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T21:05:30Z","updated_at":"2025-01-24T14:13:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user Parth-Brahmbhatt commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/900#discussion_r47557478\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/900#discussion_r47557478</a></p>\n\n<p>    &#8212; Diff: docs/documentation/Windowing.md &#8212;<br/>\n    @@ -126,6 +126,96 @@ Time duration based tumbling window that tumbles after the specified time durati</p>\n\n<p>     ```</p>\n\n<p>    +## Tuple timestamp and out of order tuples<br/>\n    +By default the timestamp tracked in the window is the time when the tuple is processed by the bolt. The window calculations<br/>\n    +are performed based on the processing timestamp. Storm has support for tracking windows based on the source generated timestamp.<br/>\n    +<br/>\n    +```java<br/>\n    +/**<br/>\n    +* Specify a field in the tuple that represents the timestamp as a long value. If this<br/>\n    +* field is not present in the incoming tuple, an </p>\n{@link IllegalArgumentException}\n<p> will be thrown.<br/>\n    +*<br/>\n    +* @param fieldName the name of the field that contains the timestamp<br/>\n    +*/<br/>\n    +public BaseWindowedBolt withTimestampField(String fieldName)<br/>\n    +```<br/>\n    +<br/>\n    +The value for the above `fieldName` will be looked up from the incoming tuple and considered for windowing calculations. <br/>\n    +If the field is not present in the tuple an exception will be thrown. Along with the timestamp field name, a time lag parameter <br/>\n    +can also be specified which indicates the max time limit for tuples with out of order timestamps. <br/>\n    +<br/>\n    +E.g. If the lag is 5 secs and a tuple `t1` arrived with timestamp `06:00:05` no tuples may arrive with tuple timestamp earlier than `06:00:00`. If a tuple<br/>\n    +arrives with timestamp 05:59:59 after `t1` and the window has moved past `t1`, it will be treated as a late tuple and not processed. <br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Lets also document how users can find out number of discarded tuples? In many cases it may also be useful to provide a handler for tuples being discarded but I am fine with not including that in this patch.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628644/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164559792","html_url":"https://github.com/apache/storm/pull/938#issuecomment-164559792","issue_url":"https://api.github.com/repos/apache/storm/issues/938","id":164559792,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU1OTc5Mg==","user":{"login":"d2r","id":905298,"node_id":"MDQ6VXNlcjkwNTI5OA==","avatar_url":"https://avatars.githubusercontent.com/u/905298?v=4","gravatar_id":"","url":"https://api.github.com/users/d2r","html_url":"https://github.com/d2r","followers_url":"https://api.github.com/users/d2r/followers","following_url":"https://api.github.com/users/d2r/following{/other_user}","gists_url":"https://api.github.com/users/d2r/gists{/gist_id}","starred_url":"https://api.github.com/users/d2r/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/d2r/subscriptions","organizations_url":"https://api.github.com/users/d2r/orgs","repos_url":"https://api.github.com/users/d2r/repos","events_url":"https://api.github.com/users/d2r/events{/privacy}","received_events_url":"https://api.github.com/users/d2r/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T21:06:15Z","updated_at":"2015-12-14T21:06:15Z","author_association":"NONE","body":"OK, replaced the branch so the new exception is a RuntimeException, so we do not have to handle it in code that uses the nimbus client.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164559792/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687543","html_url":"https://github.com/apache/storm/issues/5218#issuecomment-2612687543","issue_url":"https://api.github.com/repos/apache/storm/issues/5218","id":2612687543,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODc1NDM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T21:06:18Z","updated_at":"2025-01-24T14:38:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user d2r commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/938#issuecomment-164559792\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/938#issuecomment-164559792</a></p>\n\n<p>    OK, replaced the branch so the new exception is a RuntimeException, so we do not have to handle it in code that uses the nimbus client.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687543/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628649","html_url":"https://github.com/apache/storm/issues/5025#issuecomment-2612628649","issue_url":"https://api.github.com/repos/apache/storm/issues/5025","id":2612628649,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2Mjg2NDk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T21:21:35Z","updated_at":"2025-01-24T14:13:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user Parth-Brahmbhatt commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/900#discussion_r47559536\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/900#discussion_r47559536</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/backtype/storm/windowing/WaterMarkEventGenerator.java &#8212;<br/>\n    @@ -0,0 +1,110 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package backtype.storm.windowing;<br/>\n    +<br/>\n    +import backtype.storm.generated.GlobalStreamId;<br/>\n    +import backtype.storm.topology.FailedException;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Set;<br/>\n    +import java.util.concurrent.ConcurrentHashMap;<br/>\n    +import java.util.concurrent.ExecutionException;<br/>\n    +import java.util.concurrent.Executors;<br/>\n    +import java.util.concurrent.ScheduledExecutorService;<br/>\n    +import java.util.concurrent.ScheduledFuture;<br/>\n    +import java.util.concurrent.TimeUnit;<br/>\n    +<br/>\n    +/**<br/>\n    + * Tracks tuples across input streams and periodically emits watermark events.<br/>\n    + * Watermark event timestamp is the minimum of the latest tuple timestamps<br/>\n    + * across all the input streams (minus the lag). Once a watermark event is emitted<br/>\n    + * any tuple coming with an earlier timestamp can be considered as late events.<br/>\n    + */<br/>\n    +public class WaterMarkEventGenerator<T> implements Runnable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(WaterMarkEventGenerator.class);<br/>\n    +    private final WindowManager<T> windowManager;<br/>\n    +    private final int eventTsLag;<br/>\n    +    private final Set<GlobalStreamId> inputStreams;<br/>\n    +    private final Map<GlobalStreamId, Long> streamToTs;<br/>\n    +    private final ScheduledExecutorService executorService;<br/>\n    +    private final ScheduledFuture<?> executorFuture;<br/>\n    +    private long lastWaterMarkTs = 0;<br/>\n    +<br/>\n    +    public WaterMarkEventGenerator(WindowManager<T> windowManager, int interval,<br/>\n    +   int eventTsLag, Set<GlobalStreamId> inputStreams) </p>\n{\n    +this.windowManager = windowManager;\n    +streamToTs = new ConcurrentHashMap<>();\n    +executorService = Executors.newSingleThreadScheduledExecutor();\n    +this.executorFuture = executorService.scheduleAtFixedRate(this, interval, interval, TimeUnit.MILLISECONDS);\n    +this.eventTsLag = eventTsLag;\n    +this.inputStreams = inputStreams;\n    +    }\n<p>    +<br/>\n    +    public void track(GlobalStreamId stream, long ts) {<br/>\n    +Long currentVal = streamToTs.get(stream);<br/>\n    +if (currentVal == null || ts > currentVal) </p>\n{\n    +    streamToTs.put(stream, ts);\n    +}\n<p>    +checkFailures();<br/>\n    +    }<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public void run() {<br/>\n    +try {<br/>\n    +    long waterMarkTs = computeWaterMarkTs();<br/>\n    +    if (waterMarkTs > lastWaterMarkTs) </p>\n{\n    +this.windowManager.add(new WaterMarkEvent<T>(waterMarkTs - eventTsLag));\n    +lastWaterMarkTs = waterMarkTs;\n    +    }\n<p>    +} catch (Throwable th) </p>\n{\n    +    LOG.error(\"Failed while processing watermark event \", th);\n    +    throw th;\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    /**<br/>\n    +     * Computes the min ts across all streams.<br/>\n    +     */<br/>\n    +    private long computeWaterMarkTs() {<br/>\n    +long ts = Long.MIN_VALUE;<br/>\n    +// only if some data has arrived on each input stream<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    why do we have to wait for data to arrive on each input stream? </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628649/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164565516","html_url":"https://github.com/apache/storm/pull/900#issuecomment-164565516","issue_url":"https://api.github.com/repos/apache/storm/issues/900","id":164565516,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU2NTUxNg==","user":{"login":"Parth-Brahmbhatt","id":6914358,"node_id":"MDQ6VXNlcjY5MTQzNTg=","avatar_url":"https://avatars.githubusercontent.com/u/6914358?v=4","gravatar_id":"","url":"https://api.github.com/users/Parth-Brahmbhatt","html_url":"https://github.com/Parth-Brahmbhatt","followers_url":"https://api.github.com/users/Parth-Brahmbhatt/followers","following_url":"https://api.github.com/users/Parth-Brahmbhatt/following{/other_user}","gists_url":"https://api.github.com/users/Parth-Brahmbhatt/gists{/gist_id}","starred_url":"https://api.github.com/users/Parth-Brahmbhatt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Parth-Brahmbhatt/subscriptions","organizations_url":"https://api.github.com/users/Parth-Brahmbhatt/orgs","repos_url":"https://api.github.com/users/Parth-Brahmbhatt/repos","events_url":"https://api.github.com/users/Parth-Brahmbhatt/events{/privacy}","received_events_url":"https://api.github.com/users/Parth-Brahmbhatt/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T21:29:28Z","updated_at":"2015-12-14T21:29:28Z","author_association":"CONTRIBUTOR","body":"Overall I am +1. \n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164565516/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628657","html_url":"https://github.com/apache/storm/issues/5025#issuecomment-2612628657","issue_url":"https://api.github.com/repos/apache/storm/issues/5025","id":2612628657,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2Mjg2NTc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T21:29:29Z","updated_at":"2025-01-24T14:13:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user Parth-Brahmbhatt commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/900#issuecomment-164565516\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/900#issuecomment-164565516</a></p>\n\n<p>    Overall I am +1. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628657/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164567991","html_url":"https://github.com/apache/storm/pull/938#issuecomment-164567991","issue_url":"https://api.github.com/repos/apache/storm/issues/938","id":164567991,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU2Nzk5MQ==","user":{"login":"d2r","id":905298,"node_id":"MDQ6VXNlcjkwNTI5OA==","avatar_url":"https://avatars.githubusercontent.com/u/905298?v=4","gravatar_id":"","url":"https://api.github.com/users/d2r","html_url":"https://github.com/d2r","followers_url":"https://api.github.com/users/d2r/followers","following_url":"https://api.github.com/users/d2r/following{/other_user}","gists_url":"https://api.github.com/users/d2r/gists{/gist_id}","starred_url":"https://api.github.com/users/d2r/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/d2r/subscriptions","organizations_url":"https://api.github.com/users/d2r/orgs","repos_url":"https://api.github.com/users/d2r/repos","events_url":"https://api.github.com/users/d2r/events{/privacy}","received_events_url":"https://api.github.com/users/d2r/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T21:39:15Z","updated_at":"2015-12-14T21:39:15Z","author_association":"NONE","body":"Rebased to get test failure fix #925 \n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164567991/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687548","html_url":"https://github.com/apache/storm/issues/5218#issuecomment-2612687548","issue_url":"https://api.github.com/repos/apache/storm/issues/5218","id":2612687548,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODc1NDg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T21:39:16Z","updated_at":"2025-01-24T14:38:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user d2r commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/938#issuecomment-164567991\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/938#issuecomment-164567991</a></p>\n\n<p>    Rebased to get test failure fix #925 </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687548/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164574970","html_url":"https://github.com/apache/storm/pull/938#issuecomment-164574970","issue_url":"https://api.github.com/repos/apache/storm/issues/938","id":164574970,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU3NDk3MA==","user":{"login":"revans2","id":3441321,"node_id":"MDQ6VXNlcjM0NDEzMjE=","avatar_url":"https://avatars.githubusercontent.com/u/3441321?v=4","gravatar_id":"","url":"https://api.github.com/users/revans2","html_url":"https://github.com/revans2","followers_url":"https://api.github.com/users/revans2/followers","following_url":"https://api.github.com/users/revans2/following{/other_user}","gists_url":"https://api.github.com/users/revans2/gists{/gist_id}","starred_url":"https://api.github.com/users/revans2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/revans2/subscriptions","organizations_url":"https://api.github.com/users/revans2/orgs","repos_url":"https://api.github.com/users/revans2/repos","events_url":"https://api.github.com/users/revans2/events{/privacy}","received_events_url":"https://api.github.com/users/revans2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T22:06:49Z","updated_at":"2015-12-14T22:06:49Z","author_association":"CONTRIBUTOR","body":"+1 pending Travis\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164574970/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687555","html_url":"https://github.com/apache/storm/issues/5218#issuecomment-2612687555","issue_url":"https://api.github.com/repos/apache/storm/issues/5218","id":2612687555,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODc1NTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T22:06:50Z","updated_at":"2025-01-24T14:38:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/938#issuecomment-164574970\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/938#issuecomment-164574970</a></p>\n\n<p>    +1 pending Travis</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612687555/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688604","html_url":"https://github.com/apache/storm/issues/5225#issuecomment-2612688604","issue_url":"https://api.github.com/repos/apache/storm/issues/5225","id":2612688604,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODg2MDQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T22:39:25Z","updated_at":"2025-01-24T14:39:19Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/947#discussion_r47570143\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/947#discussion_r47570143</a></p>\n\n<p>    &#8212; Diff: external/flux/flux-core/src/main/java/org/apache/storm/flux/FluxBuilder.java &#8212;<br/>\n    @@ -395,6 +395,7 @@ private static Constructor findCompatibleConstructor(List<Object> args, Class ta<br/>\n eligibleCount++;<br/>\n     }<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    @lispking ```break``` should be here, not there.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688604/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164583819","html_url":"https://github.com/apache/storm/pull/947#issuecomment-164583819","issue_url":"https://api.github.com/repos/apache/storm/issues/947","id":164583819,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU4MzgxOQ==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T22:44:49Z","updated_at":"2015-12-14T22:44:49Z","author_association":"CONTRIBUTOR","body":"@lispking \nThough I've addressed potential bug point, I'm with @unsleepy22. \nIts role is not that we strongly need to optimize. It doesn't affect performance.\nKnowing user's intention correctly is the most important point to Flux so finding out missing point and showing warning is vaild operation, I think.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164583819/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688611","html_url":"https://github.com/apache/storm/issues/5225#issuecomment-2612688611","issue_url":"https://api.github.com/repos/apache/storm/issues/5225","id":2612688611,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODg2MTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T22:44:51Z","updated_at":"2025-01-24T14:39:19Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/947#issuecomment-164583819\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/947#issuecomment-164583819</a></p>\n\n<p>    @lispking <br/>\n    Though I've addressed potential bug point, I'm with @unsleepy22. <br/>\n    Its role is not that we strongly need to optimize. It doesn't affect performance.<br/>\n    Knowing user's intention correctly is the most important point to Flux so finding out missing point and showing warning is vaild operation, I think.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688611/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164586572","html_url":"https://github.com/apache/storm/pull/930#issuecomment-164586572","issue_url":"https://api.github.com/repos/apache/storm/issues/930","id":164586572,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDU4NjU3Mg==","user":{"login":"Parth-Brahmbhatt","id":6914358,"node_id":"MDQ6VXNlcjY5MTQzNTg=","avatar_url":"https://avatars.githubusercontent.com/u/6914358?v=4","gravatar_id":"","url":"https://api.github.com/users/Parth-Brahmbhatt","html_url":"https://github.com/Parth-Brahmbhatt","followers_url":"https://api.github.com/users/Parth-Brahmbhatt/followers","following_url":"https://api.github.com/users/Parth-Brahmbhatt/following{/other_user}","gists_url":"https://api.github.com/users/Parth-Brahmbhatt/gists{/gist_id}","starred_url":"https://api.github.com/users/Parth-Brahmbhatt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Parth-Brahmbhatt/subscriptions","organizations_url":"https://api.github.com/users/Parth-Brahmbhatt/orgs","repos_url":"https://api.github.com/users/Parth-Brahmbhatt/repos","events_url":"https://api.github.com/users/Parth-Brahmbhatt/events{/privacy}","received_events_url":"https://api.github.com/users/Parth-Brahmbhatt/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T22:55:44Z","updated_at":"2015-12-14T22:55:44Z","author_association":"CONTRIBUTOR","body":"+1.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164586572/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612627446","html_url":"https://github.com/apache/storm/issues/5017#issuecomment-2612627446","issue_url":"https://api.github.com/repos/apache/storm/issues/5017","id":2612627446,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2Mjc0NDY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T22:55:46Z","updated_at":"2025-01-24T14:12:32Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user Parth-Brahmbhatt commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/930#issuecomment-164586572\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/930#issuecomment-164586572</a></p>\n\n<p>    +1.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612627446/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685350","html_url":"https://github.com/apache/storm/issues/5207#issuecomment-2612685350","issue_url":"https://api.github.com/repos/apache/storm/issues/5207","id":2612685350,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODUzNTA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T23:10:40Z","updated_at":"2025-01-24T14:37:56Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user redsanket commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/945#discussion_r47573928\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/945#discussion_r47573928</a></p>\n\n<p>    &#8212; Diff: docs/documentation/distcache-blobstore.md &#8212;<br/>\n    @@ -0,0 +1,732 @@<br/>\n    +# Storm Distributed Cache API<br/>\n    +<br/>\n    +The distributed cache feature in storm is used to efficiently distribute files<br/>\n    +(or blobs, which is the equivalent terminology for a file in the distributed<br/>\n    +cache and is used interchangeably in this document) that are large and can<br/>\n    +change during the lifetime of a topology, such as geo-location data,<br/>\n    +dictionaries, etc. Typical use cases include phrase recognition, entity<br/>\n    +extraction, document classification, URL re-writing, location/address detection<br/>\n    +and so forth. Such files may be several KB to several GB in size. For small<br/>\n    +datasets that don't need dynamic updates, including them in the topology jar<br/>\n    +could be fine. But for large files, the startup times could become very large.<br/>\n    +In these cases, the distributed cache feature can provide fast topology startup,<br/>\n    +especially if the files were previously downloaded for the same submitter and<br/>\n    +are still in the cache. This is useful with frequent deployments, sometimes few<br/>\n    +times a day with updated jars, because the large cached files will remain available<br/>\n    +without changes. The large cached blobs that do not change frequently will<br/>\n    +remain available in the distributed cache.<br/>\n    +<br/>\n    +At the starting time of a topology, the user specifies the set of files the<br/>\n    +topology needs. Once a topology is running, the user at any time can request for<br/>\n    +any file in the distributed cache to be updated with a newer version. The<br/>\n    +updating of blobs happens in an eventual consistency model. If the topology<br/>\n    +needs to know what version of a file it has access to, it is the responsibility<br/>\n    +of the user to find this information out. The files are stored in a cache with<br/>\n    +Least-Recently Used (LRU) eviction policy, where the supervisor decides which<br/>\n    +cached files are no longer needed and can delete them to free disk space. The<br/>\n    +blobs can be compressed, and the user can request the blobs to be uncompressed<br/>\n    +before it accesses them.<br/>\n    +<br/>\n    +## Motivation for Distributed Cache<br/>\n    +* Allows sharing blobs among topologies.<br/>\n    +* Allows updating the blobs from the command line.<br/>\n    +<br/>\n    +## Distributed Cache Implementations<br/>\n    +The current BlobStore interface has the following two implementations<br/>\n    +* LocalFsBlobStore<br/>\n    +* HdfsBlobStore<br/>\n    +<br/>\n    +Appendix A contains the interface for blob store implementation.<br/>\n    +<br/>\n    +## LocalFsBlobStore<br/>\n    +!<span class=\"error\">&#91;LocalFsBlobStore&#93;</span>(images/local_blobstore.png)<br/>\n    +<br/>\n    +Local file system implementation of Blobstore can be depicted in the above timeline diagram.<br/>\n    +<br/>\n    +There are several stages from blob creation to blob download and corresponding execution of a topology. <br/>\n    +The main stages can be depicted as follows<br/>\n    +<br/>\n    +### Blob Creation Command<br/>\n    +Blobs in the blobstore can be created through command line using the following command.<br/>\n    +storm blobstore create --file README.txt --acl o::rwa --repl-fctr 4 key1<br/>\n    +The above command creates a blob with a key name “key1” corresponding to the file README.txt. <br/>\n    +The access given to all users being read, write and admin with a replication factor of 4.<br/>\n    +<br/>\n    +### Topology Submission and Blob Mapping<br/>\n    +Users can submit their topology with the following command. The command includes the <br/>\n    +topology map configuration. The configuration holds two keys “key1” and “key2” with the <br/>\n    +key “key1” having a local file name mapping named “blob_file” and it is not compressed.<br/>\n    +<br/>\n    +```<br/>\n    +storm jar /home/y/lib/storm-starter/current/storm-starter-jar-with-dependencies.jar <br/>\n    +storm.starter.clj.word_count test_topo -c topology.blobstore.map='{\"key1\":</p>\n{\"localname\":\"blob_file\", \"uncompress\":\"false\"}\n<p>,\"key2\":{}}'<br/>\n    +```<br/>\n    +<br/>\n    +### Blob Creation Process<br/>\n    +The creation of the blob takes place through the interface “ClientBlobStore”. Appendix B contains the “ClientBlobStore” interface. <br/>\n    +The concrete implementation of this interface is the  “NimbusBlobStore”. In the case of local file system the client makes a <br/>\n    +call to the nimbus to create the blobs within the local file system. The nimbus uses the local file system implementation to create these blobs. <br/>\n    +When a user submits a topology, the jar, configuration and code files are uploaded as blobs with the help of blob store. <br/>\n    +Also, all the other blobs specified by the topology are mapped to it with the help of topology.blobstore.map configuration.<br/>\n    +<br/>\n    +### Blob Download by the Supervisor<br/>\n    +Finally, the blobs corresponding to a topology are downloaded by the supervisor once it receives the assignments from the nimbus through <br/>\n    +the same “NimbusBlobStore” thrift client that uploaded the blobs. The supervisor downloads the code, jar and conf blobs by calling the <br/>\n    +“NimbusBlobStore” client directly while the blobs specified in the topology.blobstore.map are downloaded and mapped locally with the help <br/>\n    +of the Localizer. The Localizer talks to the “NimbusBlobStore” thrift client to download the blobs and adds the blob compression and local <br/>\n    +blob name mapping logic to suit the implementation of a topology. Once all the blobs have been downloaded the workers are launched to run <br/>\n    +the topologies.<br/>\n    +<br/>\n    +## HdfsBlobStore<br/>\n    +!<span class=\"error\">&#91;HdfsBlobStore&#93;</span>(images/hdfs_blobstore.png)<br/>\n    +<br/>\n    +The HdfsBlobStore functionality has a similar implementation and blob creation and download procedure barring how the replication <br/>\n    +is handled in the two blob store implementations. The replication in HDFS blob store is obvious as HDFS is equipped to handle replication <br/>\n    +and it requires no state to be stored inside the zookeeper. On the other hand, the local file system blobstore requires the state to be <br/>\n    +stored on the zookeeper in order for it to work with nimbus HA. Nimbus HA allows the local filesystem to implement the replication feature <br/>\n    +seamlessly by storing the state in the zookeeper about the running topologies and syncing the blobs on various nimbodes. On the supervisor’s <br/>\n    +end, the supervisor and localizer talks to HdfsBlobStore through “HdfsClientBlobStore” implementation.<br/>\n    +<br/>\n    +## Additional Features and Documentation<br/>\n    +```<br/>\n    +storm jar /home/y/lib/storm-starter/current/storm-starter-jar-with-dependencies.jar storm.starter.clj.word_count test_topo <br/>\n    +-c topology.blobstore.map='{\"key1\":</p>\n{\"localname\":\"blob_file\", \"uncompress\":\"false\"}\n<p>,\"key2\":{}}'<br/>\n    +```<br/>\n    + <br/>\n    +### Compression<br/>\n    +The blob store allows the user to specify the “uncompress” configuration to true or false. This configuration can be specified <br/>\n    +in the topology.blobstore.map mentioned in the above command. This allows the user to upload a compressed file like a tarball/zip. <br/>\n    +In local file system blob store, the compressed blobs are stored on the nimbus node. The localizer code takes the responsibility to <br/>\n    +uncompress the blob and store it on the supervisor node. Symbolic links to the blobs on the supervisor node are created within the worker <br/>\n    +before the execution starts.<br/>\n    +<br/>\n    +### Local File Name Mapping<br/>\n    +Apart from compression the blobstore helps to give the blob a name that can be used by the workers. The localizer takes <br/>\n    +the responsibility of mapping the blob to a local name on the supervisor node.<br/>\n    +<br/>\n    +## Additional Blob Store Implementation Details<br/>\n    +Blob store uses a hashing function to create the blobs based on the key. The blobs are generally stored inside the directory specified by <br/>\n    +the blobstore.dir configuration. By default, it is stored under “storm.local.dir/nimbus/blobs” for local file system and a similar path on <br/>\n    +hdfs file system.<br/>\n    +<br/>\n    +Once a file is submitted, the blob store reads the configs and creates a metadata for the blob with all the access control details. The metadata <br/>\n    +is generally used for authorization while accessing the blobs. The blob key and version contribute to the hash code and there by the directory <br/>\n    +under “storm.local.dir/nimbus/blobs/data” where the data is placed. The blobs are generally placed in a positive number directory like 193,822 etc.<br/>\n    +<br/>\n    +Once the topology is launched and the relevant blobs have been created the supervisor downloads blobs related to the storm.conf, storm.ser <br/>\n    +and storm.code first and all the blobs uploaded by the command line separately using the localizer to uncompress and map them to a local name <br/>\n    +specified in the topology.blobstore.map configuration. The supervisor periodically updates blobs by checking for the change of version. <br/>\n    +This allows updating the blobs on the fly and thereby making it a very useful feature.<br/>\n    +<br/>\n    +For a local file system, the distributed cache on the supervisor node is set to 10240 MB as a soft limit and the clean up code attempts <br/>\n    +to clean anything over the soft limit every 600 seconds based on LRU policy.<br/>\n    +<br/>\n    +The HDFS blob store implementation handles load better by removing the burden on the nimbus to store the blobs, which avoids it becoming a bottleneck. Moreover, it provides seamless replication of blobs. On the other hand, the local file system blob store is not very efficient in <br/>\n    +replicating the blobs and is limited by the number of nimbuses. Moreover, the supervisor talks to the HDFS blob store directly without the <br/>\n    +involvement of the nimbus and thereby reduces the load and dependency on nimbus.<br/>\n    +<br/>\n    +## Highly Available Nimbus<br/>\n    +### Problem Statement:<br/>\n    +Currently the storm master aka nimbus, is a process that runs on a single machine under supervision. In most cases the <br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I have modified nimbus HA design document here along with blobstore and rewrote most of it as the zookeeper state information needed to go into this section, We could remove nimbus-ha design document if you would like.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685350/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686348","html_url":"https://github.com/apache/storm/issues/5211#issuecomment-2612686348","issue_url":"https://api.github.com/repos/apache/storm/issues/5211","id":2612686348,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODYzNDg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-14T23:18:47Z","updated_at":"2025-01-24T14:38:19Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user redsanket commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/933#discussion_r47574811\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/933#discussion_r47574811</a></p>\n\n<p>    &#8212; Diff: conf/defaults.yaml &#8212;<br/>\n    @@ -179,7 +179,7 @@ task.refresh.poll.secs: 10<br/>\n     task.credentials.poll.secs: 30</p>\n\n<ol>\n\t<li>now should be null by default<br/>\n    -topology.backpressure.enable: true<br/>\n    +topology.backpressure.enable: false\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ol>\n\n\n<p>    Oh Im sorry I was testing few scenarios might have come along with my last commit. Will change it back</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686348/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164600569","html_url":"https://github.com/apache/storm/pull/947#issuecomment-164600569","issue_url":"https://api.github.com/repos/apache/storm/issues/947","id":164600569,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDYwMDU2OQ==","user":{"login":"lispking","id":4446580,"node_id":"MDQ6VXNlcjQ0NDY1ODA=","avatar_url":"https://avatars.githubusercontent.com/u/4446580?v=4","gravatar_id":"","url":"https://api.github.com/users/lispking","html_url":"https://github.com/lispking","followers_url":"https://api.github.com/users/lispking/followers","following_url":"https://api.github.com/users/lispking/following{/other_user}","gists_url":"https://api.github.com/users/lispking/gists{/gist_id}","starred_url":"https://api.github.com/users/lispking/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lispking/subscriptions","organizations_url":"https://api.github.com/users/lispking/orgs","repos_url":"https://api.github.com/users/lispking/repos","events_url":"https://api.github.com/users/lispking/events{/privacy}","received_events_url":"https://api.github.com/users/lispking/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T00:10:38Z","updated_at":"2015-12-15T00:10:38Z","author_association":"CONTRIBUTOR","body":"@HeartSaVioR Thank reminder, your proposal is appropriate。\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164600569/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688615","html_url":"https://github.com/apache/storm/issues/5225#issuecomment-2612688615","issue_url":"https://api.github.com/repos/apache/storm/issues/5225","id":2612688615,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODg2MTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T00:10:39Z","updated_at":"2025-01-24T14:39:19Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user lispking commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/947#issuecomment-164600569\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/947#issuecomment-164600569</a></p>\n\n<p>    @HeartSaVioR Thank reminder, your proposal is appropriate。</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612688615/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164602570","html_url":"https://github.com/apache/storm/pull/934#issuecomment-164602570","issue_url":"https://api.github.com/repos/apache/storm/issues/934","id":164602570,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDYwMjU3MA==","user":{"login":"redsanket","id":8295799,"node_id":"MDQ6VXNlcjgyOTU3OTk=","avatar_url":"https://avatars.githubusercontent.com/u/8295799?v=4","gravatar_id":"","url":"https://api.github.com/users/redsanket","html_url":"https://github.com/redsanket","followers_url":"https://api.github.com/users/redsanket/followers","following_url":"https://api.github.com/users/redsanket/following{/other_user}","gists_url":"https://api.github.com/users/redsanket/gists{/gist_id}","starred_url":"https://api.github.com/users/redsanket/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redsanket/subscriptions","organizations_url":"https://api.github.com/users/redsanket/orgs","repos_url":"https://api.github.com/users/redsanket/repos","events_url":"https://api.github.com/users/redsanket/events{/privacy}","received_events_url":"https://api.github.com/users/redsanket/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T00:23:33Z","updated_at":"2015-12-15T00:23:49Z","author_association":"NONE","body":"@revans2 Will rewrite it as suggested. I agree the example should look more like what you have suggested, I just thought more on terms of just accessing the API\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164602570/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685713","html_url":"https://github.com/apache/storm/issues/5208#issuecomment-2612685713","issue_url":"https://api.github.com/repos/apache/storm/issues/5208","id":2612685713,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODU3MTM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T00:23:34Z","updated_at":"2025-01-24T14:38:05Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user redsanket commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/934#issuecomment-164602570\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/934#issuecomment-164602570</a></p>\n\n<p>    @revans2 Will rewrite it as suggested. I agree the example should look more like what you have suggested, I just thought more on terms of just accessing the API interface</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685713/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630921","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630921","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630921,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5MjE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T00:41:14Z","updated_at":"2025-01-24T14:14:03Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user roshannaik commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47582319\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47582319</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -0,0 +1,654 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +import java.io.IOException;<br/>\n    +import java.lang.reflect.Constructor;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Timer;<br/>\n    +import java.util.TimerTask;<br/>\n    +import java.util.concurrent.LinkedBlockingQueue;<br/>\n    +import java.util.concurrent.atomic.AtomicBoolean;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import org.apache.hadoop.conf.Configuration;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.storm.hdfs.common.HdfsUtils;<br/>\n    +import org.apache.storm.hdfs.common.security.HdfsSecurityUtil;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +<br/>\n    +public class HdfsSpout extends BaseRichSpout {<br/>\n    +<br/>\n    +  private static final Logger LOG = LoggerFactory.getLogger(HdfsSpout.class);<br/>\n    +<br/>\n    +  private Path sourceDirPath;<br/>\n    +  private Path archiveDirPath;<br/>\n    +  private Path badFilesDirPath;<br/>\n    +  private Path lockDirPath;<br/>\n    +<br/>\n    +  private int commitFrequencyCount = Configs.DEFAULT_COMMIT_FREQ_COUNT;<br/>\n    +  private int commitFrequencySec = Configs.DEFAULT_COMMIT_FREQ_SEC;<br/>\n    +  private int maxDuplicates = Configs.DEFAULT_MAX_DUPLICATES;<br/>\n    +  private int lockTimeoutSec = Configs.DEFAULT_LOCK_TIMEOUT;<br/>\n    +  private boolean clocksInSync = true;<br/>\n    +<br/>\n    +  private ProgressTracker tracker = new ProgressTracker();<br/>\n    +<br/>\n    +  private FileSystem hdfs;<br/>\n    +  private FileReader reader;<br/>\n    +<br/>\n    +  private SpoutOutputCollector collector;<br/>\n    +  HashMap<MessageId, List<Object> > inflight = new HashMap<>();<br/>\n    +  LinkedBlockingQueue<HdfsUtils.Pair<MessageId, List<Object>>> retryList = new LinkedBlockingQueue<>();<br/>\n    +<br/>\n    +  private String inprogress_suffix = \".inprogress\";<br/>\n    +  private String ignoreSuffix = \".ignore\";<br/>\n    +<br/>\n    +  private Configuration hdfsConfig;<br/>\n    +  private String readerType;<br/>\n    +<br/>\n    +  private Map conf = null;<br/>\n    +  private FileLock lock;<br/>\n    +  private String spoutId = null;<br/>\n    +<br/>\n    +  HdfsUtils.Pair<Path,FileLock.LogEntry> lastExpiredLock = null;<br/>\n    +  private long lastExpiredLockTime = 0;<br/>\n    +<br/>\n    +  private long tupleCounter = 0;<br/>\n    +  private boolean ackEnabled = false;<br/>\n    +  private int acksSinceLastCommit = 0 ;<br/>\n    +  private final AtomicBoolean commitTimeElapsed = new AtomicBoolean(false);<br/>\n    +  private final Timer commitTimer = new Timer();<br/>\n    +  private boolean fileReadCompletely = false;<br/>\n    +<br/>\n    +  private String configKey = Configs.DEFAULT_HDFS_CONFIG_KEY; // key for hdfs kerberos configs<br/>\n    +<br/>\n    +  public HdfsSpout() </p>\n{\n    +  }\n<p>    +<br/>\n    +  public Path getLockDirPath() </p>\n{\n    +    return lockDirPath;\n    +  }\n<p>    +<br/>\n    +  public SpoutOutputCollector getCollector() </p>\n{\n    +    return collector;\n    +  }\n<p>    +<br/>\n    +  public HdfsSpout withConfigKey(String configKey)</p>\n{\n    +    this.configKey = configKey;\n    +    return this;\n    +  }\n<p>    +<br/>\n    +  public void nextTuple() {<br/>\n    +    LOG.debug(\"Next Tuple\");<br/>\n    +    // 1) First re-emit any previously failed tuples (from retryList)<br/>\n    +    if (!retryList.isEmpty()) </p>\n{\n    +      LOG.debug(\"Sending from retry list\");\n    +      HdfsUtils.Pair<MessageId, List<Object>> pair = retryList.remove();\n    +      emitData(pair.getValue(), pair.getKey());\n    +      return;\n    +    }\n<p>    +<br/>\n    +    if( ackEnabled  &&  tracker.size()>=maxDuplicates ) {<br/>\n    +      LOG.warn(\"Waiting for more ACKs before generating new tuples. \" +<br/>\n    +       \"Progress tracker size has reached limit {}\"<br/>\n    +      , maxDuplicates);<br/>\n    +      // Don't emit anything .. allow configured spout wait strategy to kick in<br/>\n    +      return;<br/>\n    +    }<br/>\n    +<br/>\n    +    // 2) If no failed tuples, then send tuples from hdfs<br/>\n    +    while (true) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    That loop is actually to ensure that when there is a ParseException we don't exit from the method immediately. Exiting from the method w/o emitting can trigger wait strategy. So to avoid that we retry from a new file by going back into the loop.  In other cases we such as successful parse or I/O exception, the loop will not repeat due to the return statements. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630921/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630929","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630929","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630929,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5Mjk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T00:52:36Z","updated_at":"2025-01-24T14:14:03Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user roshannaik commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47583280\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47583280</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/common/CmpFilesByModificationTime.java &#8212;<br/>\n    @@ -0,0 +1,32 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.common;<br/>\n    +<br/>\n    +import org.apache.hadoop.fs.LocatedFileStatus;<br/>\n    +<br/>\n    +import java.util.Comparator;<br/>\n    +<br/>\n    +<br/>\n    +public class CmpFilesByModificationTime<br/>\n    +implements Comparator<LocatedFileStatus> {<br/>\n    +   @Override<br/>\n    +    public int compare(LocatedFileStatus o1, LocatedFileStatus o2) </p>\n{\n    +      return new Long(o1.getModificationTime()).compareTo( o1.getModificationTime() );\n    +    }\n<p>    +}<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    oh .. good idea. thanks.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630929/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630934","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630934","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630934,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5MzQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:04:58Z","updated_at":"2025-01-24T14:14:03Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47584317\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47584317</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -0,0 +1,654 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +import java.io.IOException;<br/>\n    +import java.lang.reflect.Constructor;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Timer;<br/>\n    +import java.util.TimerTask;<br/>\n    +import java.util.concurrent.LinkedBlockingQueue;<br/>\n    +import java.util.concurrent.atomic.AtomicBoolean;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import org.apache.hadoop.conf.Configuration;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.storm.hdfs.common.HdfsUtils;<br/>\n    +import org.apache.storm.hdfs.common.security.HdfsSecurityUtil;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +<br/>\n    +public class HdfsSpout extends BaseRichSpout {<br/>\n    +<br/>\n    +  private static final Logger LOG = LoggerFactory.getLogger(HdfsSpout.class);<br/>\n    +<br/>\n    +  private Path sourceDirPath;<br/>\n    +  private Path archiveDirPath;<br/>\n    +  private Path badFilesDirPath;<br/>\n    +  private Path lockDirPath;<br/>\n    +<br/>\n    +  private int commitFrequencyCount = Configs.DEFAULT_COMMIT_FREQ_COUNT;<br/>\n    +  private int commitFrequencySec = Configs.DEFAULT_COMMIT_FREQ_SEC;<br/>\n    +  private int maxDuplicates = Configs.DEFAULT_MAX_DUPLICATES;<br/>\n    +  private int lockTimeoutSec = Configs.DEFAULT_LOCK_TIMEOUT;<br/>\n    +  private boolean clocksInSync = true;<br/>\n    +<br/>\n    +  private ProgressTracker tracker = new ProgressTracker();<br/>\n    +<br/>\n    +  private FileSystem hdfs;<br/>\n    +  private FileReader reader;<br/>\n    +<br/>\n    +  private SpoutOutputCollector collector;<br/>\n    +  HashMap<MessageId, List<Object> > inflight = new HashMap<>();<br/>\n    +  LinkedBlockingQueue<HdfsUtils.Pair<MessageId, List<Object>>> retryList = new LinkedBlockingQueue<>();<br/>\n    +<br/>\n    +  private String inprogress_suffix = \".inprogress\";<br/>\n    +  private String ignoreSuffix = \".ignore\";<br/>\n    +<br/>\n    +  private Configuration hdfsConfig;<br/>\n    +  private String readerType;<br/>\n    +<br/>\n    +  private Map conf = null;<br/>\n    +  private FileLock lock;<br/>\n    +  private String spoutId = null;<br/>\n    +<br/>\n    +  HdfsUtils.Pair<Path,FileLock.LogEntry> lastExpiredLock = null;<br/>\n    +  private long lastExpiredLockTime = 0;<br/>\n    +<br/>\n    +  private long tupleCounter = 0;<br/>\n    +  private boolean ackEnabled = false;<br/>\n    +  private int acksSinceLastCommit = 0 ;<br/>\n    +  private final AtomicBoolean commitTimeElapsed = new AtomicBoolean(false);<br/>\n    +  private final Timer commitTimer = new Timer();<br/>\n    +  private boolean fileReadCompletely = false;<br/>\n    +<br/>\n    +  private String configKey = Configs.DEFAULT_HDFS_CONFIG_KEY; // key for hdfs kerberos configs<br/>\n    +<br/>\n    +  public HdfsSpout() </p>\n{\n    +  }\n<p>    +<br/>\n    +  public Path getLockDirPath() </p>\n{\n    +    return lockDirPath;\n    +  }\n<p>    +<br/>\n    +  public SpoutOutputCollector getCollector() </p>\n{\n    +    return collector;\n    +  }\n<p>    +<br/>\n    +  public HdfsSpout withConfigKey(String configKey)</p>\n{\n    +    this.configKey = configKey;\n    +    return this;\n    +  }\n<p>    +<br/>\n    +  public void nextTuple() {<br/>\n    +    LOG.debug(\"Next Tuple\");<br/>\n    +    // 1) First re-emit any previously failed tuples (from retryList)<br/>\n    +    if (!retryList.isEmpty()) </p>\n{\n    +      LOG.debug(\"Sending from retry list\");\n    +      HdfsUtils.Pair<MessageId, List<Object>> pair = retryList.remove();\n    +      emitData(pair.getValue(), pair.getKey());\n    +      return;\n    +    }\n<p>    +<br/>\n    +    if( ackEnabled  &&  tracker.size()>=maxDuplicates ) {<br/>\n    +      LOG.warn(\"Waiting for more ACKs before generating new tuples. \" +<br/>\n    +       \"Progress tracker size has reached limit {}\"<br/>\n    +      , maxDuplicates);<br/>\n    +      // Don't emit anything .. allow configured spout wait strategy to kick in<br/>\n    +      return;<br/>\n    +    }<br/>\n    +<br/>\n    +    // 2) If no failed tuples, then send tuples from hdfs<br/>\n    +    while (true) {<br/>\n    +      try {<br/>\n    +// 3) Select a new file if one is not open already<br/>\n    +if (reader == null) {<br/>\n    +  reader = pickNextFile();<br/>\n    +  if (reader == null) </p>\n{\n    +    LOG.info(\"Currently no new files to process under : \" + sourceDirPath);\n    +    return;\n    +  }\n<p>    +}<br/>\n    +<br/>\n    +// 4) Read record from file, emit to collector and record progress<br/>\n    +List<Object> tuple = reader.next();<br/>\n    +if (tuple != null) {<br/>\n    +  fileReadCompletely= false;<br/>\n    +  ++tupleCounter;<br/>\n    +  MessageId msgId = new MessageId(tupleCounter, reader.getFilePath(), reader.getFileOffset());<br/>\n    +  emitData(tuple, msgId);<br/>\n    +<br/>\n    +  if(!ackEnabled) </p>\n{\n    +    ++acksSinceLastCommit; // assume message is immediately acked in non-ack mode\n    +    commitProgress(reader.getFileOffset());\n    +  }\n<p> else </p>\n{\n    +    commitProgress(tracker.getCommitPosition());\n    +  }\n<p>    +  return;<br/>\n    +} else {<br/>\n    +  fileReadCompletely = true;<br/>\n    +  if(!ackEnabled) </p>\n{\n    +    markFileAsDone(reader.getFilePath());\n    +  }\n<p>    +}<br/>\n    +      } catch (IOException e) </p>\n{\n    +LOG.error(\"I/O Error processing at file location \" + getFileProgress(reader), e);\n    +// don't emit anything .. allow configured spout wait strategy to kick in\n    +return;\n    +      }\n<p> catch (ParseException e) {<br/>\n    +LOG.error(\"Parsing error when processing at file location \" + getFileProgress(reader) +<br/>\n    +\". Skipping remainder of file.\", e);<br/>\n    +markFileAsBad(reader.getFilePath());<br/>\n    +// note: Unfortunately not emitting anything here due to parse error<br/>\n    +// will trigger the configured spout wait strategy which is unnecessary<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    @roshannaik <br/>\n    Quick question: Is it safe to let reader as it is? Do we want to make reader as null to trigger finding next file?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630934/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630940","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630940","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630940,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5NDA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:05:16Z","updated_at":"2025-01-24T14:14:03Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47584342\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47584342</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -0,0 +1,654 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +import java.io.IOException;<br/>\n    +import java.lang.reflect.Constructor;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Timer;<br/>\n    +import java.util.TimerTask;<br/>\n    +import java.util.concurrent.LinkedBlockingQueue;<br/>\n    +import java.util.concurrent.atomic.AtomicBoolean;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import org.apache.hadoop.conf.Configuration;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.storm.hdfs.common.HdfsUtils;<br/>\n    +import org.apache.storm.hdfs.common.security.HdfsSecurityUtil;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +<br/>\n    +public class HdfsSpout extends BaseRichSpout {<br/>\n    +<br/>\n    +  private static final Logger LOG = LoggerFactory.getLogger(HdfsSpout.class);<br/>\n    +<br/>\n    +  private Path sourceDirPath;<br/>\n    +  private Path archiveDirPath;<br/>\n    +  private Path badFilesDirPath;<br/>\n    +  private Path lockDirPath;<br/>\n    +<br/>\n    +  private int commitFrequencyCount = Configs.DEFAULT_COMMIT_FREQ_COUNT;<br/>\n    +  private int commitFrequencySec = Configs.DEFAULT_COMMIT_FREQ_SEC;<br/>\n    +  private int maxDuplicates = Configs.DEFAULT_MAX_DUPLICATES;<br/>\n    +  private int lockTimeoutSec = Configs.DEFAULT_LOCK_TIMEOUT;<br/>\n    +  private boolean clocksInSync = true;<br/>\n    +<br/>\n    +  private ProgressTracker tracker = new ProgressTracker();<br/>\n    +<br/>\n    +  private FileSystem hdfs;<br/>\n    +  private FileReader reader;<br/>\n    +<br/>\n    +  private SpoutOutputCollector collector;<br/>\n    +  HashMap<MessageId, List<Object> > inflight = new HashMap<>();<br/>\n    +  LinkedBlockingQueue<HdfsUtils.Pair<MessageId, List<Object>>> retryList = new LinkedBlockingQueue<>();<br/>\n    +<br/>\n    +  private String inprogress_suffix = \".inprogress\";<br/>\n    +  private String ignoreSuffix = \".ignore\";<br/>\n    +<br/>\n    +  private Configuration hdfsConfig;<br/>\n    +  private String readerType;<br/>\n    +<br/>\n    +  private Map conf = null;<br/>\n    +  private FileLock lock;<br/>\n    +  private String spoutId = null;<br/>\n    +<br/>\n    +  HdfsUtils.Pair<Path,FileLock.LogEntry> lastExpiredLock = null;<br/>\n    +  private long lastExpiredLockTime = 0;<br/>\n    +<br/>\n    +  private long tupleCounter = 0;<br/>\n    +  private boolean ackEnabled = false;<br/>\n    +  private int acksSinceLastCommit = 0 ;<br/>\n    +  private final AtomicBoolean commitTimeElapsed = new AtomicBoolean(false);<br/>\n    +  private final Timer commitTimer = new Timer();<br/>\n    +  private boolean fileReadCompletely = false;<br/>\n    +<br/>\n    +  private String configKey = Configs.DEFAULT_HDFS_CONFIG_KEY; // key for hdfs kerberos configs<br/>\n    +<br/>\n    +  public HdfsSpout() </p>\n{\n    +  }\n<p>    +<br/>\n    +  public Path getLockDirPath() </p>\n{\n    +    return lockDirPath;\n    +  }\n<p>    +<br/>\n    +  public SpoutOutputCollector getCollector() </p>\n{\n    +    return collector;\n    +  }\n<p>    +<br/>\n    +  public HdfsSpout withConfigKey(String configKey)</p>\n{\n    +    this.configKey = configKey;\n    +    return this;\n    +  }\n<p>    +<br/>\n    +  public void nextTuple() {<br/>\n    +    LOG.debug(\"Next Tuple\");<br/>\n    +    // 1) First re-emit any previously failed tuples (from retryList)<br/>\n    +    if (!retryList.isEmpty()) </p>\n{\n    +      LOG.debug(\"Sending from retry list\");\n    +      HdfsUtils.Pair<MessageId, List<Object>> pair = retryList.remove();\n    +      emitData(pair.getValue(), pair.getKey());\n    +      return;\n    +    }\n<p>    +<br/>\n    +    if( ackEnabled  &&  tracker.size()>=maxDuplicates ) {<br/>\n    +      LOG.warn(\"Waiting for more ACKs before generating new tuples. \" +<br/>\n    +       \"Progress tracker size has reached limit {}\"<br/>\n    +      , maxDuplicates);<br/>\n    +      // Don't emit anything .. allow configured spout wait strategy to kick in<br/>\n    +      return;<br/>\n    +    }<br/>\n    +<br/>\n    +    // 2) If no failed tuples, then send tuples from hdfs<br/>\n    +    while (true) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Idea is promising, but nextTuple should not be blocked longer cause it also blocks ack / fail.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630940/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164609684","html_url":"https://github.com/apache/storm/pull/933#issuecomment-164609684","issue_url":"https://api.github.com/repos/apache/storm/issues/933","id":164609684,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDYwOTY4NA==","user":{"login":"hustfxj","id":7270212,"node_id":"MDQ6VXNlcjcyNzAyMTI=","avatar_url":"https://avatars.githubusercontent.com/u/7270212?v=4","gravatar_id":"","url":"https://api.github.com/users/hustfxj","html_url":"https://github.com/hustfxj","followers_url":"https://api.github.com/users/hustfxj/followers","following_url":"https://api.github.com/users/hustfxj/following{/other_user}","gists_url":"https://api.github.com/users/hustfxj/gists{/gist_id}","starred_url":"https://api.github.com/users/hustfxj/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hustfxj/subscriptions","organizations_url":"https://api.github.com/users/hustfxj/orgs","repos_url":"https://api.github.com/users/hustfxj/repos","events_url":"https://api.github.com/users/hustfxj/events{/privacy}","received_events_url":"https://api.github.com/users/hustfxj/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:09:54Z","updated_at":"2015-12-15T01:09:54Z","author_association":"CONTRIBUTOR","body":"yes, others are good, but why we turned off backpressure by default.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164609684/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686352","html_url":"https://github.com/apache/storm/issues/5211#issuecomment-2612686352","issue_url":"https://api.github.com/repos/apache/storm/issues/5211","id":2612686352,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODYzNTI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:09:56Z","updated_at":"2025-01-24T14:38:19Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user hustfxj commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/933#issuecomment-164609684\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/933#issuecomment-164609684</a></p>\n\n<p>    yes, others are good, but why we turned off backpressure by default.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686352/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164611442","html_url":"https://github.com/apache/storm/pull/945#issuecomment-164611442","issue_url":"https://api.github.com/repos/apache/storm/issues/945","id":164611442,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDYxMTQ0Mg==","user":{"login":"hustfxj","id":7270212,"node_id":"MDQ6VXNlcjcyNzAyMTI=","avatar_url":"https://avatars.githubusercontent.com/u/7270212?v=4","gravatar_id":"","url":"https://api.github.com/users/hustfxj","html_url":"https://github.com/hustfxj","followers_url":"https://api.github.com/users/hustfxj/followers","following_url":"https://api.github.com/users/hustfxj/following{/other_user}","gists_url":"https://api.github.com/users/hustfxj/gists{/gist_id}","starred_url":"https://api.github.com/users/hustfxj/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hustfxj/subscriptions","organizations_url":"https://api.github.com/users/hustfxj/orgs","repos_url":"https://api.github.com/users/hustfxj/repos","events_url":"https://api.github.com/users/hustfxj/events{/privacy}","received_events_url":"https://api.github.com/users/hustfxj/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:20:52Z","updated_at":"2015-12-15T01:20:52Z","author_association":"CONTRIBUTOR","body":"+1\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164611442/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685354","html_url":"https://github.com/apache/storm/issues/5207#issuecomment-2612685354","issue_url":"https://api.github.com/repos/apache/storm/issues/5207","id":2612685354,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODUzNTQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:20:53Z","updated_at":"2025-01-24T14:37:57Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user hustfxj commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/945#issuecomment-164611442\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/945#issuecomment-164611442</a></p>\n\n<p>    +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612685354/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612632830","html_url":"https://github.com/apache/storm/issues/5048#issuecomment-2612632830","issue_url":"https://api.github.com/repos/apache/storm/issues/5048","id":2612632830,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzI4MzA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:27:12Z","updated_at":"2025-01-24T14:14:53Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/885#discussion_r47586077\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/885#discussion_r47586077</a></p>\n\n<p>    &#8212; Diff: external/storm-kafka/src/jvm/storm/kafka/PartitionManager.java &#8212;<br/>\n    @@ -149,9 +150,9 @@ public EmitState next(SpoutOutputCollector collector) {<br/>\n }</p>\n\n<p> if ((tups != null) && tups.iterator().hasNext()) {</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>if(_spoutConfig.topicAsStreamId) {<br/>\n    +       if (!Strings.isNullOrEmpty(_spoutConfig.outputStreamId)) {\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    Isn't it an overkill to import a whole package (com.google.common.base.Strings) to only test for null or empty? Can't we just use: <br/>\n    if (_spoutConfig.outputStreamId!=null && _spoutConfig.outputStreamId!=\"\") <br/>\n    or something to that effect instead of importing a new library?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612632830/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164613029","html_url":"https://github.com/apache/storm/pull/930#issuecomment-164613029","issue_url":"https://api.github.com/repos/apache/storm/issues/930","id":164613029,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDYxMzAyOQ==","user":{"login":"rfarivar","id":8742608,"node_id":"MDQ6VXNlcjg3NDI2MDg=","avatar_url":"https://avatars.githubusercontent.com/u/8742608?v=4","gravatar_id":"","url":"https://api.github.com/users/rfarivar","html_url":"https://github.com/rfarivar","followers_url":"https://api.github.com/users/rfarivar/followers","following_url":"https://api.github.com/users/rfarivar/following{/other_user}","gists_url":"https://api.github.com/users/rfarivar/gists{/gist_id}","starred_url":"https://api.github.com/users/rfarivar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rfarivar/subscriptions","organizations_url":"https://api.github.com/users/rfarivar/orgs","repos_url":"https://api.github.com/users/rfarivar/repos","events_url":"https://api.github.com/users/rfarivar/events{/privacy}","received_events_url":"https://api.github.com/users/rfarivar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:31:45Z","updated_at":"2015-12-15T01:31:45Z","author_association":"CONTRIBUTOR","body":"LGTM. +1\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164613029/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612627450","html_url":"https://github.com/apache/storm/issues/5017#issuecomment-2612627450","issue_url":"https://api.github.com/repos/apache/storm/issues/5017","id":2612627450,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2Mjc0NTA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:31:46Z","updated_at":"2025-01-24T14:12:32Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/930#issuecomment-164613029\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/930#issuecomment-164613029</a></p>\n\n<p>    LGTM. +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612627450/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598472","html_url":"https://github.com/apache/storm/issues/4876#issuecomment-2612598472","issue_url":"https://api.github.com/repos/apache/storm/issues/4876","id":2612598472,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1OTg0NzI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:34:11Z","updated_at":"2025-01-24T14:00:09Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/728#discussion_r47586615\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/728#discussion_r47586615</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/backtype/storm/messaging/netty/Client.java &#8212;<br/>\n    @@ -23,24 +23,17 @@<br/>\n     import backtype.storm.metric.api.IStatefulObject;<br/>\n     import backtype.storm.utils.StormBoundedExponentialBackoffRetry;<br/>\n     import backtype.storm.utils.Utils;<br/>\n    -import org.jboss.netty.bootstrap.ClientBootstrap;<br/>\n    -import org.jboss.netty.channel.Channel;<br/>\n    -import org.jboss.netty.channel.ChannelFactory;<br/>\n    -import org.jboss.netty.channel.ChannelFuture;<br/>\n    -import org.jboss.netty.channel.ChannelFutureListener;<br/>\n    -import org.jboss.netty.util.HashedWheelTimer;<br/>\n    -import org.jboss.netty.util.Timeout;<br/>\n    -import org.jboss.netty.util.TimerTask;<br/>\n    +import io.netty.bootstrap.Bootstrap;<br/>\n    +import io.netty.channel.*;<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Could you please expand the imports?</p>\n\n<p>    Also below. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598472/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598479","html_url":"https://github.com/apache/storm/issues/4876#issuecomment-2612598479","issue_url":"https://api.github.com/repos/apache/storm/issues/4876","id":2612598479,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1OTg0Nzk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:34:25Z","updated_at":"2025-01-24T14:00:09Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/728#discussion_r47586629\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/728#discussion_r47586629</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/backtype/storm/messaging/netty/Client.java &#8212;<br/>\n    @@ -23,24 +23,17 @@<br/>\n     import backtype.storm.metric.api.IStatefulObject;<br/>\n     import backtype.storm.utils.StormBoundedExponentialBackoffRetry;<br/>\n     import backtype.storm.utils.Utils;<br/>\n    -import org.jboss.netty.bootstrap.ClientBootstrap;<br/>\n    -import org.jboss.netty.channel.Channel;<br/>\n    -import org.jboss.netty.channel.ChannelFactory;<br/>\n    -import org.jboss.netty.channel.ChannelFuture;<br/>\n    -import org.jboss.netty.channel.ChannelFutureListener;<br/>\n    -import org.jboss.netty.util.HashedWheelTimer;<br/>\n    -import org.jboss.netty.util.Timeout;<br/>\n    -import org.jboss.netty.util.TimerTask;<br/>\n    +import io.netty.bootstrap.Bootstrap;<br/>\n    +import io.netty.channel.*;<br/>\n    +import io.netty.channel.socket.nio.NioSocketChannel;<br/>\n    +import io.netty.util.*;<br/>\n    +import io.netty.util.TimerTask;<br/>\n     import org.slf4j.Logger;<br/>\n     import org.slf4j.LoggerFactory;</p>\n\n<p>     import java.net.InetSocketAddress;<br/>\n     import java.net.SocketAddress;<br/>\n    -import java.util.ArrayList;<br/>\n    -import java.util.HashMap;<br/>\n    -import java.util.Iterator;<br/>\n    -import java.util.List;<br/>\n    -import java.util.Map;<br/>\n    +import java.util.*;<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Expand import</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598479/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598486","html_url":"https://github.com/apache/storm/issues/4876#issuecomment-2612598486","issue_url":"https://api.github.com/repos/apache/storm/issues/4876","id":2612598486,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1OTg0ODY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:37:34Z","updated_at":"2025-01-24T14:00:09Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user rfarivar commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/728#discussion_r47586860\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/728#discussion_r47586860</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/backtype/storm/messaging/netty/Client.java &#8212;<br/>\n    @@ -182,7 +177,7 @@ private boolean connectionEstablished(Channel channel) {<br/>\n     // See:<br/>\n     // - <a href=\"http://netty.io/3.9/api/org/jboss/netty/channel/ChannelEvent.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://netty.io/3.9/api/org/jboss/netty/channel/ChannelEvent.html</a><br/>\n     // - <a href=\"http://stackoverflow.com/questions/13356622/what-are-the-netty-channel-state-transitions\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://stackoverflow.com/questions/13356622/what-are-the-netty-channel-state-transitions</a></p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>return channel != null && channel.isConnected();<br/>\n    +return channel != null && channel.isOpen();\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    Why the change from connected to open? the channel could be open, but not yet in the connected state, and this could cause a bug.</p>\n\n<p>    Unless Netty 4 has changed the model....</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598486/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164617141","html_url":"https://github.com/apache/storm/pull/885#issuecomment-164617141","issue_url":"https://api.github.com/repos/apache/storm/issues/885","id":164617141,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDYxNzE0MQ==","user":{"login":"Zhiqiang-He","id":3201864,"node_id":"MDQ6VXNlcjMyMDE4NjQ=","avatar_url":"https://avatars.githubusercontent.com/u/3201864?v=4","gravatar_id":"","url":"https://api.github.com/users/Zhiqiang-He","html_url":"https://github.com/Zhiqiang-He","followers_url":"https://api.github.com/users/Zhiqiang-He/followers","following_url":"https://api.github.com/users/Zhiqiang-He/following{/other_user}","gists_url":"https://api.github.com/users/Zhiqiang-He/gists{/gist_id}","starred_url":"https://api.github.com/users/Zhiqiang-He/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Zhiqiang-He/subscriptions","organizations_url":"https://api.github.com/users/Zhiqiang-He/orgs","repos_url":"https://api.github.com/users/Zhiqiang-He/repos","events_url":"https://api.github.com/users/Zhiqiang-He/events{/privacy}","received_events_url":"https://api.github.com/users/Zhiqiang-He/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:50:56Z","updated_at":"2015-12-15T01:50:56Z","author_association":"CONTRIBUTOR","body":"@rfarivar Because guava is already import in storm-kafka.\nAnd com.google.common.collect.ImmutableMap is already used in PartitionManager.java. \n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164617141/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612632838","html_url":"https://github.com/apache/storm/issues/5048#issuecomment-2612632838","issue_url":"https://api.github.com/repos/apache/storm/issues/5048","id":2612632838,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzI4Mzg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T01:50:58Z","updated_at":"2025-01-24T14:14:53Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user Zhiqiang-He commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/885#issuecomment-164617141\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/885#issuecomment-164617141</a></p>\n\n<p>    @rfarivar Because guava is already import in storm-kafka.<br/>\n    And com.google.common.collect.ImmutableMap is already used in PartitionManager.java. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612632838/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630945","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630945","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630945,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5NDU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T02:54:49Z","updated_at":"2025-01-24T14:14:03Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user roshannaik commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47591484\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47591484</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -0,0 +1,654 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +import java.io.IOException;<br/>\n    +import java.lang.reflect.Constructor;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Timer;<br/>\n    +import java.util.TimerTask;<br/>\n    +import java.util.concurrent.LinkedBlockingQueue;<br/>\n    +import java.util.concurrent.atomic.AtomicBoolean;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import org.apache.hadoop.conf.Configuration;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.storm.hdfs.common.HdfsUtils;<br/>\n    +import org.apache.storm.hdfs.common.security.HdfsSecurityUtil;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +<br/>\n    +public class HdfsSpout extends BaseRichSpout {<br/>\n    +<br/>\n    +  private static final Logger LOG = LoggerFactory.getLogger(HdfsSpout.class);<br/>\n    +<br/>\n    +  private Path sourceDirPath;<br/>\n    +  private Path archiveDirPath;<br/>\n    +  private Path badFilesDirPath;<br/>\n    +  private Path lockDirPath;<br/>\n    +<br/>\n    +  private int commitFrequencyCount = Configs.DEFAULT_COMMIT_FREQ_COUNT;<br/>\n    +  private int commitFrequencySec = Configs.DEFAULT_COMMIT_FREQ_SEC;<br/>\n    +  private int maxDuplicates = Configs.DEFAULT_MAX_DUPLICATES;<br/>\n    +  private int lockTimeoutSec = Configs.DEFAULT_LOCK_TIMEOUT;<br/>\n    +  private boolean clocksInSync = true;<br/>\n    +<br/>\n    +  private ProgressTracker tracker = new ProgressTracker();<br/>\n    +<br/>\n    +  private FileSystem hdfs;<br/>\n    +  private FileReader reader;<br/>\n    +<br/>\n    +  private SpoutOutputCollector collector;<br/>\n    +  HashMap<MessageId, List<Object> > inflight = new HashMap<>();<br/>\n    +  LinkedBlockingQueue<HdfsUtils.Pair<MessageId, List<Object>>> retryList = new LinkedBlockingQueue<>();<br/>\n    +<br/>\n    +  private String inprogress_suffix = \".inprogress\";<br/>\n    +  private String ignoreSuffix = \".ignore\";<br/>\n    +<br/>\n    +  private Configuration hdfsConfig;<br/>\n    +  private String readerType;<br/>\n    +<br/>\n    +  private Map conf = null;<br/>\n    +  private FileLock lock;<br/>\n    +  private String spoutId = null;<br/>\n    +<br/>\n    +  HdfsUtils.Pair<Path,FileLock.LogEntry> lastExpiredLock = null;<br/>\n    +  private long lastExpiredLockTime = 0;<br/>\n    +<br/>\n    +  private long tupleCounter = 0;<br/>\n    +  private boolean ackEnabled = false;<br/>\n    +  private int acksSinceLastCommit = 0 ;<br/>\n    +  private final AtomicBoolean commitTimeElapsed = new AtomicBoolean(false);<br/>\n    +  private final Timer commitTimer = new Timer();<br/>\n    +  private boolean fileReadCompletely = false;<br/>\n    +<br/>\n    +  private String configKey = Configs.DEFAULT_HDFS_CONFIG_KEY; // key for hdfs kerberos configs<br/>\n    +<br/>\n    +  public HdfsSpout() </p>\n{\n    +  }\n<p>    +<br/>\n    +  public Path getLockDirPath() </p>\n{\n    +    return lockDirPath;\n    +  }\n<p>    +<br/>\n    +  public SpoutOutputCollector getCollector() </p>\n{\n    +    return collector;\n    +  }\n<p>    +<br/>\n    +  public HdfsSpout withConfigKey(String configKey)</p>\n{\n    +    this.configKey = configKey;\n    +    return this;\n    +  }\n<p>    +<br/>\n    +  public void nextTuple() {<br/>\n    +    LOG.debug(\"Next Tuple\");<br/>\n    +    // 1) First re-emit any previously failed tuples (from retryList)<br/>\n    +    if (!retryList.isEmpty()) </p>\n{\n    +      LOG.debug(\"Sending from retry list\");\n    +      HdfsUtils.Pair<MessageId, List<Object>> pair = retryList.remove();\n    +      emitData(pair.getValue(), pair.getKey());\n    +      return;\n    +    }\n<p>    +<br/>\n    +    if( ackEnabled  &&  tracker.size()>=maxDuplicates ) {<br/>\n    +      LOG.warn(\"Waiting for more ACKs before generating new tuples. \" +<br/>\n    +       \"Progress tracker size has reached limit {}\"<br/>\n    +      , maxDuplicates);<br/>\n    +      // Don't emit anything .. allow configured spout wait strategy to kick in<br/>\n    +      return;<br/>\n    +    }<br/>\n    +<br/>\n    +    // 2) If no failed tuples, then send tuples from hdfs<br/>\n    +    while (true) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Not sure if i understand the implied suggestion. It will be blocked for about the same time as the case when spout naturally reaches end of file and switches to next file.  exiting immediately would be a periodic perf hit.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630945/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630952","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630952","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630952,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5NTI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T02:58:33Z","updated_at":"2025-01-24T14:14:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user roshannaik commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47591673\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47591673</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -0,0 +1,654 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +import java.io.IOException;<br/>\n    +import java.lang.reflect.Constructor;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Timer;<br/>\n    +import java.util.TimerTask;<br/>\n    +import java.util.concurrent.LinkedBlockingQueue;<br/>\n    +import java.util.concurrent.atomic.AtomicBoolean;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import org.apache.hadoop.conf.Configuration;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.storm.hdfs.common.HdfsUtils;<br/>\n    +import org.apache.storm.hdfs.common.security.HdfsSecurityUtil;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +<br/>\n    +public class HdfsSpout extends BaseRichSpout {<br/>\n    +<br/>\n    +  private static final Logger LOG = LoggerFactory.getLogger(HdfsSpout.class);<br/>\n    +<br/>\n    +  private Path sourceDirPath;<br/>\n    +  private Path archiveDirPath;<br/>\n    +  private Path badFilesDirPath;<br/>\n    +  private Path lockDirPath;<br/>\n    +<br/>\n    +  private int commitFrequencyCount = Configs.DEFAULT_COMMIT_FREQ_COUNT;<br/>\n    +  private int commitFrequencySec = Configs.DEFAULT_COMMIT_FREQ_SEC;<br/>\n    +  private int maxDuplicates = Configs.DEFAULT_MAX_DUPLICATES;<br/>\n    +  private int lockTimeoutSec = Configs.DEFAULT_LOCK_TIMEOUT;<br/>\n    +  private boolean clocksInSync = true;<br/>\n    +<br/>\n    +  private ProgressTracker tracker = new ProgressTracker();<br/>\n    +<br/>\n    +  private FileSystem hdfs;<br/>\n    +  private FileReader reader;<br/>\n    +<br/>\n    +  private SpoutOutputCollector collector;<br/>\n    +  HashMap<MessageId, List<Object> > inflight = new HashMap<>();<br/>\n    +  LinkedBlockingQueue<HdfsUtils.Pair<MessageId, List<Object>>> retryList = new LinkedBlockingQueue<>();<br/>\n    +<br/>\n    +  private String inprogress_suffix = \".inprogress\";<br/>\n    +  private String ignoreSuffix = \".ignore\";<br/>\n    +<br/>\n    +  private Configuration hdfsConfig;<br/>\n    +  private String readerType;<br/>\n    +<br/>\n    +  private Map conf = null;<br/>\n    +  private FileLock lock;<br/>\n    +  private String spoutId = null;<br/>\n    +<br/>\n    +  HdfsUtils.Pair<Path,FileLock.LogEntry> lastExpiredLock = null;<br/>\n    +  private long lastExpiredLockTime = 0;<br/>\n    +<br/>\n    +  private long tupleCounter = 0;<br/>\n    +  private boolean ackEnabled = false;<br/>\n    +  private int acksSinceLastCommit = 0 ;<br/>\n    +  private final AtomicBoolean commitTimeElapsed = new AtomicBoolean(false);<br/>\n    +  private final Timer commitTimer = new Timer();<br/>\n    +  private boolean fileReadCompletely = false;<br/>\n    +<br/>\n    +  private String configKey = Configs.DEFAULT_HDFS_CONFIG_KEY; // key for hdfs kerberos configs<br/>\n    +<br/>\n    +  public HdfsSpout() </p>\n{\n    +  }\n<p>    +<br/>\n    +  public Path getLockDirPath() </p>\n{\n    +    return lockDirPath;\n    +  }\n<p>    +<br/>\n    +  public SpoutOutputCollector getCollector() </p>\n{\n    +    return collector;\n    +  }\n<p>    +<br/>\n    +  public HdfsSpout withConfigKey(String configKey)</p>\n{\n    +    this.configKey = configKey;\n    +    return this;\n    +  }\n<p>    +<br/>\n    +  public void nextTuple() {<br/>\n    +    LOG.debug(\"Next Tuple\");<br/>\n    +    // 1) First re-emit any previously failed tuples (from retryList)<br/>\n    +    if (!retryList.isEmpty()) </p>\n{\n    +      LOG.debug(\"Sending from retry list\");\n    +      HdfsUtils.Pair<MessageId, List<Object>> pair = retryList.remove();\n    +      emitData(pair.getValue(), pair.getKey());\n    +      return;\n    +    }\n<p>    +<br/>\n    +    if( ackEnabled  &&  tracker.size()>=maxDuplicates ) {<br/>\n    +      LOG.warn(\"Waiting for more ACKs before generating new tuples. \" +<br/>\n    +       \"Progress tracker size has reached limit {}\"<br/>\n    +      , maxDuplicates);<br/>\n    +      // Don't emit anything .. allow configured spout wait strategy to kick in<br/>\n    +      return;<br/>\n    +    }<br/>\n    +<br/>\n    +    // 2) If no failed tuples, then send tuples from hdfs<br/>\n    +    while (true) {<br/>\n    +      try {<br/>\n    +// 3) Select a new file if one is not open already<br/>\n    +if (reader == null) {<br/>\n    +  reader = pickNextFile();<br/>\n    +  if (reader == null) </p>\n{\n    +    LOG.info(\"Currently no new files to process under : \" + sourceDirPath);\n    +    return;\n    +  }\n<p>    +}<br/>\n    +<br/>\n    +// 4) Read record from file, emit to collector and record progress<br/>\n    +List<Object> tuple = reader.next();<br/>\n    +if (tuple != null) {<br/>\n    +  fileReadCompletely= false;<br/>\n    +  ++tupleCounter;<br/>\n    +  MessageId msgId = new MessageId(tupleCounter, reader.getFilePath(), reader.getFileOffset());<br/>\n    +  emitData(tuple, msgId);<br/>\n    +<br/>\n    +  if(!ackEnabled) </p>\n{\n    +    ++acksSinceLastCommit; // assume message is immediately acked in non-ack mode\n    +    commitProgress(reader.getFileOffset());\n    +  }\n<p> else </p>\n{\n    +    commitProgress(tracker.getCommitPosition());\n    +  }\n<p>    +  return;<br/>\n    +} else {<br/>\n    +  fileReadCompletely = true;<br/>\n    +  if(!ackEnabled) </p>\n{\n    +    markFileAsDone(reader.getFilePath());\n    +  }\n<p>    +}<br/>\n    +      } catch (IOException e) </p>\n{\n    +LOG.error(\"I/O Error processing at file location \" + getFileProgress(reader), e);\n    +// don't emit anything .. allow configured spout wait strategy to kick in\n    +return;\n    +      }\n<p> catch (ParseException e) {<br/>\n    +LOG.error(\"Parsing error when processing at file location \" + getFileProgress(reader) +<br/>\n    +\". Skipping remainder of file.\", e);<br/>\n    +markFileAsBad(reader.getFilePath());<br/>\n    +// note: Unfortunately not emitting anything here due to parse error<br/>\n    +// will trigger the configured spout wait strategy which is unnecessary<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    yes thats how it is. Reader is null-ed out by the  markFileAsBad() and markFileAsDone() methods.. triggering switch to the next file.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630952/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686360","html_url":"https://github.com/apache/storm/issues/5211#issuecomment-2612686360","issue_url":"https://api.github.com/repos/apache/storm/issues/5211","id":2612686360,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODYzNjA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T03:25:08Z","updated_at":"2025-01-24T14:38:19Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user zhuoliu commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/933#discussion_r47592998\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/933#discussion_r47592998</a></p>\n\n<p>    &#8212; Diff: conf/defaults.yaml &#8212;<br/>\n    @@ -179,7 +179,7 @@ task.refresh.poll.secs: 10<br/>\n     task.credentials.poll.secs: 30</p>\n\n<ol>\n\t<li>now should be null by default<br/>\n    -topology.backpressure.enable: true<br/>\n    +topology.backpressure.enable: false<br/>\n     backpressure.disruptor.high.watermark: 0.9<br/>\n     backpressure.disruptor.low.watermark: 0.4\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ol>\n\n\n<p>    This low/high watermark default values are now more of empirical values based on a limited set of topologies. We may need more experiments and theoretical analysis (based on representative queue draining speed, callback response time etc.) for choices of these watermark percentages.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686360/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630958","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630958","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630958,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5NTg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T03:27:51Z","updated_at":"2025-01-24T14:14:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47593112\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47593112</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -0,0 +1,654 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +import java.io.IOException;<br/>\n    +import java.lang.reflect.Constructor;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Timer;<br/>\n    +import java.util.TimerTask;<br/>\n    +import java.util.concurrent.LinkedBlockingQueue;<br/>\n    +import java.util.concurrent.atomic.AtomicBoolean;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import org.apache.hadoop.conf.Configuration;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.storm.hdfs.common.HdfsUtils;<br/>\n    +import org.apache.storm.hdfs.common.security.HdfsSecurityUtil;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +<br/>\n    +public class HdfsSpout extends BaseRichSpout {<br/>\n    +<br/>\n    +  private static final Logger LOG = LoggerFactory.getLogger(HdfsSpout.class);<br/>\n    +<br/>\n    +  private Path sourceDirPath;<br/>\n    +  private Path archiveDirPath;<br/>\n    +  private Path badFilesDirPath;<br/>\n    +  private Path lockDirPath;<br/>\n    +<br/>\n    +  private int commitFrequencyCount = Configs.DEFAULT_COMMIT_FREQ_COUNT;<br/>\n    +  private int commitFrequencySec = Configs.DEFAULT_COMMIT_FREQ_SEC;<br/>\n    +  private int maxDuplicates = Configs.DEFAULT_MAX_DUPLICATES;<br/>\n    +  private int lockTimeoutSec = Configs.DEFAULT_LOCK_TIMEOUT;<br/>\n    +  private boolean clocksInSync = true;<br/>\n    +<br/>\n    +  private ProgressTracker tracker = new ProgressTracker();<br/>\n    +<br/>\n    +  private FileSystem hdfs;<br/>\n    +  private FileReader reader;<br/>\n    +<br/>\n    +  private SpoutOutputCollector collector;<br/>\n    +  HashMap<MessageId, List<Object> > inflight = new HashMap<>();<br/>\n    +  LinkedBlockingQueue<HdfsUtils.Pair<MessageId, List<Object>>> retryList = new LinkedBlockingQueue<>();<br/>\n    +<br/>\n    +  private String inprogress_suffix = \".inprogress\";<br/>\n    +  private String ignoreSuffix = \".ignore\";<br/>\n    +<br/>\n    +  private Configuration hdfsConfig;<br/>\n    +  private String readerType;<br/>\n    +<br/>\n    +  private Map conf = null;<br/>\n    +  private FileLock lock;<br/>\n    +  private String spoutId = null;<br/>\n    +<br/>\n    +  HdfsUtils.Pair<Path,FileLock.LogEntry> lastExpiredLock = null;<br/>\n    +  private long lastExpiredLockTime = 0;<br/>\n    +<br/>\n    +  private long tupleCounter = 0;<br/>\n    +  private boolean ackEnabled = false;<br/>\n    +  private int acksSinceLastCommit = 0 ;<br/>\n    +  private final AtomicBoolean commitTimeElapsed = new AtomicBoolean(false);<br/>\n    +  private final Timer commitTimer = new Timer();<br/>\n    +  private boolean fileReadCompletely = false;<br/>\n    +<br/>\n    +  private String configKey = Configs.DEFAULT_HDFS_CONFIG_KEY; // key for hdfs kerberos configs<br/>\n    +<br/>\n    +  public HdfsSpout() </p>\n{\n    +  }\n<p>    +<br/>\n    +  public Path getLockDirPath() </p>\n{\n    +    return lockDirPath;\n    +  }\n<p>    +<br/>\n    +  public SpoutOutputCollector getCollector() </p>\n{\n    +    return collector;\n    +  }\n<p>    +<br/>\n    +  public HdfsSpout withConfigKey(String configKey)</p>\n{\n    +    this.configKey = configKey;\n    +    return this;\n    +  }\n<p>    +<br/>\n    +  public void nextTuple() {<br/>\n    +    LOG.debug(\"Next Tuple\");<br/>\n    +    // 1) First re-emit any previously failed tuples (from retryList)<br/>\n    +    if (!retryList.isEmpty()) </p>\n{\n    +      LOG.debug(\"Sending from retry list\");\n    +      HdfsUtils.Pair<MessageId, List<Object>> pair = retryList.remove();\n    +      emitData(pair.getValue(), pair.getKey());\n    +      return;\n    +    }\n<p>    +<br/>\n    +    if( ackEnabled  &&  tracker.size()>=maxDuplicates ) {<br/>\n    +      LOG.warn(\"Waiting for more ACKs before generating new tuples. \" +<br/>\n    +       \"Progress tracker size has reached limit {}\"<br/>\n    +      , maxDuplicates);<br/>\n    +      // Don't emit anything .. allow configured spout wait strategy to kick in<br/>\n    +      return;<br/>\n    +    }<br/>\n    +<br/>\n    +    // 2) If no failed tuples, then send tuples from hdfs<br/>\n    +    while (true) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Oh, seems like you already handled edge-cases (there's no file to read).<br/>\n    Another edge case I can imagine is that there're too many skewed files and read-parse-discard them takes amount of time, but it shouldn't be normal.<br/>\n    I'm fine to have this loop. Thanks.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630958/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630961","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630961","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630961,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5NjE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T03:34:49Z","updated_at":"2025-01-24T14:14:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47593392\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47593392</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -0,0 +1,654 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +import java.io.IOException;<br/>\n    +import java.lang.reflect.Constructor;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Timer;<br/>\n    +import java.util.TimerTask;<br/>\n    +import java.util.concurrent.LinkedBlockingQueue;<br/>\n    +import java.util.concurrent.atomic.AtomicBoolean;<br/>\n    +<br/>\n    +import backtype.storm.Config;<br/>\n    +import org.apache.hadoop.conf.Configuration;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.storm.hdfs.common.HdfsUtils;<br/>\n    +import org.apache.storm.hdfs.common.security.HdfsSecurityUtil;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import backtype.storm.spout.SpoutOutputCollector;<br/>\n    +import backtype.storm.task.TopologyContext;<br/>\n    +import backtype.storm.topology.OutputFieldsDeclarer;<br/>\n    +import backtype.storm.topology.base.BaseRichSpout;<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +<br/>\n    +public class HdfsSpout extends BaseRichSpout {<br/>\n    +<br/>\n    +  private static final Logger LOG = LoggerFactory.getLogger(HdfsSpout.class);<br/>\n    +<br/>\n    +  private Path sourceDirPath;<br/>\n    +  private Path archiveDirPath;<br/>\n    +  private Path badFilesDirPath;<br/>\n    +  private Path lockDirPath;<br/>\n    +<br/>\n    +  private int commitFrequencyCount = Configs.DEFAULT_COMMIT_FREQ_COUNT;<br/>\n    +  private int commitFrequencySec = Configs.DEFAULT_COMMIT_FREQ_SEC;<br/>\n    +  private int maxDuplicates = Configs.DEFAULT_MAX_DUPLICATES;<br/>\n    +  private int lockTimeoutSec = Configs.DEFAULT_LOCK_TIMEOUT;<br/>\n    +  private boolean clocksInSync = true;<br/>\n    +<br/>\n    +  private ProgressTracker tracker = new ProgressTracker();<br/>\n    +<br/>\n    +  private FileSystem hdfs;<br/>\n    +  private FileReader reader;<br/>\n    +<br/>\n    +  private SpoutOutputCollector collector;<br/>\n    +  HashMap<MessageId, List<Object> > inflight = new HashMap<>();<br/>\n    +  LinkedBlockingQueue<HdfsUtils.Pair<MessageId, List<Object>>> retryList = new LinkedBlockingQueue<>();<br/>\n    +<br/>\n    +  private String inprogress_suffix = \".inprogress\";<br/>\n    +  private String ignoreSuffix = \".ignore\";<br/>\n    +<br/>\n    +  private Configuration hdfsConfig;<br/>\n    +  private String readerType;<br/>\n    +<br/>\n    +  private Map conf = null;<br/>\n    +  private FileLock lock;<br/>\n    +  private String spoutId = null;<br/>\n    +<br/>\n    +  HdfsUtils.Pair<Path,FileLock.LogEntry> lastExpiredLock = null;<br/>\n    +  private long lastExpiredLockTime = 0;<br/>\n    +<br/>\n    +  private long tupleCounter = 0;<br/>\n    +  private boolean ackEnabled = false;<br/>\n    +  private int acksSinceLastCommit = 0 ;<br/>\n    +  private final AtomicBoolean commitTimeElapsed = new AtomicBoolean(false);<br/>\n    +  private final Timer commitTimer = new Timer();<br/>\n    +  private boolean fileReadCompletely = false;<br/>\n    +<br/>\n    +  private String configKey = Configs.DEFAULT_HDFS_CONFIG_KEY; // key for hdfs kerberos configs<br/>\n    +<br/>\n    +  public HdfsSpout() </p>\n{\n    +  }\n<p>    +<br/>\n    +  public Path getLockDirPath() </p>\n{\n    +    return lockDirPath;\n    +  }\n<p>    +<br/>\n    +  public SpoutOutputCollector getCollector() </p>\n{\n    +    return collector;\n    +  }\n<p>    +<br/>\n    +  public HdfsSpout withConfigKey(String configKey)</p>\n{\n    +    this.configKey = configKey;\n    +    return this;\n    +  }\n<p>    +<br/>\n    +  public void nextTuple() {<br/>\n    +    LOG.debug(\"Next Tuple\");<br/>\n    +    // 1) First re-emit any previously failed tuples (from retryList)<br/>\n    +    if (!retryList.isEmpty()) </p>\n{\n    +      LOG.debug(\"Sending from retry list\");\n    +      HdfsUtils.Pair<MessageId, List<Object>> pair = retryList.remove();\n    +      emitData(pair.getValue(), pair.getKey());\n    +      return;\n    +    }\n<p>    +<br/>\n    +    if( ackEnabled  &&  tracker.size()>=maxDuplicates ) {<br/>\n    +      LOG.warn(\"Waiting for more ACKs before generating new tuples. \" +<br/>\n    +       \"Progress tracker size has reached limit {}\"<br/>\n    +      , maxDuplicates);<br/>\n    +      // Don't emit anything .. allow configured spout wait strategy to kick in<br/>\n    +      return;<br/>\n    +    }<br/>\n    +<br/>\n    +    // 2) If no failed tuples, then send tuples from hdfs<br/>\n    +    while (true) {<br/>\n    +      try {<br/>\n    +// 3) Select a new file if one is not open already<br/>\n    +if (reader == null) {<br/>\n    +  reader = pickNextFile();<br/>\n    +  if (reader == null) </p>\n{\n    +    LOG.info(\"Currently no new files to process under : \" + sourceDirPath);\n    +    return;\n    +  }\n<p>    +}<br/>\n    +<br/>\n    +// 4) Read record from file, emit to collector and record progress<br/>\n    +List<Object> tuple = reader.next();<br/>\n    +if (tuple != null) {<br/>\n    +  fileReadCompletely= false;<br/>\n    +  ++tupleCounter;<br/>\n    +  MessageId msgId = new MessageId(tupleCounter, reader.getFilePath(), reader.getFileOffset());<br/>\n    +  emitData(tuple, msgId);<br/>\n    +<br/>\n    +  if(!ackEnabled) </p>\n{\n    +    ++acksSinceLastCommit; // assume message is immediately acked in non-ack mode\n    +    commitProgress(reader.getFileOffset());\n    +  }\n<p> else </p>\n{\n    +    commitProgress(tracker.getCommitPosition());\n    +  }\n<p>    +  return;<br/>\n    +} else {<br/>\n    +  fileReadCompletely = true;<br/>\n    +  if(!ackEnabled) </p>\n{\n    +    markFileAsDone(reader.getFilePath());\n    +  }\n<p>    +}<br/>\n    +      } catch (IOException e) </p>\n{\n    +LOG.error(\"I/O Error processing at file location \" + getFileProgress(reader), e);\n    +// don't emit anything .. allow configured spout wait strategy to kick in\n    +return;\n    +      }\n<p> catch (ParseException e) {<br/>\n    +LOG.error(\"Parsing error when processing at file location \" + getFileProgress(reader) +<br/>\n    +\". Skipping remainder of file.\", e);<br/>\n    +markFileAsBad(reader.getFilePath());<br/>\n    +// note: Unfortunately not emitting anything here due to parse error<br/>\n    +// will trigger the configured spout wait strategy which is unnecessary<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    @roshannaik Thanks for the explanation. I didn't see unlockAndCloseReader().</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630961/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628665","html_url":"https://github.com/apache/storm/issues/5025#issuecomment-2612628665","issue_url":"https://api.github.com/repos/apache/storm/issues/5025","id":2612628665,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2Mjg2NjU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T04:14:20Z","updated_at":"2025-01-24T14:13:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user satishd commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/900#discussion_r47595114\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/900#discussion_r47595114</a></p>\n\n<p>    &#8212; Diff: storm-core/test/jvm/backtype/storm/windowing/WaterMarkEventGeneratorTest.java &#8212;<br/>\n    @@ -0,0 +1,100 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package backtype.storm.windowing;<br/>\n    +<br/>\n    +import backtype.storm.generated.GlobalStreamId;<br/>\n    +import org.junit.Before;<br/>\n    +import org.junit.Test;<br/>\n    +import org.mockito.Mockito;<br/>\n    +<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collections;<br/>\n    +import java.util.HashSet;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Set;<br/>\n    +<br/>\n    +import static org.junit.Assert.*;<br/>\n    +<br/>\n    +/**<br/>\n    + * Unit tests for </p>\n{@link WaterMarkEventGeneratorTest}<br/>\n    &#8212; End diff &#8211;<br/>\n    <br/>\n    Minor typo: Unit tests for {@link WaterMarkEventGenerator} instead of Unit tests for {@link WaterMarkEventGeneratorTest}","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628665/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628671","html_url":"https://github.com/apache/storm/issues/5025#issuecomment-2612628671","issue_url":"https://api.github.com/repos/apache/storm/issues/5025","id":2612628671,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2Mjg2NzE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T04:22:46Z","updated_at":"2025-01-24T14:13:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user satishd commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/900#discussion_r47595521\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/900#discussion_r47595521</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/backtype/storm/windowing/EvictionPolicy.java &#8212;<br/>\n    @@ -39,4 +63,12 @@</p>\n<ul>\n\t<li>@param event the input event to be tracked<br/>\n  */<br/>\n void track(Event<T> event);<br/>\n    +<br/>\n    +    /**<br/>\n    +     * Sets a context in the eviction policy that can be used while evicting the events.<br/>\n    +     * E.g. For TimeEvictionPolicy, this could be used to set the reference timestamp.<br/>\n    +     *<br/>\n    +     * @param context<br/>\n    +     */<br/>\n    +    void setContext(Object context);\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    May want to introduce class/interface EvictionPolicyContext which may have opaque structure for now. This can be done later as this PR is waiting for long.</p>\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628671/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/164641923","html_url":"https://github.com/apache/storm/pull/900#issuecomment-164641923","issue_url":"https://api.github.com/repos/apache/storm/issues/900","id":164641923,"node_id":"MDEyOklzc3VlQ29tbWVudDE2NDY0MTkyMw==","user":{"login":"satishd","id":2577761,"node_id":"MDQ6VXNlcjI1Nzc3NjE=","avatar_url":"https://avatars.githubusercontent.com/u/2577761?v=4","gravatar_id":"","url":"https://api.github.com/users/satishd","html_url":"https://github.com/satishd","followers_url":"https://api.github.com/users/satishd/followers","following_url":"https://api.github.com/users/satishd/following{/other_user}","gists_url":"https://api.github.com/users/satishd/gists{/gist_id}","starred_url":"https://api.github.com/users/satishd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/satishd/subscriptions","organizations_url":"https://api.github.com/users/satishd/orgs","repos_url":"https://api.github.com/users/satishd/repos","events_url":"https://api.github.com/users/satishd/events{/privacy}","received_events_url":"https://api.github.com/users/satishd/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T04:23:47Z","updated_at":"2015-12-15T10:17:52Z","author_association":"MEMBER","body":"LGTM, +1 \n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/164641923/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628676","html_url":"https://github.com/apache/storm/issues/5025#issuecomment-2612628676","issue_url":"https://api.github.com/repos/apache/storm/issues/5025","id":2612628676,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2Mjg2NzY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T04:23:48Z","updated_at":"2025-01-24T14:13:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user satishd commented on the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/900#issuecomment-164641923\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/900#issuecomment-164641923</a></p>\n\n<p>    Overall LGTM, +1 </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612628676/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630969","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630969","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630969,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5Njk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T05:15:30Z","updated_at":"2025-01-24T14:14:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user satishd commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47597484\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47597484</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/TextFileReader.java &#8212;<br/>\n    @@ -0,0 +1,168 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +import org.apache.hadoop.fs.FSDataInputStream;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.BufferedReader;<br/>\n    +import java.io.IOException;<br/>\n    +import java.io.InputStreamReader;<br/>\n    +import java.util.Collections;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +<br/>\n    +// Todo: Track file offsets instead of line number<br/>\n    +class TextFileReader extends AbstractFileReader {<br/>\n    +  public static final String CHARSET = \"hdfsspout.reader.charset\";<br/>\n    +  public static final String BUFFER_SIZE = \"hdfsspout.reader.buffer.bytes\";<br/>\n    +<br/>\n    +  public static final String DEFAULT_FIELD_NAME = \"line\";<br/>\n    +<br/>\n    +  private static final int DEFAULT_BUFF_SIZE = 4096;<br/>\n    +<br/>\n    +  private BufferedReader reader;<br/>\n    +  private final Logger LOG = LoggerFactory.getLogger(TextFileReader.class);<br/>\n    +  private TextFileReader.Offset offset;<br/>\n    +<br/>\n    +  public TextFileReader(FileSystem fs, Path file, Map conf) throws IOException </p>\n{\n    +    super(fs, file, new Fields(DEFAULT_FIELD_NAME));\n    +    FSDataInputStream in = fs.open(file);\n    +    String charSet = (conf==null || !conf.containsKey(CHARSET) ) ? \"UTF-8\" : conf.get(CHARSET).toString();\n    +    int buffSz = (conf==null || !conf.containsKey(BUFFER_SIZE) ) ? DEFAULT_BUFF_SIZE : Integer.parseInt( conf.get(BUFFER_SIZE).toString() );\n    +    reader = new BufferedReader(new InputStreamReader(in, charSet), buffSz);\n    +    offset = new TextFileReader.Offset(0,0);\n    +  }\n<p>    +<br/>\n    +  public TextFileReader(FileSystem fs, Path file, Map conf, String startOffset) throws IOException </p>\n{\n    +    super(fs, file, new Fields(DEFAULT_FIELD_NAME));\n    +    offset = new TextFileReader.Offset(startOffset);\n    +    FSDataInputStream in = fs.open(file);\n    +    in.seek(offset.byteOffset);\n    +    String charSet = (conf==null || !conf.containsKey(CHARSET) ) ? \"UTF-8\" : conf.get(CHARSET).toString();\n    +    int buffSz = (conf==null || !conf.containsKey(BUFFER_SIZE) ) ? DEFAULT_BUFF_SIZE : Integer.parseInt( conf.get(BUFFER_SIZE).toString() );\n    +    reader = new BufferedReader(new InputStreamReader(in, charSet), buffSz);\n    +  }\n<p>    &#8212; End diff &#8211;</p>\n\n<p>    Two constructors share similar logic. You may want to have code like below.</p>\n\n\n<p>      public TextFileReader(FileSystem fs, Path file, Map conf) throws IOException </p>\n{\nthis(fs, file, conf, null);\n      }\n\n<p>      public TextFileReader(FileSystem fs, Path file, Map conf, String startOffset) throws IOException </p>\n{\nsuper(fs, file, new Fields(DEFAULT_FIELD_NAME));\noffset = startOffset != null? new TextFileReader.Offset(startOffset) : new TextFileReader.Offset(0,0);\nFSDataInputStream in = fs.open(file);\nin.seek(offset.byteOffset);\nString charSet = (conf==null || !conf.containsKey(CHARSET) ) ? \"UTF-8\" : conf.get(CHARSET).toString();\nint buffSz = (conf==null || !conf.containsKey(BUFFER_SIZE) ) ? DEFAULT_BUFF_SIZE : Integer.parseInt( conf.get(BUFFER_SIZE).toString() );\nreader = new BufferedReader(new InputStreamReader(in, charSet), buffSz);\n      }\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630969/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630972","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630972","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630972,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5NzI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T05:18:11Z","updated_at":"2025-01-24T14:14:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user satishd commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47597593\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47597593</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/AbstractFileReader.java &#8212;<br/>\n    @@ -0,0 +1,71 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +import backtype.storm.tuple.Fields;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +<br/>\n    +<br/>\n    +abstract class AbstractFileReader implements FileReader {<br/>\n    +<br/>\n    +  private final Path file;<br/>\n    +  private final FileSystem fs;<br/>\n    +  private Fields fields;<br/>\n    +<br/>\n    +  public AbstractFileReader(FileSystem fs, Path file, Fields fieldNames) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    fs is never used. You may want to remove that.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630972/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630980","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630980","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630980,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5ODA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T05:19:09Z","updated_at":"2025-01-24T14:14:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user satishd commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47597643\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47597643</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/common/HdfsUtils.java &#8212;<br/>\n    @@ -0,0 +1,101 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.common;<br/>\n    +<br/>\n    +import org.apache.hadoop.fs.FSDataOutputStream;<br/>\n    +import org.apache.hadoop.fs.FileAlreadyExistsException;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.LocatedFileStatus;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.hadoop.fs.RemoteIterator;<br/>\n    +import org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException;<br/>\n    +import org.apache.hadoop.ipc.RemoteException;<br/>\n    +<br/>\n    +import java.io.IOException;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.Collections;<br/>\n    +<br/>\n    +public class HdfsUtils {<br/>\n    +  /** list files sorted by modification time that have not been modified since 'olderThan'. if<br/>\n    +   * 'olderThan' is <= 0 then the filtering is disabled */<br/>\n    +  public static Collection<Path> listFilesByModificationTime(FileSystem fs, Path directory, long olderThan)<br/>\n    +  throws IOException {<br/>\n    +    ArrayList<LocatedFileStatus> fstats = new ArrayList<>();<br/>\n    +<br/>\n    +    RemoteIterator<LocatedFileStatus> itr = fs.listFiles(directory, false);<br/>\n    +    while( itr.hasNext() ) {<br/>\n    +      LocatedFileStatus fileStatus = itr.next();<br/>\n    +      if(olderThan>0) </p>\n{\n    +if( fileStatus.getModificationTime()<olderThan )\n    +  fstats.add(fileStatus);\n    +      }\n<p>    +      else </p>\n{\n    +fstats.add(fileStatus);\n    +      }\n<p>    +    }<br/>\n    +    Collections.sort(fstats, new CmpFilesByModificationTime() );<br/>\n    +<br/>\n    +    ArrayList<Path> result = new ArrayList<>(fstats.size());<br/>\n    +    for (LocatedFileStatus fstat : fstats) </p>\n{\n    +      result.add(fstat.getPath());\n    +    }\n<p>    +    return result;<br/>\n    +  }<br/>\n    +<br/>\n    +  /**<br/>\n    +   * Returns true if succeeded. False if file already exists. throws if there was unexpected problem<br/>\n    +   */<br/>\n    +  public static FSDataOutputStream tryCreateFile(FileSystem fs, Path file) throws IOException {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    You may want to update javadoc. It is not aligned with the code.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630980/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598492","html_url":"https://github.com/apache/storm/issues/4876#issuecomment-2612598492","issue_url":"https://api.github.com/repos/apache/storm/issues/4876","id":2612598492,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1OTg0OTI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T05:27:36Z","updated_at":"2025-01-24T14:00:09Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user hsun-cnnxty commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/728#discussion_r47597958\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/728#discussion_r47597958</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/backtype/storm/messaging/netty/Client.java &#8212;<br/>\n    @@ -182,7 +177,7 @@ private boolean connectionEstablished(Channel channel) {<br/>\n     // See:<br/>\n     // - <a href=\"http://netty.io/3.9/api/org/jboss/netty/channel/ChannelEvent.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://netty.io/3.9/api/org/jboss/netty/channel/ChannelEvent.html</a><br/>\n     // - <a href=\"http://stackoverflow.com/questions/13356622/what-are-the-netty-channel-state-transitions\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://stackoverflow.com/questions/13356622/what-are-the-netty-channel-state-transitions</a></p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>return channel != null && channel.isConnected();<br/>\n    +return channel != null && channel.isOpen();\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    Thanks for the code review. It could be a bug. Netty 4.x has simplified the state model. See </p>\n\n<p>    <a href=\"http://netty.io/wiki/new-and-noteworthy-in-4.0.html#wiki-h4-19\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://netty.io/wiki/new-and-noteworthy-in-4.0.html#wiki-h4-19</a>  </p>\n\n<p>    So channelOpen, channelBound, and channelConnected have been merged to channelActive and Channel.isBound() and isConnected() have been merged to isActive().  The isConnected() method is removed.  I think I should use isActive() instead of isOpen().  The code comments need update too.  I will fix it and other format issues this weekend if I get time.</p>\n\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598492/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686364","html_url":"https://github.com/apache/storm/issues/5211#issuecomment-2612686364","issue_url":"https://api.github.com/repos/apache/storm/issues/5211","id":2612686364,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2ODYzNjQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T05:30:24Z","updated_at":"2025-01-24T14:38:20Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user redsanket commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/933#discussion_r47598080\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/933#discussion_r47598080</a></p>\n\n<p>    &#8212; Diff: storm-core/test/clj/backtype/storm/nimbus_test.clj &#8212;<br/>\n    @@ -1238,10 +1238,11 @@<br/>\n       (testing \"nimbus-data uses correct ACLs\"<br/>\n (let [scheme \"digest\"<br/>\n       digest \"storm:thisisapoorpassword\"</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>auth-conf \n<div class=\"error\"><span class=\"error\">Unknown macro: {STORM-ZOOKEEPER-AUTH-SCHEME scheme    +  auth-conf (merge (read-storm-config)    +    {STORM-ZOOKEEPER-AUTH-SCHEME scheme\n  STORM-ZOOKEEPER-AUTH-PAYLOAD digest\n  STORM-PRINCIPAL-TO-LOCAL-PLUGIN \"backtype.storm.security.auth.DefaultPrincipalToLocal\"\n    -     NIMBUS-THRIFT-PORT 6666}    +     NIMBUS-THRIFT-PORT 6666}</span> </div>\n<p>)</p>\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    All the test cases in this file have a similar port, will create a JIRA to tackle this issue separately as I feel it is not a part of this change</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612686364/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630988","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630988","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630988,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5ODg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T05:35:43Z","updated_at":"2025-01-24T14:14:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user satishd commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47598290\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47598290</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/common/HdfsUtils.java &#8212;<br/>\n    @@ -0,0 +1,101 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.common;<br/>\n    +<br/>\n    +import org.apache.hadoop.fs.FSDataOutputStream;<br/>\n    +import org.apache.hadoop.fs.FileAlreadyExistsException;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.LocatedFileStatus;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.hadoop.fs.RemoteIterator;<br/>\n    +import org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException;<br/>\n    +import org.apache.hadoop.ipc.RemoteException;<br/>\n    +<br/>\n    +import java.io.IOException;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.Collections;<br/>\n    +<br/>\n    +public class HdfsUtils {<br/>\n    +  /** list files sorted by modification time that have not been modified since 'olderThan'. if<br/>\n    +   * 'olderThan' is <= 0 then the filtering is disabled */<br/>\n    +  public static Collection<Path> listFilesByModificationTime(FileSystem fs, Path directory, long olderThan)<br/>\n    +  throws IOException {<br/>\n    +    ArrayList<LocatedFileStatus> fstats = new ArrayList<>();<br/>\n    +<br/>\n    +    RemoteIterator<LocatedFileStatus> itr = fs.listFiles(directory, false);<br/>\n    +    while( itr.hasNext() ) {<br/>\n    +      LocatedFileStatus fileStatus = itr.next();<br/>\n    +      if(olderThan>0) </p>\n{\n    +if( fileStatus.getModificationTime()<olderThan )\n    +  fstats.add(fileStatus);\n    +      }\n<p>    +      else </p>\n{\n    +fstats.add(fileStatus);\n    +      }\n<p>    +    }<br/>\n    +    Collections.sort(fstats, new CmpFilesByModificationTime() );<br/>\n    +<br/>\n    +    ArrayList<Path> result = new ArrayList<>(fstats.size());<br/>\n    +    for (LocatedFileStatus fstat : fstats) </p>\n{\n    +      result.add(fstat.getPath());\n    +    }\n<p>    +    return result;<br/>\n    +  }<br/>\n    +<br/>\n    +  /**<br/>\n    +   * Returns true if succeeded. False if file already exists. throws if there was unexpected problem<br/>\n    +   */<br/>\n    +  public static FSDataOutputStream tryCreateFile(FileSystem fs, Path file) throws IOException {<br/>\n    +    try </p>\n{\n    +      FSDataOutputStream os = fs.create(file, false);\n    +      return os;\n    +    }\n<p> catch (FileAlreadyExistsException e) </p>\n{\n    +      return null;\n    +    }\n<p> catch (RemoteException e) {<br/>\n    +      if( e.getClassName().contentEquals(AlreadyBeingCreatedException.class.getName()) ) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Why contentEquals() is used instead of equals()?  Can we consider using 'instance of' instead of string equals check?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630988/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630993","html_url":"https://github.com/apache/storm/issues/5037#issuecomment-2612630993","issue_url":"https://api.github.com/repos/apache/storm/issues/5037","id":2612630993,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2MzA5OTM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-12-15T05:44:46Z","updated_at":"2025-01-24T14:14:04Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user satishd commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/936#discussion_r47598642\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/936#discussion_r47598642</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/FileLock.java &#8212;<br/>\n    @@ -0,0 +1,300 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p/><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p/><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.hdfs.spout;<br/>\n    +<br/>\n    +<br/>\n    +import org.apache.hadoop.fs.FSDataInputStream;<br/>\n    +import org.apache.hadoop.fs.FSDataOutputStream;<br/>\n    +import org.apache.hadoop.fs.FileSystem;<br/>\n    +import org.apache.hadoop.fs.Path;<br/>\n    +import org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException;<br/>\n    +import org.apache.hadoop.ipc.RemoteException;<br/>\n    +import org.apache.storm.hdfs.common.HdfsUtils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.BufferedReader;<br/>\n    +import java.io.IOException;<br/>\n    +import java.io.InputStreamReader;<br/>\n    +import java.util.Collection;<br/>\n    +<br/>\n    +/**<br/>\n    + * Facility to synchronize access to HDFS files. Thread gains exclusive access to a file by acquiring<br/>\n    + * a FileLock object. The lock itself is represented as file on HDFS. Relies on atomic file creation.<br/>\n    + * Owning thread must heartbeat periodically on the lock to prevent the lock from being deemed as<br/>\n    + * stale (i.e. lock whose owning thread have died).<br/>\n    + */<br/>\n    +public class FileLock {<br/>\n    +<br/>\n    +  private final FileSystem fs;<br/>\n    +  private final String componentID;<br/>\n    +  private final Path lockFile;<br/>\n    +  private final FSDataOutputStream lockFileStream;<br/>\n    +  private LogEntry lastEntry;<br/>\n    +<br/>\n    +  private static final Logger log = LoggerFactory.getLogger(DirLock.class);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    It should have been Logger log = LoggerFactory.getLogger(FileLock.class)</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612630993/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]