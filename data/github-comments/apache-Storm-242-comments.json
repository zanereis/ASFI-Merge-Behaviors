[{"url":"https://api.github.com/repos/apache/storm/issues/comments/234474897","html_url":"https://github.com/apache/storm/pull/1585#issuecomment-234474897","issue_url":"https://api.github.com/repos/apache/storm/issues/1585","id":234474897,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNDQ3NDg5Nw==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-22T07:34:36Z","updated_at":"2016-07-22T07:34:36Z","author_association":"CONTRIBUTOR","body":"+1\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/234474897/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931229","html_url":"https://github.com/apache/storm/issues/5782#issuecomment-2612931229","issue_url":"https://api.github.com/repos/apache/storm/issues/5782","id":2612931229,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzEyMjk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-22T07:34:38Z","updated_at":"2025-01-24T16:30:25Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1585\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1585</a></p>\n\n<p>    +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931229/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612927011","html_url":"https://github.com/apache/storm/issues/5753#issuecomment-2612927011","issue_url":"https://api.github.com/repos/apache/storm/issues/5753","id":2612927011,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjcwMTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-22T13:57:10Z","updated_at":"2025-01-24T16:28:23Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dossett\">dossett</a>:</i>\n<p>Writing each tuple doesn't necessarily result in higher network costs since caching can happen in HDFS code.  (I am not an HDFS expert, feel free to correct me if I'm wrong).  I view the sync as an outer limit on when the data is guaranteed to have been flushed and persisted to HDFS.</p>\n\n<p>It is possible that an alternative approach (batching the writes) would result in better performance &#8211; I'd be interested in seeing benchmarks for that.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612927011/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612927016","html_url":"https://github.com/apache/storm/issues/5753#issuecomment-2612927016","issue_url":"https://api.github.com/repos/apache/storm/issues/5753","id":2612927016,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjcwMTY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-22T17:37:32Z","updated_at":"2025-01-24T16:28:23Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jakesjohn\">jakesjohn</a>:</i>\n<p>Thanks for your reply.    I think overhead is very high in the current case. Writing a message of x size y times to a hdfs cluster vs write a single message of xy size to hdfs cluster.  HDFS is best at large streaming reads and writes  What are the advantages of current implementation(one message write) over the proposed one(batching writes)?    </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612927016/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612927018","html_url":"https://github.com/apache/storm/issues/5753#issuecomment-2612927018","issue_url":"https://api.github.com/repos/apache/storm/issues/5753","id":2612927018,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjcwMTg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-22T19:56:09Z","updated_at":"2025-01-24T16:28:23Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dossett\">dossett</a>:</i>\n<p>I did not create that approach (although I did carry it over in a re-write) but one advantage that comes to mind is that data will potentially appear in HDFS sooner.  Also, not all implementations of AbstractHdfsBolt may be able to support the \"write one big message\" approach.  A text file bolt certainly could, but what about Sequence File or Avro?  I don't know off the top of my head.</p>\n\n<p>If you pursue that and are able to contribute a patch, I will definitely be available for review.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612927018/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612927024","html_url":"https://github.com/apache/storm/issues/5753#issuecomment-2612927024","issue_url":"https://api.github.com/repos/apache/storm/issues/5753","id":2612927024,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjcwMjQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-22T20:53:42Z","updated_at":"2025-01-24T16:28:23Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jakesjohn\">jakesjohn</a>:</i>\n<p>Can we say that data will be in HDFS sooner?  Readers can see the latest message writes only after sync. Hence, i feel that it is safe to write a batch and do a sync immediately during every tick.   As you said, this will work for text files and i need to investigate Avro and Sequence. I am ready to contribute and I will take this up very soon.   Thanks</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612927024/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612929873","html_url":"https://github.com/apache/storm/issues/5771#issuecomment-2612929873","issue_url":"https://api.github.com/repos/apache/storm/issues/5771","id":2612929873,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjk4NzM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-22T21:03:50Z","updated_at":"2025-01-24T16:29:45Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user asfgit closed the pull request at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1579\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1579</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612929873/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612929877","html_url":"https://github.com/apache/storm/issues/5771#issuecomment-2612929877","issue_url":"https://api.github.com/repos/apache/storm/issues/5771","id":2612929877,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjk4Nzc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-22T21:05:41Z","updated_at":"2025-01-24T16:29:45Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ptgoetz\">ptgoetz</a>:</i>\n<p>Thanks <a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tibor.kiss\" class=\"user-hover\" rel=\"tibor.kiss\">Tibor Kiss</a>. Merged to 0.10.x/1.0.x/1.1.x.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612929877/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/234701503","html_url":"https://github.com/apache/storm/pull/1579#issuecomment-234701503","issue_url":"https://api.github.com/repos/apache/storm/issues/1579","id":234701503,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNDcwMTUwMw==","user":{"login":"tibkiss","id":113485,"node_id":"MDQ6VXNlcjExMzQ4NQ==","avatar_url":"https://avatars.githubusercontent.com/u/113485?v=4","gravatar_id":"","url":"https://api.github.com/users/tibkiss","html_url":"https://github.com/tibkiss","followers_url":"https://api.github.com/users/tibkiss/followers","following_url":"https://api.github.com/users/tibkiss/following{/other_user}","gists_url":"https://api.github.com/users/tibkiss/gists{/gist_id}","starred_url":"https://api.github.com/users/tibkiss/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tibkiss/subscriptions","organizations_url":"https://api.github.com/users/tibkiss/orgs","repos_url":"https://api.github.com/users/tibkiss/repos","events_url":"https://api.github.com/users/tibkiss/events{/privacy}","received_events_url":"https://api.github.com/users/tibkiss/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-23T05:57:14Z","updated_at":"2016-07-23T05:57:14Z","author_association":"CONTRIBUTOR","body":"@harshach : The patch is not interfering with CORS filter. It is an additional filter addressing the ClickJacking vulnerability. \n\n@ptgoetz : Super thanks for merging the PR to both branches. Next time I'll address the delivery to additional branches quicker.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/234701503/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612929880","html_url":"https://github.com/apache/storm/issues/5771#issuecomment-2612929880","issue_url":"https://api.github.com/repos/apache/storm/issues/5771","id":2612929880,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjk4ODA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-23T05:57:16Z","updated_at":"2025-01-24T16:29:45Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user tibkiss commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1579\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1579</a></p>\n\n<p>    @harshach : The patch is not interfering with CORS filter. It is an additional filter addressing the ClickJacking vulnerability. </p>\n\n<p>    @ptgoetz : Super thanks for merging the PR to both branches. Next time I'll address the delivery to additional branches quicker.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612929880/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907717","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907717","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907717,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3MTc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-23T07:10:36Z","updated_at":"2025-01-24T16:18:48Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user priyank5485 opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1839\" title=\"Kinesis Spout\" class=\"issue-link\" data-issue-key=\"STORM-1839\"><del>STORM-1839</del></a>: Storm spout implementation for Amazon Kinesis Streams.</p>\n\n\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/priyank5485/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/priyank5485/storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-1839\" title=\"Kinesis Spout\" class=\"issue-link\" data-issue-key=\"STORM-1839\"><del>STORM-1839</del></a></p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1586</p>\n\n<hr />\n<p>commit de68c267fcb7555c7729c9377d3f6d1e504ec25e<br/>\nAuthor: Priyank <pshah@hortonworks.com><br/>\nDate:   2016-07-12T19:17:54Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1839\" title=\"Kinesis Spout\" class=\"issue-link\" data-issue-key=\"STORM-1839\"><del>STORM-1839</del></a>: Storm spout implementation for Amazon Kinesis Streams.</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907717/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/234739756","html_url":"https://github.com/apache/storm/pull/1522#issuecomment-234739756","issue_url":"https://api.github.com/repos/apache/storm/issues/1522","id":234739756,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNDczOTc1Ng==","user":{"login":"abellina","id":1901059,"node_id":"MDQ6VXNlcjE5MDEwNTk=","avatar_url":"https://avatars.githubusercontent.com/u/1901059?v=4","gravatar_id":"","url":"https://api.github.com/users/abellina","html_url":"https://github.com/abellina","followers_url":"https://api.github.com/users/abellina/followers","following_url":"https://api.github.com/users/abellina/following{/other_user}","gists_url":"https://api.github.com/users/abellina/gists{/gist_id}","starred_url":"https://api.github.com/users/abellina/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abellina/subscriptions","organizations_url":"https://api.github.com/users/abellina/orgs","repos_url":"https://api.github.com/users/abellina/repos","events_url":"https://api.github.com/users/abellina/events{/privacy}","received_events_url":"https://api.github.com/users/abellina/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-23T20:54:17Z","updated_at":"2016-07-23T20:54:17Z","author_association":"CONTRIBUTOR","body":"Looks good @lujinhong. Thanks!\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/234739756/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612878799","html_url":"https://github.com/apache/storm/issues/5429#issuecomment-2612878799","issue_url":"https://api.github.com/repos/apache/storm/issues/5429","id":2612878799,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI4Nzg3OTk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-23T20:54:18Z","updated_at":"2025-01-24T16:05:15Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user abellina commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1522\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1522</a></p>\n\n<p>    Looks good @lujinhong. Thanks!</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612878799/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930106","html_url":"https://github.com/apache/storm/issues/5773#issuecomment-2612930106","issue_url":"https://api.github.com/repos/apache/storm/issues/5773","id":2612930106,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzAxMDY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-24T16:29:20Z","updated_at":"2025-01-24T16:29:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user darionyaphet opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1587\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1587</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1991\" title=\"Support auto.commit.interval in Kafka Client\" class=\"issue-link\" data-issue-key=\"STORM-1991\"><del>STORM-1991</del></a> Support auto.commit.interval in Kafka Client</p>\n\n<p>    <span class=\"error\">&#91;STORM-1991 Support auto.commit.interval in Kafka Client&#93;</span>(<a href=\"https://issues.apache.org/jira/browse/STORM-1991\" class=\"external-link\" rel=\"nofollow\">https://issues.apache.org/jira/browse/STORM-1991</a>)</p>\n\n<p>    Support auto.commit.interval in new Kafka spout </p>\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/darionyaphet/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/darionyaphet/storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-1991\" title=\"Support auto.commit.interval in Kafka Client\" class=\"issue-link\" data-issue-key=\"STORM-1991\"><del>STORM-1991</del></a></p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1587.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1587.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1587</p>\n\n<hr />\n<p>commit 93b53872229818ce3da85ec60a4be798026800cf<br/>\nAuthor: darionyaphet <darion.yaphet@gmail.com><br/>\nDate:   2016-07-24T16:27:11Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1991\" title=\"Support auto.commit.interval in Kafka Client\" class=\"issue-link\" data-issue-key=\"STORM-1991\"><del>STORM-1991</del></a> : Support auto.commit.interval in Kafka Client</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930106/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612561287","html_url":"https://github.com/apache/storm/issues/4681#issuecomment-2612561287","issue_url":"https://api.github.com/repos/apache/storm/issues/4681","id":2612561287,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1NjEyODc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T01:49:30Z","updated_at":"2025-01-24T13:42:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\">kabhwan</a>:</i>\n<p>No it's also reverted from under 1.0 versions as Taylor said.</p>\n\n<p><a href=\"http://storm.apache.org/releases/0.9.6/Concepts.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://storm.apache.org/releases/0.9.6/Concepts.html</a><br/>\n<a href=\"http://storm.apache.org/releases/0.10.0/Concepts.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://storm.apache.org/releases/0.10.0/Concepts.html</a><br/>\n<a href=\"http://storm.apache.org/releases/0.10.1/Concepts.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://storm.apache.org/releases/0.10.1/Concepts.html</a></p>\n\n\n<p>I'm reopening this, and will address this again.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612561287/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931094","html_url":"https://github.com/apache/storm/issues/5781#issuecomment-2612931094","issue_url":"https://api.github.com/repos/apache/storm/issues/5781","id":2612931094,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzEwOTQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T01:53:14Z","updated_at":"2025-01-24T16:30:21Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\">kabhwan</a>:</i>\n<p>1.x / 2.x doc has explanation of old doc - \"Its perfectly fine to launch new threads in bolts that do processing asynchronously. OutputCollector is thread-safe and can be called at any time.\" - which was wrong for older than 1.0.0, but it is now valid for 1.0.0 and above versions.</p>\n\n<p><a href=\"http://storm.apache.org/releases/1.0.0/Concepts.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://storm.apache.org/releases/1.0.0/Concepts.html</a><br/>\n<a href=\"http://storm.apache.org/releases/1.0.1/Concepts.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://storm.apache.org/releases/1.0.1/Concepts.html</a><br/>\n<a href=\"http://storm.apache.org/releases/2.0.0-SNAPSHOT/Concepts.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://storm.apache.org/releases/2.0.0-SNAPSHOT/Concepts.html</a></p>\n\n<p>While we would be better to announce this change for users, the docs for 1.x and 2.x are no issue on this.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931094/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930366","html_url":"https://github.com/apache/storm/issues/5775#issuecomment-2612930366","issue_url":"https://api.github.com/repos/apache/storm/issues/5775","id":2612930366,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzAzNjY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T02:17:38Z","updated_at":"2025-01-24T16:29:59Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user manuzhang commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1581#discussion_r72002584\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1581#discussion_r72002584</a></p>\n\n<p>    &#8212; Diff: external/sql/README.md &#8212;<br/>\n    @@ -70,17 +70,31 @@ To run this example, users need to include the data sources (`storm-sql-kafka` i<br/>\n     class path. One approach is to put the required jars into the `extlib` directory:</p>\n\n<p>     ```<br/>\n    -$ cp curator-client-2.5.0.jar curator-framework-2.5.0.jar zookeeper-3.4.6.jar</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>extlib/<br/>\n    -$ cp scala-library-2.10.4.jar kafka-clients-0.8.2.1.jar kafka_2.10-0.8.2.1.jar metrics-core-2.2.0.jar extlib/<br/>\n    -$ cp json-simple-1.1.1.jar extlib/<br/>\n    <del>$ cp storm-kafka</del><b>.jar storm-sql-kafka-</b>.jar storm-sql-runtime-*.jar extlib/<br/>\n    +calcite-avatica-1.4.0-incubating.jar\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    where should I look for these jar files ?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930366/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930369","html_url":"https://github.com/apache/storm/issues/5775#issuecomment-2612930369","issue_url":"https://api.github.com/repos/apache/storm/issues/5775","id":2612930369,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzAzNjk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T02:42:51Z","updated_at":"2025-01-24T16:30:00Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1581#discussion_r72003648\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1581#discussion_r72003648</a></p>\n\n<p>    &#8212; Diff: external/sql/README.md &#8212;<br/>\n    @@ -70,17 +70,31 @@ To run this example, users need to include the data sources (`storm-sql-kafka` i<br/>\n     class path. One approach is to put the required jars into the `extlib` directory:</p>\n\n<p>     ```<br/>\n    -$ cp curator-client-2.5.0.jar curator-framework-2.5.0.jar zookeeper-3.4.6.jar</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>extlib/<br/>\n    -$ cp scala-library-2.10.4.jar kafka-clients-0.8.2.1.jar kafka_2.10-0.8.2.1.jar metrics-core-2.2.0.jar extlib/<br/>\n    -$ cp json-simple-1.1.1.jar extlib/<br/>\n    <del>$ cp storm-kafka</del><b>.jar storm-sql-kafka-</b>.jar storm-sql-runtime-*.jar extlib/<br/>\n    +calcite-avatica-1.4.0-incubating.jar\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    Unfortunately you need to find them from maven central and add them to extlib. Note that they'll be added to worker classpath for all workers on cluster.</p>\n\n<p>    I know it's really bad, so I'm thinking about how to resolve this.<br/>\n    For now I'm working on adding dependencies from submission step. <br/>\n    That would be similar (nearly same) to --jars and --packages for spark-submit.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930369/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612695375","html_url":"https://github.com/apache/storm/issues/5270#issuecomment-2612695375","issue_url":"https://api.github.com/repos/apache/storm/issues/5270","id":2612695375,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2OTUzNzU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T03:46:54Z","updated_at":"2025-01-24T14:42:16Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mauzhang\">mauzhang</a>:</i>\n<p>Why is storm-kafka \"provided\" for storm-sql-kafka, which I agree with <a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.agarwal\" class=\"user-hover\" rel=\"abhishek.agarwal\">Abhishek Agarwal</a> is an application jar ? </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612695375/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941290","html_url":"https://github.com/apache/storm/issues/5784#issuecomment-2612941290","issue_url":"https://api.github.com/repos/apache/storm/issues/5784","id":2612941290,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5NDEyOTA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T05:16:19Z","updated_at":"2025-01-24T16:35:37Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user darionyaphet opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1589\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1589</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-2002\" title=\"KafkaSpout data type error \" class=\"issue-link\" data-issue-key=\"STORM-2002\"><del>STORM-2002</del></a> KafkaSpout data type error</p>\n\n<p>    <span class=\"error\">&#91;STORM-2002 KafkaSpout data type error&#93;</span>(<a href=\"https://issues.apache.org/jira/browse/STORM-2002\" class=\"external-link\" rel=\"nofollow\">https://issues.apache.org/jira/browse/STORM-2002</a>)</p>\n\n<p>    KafkaConsumer seekToBeginning and seekToEnd is using `TopicPartition...` as parameter not `Collection<TopicPartition>`</p>\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/darionyaphet/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/darionyaphet/storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-2002\" title=\"KafkaSpout data type error \" class=\"issue-link\" data-issue-key=\"STORM-2002\"><del>STORM-2002</del></a></p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1589.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1589.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1589</p>\n\n<hr />\n<p>commit 2ac640028567a1b83f7815b370b8e69dfdb55ed0<br/>\nAuthor: darionyaphet <darion.yaphet@gmail.com><br/>\nDate:   2016-07-25T05:12:47Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-2002\" title=\"KafkaSpout data type error \" class=\"issue-link\" data-issue-key=\"STORM-2002\"><del>STORM-2002</del></a> : KafkaSpout data type error</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941290/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941297","html_url":"https://github.com/apache/storm/issues/5784#issuecomment-2612941297","issue_url":"https://api.github.com/repos/apache/storm/issues/5784","id":2612941297,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5NDEyOTc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T05:32:26Z","updated_at":"2025-01-24T16:35:37Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user darionyaphet closed the pull request at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1589\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1589</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941297/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612695380","html_url":"https://github.com/apache/storm/issues/5270#issuecomment-2612695380","issue_url":"https://api.github.com/repos/apache/storm/issues/5270","id":2612695380,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2OTUzODA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T06:35:28Z","updated_at":"2025-01-24T14:42:16Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\">kabhwan</a>:</i>\n<p>I didn't look at storm-sql so I don't know about the detail.<br/>\n<a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9\" class=\"user-hover\" rel=\"wheat9\">Haohui Mai</a> Could you explain this?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612695380/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931098","html_url":"https://github.com/apache/storm/issues/5781#issuecomment-2612931098","issue_url":"https://api.github.com/repos/apache/storm/issues/5781","id":2612931098,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzEwOTg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T14:21:28Z","updated_at":"2025-01-24T16:30:21Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.duggana\">satish.duggana</a>:</i>\n<p><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\" class=\"user-hover\" rel=\"kabhwan\">Jungtaek Lim</a><br/>\n<a href=\"http://storm.apache.org/releases/1.0.0/Troubleshooting.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://storm.apache.org/releases/1.0.0/Troubleshooting.html</a><br/>\n<a href=\"http://storm.apache.org/releases/1.0.1/Troubleshooting.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://storm.apache.org/releases/1.0.1/Troubleshooting.html</a><br/>\nshows below info which needs to be corrected</p>\n\n<blockquote>\n<p>This is caused by having multiple threads issue methods on the OutputCollector. All emits, acks, and fails must happen on the same thread. One subtle way this can happen is if you make a IBasicBolt that emits on a separate thread. IBasicBolt's automatically ack after execute is called, so this would cause multiple threads to use the OutputCollector leading to this exception. When using a basic bolt, all emits must happen in the same thread that runs execute.</p></blockquote>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931098/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941405","html_url":"https://github.com/apache/storm/issues/5785#issuecomment-2612941405","issue_url":"https://api.github.com/repos/apache/storm/issues/5785","id":2612941405,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5NDE0MDU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T14:28:24Z","updated_at":"2025-01-24T16:35:41Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user darionyaphet opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1590\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1590</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-2003\" title=\"Make sure config contains TOPIC before get it\" class=\"issue-link\" data-issue-key=\"STORM-2003\"><del>STORM-2003</del></a> Make sure config contains TOPIC before get it</p>\n\n<p>    <span class=\"error\">&#91;STORM-2003 Make sure config contains TOPIC before get it&#93;</span>(<a href=\"https://issues.apache.org/jira/browse/STORM-2003\" class=\"external-link\" rel=\"nofollow\">https://issues.apache.org/jira/browse/STORM-2003</a>)</p>\n\n<p>    When topic selector is not specified, KafkaBolt will get topic name from storm config . We should make sure the topic name is not null .</p>\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/darionyaphet/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/darionyaphet/storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-2003\" title=\"Make sure config contains TOPIC before get it\" class=\"issue-link\" data-issue-key=\"STORM-2003\"><del>STORM-2003</del></a></p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1590.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1590.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1590</p>\n\n<hr />\n<p>commit db8802964ba492fcc0a81ce2bbf80075e954f64c<br/>\nAuthor: darionyaphet <darion.yaphet@gmail.com><br/>\nDate:   2016-07-25T14:26:35Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-2003\" title=\"Make sure config contains TOPIC before get it\" class=\"issue-link\" data-issue-key=\"STORM-2003\"><del>STORM-2003</del></a> : Make sure config contains TOPIC before get it</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941405/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931104","html_url":"https://github.com/apache/storm/issues/5781#issuecomment-2612931104","issue_url":"https://api.github.com/repos/apache/storm/issues/5781","id":2612931104,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzExMDQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T14:49:37Z","updated_at":"2025-01-24T16:30:21Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\">kabhwan</a>:</i>\n<p>Oh I missed it. Half resolved. Thanks for noticing.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931104/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928403","html_url":"https://github.com/apache/storm/issues/5761#issuecomment-2612928403","issue_url":"https://api.github.com/repos/apache/storm/issues/5761","id":2612928403,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjg0MDM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T15:10:21Z","updated_at":"2025-01-24T16:29:02Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user omkreddy commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1583#discussion_r72081639\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1583#discussion_r72081639</a></p>\n\n<p>    &#8212; Diff: external/storm-druid/src/main/java/org/apache/storm/druid/bolt/DruidBeamBolt.java &#8212;<br/>\n    @@ -0,0 +1,115 @@<br/>\n    +/*<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing,<br/>\n    + * software distributed under the License is distributed on an<br/>\n    + * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<br/>\n    + * KIND, either express or implied.  See the License for the<br/>\n    + * specific language governing permissions and limitations<br/>\n    + * under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.druid.bolt;<br/>\n    +<br/>\n    +import com.metamx.tranquility.tranquilizer.MessageDroppedException;<br/>\n    +import com.metamx.tranquility.tranquilizer.Tranquilizer;<br/>\n    +import com.twitter.util.Future;<br/>\n    +import com.twitter.util.FutureEventListener;<br/>\n    +import org.apache.storm.task.OutputCollector;<br/>\n    +import org.apache.storm.task.TopologyContext;<br/>\n    +import org.apache.storm.topology.OutputFieldsDeclarer;<br/>\n    +import org.apache.storm.topology.base.BaseRichBolt;<br/>\n    +import org.apache.storm.tuple.Tuple;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.util.Map;<br/>\n    +<br/>\n    +/**<br/>\n    + * Basic bolt implementation for storing data to Druid datastore.<br/>\n    + * <p/><br/>\n    + * This implementation uses Druid's Tranquility library (<a href=\"https://github.com/druid-io/tranquility\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/druid-io/tranquility</a>)<br/>\n    + * to send to druid store.<br/>\n    + * Some of the concepts are borrowed from Tranquility storm connector implementation.<br/>\n    + * (<a href=\"https://github.com/druid-io/tranquility/blob/master/docs/storm.md\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/druid-io/tranquility/blob/master/docs/storm.md</a>)<br/>\n    + *<br/>\n    + * This Bolt expects to receive tuples in which the zeroth element is your event type.<br/>\n    + * <p/><br/>\n    + *<br/>\n    + */<br/>\n    +public class DruidBeamBolt<E> extends BaseRichBolt {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(DruidBeamBolt.class);<br/>\n    +<br/>\n    +    private volatile  OutputCollector collector;<br/>\n    +    private DruidBeamFactory<E> beamFactory = null;<br/>\n    +    private int batchSize;<br/>\n    +    private Tranquilizer<E> tranquilizer = null;<br/>\n    +<br/>\n    +    public DruidBeamBolt(DruidBeamFactory<E> beamFactory) </p>\n{\n    +this(beamFactory, 2000);\n    +    }\n<p>    +<br/>\n    +    public DruidBeamBolt(DruidBeamFactory<E> beamFactory, int batchSize) </p>\n{\n    +this.beamFactory = beamFactory;\n    +this.batchSize = batchSize;\n    +    }\n<p>    +<br/>\n    +    @Override<br/>\n    +    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) </p>\n{\n    +this.collector = collector;\n    +tranquilizer = Tranquilizer.create(\n    +beamFactory.makeBeam(stormConf, context),\n    +batchSize,\n    +Tranquilizer.DefaultMaxPendingBatches(),\n    +Tranquilizer.DefaultLingerMillis());\n    +this.tranquilizer.start();\n    +\n    +    }\n<p>    +<br/>\n    +    @Override<br/>\n    +    public void execute(final Tuple tuple) {<br/>\n    +      Future future = tranquilizer.send((E)tuple.getValue(0));<br/>\n    +      future.addEventListener(new FutureEventListener() {<br/>\n    +  @Override<br/>\n    +  public void onFailure(Throwable cause) {<br/>\n    +      if(cause instanceof MessageDroppedException) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    currently druid logs discarded messages.  Also I need to find way to handle this in Trident bolt. I will do this when need arises. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928403/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/234982463","html_url":"https://github.com/apache/storm/pull/1583#issuecomment-234982463","issue_url":"https://api.github.com/repos/apache/storm/issues/1583","id":234982463,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNDk4MjQ2Mw==","user":{"login":"omkreddy","id":8134545,"node_id":"MDQ6VXNlcjgxMzQ1NDU=","avatar_url":"https://avatars.githubusercontent.com/u/8134545?v=4","gravatar_id":"","url":"https://api.github.com/users/omkreddy","html_url":"https://github.com/omkreddy","followers_url":"https://api.github.com/users/omkreddy/followers","following_url":"https://api.github.com/users/omkreddy/following{/other_user}","gists_url":"https://api.github.com/users/omkreddy/gists{/gist_id}","starred_url":"https://api.github.com/users/omkreddy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/omkreddy/subscriptions","organizations_url":"https://api.github.com/users/omkreddy/orgs","repos_url":"https://api.github.com/users/omkreddy/repos","events_url":"https://api.github.com/users/omkreddy/events{/privacy}","received_events_url":"https://api.github.com/users/omkreddy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T15:10:51Z","updated_at":"2016-07-25T15:10:51Z","author_association":"CONTRIBUTOR","body":"@ptgoetz Thanks. I added you as committer sponsor.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/234982463/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928405","html_url":"https://github.com/apache/storm/issues/5761#issuecomment-2612928405","issue_url":"https://api.github.com/repos/apache/storm/issues/5761","id":2612928405,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjg0MDU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T15:10:54Z","updated_at":"2025-01-24T16:29:02Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user omkreddy commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1583\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1583</a></p>\n\n<p>    @ptgoetz Thanks. I added you as committer sponsor.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928405/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928407","html_url":"https://github.com/apache/storm/issues/5761#issuecomment-2612928407","issue_url":"https://api.github.com/repos/apache/storm/issues/5761","id":2612928407,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjg0MDc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T15:13:35Z","updated_at":"2025-01-24T16:29:02Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user omkreddy commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1583#discussion_r72082307\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1583#discussion_r72082307</a></p>\n\n<p>    &#8212; Diff: external/storm-druid/src/main/java/org/apache/storm/druid/bolt/DruidBeamBolt.java &#8212;<br/>\n    @@ -0,0 +1,115 @@<br/>\n    +/*<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing,<br/>\n    + * software distributed under the License is distributed on an<br/>\n    + * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<br/>\n    + * KIND, either express or implied.  See the License for the<br/>\n    + * specific language governing permissions and limitations<br/>\n    + * under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.druid.bolt;<br/>\n    +<br/>\n    +import com.metamx.tranquility.tranquilizer.MessageDroppedException;<br/>\n    +import com.metamx.tranquility.tranquilizer.Tranquilizer;<br/>\n    +import com.twitter.util.Future;<br/>\n    +import com.twitter.util.FutureEventListener;<br/>\n    +import org.apache.storm.task.OutputCollector;<br/>\n    +import org.apache.storm.task.TopologyContext;<br/>\n    +import org.apache.storm.topology.OutputFieldsDeclarer;<br/>\n    +import org.apache.storm.topology.base.BaseRichBolt;<br/>\n    +import org.apache.storm.tuple.Tuple;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.util.Map;<br/>\n    +<br/>\n    +/**<br/>\n    + * Basic bolt implementation for storing data to Druid datastore.<br/>\n    + * <p/><br/>\n    + * This implementation uses Druid's Tranquility library (<a href=\"https://github.com/druid-io/tranquility\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/druid-io/tranquility</a>)<br/>\n    + * to send to druid store.<br/>\n    + * Some of the concepts are borrowed from Tranquility storm connector implementation.<br/>\n    + * (<a href=\"https://github.com/druid-io/tranquility/blob/master/docs/storm.md\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/druid-io/tranquility/blob/master/docs/storm.md</a>)<br/>\n    + *<br/>\n    + * This Bolt expects to receive tuples in which the zeroth element is your event type.<br/>\n    + * <p/><br/>\n    + *<br/>\n    + */<br/>\n    +public class DruidBeamBolt<E> extends BaseRichBolt {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(DruidBeamBolt.class);<br/>\n    +<br/>\n    +    private volatile  OutputCollector collector;<br/>\n    +    private DruidBeamFactory<E> beamFactory = null;<br/>\n    +    private int batchSize;<br/>\n    +    private Tranquilizer<E> tranquilizer = null;<br/>\n    +<br/>\n    +    public DruidBeamBolt(DruidBeamFactory<E> beamFactory) {<br/>\n    +this(beamFactory, 2000);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    removed the constructor.  Now users has to pass the batchSize. as of now we have only one config value. will add config class when need arises.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928407/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/234992550","html_url":"https://github.com/apache/storm/pull/1554#issuecomment-234992550","issue_url":"https://api.github.com/repos/apache/storm/issues/1554","id":234992550,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNDk5MjU1MA==","user":{"login":"darionyaphet","id":4414314,"node_id":"MDQ6VXNlcjQ0MTQzMTQ=","avatar_url":"https://avatars.githubusercontent.com/u/4414314?v=4","gravatar_id":"","url":"https://api.github.com/users/darionyaphet","html_url":"https://github.com/darionyaphet","followers_url":"https://api.github.com/users/darionyaphet/followers","following_url":"https://api.github.com/users/darionyaphet/following{/other_user}","gists_url":"https://api.github.com/users/darionyaphet/gists{/gist_id}","starred_url":"https://api.github.com/users/darionyaphet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/darionyaphet/subscriptions","organizations_url":"https://api.github.com/users/darionyaphet/orgs","repos_url":"https://api.github.com/users/darionyaphet/repos","events_url":"https://api.github.com/users/darionyaphet/events{/privacy}","received_events_url":"https://api.github.com/users/darionyaphet/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T15:43:26Z","updated_at":"2016-07-25T15:43:26Z","author_association":"CONTRIBUTOR","body":"Looks Good To Me\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/234992550/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/235027177","html_url":"https://github.com/apache/storm/pull/1585#issuecomment-235027177","issue_url":"https://api.github.com/repos/apache/storm/issues/1585","id":235027177,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTAyNzE3Nw==","user":{"login":"ptgoetz","id":260896,"node_id":"MDQ6VXNlcjI2MDg5Ng==","avatar_url":"https://avatars.githubusercontent.com/u/260896?v=4","gravatar_id":"","url":"https://api.github.com/users/ptgoetz","html_url":"https://github.com/ptgoetz","followers_url":"https://api.github.com/users/ptgoetz/followers","following_url":"https://api.github.com/users/ptgoetz/following{/other_user}","gists_url":"https://api.github.com/users/ptgoetz/gists{/gist_id}","starred_url":"https://api.github.com/users/ptgoetz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ptgoetz/subscriptions","organizations_url":"https://api.github.com/users/ptgoetz/orgs","repos_url":"https://api.github.com/users/ptgoetz/repos","events_url":"https://api.github.com/users/ptgoetz/events{/privacy}","received_events_url":"https://api.github.com/users/ptgoetz/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T17:43:14Z","updated_at":"2016-07-25T17:43:14Z","author_association":"MEMBER","body":"+1\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/235027177/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931232","html_url":"https://github.com/apache/storm/issues/5782#issuecomment-2612931232","issue_url":"https://api.github.com/repos/apache/storm/issues/5782","id":2612931232,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzEyMzI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T17:43:16Z","updated_at":"2025-01-24T16:30:25Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user ptgoetz commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1585\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1585</a></p>\n\n<p>    +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931232/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931235","html_url":"https://github.com/apache/storm/issues/5782#issuecomment-2612931235","issue_url":"https://api.github.com/repos/apache/storm/issues/5782","id":2612931235,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzEyMzU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T17:49:32Z","updated_at":"2025-01-24T16:30:25Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user asfgit closed the pull request at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1585\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1585</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931235/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931240","html_url":"https://github.com/apache/storm/issues/5782#issuecomment-2612931240","issue_url":"https://api.github.com/repos/apache/storm/issues/5782","id":2612931240,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzEyNDA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T17:50:10Z","updated_at":"2025-01-24T16:30:25Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ptgoetz\">ptgoetz</a>:</i>\n<p>Merged to master/1.x-branch.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612931240/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612913112","html_url":"https://github.com/apache/storm/issues/5659#issuecomment-2612913112","issue_url":"https://api.github.com/repos/apache/storm/issues/5659","id":2612913112,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTMxMTI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T21:09:47Z","updated_at":"2025-01-24T16:21:27Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user asfgit closed the pull request at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1482\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1482</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612913112/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612913120","html_url":"https://github.com/apache/storm/issues/5659#issuecomment-2612913120","issue_url":"https://api.github.com/repos/apache/storm/issues/5659","id":2612913120,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTMxMjA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-25T21:13:52Z","updated_at":"2025-01-24T16:21:27Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ptgoetz\">ptgoetz</a>:</i>\n<p>Thanks <a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.agarwal\" class=\"user-hover\" rel=\"abhishek.agarwal\">Abhishek Agarwal</a>, I merged this to master/1.x/1.0.x.</p>\n\n<p>One thing I did as part of the merge was to change the property names to make things (somewhat) more clear. So now they roughly follow the naming convention of storm-kafka and storm-kafka-client (storm.kafka.version and storm.kafka.client.version). This naming is now consistent across all branches.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612913120/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598581","html_url":"https://github.com/apache/storm/issues/4876#issuecomment-2612598581","issue_url":"https://api.github.com/repos/apache/storm/issues/4876","id":2612598581,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1OTg1ODE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T01:28:39Z","updated_at":"2025-01-24T14:00:11Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user hsun-cnnxty opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1591\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1591</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1038\" title=\"Upgrade netty transport from 3.x to 4.x\" class=\"issue-link\" data-issue-key=\"STORM-1038\"><del>STORM-1038</del></a>: Upgrade netty to 4.x in 1.x-branch</p>\n\n<p>    This is to add the feature to 1.x-branch.  The original PR for master branch is #728.</p>\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/hsun-cnnxty/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/hsun-cnnxty/storm</a> 1.x-branch-netty4</p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1591.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1591.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1591</p>\n\n<hr />\n<p>commit 57fbccc7e0d710ccaf04a5a828f0ff4cf29ec855<br/>\nAuthor: Hang Sun <hsun@connexity.com><br/>\nDate:   2016-07-25T22:30:54Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1038\" title=\"Upgrade netty transport from 3.x to 4.x\" class=\"issue-link\" data-issue-key=\"STORM-1038\"><del>STORM-1038</del></a>: Upgraded netty to 4.x</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598581/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/235136685","html_url":"https://github.com/apache/storm/pull/728#issuecomment-235136685","issue_url":"https://api.github.com/repos/apache/storm/issues/728","id":235136685,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTEzNjY4NQ==","user":{"login":"ooasis","id":10720176,"node_id":"MDQ6VXNlcjEwNzIwMTc2","avatar_url":"https://avatars.githubusercontent.com/u/10720176?v=4","gravatar_id":"","url":"https://api.github.com/users/ooasis","html_url":"https://github.com/ooasis","followers_url":"https://api.github.com/users/ooasis/followers","following_url":"https://api.github.com/users/ooasis/following{/other_user}","gists_url":"https://api.github.com/users/ooasis/gists{/gist_id}","starred_url":"https://api.github.com/users/ooasis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ooasis/subscriptions","organizations_url":"https://api.github.com/users/ooasis/orgs","repos_url":"https://api.github.com/users/ooasis/repos","events_url":"https://api.github.com/users/ooasis/events{/privacy}","received_events_url":"https://api.github.com/users/ooasis/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T01:29:53Z","updated_at":"2016-07-26T01:29:53Z","author_association":"NONE","body":"As this PR is for master,  new PR #1591 is created for 1.x-branch.  Performance tests to be done soon.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/235136685/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598588","html_url":"https://github.com/apache/storm/issues/4876#issuecomment-2612598588","issue_url":"https://api.github.com/repos/apache/storm/issues/4876","id":2612598588,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI1OTg1ODg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T01:29:55Z","updated_at":"2025-01-24T14:00:11Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user hsun-cnnxty commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/728\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/728</a></p>\n\n<p>    As this PR is for master,  new PR #1591 is created for 1.x-branch.  Performance tests to be done soon.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612598588/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941680","html_url":"https://github.com/apache/storm/issues/5787#issuecomment-2612941680","issue_url":"https://api.github.com/repos/apache/storm/issues/5787","id":2612941680,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5NDE2ODA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T03:12:45Z","updated_at":"2025-01-24T16:35:48Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hycsun\">hycsun</a>:</i>\n<p>the log writes  Getting metrics for client connection to Netty-Client-slave3/133.31.12.31:6700<br/>\nGetting metrics for client connection to Netty-Client-master/133.31.12.32:6702</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941680/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930479","html_url":"https://github.com/apache/storm/issues/5776#issuecomment-2612930479","issue_url":"https://api.github.com/repos/apache/storm/issues/5776","id":2612930479,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzA0Nzk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T04:21:45Z","updated_at":"2025-01-24T16:30:03Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user abellina opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1592\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1592</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1994\" title=\"Add table with per-topology & worker resource usage and components in (new) supervisor and topology pages\" class=\"issue-link\" data-issue-key=\"STORM-1994\"><del>STORM-1994</del></a>: Add table with per-topology and worker resource usage and…</p>\n\n<p>    … components in (new) supervisor and topology pages</p>\n\n<p>    This adds a collapsible table to the topology page and a new supervisor page that show per worker assigned resources, number of executors and the components running on each worker. We use this as a debugging tool, helping identify where components are running and to visualize all running components in a specific host.</p>\n\n<p>    Thanks to @kishorvpatil for coming up with the idea in the first place, and reviewing and testing the feature. Also thanks to @knusbaum, and @d2r who reviewed the code and provided bug fixes and code refactors. </p>\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/abellina/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/abellina/storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-1994\" title=\"Add table with per-topology & worker resource usage and components in (new) supervisor and topology pages\" class=\"issue-link\" data-issue-key=\"STORM-1994\"><del>STORM-1994</del></a>_add_per_worker_components_and_resource_usage</p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1592.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1592.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1592</p>\n\n<hr />\n<p>commit f5ad92888b6f1470e4d7f179fbe5ae73e37a07f7<br/>\nAuthor: Alessandro Bellina <abellina@yahoo-inc.com><br/>\nDate:   2016-07-06T19:23:18Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1994\" title=\"Add table with per-topology & worker resource usage and components in (new) supervisor and topology pages\" class=\"issue-link\" data-issue-key=\"STORM-1994\"><del>STORM-1994</del></a>: Add table with per-topology and worker resource usage and components in (new) supervisor and topology pages</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930479/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612913123","html_url":"https://github.com/apache/storm/issues/5659#issuecomment-2612913123","issue_url":"https://api.github.com/repos/apache/storm/issues/5659","id":2612913123,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTMxMjM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T05:13:48Z","updated_at":"2025-01-24T16:21:27Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.agarwal\">abhishek.agarwal</a>:</i>\n<p>Thank you <a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ptgoetz\" class=\"user-hover\" rel=\"ptgoetz\">P. Taylor Goetz</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612913123/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930613","html_url":"https://github.com/apache/storm/issues/5777#issuecomment-2612930613","issue_url":"https://api.github.com/repos/apache/storm/issues/5777","id":2612930613,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzA2MTM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T05:23:54Z","updated_at":"2025-01-24T16:30:06Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user abellina opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1593\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1593</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1995\" title=\"downloadChunk in nimbus.clj should close the input stream\" class=\"issue-link\" data-issue-key=\"STORM-1995\"><del>STORM-1995</del></a>: close input stream and other tweaks to downloadChunk</p>\n\n<p>    When the input stream is being removed from its parent collection (after reading fully) in downloadChunk it isn't being closed, causing a leak.</p>\n\n<p>    Thanks to @tgravescs for making this change.</p>\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/abellina/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/abellina/storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-1995\" title=\"downloadChunk in nimbus.clj should close the input stream\" class=\"issue-link\" data-issue-key=\"STORM-1995\"><del>STORM-1995</del></a>_downloadChunk_should_close_input_stream</p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1593.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1593.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1593</p>\n\n<hr />\n<p>commit f38982c022e38dd7e970babfdfaf941064ebfba2<br/>\nAuthor: Alessandro Bellina <abellina@yahoo-inc.com><br/>\nDate:   2016-07-21T05:26:20Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1995\" title=\"downloadChunk in nimbus.clj should close the input stream\" class=\"issue-link\" data-issue-key=\"STORM-1995\"><del>STORM-1995</del></a>: close input stream and other tweaks to downloadChunk</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930613/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612699134","html_url":"https://github.com/apache/storm/issues/5295#issuecomment-2612699134","issue_url":"https://api.github.com/repos/apache/storm/issues/5295","id":2612699134,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2OTkxMzQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T05:55:26Z","updated_at":"2025-01-24T14:43:53Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hongyu.bi\">hongyu.bi</a>:</i>\n<p>ping</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612699134/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941806","html_url":"https://github.com/apache/storm/issues/5788#issuecomment-2612941806","issue_url":"https://api.github.com/repos/apache/storm/issues/5788","id":2612941806,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5NDE4MDY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T09:22:36Z","updated_at":"2025-01-24T16:35:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user HeartSaVioR opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1594\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1594</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-2006\" title=\"Storm metrics feature improvement: support per-worker level metrics aggregation\" class=\"issue-link\" data-issue-key=\"STORM-2006\"><del>STORM-2006</del></a> Storm metrics feature improvement: support per-worker level metrics aggregation (1.x)</p>\n\n<ul>\n\t<li>SystemBolt handles task level metrics via two mode\n\t<ul>\n\t\t<li>non-aggregate: same to previous, just applying expansion and pass to MetricConsumerBolts</li>\n\t\t<li>aggregate: apply expansion, do aggregation, pass aggregated metrics to MetricConsumerBolts</li>\n\t</ul>\n\t</li>\n\t<li>all task level metrics should pass by SystemBolt within its worker\n\t<ul>\n\t\t<li>it drops all connections between tasks and MetricsConsumerBolts</li>\n\t\t<li>only SystemBolts and MetricConsumerBolts will be connected</li>\n\t</ul>\n\t</li>\n\t<li>move configurations: expandMapType and metricNameSeparator to global\n\t<ul>\n\t\t<li>since SystemBolt needs to handle expansion when both worker level aggregation and expandMapType are turned on</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    Manually tested via matrix of options : aggregate x expand</p>\n\n<p>    I'm not sure how to create unit tests playing with SystemBolt, but will try to come up unit tests.</p>\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/HeartSaVioR/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/HeartSaVioR/storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-2006\" title=\"Storm metrics feature improvement: support per-worker level metrics aggregation\" class=\"issue-link\" data-issue-key=\"STORM-2006\"><del>STORM-2006</del></a>-1.x</p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1594.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1594.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1594</p>\n\n<hr />\n<p>commit b2acd027768c30b71357a55a8eccd13a485089f3<br/>\nAuthor: Jungtaek Lim <kabhwan@gmail.com><br/>\nDate:   2016-07-25T13:43:02Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-2006\" title=\"Storm metrics feature improvement: support per-worker level metrics aggregation\" class=\"issue-link\" data-issue-key=\"STORM-2006\"><del>STORM-2006</del></a> Storm metrics feature improvement: support per-worker level metrics aggregation</p>\n\n<ul>\n\t<li>SystemBolt handles task level metrics via two mode\n\t<ul>\n\t\t<li>non-aggregate: same to previous, just applying expansion and pass to MetricConsumerBolts</li>\n\t\t<li>aggregate: apply expansion, do aggregation, pass aggregated metrics to MetricConsumerBolts</li>\n\t</ul>\n\t</li>\n\t<li>all task level metrics should pass by SystemBolt within its worker\n\t<ul>\n\t\t<li>it drops all connections between tasks and MetricsConsumerBolts</li>\n\t\t<li>only SystemBolts and MetricConsumerBolts will be connected</li>\n\t</ul>\n\t</li>\n\t<li>move configurations: expandMapType and metricNameSeparator to global\n\t<ul>\n\t\t<li>since SystemBolt needs to handle expansion when both worker level aggregation and expandMapType are turned on</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941806/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941813","html_url":"https://github.com/apache/storm/issues/5788#issuecomment-2612941813","issue_url":"https://api.github.com/repos/apache/storm/issues/5788","id":2612941813,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5NDE4MTM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T09:31:16Z","updated_at":"2025-01-24T16:35:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user HeartSaVioR opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1595\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1595</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-2006\" title=\"Storm metrics feature improvement: support per-worker level metrics aggregation\" class=\"issue-link\" data-issue-key=\"STORM-2006\"><del>STORM-2006</del></a> Storm metrics feature improvement: support per-worker level metrics aggregation</p>\n\n<p>    PR for 1.x : #1594 </p>\n\n<ul>\n\t<li>SystemBolt handles task level metrics via two mode</li>\n\t<li>non-aggregate: same to previous, just applying expansion and pass to MetricConsumerBolts</li>\n\t<li>aggregate: apply expansion, do aggregation, pass aggregated metrics to MetricConsumerBolts</li>\n\t<li>all task level metrics should pass by SystemBolt within its worker</li>\n\t<li>it drops all connections between tasks and MetricsConsumerBolts</li>\n\t<li>only SystemBolts and MetricConsumerBolts will be connected</li>\n\t<li>move configurations: expandMapType and metricNameSeparator to global</li>\n\t<li>since SystemBolt needs to handle expansion when both worker level aggregation and expandMapType are turned on</li>\n</ul>\n\n\n<p>    This could break #1445 and it's already broken. We ideally want to stop adding new feature on 1.x and concentrate on 2.x but life is not easy.<br/>\n    I can volunteer to fix the conflict if this PR breaks #1445 in many places.</p>\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/HeartSaVioR/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/HeartSaVioR/storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-2006\" title=\"Storm metrics feature improvement: support per-worker level metrics aggregation\" class=\"issue-link\" data-issue-key=\"STORM-2006\"><del>STORM-2006</del></a></p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1595.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1595.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1595</p>\n\n<hr />\n<p>commit 8d1bc0b7ca2e50d45af3bc1bf41944925611910e<br/>\nAuthor: Jungtaek Lim <kabhwan@gmail.com><br/>\nDate:   2016-07-25T13:43:02Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-2006\" title=\"Storm metrics feature improvement: support per-worker level metrics aggregation\" class=\"issue-link\" data-issue-key=\"STORM-2006\"><del>STORM-2006</del></a> Storm metrics feature improvement: support per-worker level metrics aggregation</p>\n\n<ul>\n\t<li>SystemBolt handles task level metrics via two mode\n\t<ul>\n\t\t<li>non-aggregate: same to previous, just applying expansion and pass to MetricConsumerBolts</li>\n\t\t<li>aggregate: apply expansion, do aggregation, pass aggregated metrics to MetricConsumerBolts</li>\n\t</ul>\n\t</li>\n\t<li>all task level metrics should pass by SystemBolt within its worker\n\t<ul>\n\t\t<li>it drops all connections between tasks and MetricsConsumerBolts</li>\n\t\t<li>only SystemBolts and MetricConsumerBolts will be connected</li>\n\t</ul>\n\t</li>\n\t<li>move configurations: expandMapType and metricNameSeparator to global\n\t<ul>\n\t\t<li>since SystemBolt needs to handle expansion when both worker level aggregation and expandMapType are turned on</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612941813/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930621","html_url":"https://github.com/apache/storm/issues/5777#issuecomment-2612930621","issue_url":"https://api.github.com/repos/apache/storm/issues/5777","id":2612930621,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzA2MjE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T13:06:31Z","updated_at":"2025-01-24T16:30:07Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1593#discussion_r72244414\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1593#discussion_r72244414</a></p>\n\n<p>    &#8212; Diff: storm-core/src/clj/org/apache/storm/daemon/nimbus.clj &#8212;<br/>\n    @@ -1793,16 +1793,16 @@<br/>\n     (.mark nimbus:num-downloadChunk-calls)<br/>\n     (check-authorization! nimbus nil nil \"fileDownload\")<br/>\n     (let [downloaders (:downloaders nimbus)</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>^BufferFileInputStream is (.get downloaders id)]<br/>\n    +      ^BufferInputStream is (.get downloaders id)]\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    Is there a reason to change type hint class name?<br/>\n    <a href=\"http://storm.apache.org/releases/1.0.0/javadocs/org/apache/storm/utils/BufferFileInputStream.html\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://storm.apache.org/releases/1.0.0/javadocs/org/apache/storm/utils/BufferFileInputStream.html</a><br/>\n    BufferFileInputStream is not a \"is-a\" BufferInputStream, and it also has close() method itself.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930621/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930625","html_url":"https://github.com/apache/storm/issues/5777#issuecomment-2612930625","issue_url":"https://api.github.com/repos/apache/storm/issues/5777","id":2612930625,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzA2MjU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T13:17:59Z","updated_at":"2025-01-24T16:30:07Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user abellina commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1593#discussion_r72246238\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1593#discussion_r72246238</a></p>\n\n<p>    &#8212; Diff: storm-core/src/clj/org/apache/storm/daemon/nimbus.clj &#8212;<br/>\n    @@ -1793,16 +1793,16 @@<br/>\n     (.mark nimbus:num-downloadChunk-calls)<br/>\n     (check-authorization! nimbus nil nil \"fileDownload\")<br/>\n     (let [downloaders (:downloaders nimbus)</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>^BufferFileInputStream is (.get downloaders id)]<br/>\n    +      ^BufferInputStream is (.get downloaders id)]\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    @HeartSaVioR, in beginFileDownload (just above the impl for downloadChunk) the type used for the input stream and put into :downloaders is a BufferInputStream, hence the change in downloadChunk.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930625/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930628","html_url":"https://github.com/apache/storm/issues/5777#issuecomment-2612930628","issue_url":"https://api.github.com/repos/apache/storm/issues/5777","id":2612930628,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzA2Mjg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T13:22:00Z","updated_at":"2025-01-24T16:30:07Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1593#discussion_r72246867\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1593#discussion_r72246867</a></p>\n\n<p>    &#8212; Diff: storm-core/src/clj/org/apache/storm/daemon/nimbus.clj &#8212;<br/>\n    @@ -1793,16 +1793,16 @@<br/>\n     (.mark nimbus:num-downloadChunk-calls)<br/>\n     (check-authorization! nimbus nil nil \"fileDownload\")<br/>\n     (let [downloaders (:downloaders nimbus)</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>^BufferFileInputStream is (.get downloaders id)]<br/>\n    +      ^BufferInputStream is (.get downloaders id)]\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    @abellina OK I didn't know about the context. Great change.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930628/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/235265228","html_url":"https://github.com/apache/storm/pull/1593#issuecomment-235265228","issue_url":"https://api.github.com/repos/apache/storm/issues/1593","id":235265228,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTI2NTIyOA==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T13:22:06Z","updated_at":"2016-07-26T13:22:06Z","author_association":"CONTRIBUTOR","body":"+1\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/235265228/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930632","html_url":"https://github.com/apache/storm/issues/5777#issuecomment-2612930632","issue_url":"https://api.github.com/repos/apache/storm/issues/5777","id":2612930632,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzA2MzI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T13:22:07Z","updated_at":"2025-01-24T16:30:07Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1593\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1593</a></p>\n\n<p>    +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930632/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/235312438","html_url":"https://github.com/apache/storm/pull/1587#issuecomment-235312438","issue_url":"https://api.github.com/repos/apache/storm/issues/1587","id":235312438,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTMxMjQzOA==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T15:50:49Z","updated_at":"2016-07-26T15:50:49Z","author_association":"CONTRIBUTOR","body":"@hmcl can you review this.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/235312438/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930111","html_url":"https://github.com/apache/storm/issues/5773#issuecomment-2612930111","issue_url":"https://api.github.com/repos/apache/storm/issues/5773","id":2612930111,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzAxMTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T15:50:51Z","updated_at":"2025-01-24T16:29:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1587\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1587</a></p>\n\n<p>    @hmcl can you review this.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930111/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907720","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907720","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907720,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3MjA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T15:52:20Z","updated_at":"2025-01-24T16:18:49Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72278528\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72278528</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/Config.java &#8212;<br/>\n    @@ -0,0 +1,166 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Date;<br/>\n    +<br/>\n    +public class Config implements Serializable {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    given that this is a public class going to be used by devs. Can we rename this as KinesisConfig</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907720/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907721","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907721","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907721,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3MjE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T15:55:08Z","updated_at":"2025-01-24T16:18:49Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72279114\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72279114</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/Config.java &#8212;<br/>\n    @@ -0,0 +1,166 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Date;<br/>\n    +<br/>\n    +public class Config implements Serializable {<br/>\n    +    // kinesis stream name to read from<br/>\n    +    private final String streamName;<br/>\n    +    // shard iterator type based on kinesis api - beginning of time, latest, at timestamp are only supported<br/>\n    +    private final ShardIteratorType shardIteratorType;<br/>\n    +    // implementation for converting a Kinesis record to a storm tuple<br/>\n    +    private final RecordToTupleMapper recordToTupleMapper;<br/>\n    +    // timestamp to be used for shardIteratorType AT_TIMESTAMP - can be null<br/>\n    +    private final Date timestamp;<br/>\n    +    // implementation for handling the failed messages retry logic<br/>\n    +    private final FailedMessageRetryHandler failedMessageRetryHandler;<br/>\n    +    // object capturing all zk related information for storing committed sequence numbers<br/>\n    +    private final ZkInfo zkInfo;<br/>\n    +    // object representing information on paramaters to use while connecting to kinesis using kinesis client<br/>\n    +    private final KinesisConnectionInfo kinesisConnectionInfo;<br/>\n    +    // this number represents the number of messages that are still not committed to zk. it will prevent the spout from emitting further.<br/>\n    +    // for e.g. if 1 failed and 2,3,4,5..... all have been acked by storm, they still cant be committed to zk because 1 is still in failed set. As a result<br/>\n    +    // the acked queue can infinitely grow without any of them being committed to zk. topology max pending does not help since from storm's view they are acked<br/>\n    +    private final Long maxUncommittedRecords;<br/>\n    +<br/>\n    +    public Config (String streamName, ShardIteratorType shardIteratorType, RecordToTupleMapper recordToTupleMapper, Date timestamp, FailedMessageRetryHandler<br/>\n    +    failedMessageRetryHandler, ZkInfo zkInfo, KinesisConnectionInfo kinesisConnectionInfo, Long maxUncommittedRecords) </p>\n{\n    +this.streamName = streamName;\n    +this.shardIteratorType = shardIteratorType;\n    +this.recordToTupleMapper = recordToTupleMapper;\n    +this.timestamp = timestamp;\n    +this.failedMessageRetryHandler = failedMessageRetryHandler;\n    +this.zkInfo = zkInfo;\n    +this.kinesisConnectionInfo = kinesisConnectionInfo;\n    +this.maxUncommittedRecords = maxUncommittedRecords;\n    +validate();\n    +    }\n<p>    +<br/>\n    +    private void validate () {<br/>\n    +if (streamName == null || streamName.length() < 1) </p>\n{\n    +    throw new IllegalArgumentException(\"streamName is required and cannot be of length 0.\");\n    +}\n<p>    +if (shardIteratorType == null || shardIteratorType.equals(ShardIteratorType.AFTER_SEQUENCE_NUMBER) || shardIteratorType.equals(ShardIteratorType<br/>\n    +.AT_SEQUENCE_NUMBER)) </p>\n{\n    +    throw new IllegalArgumentException(\"shardIteratorType has to be one of the \" + ShardIteratorType.AT_TIMESTAMP + \",\" + ShardIteratorType.LATEST +\n    +    \",\" + ShardIteratorType.TRIM_HORIZON);\n    +}\n<p>    +if (shardIteratorType.equals(ShardIteratorType.AT_TIMESTAMP) && timestamp == null) </p>\n{\n    +    throw new IllegalArgumentException(\"timestamp must be provided if shardIteratorType is \" + ShardIteratorType.AT_TIMESTAMP);\n    +}\n<p>    +if (recordToTupleMapper == null) </p>\n{\n    +    throw new IllegalArgumentException(\"recordToTupleMapper cannot be null\");\n    +}\n<p>    +if (failedMessageRetryHandler == null) </p>\n{\n    +    throw new IllegalArgumentException(\"failedMessageRetryHandler cannot be null\");\n    +}\n<p>    +if (zkInfo == null) </p>\n{\n    +    throw new IllegalArgumentException(\"zkInfo cannot be null\");\n    +}\n<p>    +if (kinesisConnectionInfo == null) </p>\n{\n    +    throw new IllegalArgumentException(\"kinesisConnectionInfo cannot be null\");\n    +}\n<p>    +if (maxUncommittedRecords == null || maxUncommittedRecords < 1) </p>\n{\n    +    throw new IllegalArgumentException(\"maxUncommittedRecords has to be a positive integer\");\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    public String getStreamName() </p>\n{\n    +return streamName;\n    +    }\n<p>    +<br/>\n    +    public ShardIteratorType getShardIteratorType() </p>\n{\n    +return shardIteratorType;\n    +    }\n<p>    +<br/>\n    +    public RecordToTupleMapper getRecordToTupleMapper() </p>\n{\n    +return recordToTupleMapper;\n    +    }\n<p>    +<br/>\n    +    public Date getTimestamp() </p>\n{\n    +return timestamp;\n    +    }\n<p>    +<br/>\n    +    public FailedMessageRetryHandler getFailedMessageRetryHandler () </p>\n{\n    +return failedMessageRetryHandler;\n    +    }\n<p>    +<br/>\n    +    public ZkInfo getZkInfo () </p>\n{\n    +return zkInfo;\n    +    }\n<p>    +<br/>\n    +    public KinesisConnectionInfo getKinesisConnectionInfo () </p>\n{\n    +return kinesisConnectionInfo;\n    +    }\n<p>    +<br/>\n    +    public Long getMaxUncommittedRecords () </p>\n{\n    +return maxUncommittedRecords;\n    +    }\n<p>    +<br/>\n    +    @Override<br/>\n    +    public boolean equals(Object o) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Do we need equals and hash code . Not sure where do we do comparisons of config object.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907721/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907724","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907724","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907724,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3MjQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T15:56:18Z","updated_at":"2025-01-24T16:18:49Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72279392\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72279392</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ExponentialBackoffRetrier.java &#8212;<br/>\n    @@ -0,0 +1,164 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.SortedSet;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +public class ExponentialBackoffRetrier implements FailedMessageRetryHandler, Serializable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(ExponentialBackoffRetrier.class);<br/>\n    +    // Wait interfal for retrying after first failure<br/>\n    +    private final Long initialDelayMillis;<br/>\n    +    // Base for exponential function in seconds for retrying for second, third and so on failures<br/>\n    +    private final Long baseSeconds;<br/>\n    +    // Maximum number of retries<br/>\n    +    private final Long maxRetries;<br/>\n    +    // map to track number of failures for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> failCounts = new HashMap<>();<br/>\n    +    // map to track next retry time for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> retryTimes = new HashMap<>();<br/>\n    +    // sorted set of records to be retrued based on retry time. earliest retryTime record comes first<br/>\n    +    private SortedSet<KinesisMessageId> retryMessageSet = new TreeSet<>(new RetryTimeComparator());<br/>\n    +<br/>\n    +    /**<br/>\n    +     * no args constructor that uses defaults of 100 ms for first retry, max retries of Long.MAX_VALUE and an exponential backoff of Math.pow(2,i-1) secs for<br/>\n    +     * retry i where i = 2,3,<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier () </p>\n{\n    +this(100L, 2L, Long.MAX_VALUE);\n    +    }\n<p>    +<br/>\n    +    /**<br/>\n    +     *<br/>\n    +     * @param initialDelayMillis delay in milliseconds for first retry<br/>\n    +     * @param baseSeconds base for exponent function in seconds<br/>\n    +     * @param maxRetries maximum number of retries before the record is discarded/acked<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier (Long initialDelayMillis, Long baseSeconds, Long maxRetries) </p>\n{\n    +this.initialDelayMillis = initialDelayMillis;\n    +this.baseSeconds = baseSeconds;\n    +this.maxRetries = maxRetries;\n    +validate();\n    +    }\n<p>    +<br/>\n    +    private void validate () {<br/>\n    +if (initialDelayMillis < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"initialDelayMillis cannot be negative.\" );\n    +}\n<p>    +if (baseSeconds < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"baseSeconds cannot be negative.\");\n    +}\n<p>    +if (maxRetries < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"maxRetries cannot be negative.\");\n    +}\n<p>    +    }<br/>\n    +    @Override<br/>\n    +    public boolean failed(KinesisMessageId messageId) {<br/>\n    +LOG.debug(\"Handling failed message \" + messageId);<br/>\n    +// if maxRetries is 0, dont retry and return false as per interface contract<br/>\n    +if (maxRetries == 0) </p>\n{\n    +    LOG.debug(\"maxRetries set to 0. Hence not queueing \" + messageId);\n    +    return false;\n    +}\n<p>    +// if first failure add it to the count map<br/>\n    +if (!failCounts.containsKey(messageId)) </p>\n{\n    +    failCounts.put(messageId, 0L);\n    +}\n<p>    +// increment the fail count as we started with 0<br/>\n    +Long failCount = failCounts.get(messageId);<br/>\n    +failCounts.put(messageId, ++failCount);<br/>\n    +// if fail count is greater than maxRetries, discard or ack. for e.g. for maxRetries 3, 4 failures are allowed at maximum<br/>\n    +if (failCount > maxRetries) {<br/>\n    +    LOG.debug(\"maxRetries reached so dropping \" + messageId);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    can you make this as warn as it can be useful to see this in the logs by default</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907724/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907730","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907730","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907730,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3MzA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T15:56:29Z","updated_at":"2025-01-24T16:18:49Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72279426\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72279426</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ExponentialBackoffRetrier.java &#8212;<br/>\n    @@ -0,0 +1,164 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.SortedSet;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +public class ExponentialBackoffRetrier implements FailedMessageRetryHandler, Serializable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(ExponentialBackoffRetrier.class);<br/>\n    +    // Wait interfal for retrying after first failure<br/>\n    +    private final Long initialDelayMillis;<br/>\n    +    // Base for exponential function in seconds for retrying for second, third and so on failures<br/>\n    +    private final Long baseSeconds;<br/>\n    +    // Maximum number of retries<br/>\n    +    private final Long maxRetries;<br/>\n    +    // map to track number of failures for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> failCounts = new HashMap<>();<br/>\n    +    // map to track next retry time for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> retryTimes = new HashMap<>();<br/>\n    +    // sorted set of records to be retrued based on retry time. earliest retryTime record comes first<br/>\n    +    private SortedSet<KinesisMessageId> retryMessageSet = new TreeSet<>(new RetryTimeComparator());<br/>\n    +<br/>\n    +    /**<br/>\n    +     * no args constructor that uses defaults of 100 ms for first retry, max retries of Long.MAX_VALUE and an exponential backoff of Math.pow(2,i-1) secs for<br/>\n    +     * retry i where i = 2,3,<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier () </p>\n{\n    +this(100L, 2L, Long.MAX_VALUE);\n    +    }\n<p>    +<br/>\n    +    /**<br/>\n    +     *<br/>\n    +     * @param initialDelayMillis delay in milliseconds for first retry<br/>\n    +     * @param baseSeconds base for exponent function in seconds<br/>\n    +     * @param maxRetries maximum number of retries before the record is discarded/acked<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier (Long initialDelayMillis, Long baseSeconds, Long maxRetries) </p>\n{\n    +this.initialDelayMillis = initialDelayMillis;\n    +this.baseSeconds = baseSeconds;\n    +this.maxRetries = maxRetries;\n    +validate();\n    +    }\n<p>    +<br/>\n    +    private void validate () {<br/>\n    +if (initialDelayMillis < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"initialDelayMillis cannot be negative.\" );\n    +}\n<p>    +if (baseSeconds < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"baseSeconds cannot be negative.\");\n    +}\n<p>    +if (maxRetries < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"maxRetries cannot be negative.\");\n    +}\n<p>    +    }<br/>\n    +    @Override<br/>\n    +    public boolean failed(KinesisMessageId messageId) {<br/>\n    +LOG.debug(\"Handling failed message \" + messageId);<br/>\n    +// if maxRetries is 0, dont retry and return false as per interface contract<br/>\n    +if (maxRetries == 0) </p>\n{\n    +    LOG.debug(\"maxRetries set to 0. Hence not queueing \" + messageId);\n    +    return false;\n    +}\n<p>    +// if first failure add it to the count map<br/>\n    +if (!failCounts.containsKey(messageId)) </p>\n{\n    +    failCounts.put(messageId, 0L);\n    +}\n<p>    +// increment the fail count as we started with 0<br/>\n    +Long failCount = failCounts.get(messageId);<br/>\n    +failCounts.put(messageId, ++failCount);<br/>\n    +// if fail count is greater than maxRetries, discard or ack. for e.g. for maxRetries 3, 4 failures are allowed at maximum<br/>\n    +if (failCount > maxRetries) </p>\n{\n    +    LOG.debug(\"maxRetries reached so dropping \" + messageId);\n    +    failCounts.remove(messageId);\n    +    return false;\n    +}\n<p>    +// if reached so far, add it to the set of messages waiting to be retried with next retry time based on how many times it failed<br/>\n    +retryTimes.put(messageId, getRetryTime(failCount));<br/>\n    +retryMessageSet.add(messageId);<br/>\n    +LOG.debug(\"Scheduled \" + messageId + \" for retry at \" + retryTimes.get(messageId) + \" and retry attempt \" + failCount);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I recommend this to be at warn level as well.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907730/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907734","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907734","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907734,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3MzQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T15:56:54Z","updated_at":"2025-01-24T16:18:49Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72279515\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72279515</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ExponentialBackoffRetrier.java &#8212;<br/>\n    @@ -0,0 +1,164 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.SortedSet;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +public class ExponentialBackoffRetrier implements FailedMessageRetryHandler, Serializable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(ExponentialBackoffRetrier.class);<br/>\n    +    // Wait interfal for retrying after first failure<br/>\n    +    private final Long initialDelayMillis;<br/>\n    +    // Base for exponential function in seconds for retrying for second, third and so on failures<br/>\n    +    private final Long baseSeconds;<br/>\n    +    // Maximum number of retries<br/>\n    +    private final Long maxRetries;<br/>\n    +    // map to track number of failures for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> failCounts = new HashMap<>();<br/>\n    +    // map to track next retry time for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> retryTimes = new HashMap<>();<br/>\n    +    // sorted set of records to be retrued based on retry time. earliest retryTime record comes first<br/>\n    +    private SortedSet<KinesisMessageId> retryMessageSet = new TreeSet<>(new RetryTimeComparator());<br/>\n    +<br/>\n    +    /**<br/>\n    +     * no args constructor that uses defaults of 100 ms for first retry, max retries of Long.MAX_VALUE and an exponential backoff of Math.pow(2,i-1) secs for<br/>\n    +     * retry i where i = 2,3,<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier () </p>\n{\n    +this(100L, 2L, Long.MAX_VALUE);\n    +    }\n<p>    +<br/>\n    +    /**<br/>\n    +     *<br/>\n    +     * @param initialDelayMillis delay in milliseconds for first retry<br/>\n    +     * @param baseSeconds base for exponent function in seconds<br/>\n    +     * @param maxRetries maximum number of retries before the record is discarded/acked<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier (Long initialDelayMillis, Long baseSeconds, Long maxRetries) </p>\n{\n    +this.initialDelayMillis = initialDelayMillis;\n    +this.baseSeconds = baseSeconds;\n    +this.maxRetries = maxRetries;\n    +validate();\n    +    }\n<p>    +<br/>\n    +    private void validate () {<br/>\n    +if (initialDelayMillis < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"initialDelayMillis cannot be negative.\" );\n    +}\n<p>    +if (baseSeconds < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"baseSeconds cannot be negative.\");\n    +}\n<p>    +if (maxRetries < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"maxRetries cannot be negative.\");\n    +}\n<p>    +    }<br/>\n    +    @Override<br/>\n    +    public boolean failed(KinesisMessageId messageId) {<br/>\n    +LOG.debug(\"Handling failed message \" + messageId);<br/>\n    +// if maxRetries is 0, dont retry and return false as per interface contract<br/>\n    +if (maxRetries == 0) {<br/>\n    +    LOG.debug(\"maxRetries set to 0. Hence not queueing \" + messageId);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    warn here as well</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907734/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907737","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907737","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907737,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3Mzc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T15:58:00Z","updated_at":"2025-01-24T16:18:49Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72279789\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72279789</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ExponentialBackoffRetrier.java &#8212;<br/>\n    @@ -0,0 +1,164 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.SortedSet;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +public class ExponentialBackoffRetrier implements FailedMessageRetryHandler, Serializable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(ExponentialBackoffRetrier.class);<br/>\n    +    // Wait interfal for retrying after first failure<br/>\n    +    private final Long initialDelayMillis;<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    should we have any defaults for these variables.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907737/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907738","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907738","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907738,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3Mzg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T16:06:41Z","updated_at":"2025-01-24T16:18:49Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72281666\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72281666</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ExponentialBackoffRetrier.java &#8212;<br/>\n    @@ -0,0 +1,164 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.SortedSet;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +public class ExponentialBackoffRetrier implements FailedMessageRetryHandler, Serializable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(ExponentialBackoffRetrier.class);<br/>\n    +    // Wait interfal for retrying after first failure<br/>\n    +    private final Long initialDelayMillis;<br/>\n    +    // Base for exponential function in seconds for retrying for second, third and so on failures<br/>\n    +    private final Long baseSeconds;<br/>\n    +    // Maximum number of retries<br/>\n    +    private final Long maxRetries;<br/>\n    +    // map to track number of failures for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> failCounts = new HashMap<>();<br/>\n    +    // map to track next retry time for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> retryTimes = new HashMap<>();<br/>\n    +    // sorted set of records to be retrued based on retry time. earliest retryTime record comes first<br/>\n    +    private SortedSet<KinesisMessageId> retryMessageSet = new TreeSet<>(new RetryTimeComparator());<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    are we going to store the same message in retryMessageSet and retryTimes?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907738/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/235319060","html_url":"https://github.com/apache/storm/pull/1587#issuecomment-235319060","issue_url":"https://api.github.com/repos/apache/storm/issues/1587","id":235319060,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTMxOTA2MA==","user":{"login":"hmcl","id":10284328,"node_id":"MDQ6VXNlcjEwMjg0MzI4","avatar_url":"https://avatars.githubusercontent.com/u/10284328?v=4","gravatar_id":"","url":"https://api.github.com/users/hmcl","html_url":"https://github.com/hmcl","followers_url":"https://api.github.com/users/hmcl/followers","following_url":"https://api.github.com/users/hmcl/following{/other_user}","gists_url":"https://api.github.com/users/hmcl/gists{/gist_id}","starred_url":"https://api.github.com/users/hmcl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hmcl/subscriptions","organizations_url":"https://api.github.com/users/hmcl/orgs","repos_url":"https://api.github.com/users/hmcl/repos","events_url":"https://api.github.com/users/hmcl/events{/privacy}","received_events_url":"https://api.github.com/users/hmcl/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T16:10:58Z","updated_at":"2016-07-26T16:16:52Z","author_association":"CONTRIBUTOR","body":"@darionyaphet can you please clarify why this patch is needed? In my understanding it shouldn't be necessary to have any logic for auto commit interval. If one wishes to set the auto commit interval, one can do so using the kafka properties `autocommit.interval.ms` and `autocommit.enable`. These properties can be specified as in [this example](https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/test/KafkaSpoutTopologyMainNamedTopics.java#L115-L123), by doing `put(\"autocommit.interval.ms\",200)` and `put(\"autocommit.enable\",true)`\n\nThe Kafka specific properties are then passed the `KafkaConsumer` [here](https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L350).\n\nThe [commit timer](https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L111) is only used when in non auto commit mode. The 500 is only the initial delay. One can make this initial delay configurable, but it may not be of extreme importance to do so.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/235319060/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930115","html_url":"https://github.com/apache/storm/issues/5773#issuecomment-2612930115","issue_url":"https://api.github.com/repos/apache/storm/issues/5773","id":2612930115,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzAxMTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T16:10:59Z","updated_at":"2025-01-24T16:29:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user hmcl commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1587\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1587</a></p>\n\n<p>    @darionyaphet can you please clarify why this patch is needed? In my understanding it shouldn't be necessary to have any logic for auto commit interval. If one wishes to set the auto commit interval, one can do so using the kafka properties `autocommit.interval.ms` and `autocommit.enable`. These properties will then be passed the `KafkaConsumer` <span class=\"error\">&#91;here&#93;</span>(<a href=\"https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L350\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L350</a>)</p>\n\n<p>    The <span class=\"error\">&#91;commit timer&#93;</span>(<a href=\"https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L111\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L111</a>) is only used when in non auto commit mode. The 500 is only the initial delay. One can make this initial delay configurable, but it may not be of extreme importance to do so.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930115/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/235330288","html_url":"https://github.com/apache/storm/pull/1587#issuecomment-235330288","issue_url":"https://api.github.com/repos/apache/storm/issues/1587","id":235330288,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTMzMDI4OA==","user":{"login":"darionyaphet","id":4414314,"node_id":"MDQ6VXNlcjQ0MTQzMTQ=","avatar_url":"https://avatars.githubusercontent.com/u/4414314?v=4","gravatar_id":"","url":"https://api.github.com/users/darionyaphet","html_url":"https://github.com/darionyaphet","followers_url":"https://api.github.com/users/darionyaphet/followers","following_url":"https://api.github.com/users/darionyaphet/following{/other_user}","gists_url":"https://api.github.com/users/darionyaphet/gists{/gist_id}","starred_url":"https://api.github.com/users/darionyaphet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/darionyaphet/subscriptions","organizations_url":"https://api.github.com/users/darionyaphet/orgs","repos_url":"https://api.github.com/users/darionyaphet/repos","events_url":"https://api.github.com/users/darionyaphet/events{/privacy}","received_events_url":"https://api.github.com/users/darionyaphet/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T16:47:54Z","updated_at":"2016-07-26T16:47:54Z","author_association":"CONTRIBUTOR","body":"Hi @hmcl  `auto.commit.interval.ms` is the interval to committed offset into zookeeper and it default value is `60 * 1000 (1S)`.  I found there is a constant in `KafkaSpoutConfig .Consumer` , so I try to expose a method to config it. The commit time is `500ms` in `KafkaSpoutConfig` ,actually they are the same .\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/235330288/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930119","html_url":"https://github.com/apache/storm/issues/5773#issuecomment-2612930119","issue_url":"https://api.github.com/repos/apache/storm/issues/5773","id":2612930119,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MzAxMTk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T16:47:55Z","updated_at":"2025-01-24T16:29:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user darionyaphet commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1587\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1587</a></p>\n\n<p>    Hi @hmcl  `auto.commit.interval.ms` is the interval to committed offset into zookeeper and it default value is `60 * 1000 (1S)`.  I found there is a constant in `KafkaSpoutConfig .Consumer` , so I try to expose a method to config it. The commit time is `500ms` in `KafkaSpoutConfig` ,actually they are the same .</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612930119/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907744","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907744","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907744,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3NDQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T16:57:24Z","updated_at":"2025-01-24T16:18:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72291240\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72291240</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/Config.java &#8212;<br/>\n    @@ -0,0 +1,166 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Date;<br/>\n    +<br/>\n    +public class Config implements Serializable {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Will change it.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907744/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907747","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907747","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907747,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3NDc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T16:58:23Z","updated_at":"2025-01-24T16:18:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72291464\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72291464</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/Config.java &#8212;<br/>\n    @@ -0,0 +1,166 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Date;<br/>\n    +<br/>\n    +public class Config implements Serializable {<br/>\n    +    // kinesis stream name to read from<br/>\n    +    private final String streamName;<br/>\n    +    // shard iterator type based on kinesis api - beginning of time, latest, at timestamp are only supported<br/>\n    +    private final ShardIteratorType shardIteratorType;<br/>\n    +    // implementation for converting a Kinesis record to a storm tuple<br/>\n    +    private final RecordToTupleMapper recordToTupleMapper;<br/>\n    +    // timestamp to be used for shardIteratorType AT_TIMESTAMP - can be null<br/>\n    +    private final Date timestamp;<br/>\n    +    // implementation for handling the failed messages retry logic<br/>\n    +    private final FailedMessageRetryHandler failedMessageRetryHandler;<br/>\n    +    // object capturing all zk related information for storing committed sequence numbers<br/>\n    +    private final ZkInfo zkInfo;<br/>\n    +    // object representing information on paramaters to use while connecting to kinesis using kinesis client<br/>\n    +    private final KinesisConnectionInfo kinesisConnectionInfo;<br/>\n    +    // this number represents the number of messages that are still not committed to zk. it will prevent the spout from emitting further.<br/>\n    +    // for e.g. if 1 failed and 2,3,4,5..... all have been acked by storm, they still cant be committed to zk because 1 is still in failed set. As a result<br/>\n    +    // the acked queue can infinitely grow without any of them being committed to zk. topology max pending does not help since from storm's view they are acked<br/>\n    +    private final Long maxUncommittedRecords;<br/>\n    +<br/>\n    +    public Config (String streamName, ShardIteratorType shardIteratorType, RecordToTupleMapper recordToTupleMapper, Date timestamp, FailedMessageRetryHandler<br/>\n    +    failedMessageRetryHandler, ZkInfo zkInfo, KinesisConnectionInfo kinesisConnectionInfo, Long maxUncommittedRecords) </p>\n{\n    +this.streamName = streamName;\n    +this.shardIteratorType = shardIteratorType;\n    +this.recordToTupleMapper = recordToTupleMapper;\n    +this.timestamp = timestamp;\n    +this.failedMessageRetryHandler = failedMessageRetryHandler;\n    +this.zkInfo = zkInfo;\n    +this.kinesisConnectionInfo = kinesisConnectionInfo;\n    +this.maxUncommittedRecords = maxUncommittedRecords;\n    +validate();\n    +    }\n<p>    +<br/>\n    +    private void validate () {<br/>\n    +if (streamName == null || streamName.length() < 1) </p>\n{\n    +    throw new IllegalArgumentException(\"streamName is required and cannot be of length 0.\");\n    +}\n<p>    +if (shardIteratorType == null || shardIteratorType.equals(ShardIteratorType.AFTER_SEQUENCE_NUMBER) || shardIteratorType.equals(ShardIteratorType<br/>\n    +.AT_SEQUENCE_NUMBER)) </p>\n{\n    +    throw new IllegalArgumentException(\"shardIteratorType has to be one of the \" + ShardIteratorType.AT_TIMESTAMP + \",\" + ShardIteratorType.LATEST +\n    +    \",\" + ShardIteratorType.TRIM_HORIZON);\n    +}\n<p>    +if (shardIteratorType.equals(ShardIteratorType.AT_TIMESTAMP) && timestamp == null) </p>\n{\n    +    throw new IllegalArgumentException(\"timestamp must be provided if shardIteratorType is \" + ShardIteratorType.AT_TIMESTAMP);\n    +}\n<p>    +if (recordToTupleMapper == null) </p>\n{\n    +    throw new IllegalArgumentException(\"recordToTupleMapper cannot be null\");\n    +}\n<p>    +if (failedMessageRetryHandler == null) </p>\n{\n    +    throw new IllegalArgumentException(\"failedMessageRetryHandler cannot be null\");\n    +}\n<p>    +if (zkInfo == null) </p>\n{\n    +    throw new IllegalArgumentException(\"zkInfo cannot be null\");\n    +}\n<p>    +if (kinesisConnectionInfo == null) </p>\n{\n    +    throw new IllegalArgumentException(\"kinesisConnectionInfo cannot be null\");\n    +}\n<p>    +if (maxUncommittedRecords == null || maxUncommittedRecords < 1) </p>\n{\n    +    throw new IllegalArgumentException(\"maxUncommittedRecords has to be a positive integer\");\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    public String getStreamName() </p>\n{\n    +return streamName;\n    +    }\n<p>    +<br/>\n    +    public ShardIteratorType getShardIteratorType() </p>\n{\n    +return shardIteratorType;\n    +    }\n<p>    +<br/>\n    +    public RecordToTupleMapper getRecordToTupleMapper() </p>\n{\n    +return recordToTupleMapper;\n    +    }\n<p>    +<br/>\n    +    public Date getTimestamp() </p>\n{\n    +return timestamp;\n    +    }\n<p>    +<br/>\n    +    public FailedMessageRetryHandler getFailedMessageRetryHandler () </p>\n{\n    +return failedMessageRetryHandler;\n    +    }\n<p>    +<br/>\n    +    public ZkInfo getZkInfo () </p>\n{\n    +return zkInfo;\n    +    }\n<p>    +<br/>\n    +    public KinesisConnectionInfo getKinesisConnectionInfo () </p>\n{\n    +return kinesisConnectionInfo;\n    +    }\n<p>    +<br/>\n    +    public Long getMaxUncommittedRecords () </p>\n{\n    +return maxUncommittedRecords;\n    +    }\n<p>    +<br/>\n    +    @Override<br/>\n    +    public boolean equals(Object o) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    We dont need equals and hashcode. I will remove it.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907747/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907755","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907755","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907755,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3NTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T16:59:15Z","updated_at":"2025-01-24T16:18:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72291643\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72291643</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ExponentialBackoffRetrier.java &#8212;<br/>\n    @@ -0,0 +1,164 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.SortedSet;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +public class ExponentialBackoffRetrier implements FailedMessageRetryHandler, Serializable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(ExponentialBackoffRetrier.class);<br/>\n    +    // Wait interfal for retrying after first failure<br/>\n    +    private final Long initialDelayMillis;<br/>\n    +    // Base for exponential function in seconds for retrying for second, third and so on failures<br/>\n    +    private final Long baseSeconds;<br/>\n    +    // Maximum number of retries<br/>\n    +    private final Long maxRetries;<br/>\n    +    // map to track number of failures for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> failCounts = new HashMap<>();<br/>\n    +    // map to track next retry time for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> retryTimes = new HashMap<>();<br/>\n    +    // sorted set of records to be retrued based on retry time. earliest retryTime record comes first<br/>\n    +    private SortedSet<KinesisMessageId> retryMessageSet = new TreeSet<>(new RetryTimeComparator());<br/>\n    +<br/>\n    +    /**<br/>\n    +     * no args constructor that uses defaults of 100 ms for first retry, max retries of Long.MAX_VALUE and an exponential backoff of Math.pow(2,i-1) secs for<br/>\n    +     * retry i where i = 2,3,<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier () </p>\n{\n    +this(100L, 2L, Long.MAX_VALUE);\n    +    }\n<p>    +<br/>\n    +    /**<br/>\n    +     *<br/>\n    +     * @param initialDelayMillis delay in milliseconds for first retry<br/>\n    +     * @param baseSeconds base for exponent function in seconds<br/>\n    +     * @param maxRetries maximum number of retries before the record is discarded/acked<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier (Long initialDelayMillis, Long baseSeconds, Long maxRetries) </p>\n{\n    +this.initialDelayMillis = initialDelayMillis;\n    +this.baseSeconds = baseSeconds;\n    +this.maxRetries = maxRetries;\n    +validate();\n    +    }\n<p>    +<br/>\n    +    private void validate () {<br/>\n    +if (initialDelayMillis < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"initialDelayMillis cannot be negative.\" );\n    +}\n<p>    +if (baseSeconds < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"baseSeconds cannot be negative.\");\n    +}\n<p>    +if (maxRetries < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"maxRetries cannot be negative.\");\n    +}\n<p>    +    }<br/>\n    +    @Override<br/>\n    +    public boolean failed(KinesisMessageId messageId) {<br/>\n    +LOG.debug(\"Handling failed message \" + messageId);<br/>\n    +// if maxRetries is 0, dont retry and return false as per interface contract<br/>\n    +if (maxRetries == 0) </p>\n{\n    +    LOG.debug(\"maxRetries set to 0. Hence not queueing \" + messageId);\n    +    return false;\n    +}\n<p>    +// if first failure add it to the count map<br/>\n    +if (!failCounts.containsKey(messageId)) </p>\n{\n    +    failCounts.put(messageId, 0L);\n    +}\n<p>    +// increment the fail count as we started with 0<br/>\n    +Long failCount = failCounts.get(messageId);<br/>\n    +failCounts.put(messageId, ++failCount);<br/>\n    +// if fail count is greater than maxRetries, discard or ack. for e.g. for maxRetries 3, 4 failures are allowed at maximum<br/>\n    +if (failCount > maxRetries) {<br/>\n    +    LOG.debug(\"maxRetries reached so dropping \" + messageId);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I will change it</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907755/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907759","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907759","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907759,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3NTk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T16:59:39Z","updated_at":"2025-01-24T16:18:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72291774\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72291774</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ExponentialBackoffRetrier.java &#8212;<br/>\n    @@ -0,0 +1,164 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.SortedSet;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +public class ExponentialBackoffRetrier implements FailedMessageRetryHandler, Serializable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(ExponentialBackoffRetrier.class);<br/>\n    +    // Wait interfal for retrying after first failure<br/>\n    +    private final Long initialDelayMillis;<br/>\n    +    // Base for exponential function in seconds for retrying for second, third and so on failures<br/>\n    +    private final Long baseSeconds;<br/>\n    +    // Maximum number of retries<br/>\n    +    private final Long maxRetries;<br/>\n    +    // map to track number of failures for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> failCounts = new HashMap<>();<br/>\n    +    // map to track next retry time for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> retryTimes = new HashMap<>();<br/>\n    +    // sorted set of records to be retrued based on retry time. earliest retryTime record comes first<br/>\n    +    private SortedSet<KinesisMessageId> retryMessageSet = new TreeSet<>(new RetryTimeComparator());<br/>\n    +<br/>\n    +    /**<br/>\n    +     * no args constructor that uses defaults of 100 ms for first retry, max retries of Long.MAX_VALUE and an exponential backoff of Math.pow(2,i-1) secs for<br/>\n    +     * retry i where i = 2,3,<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier () </p>\n{\n    +this(100L, 2L, Long.MAX_VALUE);\n    +    }\n<p>    +<br/>\n    +    /**<br/>\n    +     *<br/>\n    +     * @param initialDelayMillis delay in milliseconds for first retry<br/>\n    +     * @param baseSeconds base for exponent function in seconds<br/>\n    +     * @param maxRetries maximum number of retries before the record is discarded/acked<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier (Long initialDelayMillis, Long baseSeconds, Long maxRetries) </p>\n{\n    +this.initialDelayMillis = initialDelayMillis;\n    +this.baseSeconds = baseSeconds;\n    +this.maxRetries = maxRetries;\n    +validate();\n    +    }\n<p>    +<br/>\n    +    private void validate () {<br/>\n    +if (initialDelayMillis < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"initialDelayMillis cannot be negative.\" );\n    +}\n<p>    +if (baseSeconds < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"baseSeconds cannot be negative.\");\n    +}\n<p>    +if (maxRetries < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"maxRetries cannot be negative.\");\n    +}\n<p>    +    }<br/>\n    +    @Override<br/>\n    +    public boolean failed(KinesisMessageId messageId) {<br/>\n    +LOG.debug(\"Handling failed message \" + messageId);<br/>\n    +// if maxRetries is 0, dont retry and return false as per interface contract<br/>\n    +if (maxRetries == 0) </p>\n{\n    +    LOG.debug(\"maxRetries set to 0. Hence not queueing \" + messageId);\n    +    return false;\n    +}\n<p>    +// if first failure add it to the count map<br/>\n    +if (!failCounts.containsKey(messageId)) </p>\n{\n    +    failCounts.put(messageId, 0L);\n    +}\n<p>    +// increment the fail count as we started with 0<br/>\n    +Long failCount = failCounts.get(messageId);<br/>\n    +failCounts.put(messageId, ++failCount);<br/>\n    +// if fail count is greater than maxRetries, discard or ack. for e.g. for maxRetries 3, 4 failures are allowed at maximum<br/>\n    +if (failCount > maxRetries) </p>\n{\n    +    LOG.debug(\"maxRetries reached so dropping \" + messageId);\n    +    failCounts.remove(messageId);\n    +    return false;\n    +}\n<p>    +// if reached so far, add it to the set of messages waiting to be retried with next retry time based on how many times it failed<br/>\n    +retryTimes.put(messageId, getRetryTime(failCount));<br/>\n    +retryMessageSet.add(messageId);<br/>\n    +LOG.debug(\"Scheduled \" + messageId + \" for retry at \" + retryTimes.get(messageId) + \" and retry attempt \" + failCount);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I will change it</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907759/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907764","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907764","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907764,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3NjQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:00:36Z","updated_at":"2025-01-24T16:18:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72291939\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72291939</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ExponentialBackoffRetrier.java &#8212;<br/>\n    @@ -0,0 +1,164 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.SortedSet;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +public class ExponentialBackoffRetrier implements FailedMessageRetryHandler, Serializable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(ExponentialBackoffRetrier.class);<br/>\n    +    // Wait interfal for retrying after first failure<br/>\n    +    private final Long initialDelayMillis;<br/>\n    +    // Base for exponential function in seconds for retrying for second, third and so on failures<br/>\n    +    private final Long baseSeconds;<br/>\n    +    // Maximum number of retries<br/>\n    +    private final Long maxRetries;<br/>\n    +    // map to track number of failures for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> failCounts = new HashMap<>();<br/>\n    +    // map to track next retry time for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> retryTimes = new HashMap<>();<br/>\n    +    // sorted set of records to be retrued based on retry time. earliest retryTime record comes first<br/>\n    +    private SortedSet<KinesisMessageId> retryMessageSet = new TreeSet<>(new RetryTimeComparator());<br/>\n    +<br/>\n    +    /**<br/>\n    +     * no args constructor that uses defaults of 100 ms for first retry, max retries of Long.MAX_VALUE and an exponential backoff of Math.pow(2,i-1) secs for<br/>\n    +     * retry i where i = 2,3,<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier () </p>\n{\n    +this(100L, 2L, Long.MAX_VALUE);\n    +    }\n<p>    +<br/>\n    +    /**<br/>\n    +     *<br/>\n    +     * @param initialDelayMillis delay in milliseconds for first retry<br/>\n    +     * @param baseSeconds base for exponent function in seconds<br/>\n    +     * @param maxRetries maximum number of retries before the record is discarded/acked<br/>\n    +     */<br/>\n    +    public ExponentialBackoffRetrier (Long initialDelayMillis, Long baseSeconds, Long maxRetries) </p>\n{\n    +this.initialDelayMillis = initialDelayMillis;\n    +this.baseSeconds = baseSeconds;\n    +this.maxRetries = maxRetries;\n    +validate();\n    +    }\n<p>    +<br/>\n    +    private void validate () {<br/>\n    +if (initialDelayMillis < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"initialDelayMillis cannot be negative.\" );\n    +}\n<p>    +if (baseSeconds < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"baseSeconds cannot be negative.\");\n    +}\n<p>    +if (maxRetries < 0) </p>\n{\n    +    throw new IllegalArgumentException(\"maxRetries cannot be negative.\");\n    +}\n<p>    +    }<br/>\n    +    @Override<br/>\n    +    public boolean failed(KinesisMessageId messageId) {<br/>\n    +LOG.debug(\"Handling failed message \" + messageId);<br/>\n    +// if maxRetries is 0, dont retry and return false as per interface contract<br/>\n    +if (maxRetries == 0) {<br/>\n    +    LOG.debug(\"maxRetries set to 0. Hence not queueing \" + messageId);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I will change it. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907764/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907767","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907767","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907767,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3Njc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:01:35Z","updated_at":"2025-01-24T16:18:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72292144\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72292144</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ExponentialBackoffRetrier.java &#8212;<br/>\n    @@ -0,0 +1,164 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.SortedSet;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +public class ExponentialBackoffRetrier implements FailedMessageRetryHandler, Serializable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(ExponentialBackoffRetrier.class);<br/>\n    +    // Wait interfal for retrying after first failure<br/>\n    +    private final Long initialDelayMillis;<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    ExponentialBackoffRetrier has two constructors. The no args constructor will set the default values for these variables.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907767/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907776","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907776","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907776,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3NzY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:04:52Z","updated_at":"2025-01-24T16:18:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72292758\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72292758</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ExponentialBackoffRetrier.java &#8212;<br/>\n    @@ -0,0 +1,164 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.SortedSet;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +public class ExponentialBackoffRetrier implements FailedMessageRetryHandler, Serializable {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(ExponentialBackoffRetrier.class);<br/>\n    +    // Wait interfal for retrying after first failure<br/>\n    +    private final Long initialDelayMillis;<br/>\n    +    // Base for exponential function in seconds for retrying for second, third and so on failures<br/>\n    +    private final Long baseSeconds;<br/>\n    +    // Maximum number of retries<br/>\n    +    private final Long maxRetries;<br/>\n    +    // map to track number of failures for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> failCounts = new HashMap<>();<br/>\n    +    // map to track next retry time for each kinesis message that failed<br/>\n    +    private Map<KinesisMessageId, Long> retryTimes = new HashMap<>();<br/>\n    +    // sorted set of records to be retrued based on retry time. earliest retryTime record comes first<br/>\n    +    private SortedSet<KinesisMessageId> retryMessageSet = new TreeSet<>(new RetryTimeComparator());<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    No. Messages are not stored anywhere in ExponentialBackoffRetrier. retryTimes is just used to implement the comparator interface that will be used by retryMessageSet TreeSet to order the messages on their next retry time. You can check out the RetryTimeComparator in this class</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907776/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907782","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907782","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907782,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3ODI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:13:42Z","updated_at":"2025-01-24T16:18:50Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72294493\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72294493</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisConnectionInfo.java &#8212;<br/>\n    @@ -0,0 +1,137 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.ClientConfiguration;<br/>\n    +import com.amazonaws.auth.AWSCredentialsProvider;<br/>\n    +import com.amazonaws.regions.Regions;<br/>\n    +import com.esotericsoftware.kryo.Kryo;<br/>\n    +import com.esotericsoftware.kryo.io.Input;<br/>\n    +import com.esotericsoftware.kryo.io.Output;<br/>\n    +import org.objenesis.strategy.StdInstantiatorStrategy;<br/>\n    +<br/>\n    +import java.io.ByteArrayInputStream;<br/>\n    +import java.io.ByteArrayOutputStream;<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Arrays;<br/>\n    +<br/>\n    +public class KinesisConnectionInfo implements Serializable {<br/>\n    +    private final byte[] serializedKinesisCredsProvider;<br/>\n    +    private final byte[] serializedkinesisClientConfig;<br/>\n    +    private final Integer recordsLimit;<br/>\n    +    private final Regions region;<br/>\n    +<br/>\n    +    private transient AWSCredentialsProvider credentialsProvider;<br/>\n    +    private transient ClientConfiguration clientConfiguration;<br/>\n    +<br/>\n    +    /**<br/>\n    +     *<br/>\n    +     * @param credentialsProvider implementation to provide credentials to connect to kinesis<br/>\n    +     * @param clientConfiguration client configuration to pass to kinesis client<br/>\n    +     * @param region region to connect to<br/>\n    +     * @param recordsLimit max records to be fetched in a getRecords request to kinesis<br/>\n    +     */<br/>\n    +    public KinesisConnectionInfo (AWSCredentialsProvider credentialsProvider, ClientConfiguration clientConfiguration, Regions region, Integer recordsLimit) {<br/>\n    +if (recordsLimit == null || recordsLimit <= 0) </p>\n{\n    +    throw new IllegalArgumentException(\"recordsLimit has to be a positive integer\");\n    +}\n<p>    +if (region == null) </p>\n{\n    +    throw new IllegalArgumentException(\"region cannot be null\");\n    +}\n<p>    +serializedKinesisCredsProvider = getKryoSerializedBytes(credentialsProvider);<br/>\n    +serializedkinesisClientConfig = getKryoSerializedBytes(clientConfiguration);<br/>\n    +this.recordsLimit = recordsLimit;<br/>\n    +this.region = region;<br/>\n    +<br/>\n    +this.credentialsProvider = null;<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    we don't need to explicitly assign a null to these. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907782/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907786","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907786","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907786,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3ODY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:14:57Z","updated_at":"2025-01-24T16:18:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72294716\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72294716</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisConnectionInfo.java &#8212;<br/>\n    @@ -0,0 +1,137 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.ClientConfiguration;<br/>\n    +import com.amazonaws.auth.AWSCredentialsProvider;<br/>\n    +import com.amazonaws.regions.Regions;<br/>\n    +import com.esotericsoftware.kryo.Kryo;<br/>\n    +import com.esotericsoftware.kryo.io.Input;<br/>\n    +import com.esotericsoftware.kryo.io.Output;<br/>\n    +import org.objenesis.strategy.StdInstantiatorStrategy;<br/>\n    +<br/>\n    +import java.io.ByteArrayInputStream;<br/>\n    +import java.io.ByteArrayOutputStream;<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Arrays;<br/>\n    +<br/>\n    +public class KinesisConnectionInfo implements Serializable {<br/>\n    +    private final byte[] serializedKinesisCredsProvider;<br/>\n    +    private final byte[] serializedkinesisClientConfig;<br/>\n    +    private final Integer recordsLimit;<br/>\n    +    private final Regions region;<br/>\n    +<br/>\n    +    private transient AWSCredentialsProvider credentialsProvider;<br/>\n    +    private transient ClientConfiguration clientConfiguration;<br/>\n    +<br/>\n    +    /**<br/>\n    +     *<br/>\n    +     * @param credentialsProvider implementation to provide credentials to connect to kinesis<br/>\n    +     * @param clientConfiguration client configuration to pass to kinesis client<br/>\n    +     * @param region region to connect to<br/>\n    +     * @param recordsLimit max records to be fetched in a getRecords request to kinesis<br/>\n    +     */<br/>\n    +    public KinesisConnectionInfo (AWSCredentialsProvider credentialsProvider, ClientConfiguration clientConfiguration, Regions region, Integer recordsLimit) {<br/>\n    +if (recordsLimit == null || recordsLimit <= 0) </p>\n{\n    +    throw new IllegalArgumentException(\"recordsLimit has to be a positive integer\");\n    +}\n<p>    +if (region == null) </p>\n{\n    +    throw new IllegalArgumentException(\"region cannot be null\");\n    +}\n<p>    +serializedKinesisCredsProvider = getKryoSerializedBytes(credentialsProvider);<br/>\n    +serializedkinesisClientConfig = getKryoSerializedBytes(clientConfiguration);<br/>\n    +this.recordsLimit = recordsLimit;<br/>\n    +this.region = region;<br/>\n    +<br/>\n    +this.credentialsProvider = null;<br/>\n    +this.clientConfiguration = null;<br/>\n    +    }<br/>\n    +<br/>\n    +    public Integer getRecordsLimit() </p>\n{\n    +return recordsLimit;\n    +    }\n<p>    +<br/>\n    +    public AWSCredentialsProvider getCredentialsProvider() {<br/>\n    +if (credentialsProvider == null) </p>\n{\n    +    credentialsProvider = (AWSCredentialsProvider) this.getKryoDeserializedObject(serializedKinesisCredsProvider);\n    +}\n<p>    +return credentialsProvider;<br/>\n    +    }<br/>\n    +<br/>\n    +    public ClientConfiguration getClientConfiguration() {<br/>\n    +if (clientConfiguration == null) </p>\n{\n    +    clientConfiguration = (ClientConfiguration) this.getKryoDeserializedObject(serializedkinesisClientConfig);\n    +}\n<p>    +return clientConfiguration;<br/>\n    +    }<br/>\n    +<br/>\n    +    public Regions getRegion() </p>\n{\n    +return region;\n    +    }\n<p>    +<br/>\n    +    private byte[] getKryoSerializedBytes (final Object obj) </p>\n{\n    +final Kryo kryo = new Kryo();\n    +final ByteArrayOutputStream os = new ByteArrayOutputStream();\n    +final Output output = new Output(os);\n    +kryo.setInstantiatorStrategy(new StdInstantiatorStrategy());\n    +kryo.writeClassAndObject(output, obj);\n    +output.flush();\n    +return os.toByteArray();\n    +    }\n<p>    +<br/>\n    +    private Object getKryoDeserializedObject (final byte[] ser) </p>\n{\n    +final Kryo kryo = new Kryo();\n    +final Input input = new Input(new ByteArrayInputStream(ser));\n    +kryo.setInstantiatorStrategy(new StdInstantiatorStrategy());\n    +return kryo.readClassAndObject(input);\n    +    }\n<p>    +<br/>\n    +    @Override<br/>\n    +    public boolean equals(Object o) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    we probably can remove these equals, hash here as well.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907786/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907790","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907790","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907790,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3OTA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:23:30Z","updated_at":"2025-01-24T16:18:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72296325\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72296325</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}\n<p>    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) </p>\n{\n    +    fetchFailedRecords(failedMessageId);\n    +}\n<p>    +if (emitFailedRecord(collector, failedMessageId)) </p>\n{\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);\n    +    return;\n    +}\n<p> else </p>\n{\n    +    LOG.debug(\"failedMessageEmitted not called on retrier for \" + failedMessageId + \". This can happen a few times but should not happen \" +\n    +    \"infinitely\");\n    +}\n<p>    +    } else </p>\n{\n    +LOG.debug(\"failedPerShard does not contain \" + failedMessageId + \". This should never happen.\");\n    +    }\n<p>    +}<br/>\n    +LOG.debug(\"No failed record to emit for now. Hence will try to emit new records\");<br/>\n    +// if maximum uncommitted records count has reached, so dont emit any new records and return<br/>\n    +if (!(getUncommittedRecordsCount() < config.getMaxUncommittedRecords())) {<br/>\n    +    LOG.debug(\"maximum uncommitted records count has reached. so not emitting any new records and returning\");<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    this should be warn</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907790/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907797","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907797","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907797,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc3OTc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:23:50Z","updated_at":"2025-01-24T16:18:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72296389\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72296389</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}\n<p>    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) </p>\n{\n    +    fetchFailedRecords(failedMessageId);\n    +}\n<p>    +if (emitFailedRecord(collector, failedMessageId)) </p>\n{\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);\n    +    return;\n    +}\n<p> else </p>\n{\n    +    LOG.debug(\"failedMessageEmitted not called on retrier for \" + failedMessageId + \". This can happen a few times but should not happen \" +\n    +    \"infinitely\");\n    +}\n<p>    +    } else </p>\n{\n    +LOG.debug(\"failedPerShard does not contain \" + failedMessageId + \". This should never happen.\");\n    +    }\n<p>    +}<br/>\n    +LOG.debug(\"No failed record to emit for now. Hence will try to emit new records\");<br/>\n    +// if maximum uncommitted records count has reached, so dont emit any new records and return<br/>\n    +if (!(getUncommittedRecordsCount() < config.getMaxUncommittedRecords())) </p>\n{\n    +    LOG.debug(\"maximum uncommitted records count has reached. so not emitting any new records and returning\");\n    +    return;\n    +}\n<p>    +// early return as no shard is assigned - probably because number of executors > number of shards<br/>\n    +if (toEmitPerShard.isEmpty()) {<br/>\n    +    LOG.debug(\"No shard is assigned to this task. Hence not emitting any tuple.\");<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    same here</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907797/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907803","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907803","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907803,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4MDM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:26:11Z","updated_at":"2025-01-24T16:18:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72296861\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72296861</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}\n<p>    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) </p>\n{\n    +    fetchFailedRecords(failedMessageId);\n    +}\n<p>    +if (emitFailedRecord(collector, failedMessageId)) {<br/>\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);<br/>\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);<br/>\n    +    return;<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    if we can make multiple returns into one or two we should try.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907803/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907808","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907808","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907808,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4MDg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:26:46Z","updated_at":"2025-01-24T16:18:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72296990\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72296990</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}\n<p>    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) </p>\n{\n    +    fetchFailedRecords(failedMessageId);\n    +}\n<p>    +if (emitFailedRecord(collector, failedMessageId)) </p>\n{\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);\n    +    return;\n    +}\n<p> else </p>\n{\n    +    LOG.debug(\"failedMessageEmitted not called on retrier for \" + failedMessageId + \". This can happen a few times but should not happen \" +\n    +    \"infinitely\");\n    +}\n<p>    +    } else </p>\n{\n    +LOG.debug(\"failedPerShard does not contain \" + failedMessageId + \". This should never happen.\");\n    +    }\n<p>    +}<br/>\n    +LOG.debug(\"No failed record to emit for now. Hence will try to emit new records\");<br/>\n    +// if maximum uncommitted records count has reached, so dont emit any new records and return<br/>\n    +if (!(getUncommittedRecordsCount() < config.getMaxUncommittedRecords())) </p>\n{\n    +    LOG.debug(\"maximum uncommitted records count has reached. so not emitting any new records and returning\");\n    +    return;\n    +}\n<p>    +// early return as no shard is assigned - probably because number of executors > number of shards<br/>\n    +if (toEmitPerShard.isEmpty()) </p>\n{\n    +    LOG.debug(\"No shard is assigned to this task. Hence not emitting any tuple.\");\n    +    return;\n    +}\n<p>    +<br/>\n    +if (shouldFetchNewRecords()) </p>\n{\n    +    fetchNewRecords();\n    +}\n<p>    +emitNewRecord(collector);<br/>\n    +    }<br/>\n    +<br/>\n    +    void ack (KinesisMessageId kinesisMessageId) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    if we can document via comments on this ack logic that would be great.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907808/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907811","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907811","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907811,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4MTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:29:37Z","updated_at":"2025-01-24T16:18:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72297573\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72297573</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/README.md &#8212;<br/>\n    @@ -0,0 +1,139 @@<br/>\n    +#Storm Kinesis Spout<br/>\n    +Provides core storm spout for consuming data from a stream in Amazon Kinesis Streams. It stores the sequence numbers that can be committed in zookeeper and <br/>\n    +starts consuming records after that sequence number on restart by default. Below is the code sample to create a sample topology that uses the spout. Each <br/>\n    +object used in configuring the spout is explained below. Ideally, the number of spout tasks should be equal to number of shards in kinesis. However each task <br/>\n    +can read from more than one shard.<br/>\n    +<br/>\n    +```java<br/>\n    +public class KinesisSpoutTopology {<br/>\n    +    public static void main (String args[]) throws InvalidTopologyException, AuthorizationException, AlreadyAliveException </p>\n{\n    +String topologyName = args[0];\n    +RecordToTupleMapper recordToTupleMapper = new TestRecordToTupleMapper();\n    +KinesisConnectionInfo kinesisConnectionInfo = new KinesisConnectionInfo(new CredentialsProviderChain(), new ClientConfiguration(), Regions.US_WEST_2,\n    +1000);\n    +org.apache.storm.kinesis.spout.Config config = new org.apache.storm.kinesis.spout.Config(args[1], ShardIteratorType.TRIM_HORIZON,\n    +recordToTupleMapper, new Date(), new ExponentialBackoffRetrier(), new ZkInfo(), kinesisConnectionInfo, 10000L);\n    +KinesisSpout kinesisSpout = new KinesisSpout(config);\n    +TopologyBuilder topologyBuilder = new TopologyBuilder();\n    +topologyBuilder.setSpout(\"spout\", kinesisSpout, 3);\n    +topologyBuilder.setBolt(\"bolt\", new KinesisBoltTest(), 1).shuffleGrouping(\"spout\");\n    +Config topologyConfig = new Config();\n    +topologyConfig.setDebug(true);\n    +topologyConfig.setNumWorkers(3);\n    +StormSubmitter.submitTopology(topologyName, topologyConfig, topologyBuilder.createTopology());\n    +    }\n<p>    +}<br/>\n    +```<br/>\n    +As you can see above the spout takes an object of Config in its constructor. The constructor of Config takes 8 objects as explained below.<br/>\n    +<br/>\n    +#### `String` streamName<br/>\n    +name of kinesis stream to consume data from<br/>\n    +<br/>\n    +#### `ShardIteratorType` shardIteratorType<br/>\n    +3 types are supported - TRIM_HORIZON(beginning of shard), LATEST and AT_TIMESTAMP. By default this argument is ignored if state for shards <br/>\n    +is found in zookeeper. Hence they will apply the first time a topology is started. If you want to use any of these in subsequent runs of the topology, you <br/>\n    +will need to clear the state of zookeeper node used for storing sequence numbers<br/>\n    +#### `RecordToTupleMapper` recordToTupleMapper<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    line break</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907811/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907815","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907815","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907815,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4MTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:35:38Z","updated_at":"2025-01-24T16:18:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72298716\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72298716</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}<br/>\n    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) {\n    +    fetchFailedRecords(failedMessageId);\n    +}<br/>\n    +if (emitFailedRecord(collector, failedMessageId)) {\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);\n    +    return;\n    +} else {\n    +    LOG.debug(\"failedMessageEmitted not called on retrier for \" + failedMessageId + \". This can happen a few times but should not happen \" +\n    +    \"infinitely\");\n    +}<br/>\n    +    } else {\n    +LOG.debug(\"failedPerShard does not contain \" + failedMessageId + \". This should never happen.\");\n    +    }<br/>\n    +}<br/>\n    +LOG.debug(\"No failed record to emit for now. Hence will try to emit new records\");<br/>\n    +// if maximum uncommitted records count has reached, so dont emit any new records and return<br/>\n    +if (!(getUncommittedRecordsCount() < config.getMaxUncommittedRecords())) {\n    +    LOG.debug(\"maximum uncommitted records count has reached. so not emitting any new records and returning\");\n    +    return;\n    +}<br/>\n    +// early return as no shard is assigned - probably because number of executors > number of shards<br/>\n    +if (toEmitPerShard.isEmpty()) {\n    +    LOG.debug(\"No shard is assigned to this task. Hence not emitting any tuple.\");\n    +    return;\n    +}<br/>\n    +<br/>\n    +if (shouldFetchNewRecords()) {\n    +    fetchNewRecords();\n    +}<br/>\n    +emitNewRecord(collector);<br/>\n    +    }<br/>\n    +<br/>\n    +    void ack (KinesisMessageId kinesisMessageId) {<br/>\n    +// for an acked message add it to acked set and remove it from emitted and failed<br/>\n    +String shardId = kinesisMessageId.getShardId();<br/>\n    +BigInteger sequenceNumber = new BigInteger(kinesisMessageId.getSequenceNumber());<br/>\n    +LOG.debug(\"Ack received for shardId: \" + shardId + \" sequenceNumber: \" + sequenceNumber);<br/>\n    +if (!ackedPerShard.containsKey(shardId)) {\n    +    ackedPerShard.put(shardId, new TreeSet<BigInteger>());\n    +}<br/>\n    +ackedPerShard.get(shardId).add(sequenceNumber);<br/>\n    +if (emittedPerShard.containsKey(shardId)) {\n    +    TreeSet<BigInteger> emitted = emittedPerShard.get(shardId);\n    +    emitted.remove(sequenceNumber);\n    +}<br/>\n    +if (failedPerShard.containsKey(shardId)) {\n    +    failedPerShard.get(shardId).remove(sequenceNumber);\n    +}<br/>\n    +if (failedandFetchedRecords.containsKey(kinesisMessageId)) {\n    +    config.getFailedMessageRetryHandler().acked(kinesisMessageId);\n    +    failedandFetchedRecords.remove(kinesisMessageId);\n    +}<br/>\n    +// keep committing when topology is deactivated since ack and fail keep getting called on deactivated topology<br/>\n    +if (deactivated) {    +    commit();    +}\n<p>    +    }<br/>\n    +<br/>\n    +    void fail (KinesisMessageId kinesisMessageId) {<br/>\n    +String shardId = kinesisMessageId.getShardId();<br/>\n    +BigInteger sequenceNumber = new BigInteger(kinesisMessageId.getSequenceNumber());<br/>\n    +LOG.debug(\"Fail received for shardId: \" + shardId + \" sequenceNumber: \" + sequenceNumber);<br/>\n    +// for a failed message add it to failed set if it will be retried, otherwise ack it; remove from emitted either way<br/>\n    +if (config.getFailedMessageRetryHandler().failed(kinesisMessageId)) {<br/>\n    +    if (!failedPerShard.containsKey(shardId)) </p>\n{\n    +failedPerShard.put(shardId, new TreeSet<BigInteger>());\n    +    }\n<p>    +    failedPerShard.get(shardId).add(sequenceNumber);<br/>\n    +    TreeSet<BigInteger> emitted = emittedPerShard.get(shardId);<br/>\n    +    emitted.remove(sequenceNumber);<br/>\n    +} else </p>\n{\n    +    ack(kinesisMessageId);\n    +}\n<p>    +// keep committing when topology is deactivated since ack and fail keep getting called on deactivated topology<br/>\n    +if (deactivated) </p>\n{\n    +    commit();\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    void commit () {<br/>\n    +// Logic for deciding what sequence number to ack is find the highest sequence number from acked called X such that there is no sequence number Y in<br/>\n    +// emitted or failed that satisfies X > Y. For e.g. is acked is 1,3,5. Emitted is 2,4,6 then we can only commit 1 and not 3 because 2 is still pending<br/>\n    +for (String shardId: toEmitPerShard.keySet()) {<br/>\n    +    if (ackedPerShard.containsKey(shardId)) {<br/>\n    +BigInteger commitSequenceNumberBound = null;<br/>\n    +if (failedPerShard.containsKey(shardId) && !failedPerShard.get(shardId).isEmpty()) </p>\n{\n    +    commitSequenceNumberBound = failedPerShard.get(shardId).first();\n    +}\n<p>    +if (emittedPerShard.containsKey(shardId) && !emittedPerShard.get(shardId).isEmpty()) {<br/>\n    +    BigInteger smallestEmittedSequenceNumber = emittedPerShard.get(shardId).first();<br/>\n    +    if (commitSequenceNumberBound == null || (commitSequenceNumberBound.compareTo(smallestEmittedSequenceNumber) == 1)) </p>\n{\n    +commitSequenceNumberBound = smallestEmittedSequenceNumber;\n    +    }\n<p>    +}<br/>\n    +Iterator<BigInteger> ackedSequenceNumbers = ackedPerShard.get(shardId).iterator();<br/>\n    +BigInteger ackedSequenceNumberToCommit = null;<br/>\n    +while (ackedSequenceNumbers.hasNext()) {<br/>\n    +    BigInteger ackedSequenceNumber = ackedSequenceNumbers.next();<br/>\n    +    if (commitSequenceNumberBound == null || (commitSequenceNumberBound.compareTo(ackedSequenceNumber) == 1)) </p>\n{\n    +ackedSequenceNumberToCommit = ackedSequenceNumber;\n    +ackedSequenceNumbers.remove();\n    +    }\n<p> else </p>\n{\n    +break;\n    +    }\n<p>    +}<br/>\n    +if (ackedSequenceNumberToCommit != null) </p>\n{\n    +    Map<Object, Object> state = new HashMap<>();\n    +    state.put(\"committedSequenceNumber\", ackedSequenceNumberToCommit.toString());\n    +    LOG.debug(\"Committing sequence number \" + ackedSequenceNumberToCommit.toString() + \" for shardId \" + shardId);\n    +    String path = getZkPath(shardId);\n    +    commitState(path, state);\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +    }<br/>\n    +<br/>\n    +    void activate () </p>\n{\n    +LOG.info(\"Activate called\");\n    +deactivated = false;\n    +initializeKinesisClient();\n    +    }\n<p>    +<br/>\n    +    void deactivate () </p>\n{\n    +LOG.info(\"Deactivate called\");\n    +deactivated = true;\n    +commit();\n    +shutdownKinesisClient();\n    +    }\n<p>    +<br/>\n    +    void close () </p>\n{\n    +commit();\n    +shutdownKinesisClient();\n    +shutdownCurator();\n    +    }\n<p>    +<br/>\n    +    private String getZkPath (String shardId) {<br/>\n    +String path = \"\";<br/>\n    +if (!config.getZkInfo().getZkNode().startsWith(\"/\")) </p>\n{\n    +    path += \"/\";\n    +}<br/>\n    +path += config.getZkInfo().getZkNode();<br/>\n    +if (!config.getZkInfo().getZkNode().endsWith(\"/\")) {    +    path += \"/\";    +}\n<p>    +path += (config.getStreamName() + \"/\" + shardId);<br/>\n    +return path;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void commitState (String path, Map<Object, Object> state) {<br/>\n    +byte[] bytes = JSONValue.toJSONString(state).getBytes(Charset.forName(\"UTF-8\"));<br/>\n    +try {<br/>\n    +    if (curatorFramework.checkExists().forPath(path) == null) </p>\n{\n    +curatorFramework.create()\n    +.creatingParentsIfNeeded()\n    +.withMode(CreateMode.PERSISTENT)\n    +.forPath(path, bytes);\n    +    }\n<p> else </p>\n{\n    +curatorFramework.setData().forPath(path, bytes);\n    +    }\n<p>    +} catch (Exception e) </p>\n{\n    +    throw new RuntimeException(e);\n    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Object, Object> readState (String path) {<br/>\n    +try {<br/>\n    +    Map<Object, Object> state = null;<br/>\n    +    byte[] b = null;<br/>\n    +    if (curatorFramework.checkExists().forPath(path) != null) {\n    +b = curatorFramework.getData().forPath(path);\n    +    }<br/>\n    +    if (b != null) {\n    +state = (Map<Object, Object>) JSONValue.parse(new String(b, \"UTF-8\"));\n    +    }<br/>\n    +    return state;<br/>\n    +} catch (Exception e) {    +    throw new RuntimeException(e);    +}\n<p>    +    }<br/>\n    +<br/>\n    +    // fetch records from kinesis starting at sequence number for message passed as argument. Any other messages fetched and are in the failed queue will also<br/>\n    +    // be kept in memory to avoid going to kinesis again for retry<br/>\n    +    private void fetchFailedRecords (KinesisMessageId kinesisMessageId) {<br/>\n    +// if shard iterator not present for this message, get it<br/>\n    +if (!shardIteratorPerFailedMessage.containsKey(kinesisMessageId)) </p>\n{\n    +    refreshShardIteratorForFailedRecord(kinesisMessageId);\n    +}\n<p>    +String shardIterator = shardIteratorPerFailedMessage.get(kinesisMessageId);<br/>\n    +LOG.debug(\"Fetching failed records for shard id :\" + kinesisMessageId.getShardId() + \" at sequence number \" + kinesisMessageId.getSequenceNumber() +<br/>\n    +\" using shardIterator \" + shardIterator);<br/>\n    +try {<br/>\n    +    GetRecordsResult getRecordsResult = fetchRecords(shardIterator);<br/>\n    +    if (getRecordsResult != null) {<br/>\n    +List<Record> records = getRecordsResult.getRecords();<br/>\n    +LOG.debug(\"Records size from fetchFailedRecords is \" + records.size());<br/>\n    +// update the shard iterator to next one in case this fetch does not give the message.<br/>\n    +shardIteratorPerFailedMessage.put(kinesisMessageId, getRecordsResult.getNextShardIterator());<br/>\n    +if (records.size() == 0) {<br/>\n    +    LOG.debug(\"No records returned from kinesis. Hence sleeping for 1 second\");<br/>\n    +    Thread.sleep(1000);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    should this be configurable ? or probably a candidate for exponential back off . we can address this in follow-up jira</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907815/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907823","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907823","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907823,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4MjM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:36:24Z","updated_at":"2025-01-24T16:18:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72298863\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72298863</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}<br/>\n    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) {\n    +    fetchFailedRecords(failedMessageId);\n    +}<br/>\n    +if (emitFailedRecord(collector, failedMessageId)) {\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);\n    +    return;\n    +} else {\n    +    LOG.debug(\"failedMessageEmitted not called on retrier for \" + failedMessageId + \". This can happen a few times but should not happen \" +\n    +    \"infinitely\");\n    +}<br/>\n    +    } else {\n    +LOG.debug(\"failedPerShard does not contain \" + failedMessageId + \". This should never happen.\");\n    +    }<br/>\n    +}<br/>\n    +LOG.debug(\"No failed record to emit for now. Hence will try to emit new records\");<br/>\n    +// if maximum uncommitted records count has reached, so dont emit any new records and return<br/>\n    +if (!(getUncommittedRecordsCount() < config.getMaxUncommittedRecords())) {\n    +    LOG.debug(\"maximum uncommitted records count has reached. so not emitting any new records and returning\");\n    +    return;\n    +}<br/>\n    +// early return as no shard is assigned - probably because number of executors > number of shards<br/>\n    +if (toEmitPerShard.isEmpty()) {\n    +    LOG.debug(\"No shard is assigned to this task. Hence not emitting any tuple.\");\n    +    return;\n    +}<br/>\n    +<br/>\n    +if (shouldFetchNewRecords()) {\n    +    fetchNewRecords();\n    +}<br/>\n    +emitNewRecord(collector);<br/>\n    +    }<br/>\n    +<br/>\n    +    void ack (KinesisMessageId kinesisMessageId) {<br/>\n    +// for an acked message add it to acked set and remove it from emitted and failed<br/>\n    +String shardId = kinesisMessageId.getShardId();<br/>\n    +BigInteger sequenceNumber = new BigInteger(kinesisMessageId.getSequenceNumber());<br/>\n    +LOG.debug(\"Ack received for shardId: \" + shardId + \" sequenceNumber: \" + sequenceNumber);<br/>\n    +if (!ackedPerShard.containsKey(shardId)) {\n    +    ackedPerShard.put(shardId, new TreeSet<BigInteger>());\n    +}<br/>\n    +ackedPerShard.get(shardId).add(sequenceNumber);<br/>\n    +if (emittedPerShard.containsKey(shardId)) {\n    +    TreeSet<BigInteger> emitted = emittedPerShard.get(shardId);\n    +    emitted.remove(sequenceNumber);\n    +}<br/>\n    +if (failedPerShard.containsKey(shardId)) {\n    +    failedPerShard.get(shardId).remove(sequenceNumber);\n    +}<br/>\n    +if (failedandFetchedRecords.containsKey(kinesisMessageId)) {\n    +    config.getFailedMessageRetryHandler().acked(kinesisMessageId);\n    +    failedandFetchedRecords.remove(kinesisMessageId);\n    +}<br/>\n    +// keep committing when topology is deactivated since ack and fail keep getting called on deactivated topology<br/>\n    +if (deactivated) {    +    commit();    +}\n<p>    +    }<br/>\n    +<br/>\n    +    void fail (KinesisMessageId kinesisMessageId) {<br/>\n    +String shardId = kinesisMessageId.getShardId();<br/>\n    +BigInteger sequenceNumber = new BigInteger(kinesisMessageId.getSequenceNumber());<br/>\n    +LOG.debug(\"Fail received for shardId: \" + shardId + \" sequenceNumber: \" + sequenceNumber);<br/>\n    +// for a failed message add it to failed set if it will be retried, otherwise ack it; remove from emitted either way<br/>\n    +if (config.getFailedMessageRetryHandler().failed(kinesisMessageId)) {<br/>\n    +    if (!failedPerShard.containsKey(shardId)) </p>\n{\n    +failedPerShard.put(shardId, new TreeSet<BigInteger>());\n    +    }\n<p>    +    failedPerShard.get(shardId).add(sequenceNumber);<br/>\n    +    TreeSet<BigInteger> emitted = emittedPerShard.get(shardId);<br/>\n    +    emitted.remove(sequenceNumber);<br/>\n    +} else </p>\n{\n    +    ack(kinesisMessageId);\n    +}\n<p>    +// keep committing when topology is deactivated since ack and fail keep getting called on deactivated topology<br/>\n    +if (deactivated) </p>\n{\n    +    commit();\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    void commit () {<br/>\n    +// Logic for deciding what sequence number to ack is find the highest sequence number from acked called X such that there is no sequence number Y in<br/>\n    +// emitted or failed that satisfies X > Y. For e.g. is acked is 1,3,5. Emitted is 2,4,6 then we can only commit 1 and not 3 because 2 is still pending<br/>\n    +for (String shardId: toEmitPerShard.keySet()) {<br/>\n    +    if (ackedPerShard.containsKey(shardId)) {<br/>\n    +BigInteger commitSequenceNumberBound = null;<br/>\n    +if (failedPerShard.containsKey(shardId) && !failedPerShard.get(shardId).isEmpty()) </p>\n{\n    +    commitSequenceNumberBound = failedPerShard.get(shardId).first();\n    +}\n<p>    +if (emittedPerShard.containsKey(shardId) && !emittedPerShard.get(shardId).isEmpty()) {<br/>\n    +    BigInteger smallestEmittedSequenceNumber = emittedPerShard.get(shardId).first();<br/>\n    +    if (commitSequenceNumberBound == null || (commitSequenceNumberBound.compareTo(smallestEmittedSequenceNumber) == 1)) </p>\n{\n    +commitSequenceNumberBound = smallestEmittedSequenceNumber;\n    +    }\n<p>    +}<br/>\n    +Iterator<BigInteger> ackedSequenceNumbers = ackedPerShard.get(shardId).iterator();<br/>\n    +BigInteger ackedSequenceNumberToCommit = null;<br/>\n    +while (ackedSequenceNumbers.hasNext()) {<br/>\n    +    BigInteger ackedSequenceNumber = ackedSequenceNumbers.next();<br/>\n    +    if (commitSequenceNumberBound == null || (commitSequenceNumberBound.compareTo(ackedSequenceNumber) == 1)) </p>\n{\n    +ackedSequenceNumberToCommit = ackedSequenceNumber;\n    +ackedSequenceNumbers.remove();\n    +    }\n<p> else </p>\n{\n    +break;\n    +    }\n<p>    +}<br/>\n    +if (ackedSequenceNumberToCommit != null) </p>\n{\n    +    Map<Object, Object> state = new HashMap<>();\n    +    state.put(\"committedSequenceNumber\", ackedSequenceNumberToCommit.toString());\n    +    LOG.debug(\"Committing sequence number \" + ackedSequenceNumberToCommit.toString() + \" for shardId \" + shardId);\n    +    String path = getZkPath(shardId);\n    +    commitState(path, state);\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +    }<br/>\n    +<br/>\n    +    void activate () </p>\n{\n    +LOG.info(\"Activate called\");\n    +deactivated = false;\n    +initializeKinesisClient();\n    +    }\n<p>    +<br/>\n    +    void deactivate () </p>\n{\n    +LOG.info(\"Deactivate called\");\n    +deactivated = true;\n    +commit();\n    +shutdownKinesisClient();\n    +    }\n<p>    +<br/>\n    +    void close () </p>\n{\n    +commit();\n    +shutdownKinesisClient();\n    +shutdownCurator();\n    +    }\n<p>    +<br/>\n    +    private String getZkPath (String shardId) {<br/>\n    +String path = \"\";<br/>\n    +if (!config.getZkInfo().getZkNode().startsWith(\"/\")) </p>\n{\n    +    path += \"/\";\n    +}<br/>\n    +path += config.getZkInfo().getZkNode();<br/>\n    +if (!config.getZkInfo().getZkNode().endsWith(\"/\")) {    +    path += \"/\";    +}\n<p>    +path += (config.getStreamName() + \"/\" + shardId);<br/>\n    +return path;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void commitState (String path, Map<Object, Object> state) {<br/>\n    +byte[] bytes = JSONValue.toJSONString(state).getBytes(Charset.forName(\"UTF-8\"));<br/>\n    +try {<br/>\n    +    if (curatorFramework.checkExists().forPath(path) == null) </p>\n{\n    +curatorFramework.create()\n    +.creatingParentsIfNeeded()\n    +.withMode(CreateMode.PERSISTENT)\n    +.forPath(path, bytes);\n    +    }\n<p> else </p>\n{\n    +curatorFramework.setData().forPath(path, bytes);\n    +    }\n<p>    +} catch (Exception e) </p>\n{\n    +    throw new RuntimeException(e);\n    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Object, Object> readState (String path) {<br/>\n    +try {<br/>\n    +    Map<Object, Object> state = null;<br/>\n    +    byte[] b = null;<br/>\n    +    if (curatorFramework.checkExists().forPath(path) != null) {\n    +b = curatorFramework.getData().forPath(path);\n    +    }<br/>\n    +    if (b != null) {\n    +state = (Map<Object, Object>) JSONValue.parse(new String(b, \"UTF-8\"));\n    +    }<br/>\n    +    return state;<br/>\n    +} catch (Exception e) {    +    throw new RuntimeException(e);    +}\n<p>    +    }<br/>\n    +<br/>\n    +    // fetch records from kinesis starting at sequence number for message passed as argument. Any other messages fetched and are in the failed queue will also<br/>\n    +    // be kept in memory to avoid going to kinesis again for retry<br/>\n    +    private void fetchFailedRecords (KinesisMessageId kinesisMessageId) {<br/>\n    +// if shard iterator not present for this message, get it<br/>\n    +if (!shardIteratorPerFailedMessage.containsKey(kinesisMessageId)) </p>\n{\n    +    refreshShardIteratorForFailedRecord(kinesisMessageId);\n    +}\n<p>    +String shardIterator = shardIteratorPerFailedMessage.get(kinesisMessageId);<br/>\n    +LOG.debug(\"Fetching failed records for shard id :\" + kinesisMessageId.getShardId() + \" at sequence number \" + kinesisMessageId.getSequenceNumber() +<br/>\n    +\" using shardIterator \" + shardIterator);<br/>\n    +try {<br/>\n    +    GetRecordsResult getRecordsResult = fetchRecords(shardIterator);<br/>\n    +    if (getRecordsResult != null) {<br/>\n    +List<Record> records = getRecordsResult.getRecords();<br/>\n    +LOG.debug(\"Records size from fetchFailedRecords is \" + records.size());<br/>\n    +// update the shard iterator to next one in case this fetch does not give the message.<br/>\n    +shardIteratorPerFailedMessage.put(kinesisMessageId, getRecordsResult.getNextShardIterator());<br/>\n    +if (records.size() == 0) </p>\n{\n    +    LOG.debug(\"No records returned from kinesis. Hence sleeping for 1 second\");\n    +    Thread.sleep(1000);\n    +}\n<p> else {<br/>\n    +    // add all fetched records to the set of failed records if they are present in failed set<br/>\n    +    for (Record record: records) {<br/>\n    +KinesisMessageId current = new KinesisMessageId(kinesisMessageId.getStreamName(), kinesisMessageId.getShardId(), record.getSequenceNumber());<br/>\n    +if (failedPerShard.get(kinesisMessageId.getShardId()).contains(new BigInteger(current.getSequenceNumber()))) </p>\n{\n    +    failedandFetchedRecords.put(current, record);\n    +    shardIteratorPerFailedMessage.remove(current);\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +    }<br/>\n    +} catch (InterruptedException ie) {<br/>\n    +    LOG.debug(\"Thread interrupted while sleeping\", ie);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    lets make these warns for all the exceptions unless you think this might result lot of noise. Even than it will be helpful to print them given that these are critical errors.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907823/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907828","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907828","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907828,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4Mjg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:36:35Z","updated_at":"2025-01-24T16:18:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72298893\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72298893</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}<br/>\n    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) {\n    +    fetchFailedRecords(failedMessageId);\n    +}<br/>\n    +if (emitFailedRecord(collector, failedMessageId)) {\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);\n    +    return;\n    +} else {\n    +    LOG.debug(\"failedMessageEmitted not called on retrier for \" + failedMessageId + \". This can happen a few times but should not happen \" +\n    +    \"infinitely\");\n    +}<br/>\n    +    } else {\n    +LOG.debug(\"failedPerShard does not contain \" + failedMessageId + \". This should never happen.\");\n    +    }<br/>\n    +}<br/>\n    +LOG.debug(\"No failed record to emit for now. Hence will try to emit new records\");<br/>\n    +// if maximum uncommitted records count has reached, so dont emit any new records and return<br/>\n    +if (!(getUncommittedRecordsCount() < config.getMaxUncommittedRecords())) {\n    +    LOG.debug(\"maximum uncommitted records count has reached. so not emitting any new records and returning\");\n    +    return;\n    +}<br/>\n    +// early return as no shard is assigned - probably because number of executors > number of shards<br/>\n    +if (toEmitPerShard.isEmpty()) {\n    +    LOG.debug(\"No shard is assigned to this task. Hence not emitting any tuple.\");\n    +    return;\n    +}<br/>\n    +<br/>\n    +if (shouldFetchNewRecords()) {\n    +    fetchNewRecords();\n    +}<br/>\n    +emitNewRecord(collector);<br/>\n    +    }<br/>\n    +<br/>\n    +    void ack (KinesisMessageId kinesisMessageId) {<br/>\n    +// for an acked message add it to acked set and remove it from emitted and failed<br/>\n    +String shardId = kinesisMessageId.getShardId();<br/>\n    +BigInteger sequenceNumber = new BigInteger(kinesisMessageId.getSequenceNumber());<br/>\n    +LOG.debug(\"Ack received for shardId: \" + shardId + \" sequenceNumber: \" + sequenceNumber);<br/>\n    +if (!ackedPerShard.containsKey(shardId)) {\n    +    ackedPerShard.put(shardId, new TreeSet<BigInteger>());\n    +}<br/>\n    +ackedPerShard.get(shardId).add(sequenceNumber);<br/>\n    +if (emittedPerShard.containsKey(shardId)) {\n    +    TreeSet<BigInteger> emitted = emittedPerShard.get(shardId);\n    +    emitted.remove(sequenceNumber);\n    +}<br/>\n    +if (failedPerShard.containsKey(shardId)) {\n    +    failedPerShard.get(shardId).remove(sequenceNumber);\n    +}<br/>\n    +if (failedandFetchedRecords.containsKey(kinesisMessageId)) {\n    +    config.getFailedMessageRetryHandler().acked(kinesisMessageId);\n    +    failedandFetchedRecords.remove(kinesisMessageId);\n    +}<br/>\n    +// keep committing when topology is deactivated since ack and fail keep getting called on deactivated topology<br/>\n    +if (deactivated) {    +    commit();    +}\n<p>    +    }<br/>\n    +<br/>\n    +    void fail (KinesisMessageId kinesisMessageId) {<br/>\n    +String shardId = kinesisMessageId.getShardId();<br/>\n    +BigInteger sequenceNumber = new BigInteger(kinesisMessageId.getSequenceNumber());<br/>\n    +LOG.debug(\"Fail received for shardId: \" + shardId + \" sequenceNumber: \" + sequenceNumber);<br/>\n    +// for a failed message add it to failed set if it will be retried, otherwise ack it; remove from emitted either way<br/>\n    +if (config.getFailedMessageRetryHandler().failed(kinesisMessageId)) {<br/>\n    +    if (!failedPerShard.containsKey(shardId)) </p>\n{\n    +failedPerShard.put(shardId, new TreeSet<BigInteger>());\n    +    }\n<p>    +    failedPerShard.get(shardId).add(sequenceNumber);<br/>\n    +    TreeSet<BigInteger> emitted = emittedPerShard.get(shardId);<br/>\n    +    emitted.remove(sequenceNumber);<br/>\n    +} else </p>\n{\n    +    ack(kinesisMessageId);\n    +}\n<p>    +// keep committing when topology is deactivated since ack and fail keep getting called on deactivated topology<br/>\n    +if (deactivated) </p>\n{\n    +    commit();\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    void commit () {<br/>\n    +// Logic for deciding what sequence number to ack is find the highest sequence number from acked called X such that there is no sequence number Y in<br/>\n    +// emitted or failed that satisfies X > Y. For e.g. is acked is 1,3,5. Emitted is 2,4,6 then we can only commit 1 and not 3 because 2 is still pending<br/>\n    +for (String shardId: toEmitPerShard.keySet()) {<br/>\n    +    if (ackedPerShard.containsKey(shardId)) {<br/>\n    +BigInteger commitSequenceNumberBound = null;<br/>\n    +if (failedPerShard.containsKey(shardId) && !failedPerShard.get(shardId).isEmpty()) </p>\n{\n    +    commitSequenceNumberBound = failedPerShard.get(shardId).first();\n    +}\n<p>    +if (emittedPerShard.containsKey(shardId) && !emittedPerShard.get(shardId).isEmpty()) {<br/>\n    +    BigInteger smallestEmittedSequenceNumber = emittedPerShard.get(shardId).first();<br/>\n    +    if (commitSequenceNumberBound == null || (commitSequenceNumberBound.compareTo(smallestEmittedSequenceNumber) == 1)) </p>\n{\n    +commitSequenceNumberBound = smallestEmittedSequenceNumber;\n    +    }\n<p>    +}<br/>\n    +Iterator<BigInteger> ackedSequenceNumbers = ackedPerShard.get(shardId).iterator();<br/>\n    +BigInteger ackedSequenceNumberToCommit = null;<br/>\n    +while (ackedSequenceNumbers.hasNext()) {<br/>\n    +    BigInteger ackedSequenceNumber = ackedSequenceNumbers.next();<br/>\n    +    if (commitSequenceNumberBound == null || (commitSequenceNumberBound.compareTo(ackedSequenceNumber) == 1)) </p>\n{\n    +ackedSequenceNumberToCommit = ackedSequenceNumber;\n    +ackedSequenceNumbers.remove();\n    +    }\n<p> else </p>\n{\n    +break;\n    +    }\n<p>    +}<br/>\n    +if (ackedSequenceNumberToCommit != null) </p>\n{\n    +    Map<Object, Object> state = new HashMap<>();\n    +    state.put(\"committedSequenceNumber\", ackedSequenceNumberToCommit.toString());\n    +    LOG.debug(\"Committing sequence number \" + ackedSequenceNumberToCommit.toString() + \" for shardId \" + shardId);\n    +    String path = getZkPath(shardId);\n    +    commitState(path, state);\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +    }<br/>\n    +<br/>\n    +    void activate () </p>\n{\n    +LOG.info(\"Activate called\");\n    +deactivated = false;\n    +initializeKinesisClient();\n    +    }\n<p>    +<br/>\n    +    void deactivate () </p>\n{\n    +LOG.info(\"Deactivate called\");\n    +deactivated = true;\n    +commit();\n    +shutdownKinesisClient();\n    +    }\n<p>    +<br/>\n    +    void close () </p>\n{\n    +commit();\n    +shutdownKinesisClient();\n    +shutdownCurator();\n    +    }\n<p>    +<br/>\n    +    private String getZkPath (String shardId) {<br/>\n    +String path = \"\";<br/>\n    +if (!config.getZkInfo().getZkNode().startsWith(\"/\")) </p>\n{\n    +    path += \"/\";\n    +}<br/>\n    +path += config.getZkInfo().getZkNode();<br/>\n    +if (!config.getZkInfo().getZkNode().endsWith(\"/\")) {    +    path += \"/\";    +}\n<p>    +path += (config.getStreamName() + \"/\" + shardId);<br/>\n    +return path;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void commitState (String path, Map<Object, Object> state) {<br/>\n    +byte[] bytes = JSONValue.toJSONString(state).getBytes(Charset.forName(\"UTF-8\"));<br/>\n    +try {<br/>\n    +    if (curatorFramework.checkExists().forPath(path) == null) </p>\n{\n    +curatorFramework.create()\n    +.creatingParentsIfNeeded()\n    +.withMode(CreateMode.PERSISTENT)\n    +.forPath(path, bytes);\n    +    }\n<p> else </p>\n{\n    +curatorFramework.setData().forPath(path, bytes);\n    +    }\n<p>    +} catch (Exception e) </p>\n{\n    +    throw new RuntimeException(e);\n    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Object, Object> readState (String path) {<br/>\n    +try {<br/>\n    +    Map<Object, Object> state = null;<br/>\n    +    byte[] b = null;<br/>\n    +    if (curatorFramework.checkExists().forPath(path) != null) {\n    +b = curatorFramework.getData().forPath(path);\n    +    }<br/>\n    +    if (b != null) {\n    +state = (Map<Object, Object>) JSONValue.parse(new String(b, \"UTF-8\"));\n    +    }<br/>\n    +    return state;<br/>\n    +} catch (Exception e) {    +    throw new RuntimeException(e);    +}\n<p>    +    }<br/>\n    +<br/>\n    +    // fetch records from kinesis starting at sequence number for message passed as argument. Any other messages fetched and are in the failed queue will also<br/>\n    +    // be kept in memory to avoid going to kinesis again for retry<br/>\n    +    private void fetchFailedRecords (KinesisMessageId kinesisMessageId) {<br/>\n    +// if shard iterator not present for this message, get it<br/>\n    +if (!shardIteratorPerFailedMessage.containsKey(kinesisMessageId)) </p>\n{\n    +    refreshShardIteratorForFailedRecord(kinesisMessageId);\n    +}\n<p>    +String shardIterator = shardIteratorPerFailedMessage.get(kinesisMessageId);<br/>\n    +LOG.debug(\"Fetching failed records for shard id :\" + kinesisMessageId.getShardId() + \" at sequence number \" + kinesisMessageId.getSequenceNumber() +<br/>\n    +\" using shardIterator \" + shardIterator);<br/>\n    +try {<br/>\n    +    GetRecordsResult getRecordsResult = fetchRecords(shardIterator);<br/>\n    +    if (getRecordsResult != null) {<br/>\n    +List<Record> records = getRecordsResult.getRecords();<br/>\n    +LOG.debug(\"Records size from fetchFailedRecords is \" + records.size());<br/>\n    +// update the shard iterator to next one in case this fetch does not give the message.<br/>\n    +shardIteratorPerFailedMessage.put(kinesisMessageId, getRecordsResult.getNextShardIterator());<br/>\n    +if (records.size() == 0) </p>\n{\n    +    LOG.debug(\"No records returned from kinesis. Hence sleeping for 1 second\");\n    +    Thread.sleep(1000);\n    +}\n<p> else {<br/>\n    +    // add all fetched records to the set of failed records if they are present in failed set<br/>\n    +    for (Record record: records) {<br/>\n    +KinesisMessageId current = new KinesisMessageId(kinesisMessageId.getStreamName(), kinesisMessageId.getShardId(), record.getSequenceNumber());<br/>\n    +if (failedPerShard.get(kinesisMessageId.getShardId()).contains(new BigInteger(current.getSequenceNumber()))) </p>\n{\n    +    failedandFetchedRecords.put(current, record);\n    +    shardIteratorPerFailedMessage.remove(current);\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +    }<br/>\n    +} catch (InterruptedException ie) </p>\n{\n    +    LOG.debug(\"Thread interrupted while sleeping\", ie);\n    +}\n<p> catch (ExpiredIteratorException ex) </p>\n{\n    +    LOG.debug(\"shardIterator for failedRecord \" + kinesisMessageId + \" has expired. Refreshing shardIterator\");\n    +    refreshShardIteratorForFailedRecord(kinesisMessageId);\n    +}\n<p> catch (ProvisionedThroughputExceededException pe) {<br/>\n    +    try {<br/>\n    +LOG.debug(\"ProvisionedThroughputExceededException occured. Check your limits. Sleeping for 1 second.\", pe);<br/>\n    +Thread.sleep(1000);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    same as before</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907828/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907835","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907835","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907835,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4MzU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:38:31Z","updated_at":"2025-01-24T16:18:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72299262\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72299262</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}<br/>\n    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) {\n    +    fetchFailedRecords(failedMessageId);\n    +}<br/>\n    +if (emitFailedRecord(collector, failedMessageId)) {\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);\n    +    return;\n    +} else {\n    +    LOG.debug(\"failedMessageEmitted not called on retrier for \" + failedMessageId + \". This can happen a few times but should not happen \" +\n    +    \"infinitely\");\n    +}<br/>\n    +    } else {\n    +LOG.debug(\"failedPerShard does not contain \" + failedMessageId + \". This should never happen.\");\n    +    }<br/>\n    +}<br/>\n    +LOG.debug(\"No failed record to emit for now. Hence will try to emit new records\");<br/>\n    +// if maximum uncommitted records count has reached, so dont emit any new records and return<br/>\n    +if (!(getUncommittedRecordsCount() < config.getMaxUncommittedRecords())) {\n    +    LOG.debug(\"maximum uncommitted records count has reached. so not emitting any new records and returning\");\n    +    return;\n    +}<br/>\n    +// early return as no shard is assigned - probably because number of executors > number of shards<br/>\n    +if (toEmitPerShard.isEmpty()) {\n    +    LOG.debug(\"No shard is assigned to this task. Hence not emitting any tuple.\");\n    +    return;\n    +}<br/>\n    +<br/>\n    +if (shouldFetchNewRecords()) {\n    +    fetchNewRecords();\n    +}<br/>\n    +emitNewRecord(collector);<br/>\n    +    }<br/>\n    +<br/>\n    +    void ack (KinesisMessageId kinesisMessageId) {<br/>\n    +// for an acked message add it to acked set and remove it from emitted and failed<br/>\n    +String shardId = kinesisMessageId.getShardId();<br/>\n    +BigInteger sequenceNumber = new BigInteger(kinesisMessageId.getSequenceNumber());<br/>\n    +LOG.debug(\"Ack received for shardId: \" + shardId + \" sequenceNumber: \" + sequenceNumber);<br/>\n    +if (!ackedPerShard.containsKey(shardId)) {\n    +    ackedPerShard.put(shardId, new TreeSet<BigInteger>());\n    +}<br/>\n    +ackedPerShard.get(shardId).add(sequenceNumber);<br/>\n    +if (emittedPerShard.containsKey(shardId)) {\n    +    TreeSet<BigInteger> emitted = emittedPerShard.get(shardId);\n    +    emitted.remove(sequenceNumber);\n    +}<br/>\n    +if (failedPerShard.containsKey(shardId)) {\n    +    failedPerShard.get(shardId).remove(sequenceNumber);\n    +}<br/>\n    +if (failedandFetchedRecords.containsKey(kinesisMessageId)) {\n    +    config.getFailedMessageRetryHandler().acked(kinesisMessageId);\n    +    failedandFetchedRecords.remove(kinesisMessageId);\n    +}<br/>\n    +// keep committing when topology is deactivated since ack and fail keep getting called on deactivated topology<br/>\n    +if (deactivated) {    +    commit();    +}\n<p>    +    }<br/>\n    +<br/>\n    +    void fail (KinesisMessageId kinesisMessageId) {<br/>\n    +String shardId = kinesisMessageId.getShardId();<br/>\n    +BigInteger sequenceNumber = new BigInteger(kinesisMessageId.getSequenceNumber());<br/>\n    +LOG.debug(\"Fail received for shardId: \" + shardId + \" sequenceNumber: \" + sequenceNumber);<br/>\n    +// for a failed message add it to failed set if it will be retried, otherwise ack it; remove from emitted either way<br/>\n    +if (config.getFailedMessageRetryHandler().failed(kinesisMessageId)) {<br/>\n    +    if (!failedPerShard.containsKey(shardId)) </p>\n{\n    +failedPerShard.put(shardId, new TreeSet<BigInteger>());\n    +    }\n<p>    +    failedPerShard.get(shardId).add(sequenceNumber);<br/>\n    +    TreeSet<BigInteger> emitted = emittedPerShard.get(shardId);<br/>\n    +    emitted.remove(sequenceNumber);<br/>\n    +} else </p>\n{\n    +    ack(kinesisMessageId);\n    +}\n<p>    +// keep committing when topology is deactivated since ack and fail keep getting called on deactivated topology<br/>\n    +if (deactivated) </p>\n{\n    +    commit();\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    void commit () {<br/>\n    +// Logic for deciding what sequence number to ack is find the highest sequence number from acked called X such that there is no sequence number Y in<br/>\n    +// emitted or failed that satisfies X > Y. For e.g. is acked is 1,3,5. Emitted is 2,4,6 then we can only commit 1 and not 3 because 2 is still pending<br/>\n    +for (String shardId: toEmitPerShard.keySet()) {<br/>\n    +    if (ackedPerShard.containsKey(shardId)) {<br/>\n    +BigInteger commitSequenceNumberBound = null;<br/>\n    +if (failedPerShard.containsKey(shardId) && !failedPerShard.get(shardId).isEmpty()) </p>\n{\n    +    commitSequenceNumberBound = failedPerShard.get(shardId).first();\n    +}\n<p>    +if (emittedPerShard.containsKey(shardId) && !emittedPerShard.get(shardId).isEmpty()) {<br/>\n    +    BigInteger smallestEmittedSequenceNumber = emittedPerShard.get(shardId).first();<br/>\n    +    if (commitSequenceNumberBound == null || (commitSequenceNumberBound.compareTo(smallestEmittedSequenceNumber) == 1)) </p>\n{\n    +commitSequenceNumberBound = smallestEmittedSequenceNumber;\n    +    }\n<p>    +}<br/>\n    +Iterator<BigInteger> ackedSequenceNumbers = ackedPerShard.get(shardId).iterator();<br/>\n    +BigInteger ackedSequenceNumberToCommit = null;<br/>\n    +while (ackedSequenceNumbers.hasNext()) {<br/>\n    +    BigInteger ackedSequenceNumber = ackedSequenceNumbers.next();<br/>\n    +    if (commitSequenceNumberBound == null || (commitSequenceNumberBound.compareTo(ackedSequenceNumber) == 1)) </p>\n{\n    +ackedSequenceNumberToCommit = ackedSequenceNumber;\n    +ackedSequenceNumbers.remove();\n    +    }\n<p> else </p>\n{\n    +break;\n    +    }\n<p>    +}<br/>\n    +if (ackedSequenceNumberToCommit != null) </p>\n{\n    +    Map<Object, Object> state = new HashMap<>();\n    +    state.put(\"committedSequenceNumber\", ackedSequenceNumberToCommit.toString());\n    +    LOG.debug(\"Committing sequence number \" + ackedSequenceNumberToCommit.toString() + \" for shardId \" + shardId);\n    +    String path = getZkPath(shardId);\n    +    commitState(path, state);\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +    }<br/>\n    +<br/>\n    +    void activate () </p>\n{\n    +LOG.info(\"Activate called\");\n    +deactivated = false;\n    +initializeKinesisClient();\n    +    }\n<p>    +<br/>\n    +    void deactivate () </p>\n{\n    +LOG.info(\"Deactivate called\");\n    +deactivated = true;\n    +commit();\n    +shutdownKinesisClient();\n    +    }\n<p>    +<br/>\n    +    void close () </p>\n{\n    +commit();\n    +shutdownKinesisClient();\n    +shutdownCurator();\n    +    }\n<p>    +<br/>\n    +    private String getZkPath (String shardId) {<br/>\n    +String path = \"\";<br/>\n    +if (!config.getZkInfo().getZkNode().startsWith(\"/\")) </p>\n{\n    +    path += \"/\";\n    +}<br/>\n    +path += config.getZkInfo().getZkNode();<br/>\n    +if (!config.getZkInfo().getZkNode().endsWith(\"/\")) {    +    path += \"/\";    +}\n<p>    +path += (config.getStreamName() + \"/\" + shardId);<br/>\n    +return path;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void commitState (String path, Map<Object, Object> state) {<br/>\n    +byte[] bytes = JSONValue.toJSONString(state).getBytes(Charset.forName(\"UTF-8\"));<br/>\n    +try {<br/>\n    +    if (curatorFramework.checkExists().forPath(path) == null) </p>\n{\n    +curatorFramework.create()\n    +.creatingParentsIfNeeded()\n    +.withMode(CreateMode.PERSISTENT)\n    +.forPath(path, bytes);\n    +    }\n<p> else </p>\n{\n    +curatorFramework.setData().forPath(path, bytes);\n    +    }\n<p>    +} catch (Exception e) </p>\n{\n    +    throw new RuntimeException(e);\n    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Object, Object> readState (String path) {<br/>\n    +try {<br/>\n    +    Map<Object, Object> state = null;<br/>\n    +    byte[] b = null;<br/>\n    +    if (curatorFramework.checkExists().forPath(path) != null) {\n    +b = curatorFramework.getData().forPath(path);\n    +    }<br/>\n    +    if (b != null) {\n    +state = (Map<Object, Object>) JSONValue.parse(new String(b, \"UTF-8\"));\n    +    }<br/>\n    +    return state;<br/>\n    +} catch (Exception e) {    +    throw new RuntimeException(e);    +}\n<p>    +    }<br/>\n    +<br/>\n    +    // fetch records from kinesis starting at sequence number for message passed as argument. Any other messages fetched and are in the failed queue will also<br/>\n    +    // be kept in memory to avoid going to kinesis again for retry<br/>\n    +    private void fetchFailedRecords (KinesisMessageId kinesisMessageId) {<br/>\n    +// if shard iterator not present for this message, get it<br/>\n    +if (!shardIteratorPerFailedMessage.containsKey(kinesisMessageId)) </p>\n{\n    +    refreshShardIteratorForFailedRecord(kinesisMessageId);\n    +}\n<p>    +String shardIterator = shardIteratorPerFailedMessage.get(kinesisMessageId);<br/>\n    +LOG.debug(\"Fetching failed records for shard id :\" + kinesisMessageId.getShardId() + \" at sequence number \" + kinesisMessageId.getSequenceNumber() +<br/>\n    +\" using shardIterator \" + shardIterator);<br/>\n    +try {<br/>\n    +    GetRecordsResult getRecordsResult = fetchRecords(shardIterator);<br/>\n    +    if (getRecordsResult != null) {<br/>\n    +List<Record> records = getRecordsResult.getRecords();<br/>\n    +LOG.debug(\"Records size from fetchFailedRecords is \" + records.size());<br/>\n    +// update the shard iterator to next one in case this fetch does not give the message.<br/>\n    +shardIteratorPerFailedMessage.put(kinesisMessageId, getRecordsResult.getNextShardIterator());<br/>\n    +if (records.size() == 0) </p>\n{\n    +    LOG.debug(\"No records returned from kinesis. Hence sleeping for 1 second\");\n    +    Thread.sleep(1000);\n    +}\n<p> else {<br/>\n    +    // add all fetched records to the set of failed records if they are present in failed set<br/>\n    +    for (Record record: records) {<br/>\n    +KinesisMessageId current = new KinesisMessageId(kinesisMessageId.getStreamName(), kinesisMessageId.getShardId(), record.getSequenceNumber());<br/>\n    +if (failedPerShard.get(kinesisMessageId.getShardId()).contains(new BigInteger(current.getSequenceNumber()))) </p>\n{\n    +    failedandFetchedRecords.put(current, record);\n    +    shardIteratorPerFailedMessage.remove(current);\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +    }<br/>\n    +} catch (InterruptedException ie) </p>\n{\n    +    LOG.debug(\"Thread interrupted while sleeping\", ie);\n    +}\n<p> catch (ExpiredIteratorException ex) </p>\n{\n    +    LOG.debug(\"shardIterator for failedRecord \" + kinesisMessageId + \" has expired. Refreshing shardIterator\");\n    +    refreshShardIteratorForFailedRecord(kinesisMessageId);\n    +}\n<p> catch (ProvisionedThroughputExceededException pe) {<br/>\n    +    try </p>\n{\n    +LOG.debug(\"ProvisionedThroughputExceededException occured. Check your limits. Sleeping for 1 second.\", pe);\n    +Thread.sleep(1000);\n    +    }\n<p> catch (InterruptedException e) </p>\n{\n    +LOG.debug(\"Thread interrupted exception\", e);\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private void fetchNewRecords () {<br/>\n    +for (Map.Entry<String, LinkedList<Record>> entry : toEmitPerShard.entrySet()) {<br/>\n    +    String shardId = entry.getKey();<br/>\n    +    try {<br/>\n    +String shardIterator = shardIteratorPerShard.get(shardId);<br/>\n    +LOG.debug(\"Fetching new records for shard id :\" + shardId + \" using shardIterator \" + shardIterator + \" after sequence number \" +<br/>\n    +fetchedSequenceNumberPerShard.get(shardId));<br/>\n    +GetRecordsResult getRecordsResult = fetchRecords(shardIterator);<br/>\n    +if (getRecordsResult != null) {<br/>\n    +    List<Record> records = getRecordsResult.getRecords();<br/>\n    +    LOG.debug(\"Records size from fetchNewRecords is \" + records.size());<br/>\n    +    // update the shard iterator to next one in case this fetch does not give the message.<br/>\n    +    shardIteratorPerShard.put(shardId, getRecordsResult.getNextShardIterator());<br/>\n    +    if (records.size() == 0) </p>\n{\n    +LOG.debug(\"No records returned from kinesis. Hence sleeping for 1 second\");\n    +Thread.sleep(1000);\n    +    }\n<p> else </p>\n{\n    +entry.getValue().addAll(records);\n    +fetchedSequenceNumberPerShard.put(shardId, records.get(records.size() - 1).getSequenceNumber());\n    +    }\n<p>    +}<br/>\n    +    } catch (InterruptedException ie) </p>\n{\n    +LOG.debug(\"Thread interrupted while sleeping\", ie);\n    +    }\n<p> catch (ExpiredIteratorException ex) </p>\n{\n    +LOG.debug(\"shardIterator for shardId \" + shardId + \" has expired. Refreshing shardIterator\");\n    +refreshShardIteratorForNewRecords(shardId);\n    +    }\n<p> catch (ProvisionedThroughputExceededException pe) {<br/>\n    +try </p>\n{\n    +    LOG.debug(\"ProvisionedThroughputExceededException occured. Check your limits. Sleeping for 1 second.\", pe);\n    +    Thread.sleep(1000);\n    +}\n<p> catch (InterruptedException e) </p>\n{\n    +    LOG.debug(\"Thread interrupted exception\", e);\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private GetRecordsResult fetchRecords (String shardIterator) </p>\n{\n    +List<Record> records = new ArrayList<>();\n    +GetRecordsRequest getRecordsRequest = new GetRecordsRequest();\n    +getRecordsRequest.setShardIterator(shardIterator);\n    +getRecordsRequest.setLimit(config.getKinesisConnectionInfo().getRecordsLimit());\n    +GetRecordsResult getRecordsResult = kinesisClient.getRecords(getRecordsRequest);\n    +return getRecordsResult;\n    +    }\n<p>    +<br/>\n    +    private List<Shard> getShards () {<br/>\n    +DescribeStreamRequest describeStreamRequest = new DescribeStreamRequest();<br/>\n    +describeStreamRequest.setStreamName(config.getStreamName());<br/>\n    +List<Shard> shards = new ArrayList<>();<br/>\n    +String exclusiveStartShardId = null;<br/>\n    +do {<br/>\n    +    describeStreamRequest.setExclusiveStartShardId(exclusiveStartShardId);<br/>\n    +    DescribeStreamResult describeStreamResult = kinesisClient.describeStream(describeStreamRequest);<br/>\n    +    shards.addAll(describeStreamResult.getStreamDescription().getShards());<br/>\n    +    if (describeStreamResult.getStreamDescription().getHasMoreShards() && shards.size() > 0) </p>\n{\n    +exclusiveStartShardId = shards.get(shards.size() - 1).getShardId();\n    +    }\n<p> else </p>\n{\n    +exclusiveStartShardId = null;\n    +    }\n<p>    +} while ( exclusiveStartShardId != null );<br/>\n    +LOG.info(\"Number of shards for stream \" + config.getStreamName() + \" are \" + shards.size());<br/>\n    +return shards;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void emitNewRecord (SpoutOutputCollector collector) {<br/>\n    +for (Map.Entry<String, LinkedList<Record>> entry: toEmitPerShard.entrySet()) {<br/>\n    +    String shardId = entry.getKey();<br/>\n    +    LinkedList<Record> listOfRecords = entry.getValue();<br/>\n    +    Record record;<br/>\n    +    while ((record = listOfRecords.pollFirst()) != null) {<br/>\n    +KinesisMessageId kinesisMessageId = new KinesisMessageId(config.getStreamName(), shardId, record.getSequenceNumber());<br/>\n    +if (emitRecord(collector, record, kinesisMessageId)) </p>\n{\n    +   return;\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean emitFailedRecord (SpoutOutputCollector collector, KinesisMessageId kinesisMessageId) {<br/>\n    +if (!failedandFetchedRecords.containsKey(kinesisMessageId)) </p>\n{\n    +    return false;\n    +}\n<p>    +return emitRecord(collector, failedandFetchedRecords.get(kinesisMessageId), kinesisMessageId);<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean emitRecord (SpoutOutputCollector collector, Record record, KinesisMessageId kinesisMessageId) {<br/>\n    +boolean result = false;<br/>\n    +List<Object> tuple = config.getRecordToTupleMapper().getTuple(record);<br/>\n    +// if a record is returned put the sequence number in the emittedPerShard to tie back with ack or fail<br/>\n    +if (tuple != null && tuple.size() > 0) {<br/>\n    +    collector.emit(tuple, kinesisMessageId);<br/>\n    +    if (!emittedPerShard.containsKey(kinesisMessageId.getShardId())) </p>\n{\n    +emittedPerShard.put(kinesisMessageId.getShardId(), new TreeSet<BigInteger>());\n    +    }\n<p>    +    emittedPerShard.get(kinesisMessageId.getShardId()).add(new BigInteger(record.getSequenceNumber()));<br/>\n    +    result = true;<br/>\n    +} else </p>\n{\n    +    // ack to not process the record again on restart and move on to next message\n    +    LOG.debug(\"Record \" + record + \" did not return a tuple to emit. Hence acking it\");\n    +    ack(kinesisMessageId);\n    +}\n<p>    +return result;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean shouldCommit () </p>\n{\n    +return (System.currentTimeMillis() - lastCommitTime >= config.getZkInfo().getCommitIntervalMs());\n    +    }\n<p>    +<br/>\n    +    private void initializeFetchedSequenceNumbers () {<br/>\n    +for (String shardId : toEmitPerShard.keySet()) {<br/>\n    +    Map<Object, Object> state = readState(getZkPath(shardId));<br/>\n    +    // if state found for this shard in zk, then set the sequence number in fetchedSequenceNumber<br/>\n    +    if (state != null) {<br/>\n    +Object committedSequenceNumber = state.get(\"committedSequenceNumber\");<br/>\n    +LOG.info(\"State read is committedSequenceNumber: \" + committedSequenceNumber + \" shardId:\" + shardId);<br/>\n    +if (committedSequenceNumber != null) </p>\n{\n    +    fetchedSequenceNumberPerShard.put(shardId, (String) committedSequenceNumber);\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private void refreshShardIteratorsForNewRecords () {<br/>\n    +for (String shardId: toEmitPerShard.keySet()) </p>\n{\n    +    refreshShardIteratorForNewRecords(shardId);\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    private void refreshShardIteratorForNewRecords (String shardId) {<br/>\n    +String shardIterator = null;<br/>\n    +String lastFetchedSequenceNumber = fetchedSequenceNumberPerShard.get(shardId);<br/>\n    +ShardIteratorType shardIteratorType = (lastFetchedSequenceNumber == null ? config.getShardIteratorType() : ShardIteratorType<br/>\n    +.AFTER_SEQUENCE_NUMBER);<br/>\n    +// Set the shard iterator for last fetched sequence number to start from correct position in shard<br/>\n    +shardIterator = this.getShardIterator(shardId, shardIteratorType, lastFetchedSequenceNumber, config.getTimestamp());<br/>\n    +if (shardIterator != null && !shardIterator.isEmpty()) </p>\n{\n    +    LOG.debug(\"Refreshing shard iterator for new records for shardId \" + shardId + \" with shardIterator \" + shardIterator);\n    +    shardIteratorPerShard.put(shardId, shardIterator);\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    private void refreshShardIteratorForFailedRecord (KinesisMessageId kinesisMessageId) {<br/>\n    +String shardIterator = null;<br/>\n    +// Set the shard iterator for last fetched sequence number to start from correct position in shard<br/>\n    +shardIterator = this.getShardIterator(kinesisMessageId.getShardId(), ShardIteratorType.AT_SEQUENCE_NUMBER, kinesisMessageId.getSequenceNumber(), null);<br/>\n    +if (shardIterator != null && !shardIterator.isEmpty()) </p>\n{\n    +    LOG.debug(\"Refreshing shard iterator for failed records for message \" + kinesisMessageId + \" with shardIterator \" + shardIterator);\n    +    shardIteratorPerFailedMessage.put(kinesisMessageId, shardIterator);\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    private String getShardIterator (String shardId, ShardIteratorType shardIteratorType, String sequenceNumber, Date timestamp) {<br/>\n    +String shardIterator = \"\";<br/>\n    +try {<br/>\n    +    GetShardIteratorRequest getShardIteratorRequest = new GetShardIteratorRequest();<br/>\n    +    getShardIteratorRequest.setStreamName(config.getStreamName());<br/>\n    +    getShardIteratorRequest.setShardId(shardId);<br/>\n    +    getShardIteratorRequest.setShardIteratorType(shardIteratorType);<br/>\n    +    if (shardIteratorType.equals(ShardIteratorType.AFTER_SEQUENCE_NUMBER) || shardIteratorType.equals(ShardIteratorType.AT_SEQUENCE_NUMBER)) </p>\n{\n    +getShardIteratorRequest.setStartingSequenceNumber(sequenceNumber);\n    +    }\n<p> else if (shardIteratorType.equals(ShardIteratorType.AT_TIMESTAMP)) </p>\n{\n    +getShardIteratorRequest.setTimestamp(timestamp);\n    +    }\n<p>    +    GetShardIteratorResult getShardIteratorResult = kinesisClient.getShardIterator(getShardIteratorRequest);<br/>\n    +    if (getShardIteratorResult != null) </p>\n{\n    +shardIterator = getShardIteratorResult.getShardIterator();\n    +    }\n<p>    +} catch (Exception e) </p>\n{\n    +    LOG.debug(\"Exception occured while getting shardIterator for shard \" + shardId + \" shardIteratorType \" + shardIteratorType + \" sequence number \" +\n    +    sequenceNumber + \" timestamp \" + timestamp, e);\n    +}\n<p>    +LOG.debug(\"Returning shardIterator \" + shardIterator + \" for shardId \" + shardId + \" shardIteratorType \" + shardIteratorType + \" sequenceNumber \" +<br/>\n    +sequenceNumber + \" timestamp\" + timestamp);<br/>\n    +return shardIterator;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Long getUncommittedRecordsCount () {<br/>\n    +Long result = 0L;<br/>\n    +for (Map.Entry<String, TreeSet<BigInteger>> emitted: emittedPerShard.entrySet()) </p>\n{\n    +    result += emitted.getValue().size();\n    +}\n<p>    +for (Map.Entry<String, TreeSet<BigInteger>> acked: ackedPerShard.entrySet()) </p>\n{\n    +    result += acked.getValue().size();\n    +}\n<p>    +for (Map.Entry<String, TreeSet<BigInteger>> failed: failedPerShard.entrySet()) </p>\n{\n    +    result += failed.getValue().size();\n    +}\n<p>    +LOG.debug(\"Returning uncommittedRecordsCount as \" + result);<br/>\n    +return result;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean shouldFetchNewRecords () {<br/>\n    +// check to see if any shard has already fetched records waiting to be emitted, in which case dont fetch more<br/>\n    +boolean fetchRecords = true;<br/>\n    +for (Map.Entry<String, LinkedList<Record>> entry: toEmitPerShard.entrySet()) {<br/>\n    +    if (!entry.getValue().isEmpty()) </p>\n{\n    +fetchRecords = false;\n    +break;\n    +    }\n<p>    +}<br/>\n    +return fetchRecords;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void initializeCurator () </p>\n{\n    +ZkInfo zkInfo = config.getZkInfo();\n    +curatorFramework = CuratorFrameworkFactory.newClient(zkInfo.getZkUrl(), zkInfo.getSessionTimeoutMs(), zkInfo.getConnectionTimeoutMs(), new\n    +RetryNTimes(zkInfo.getRetryAttempts(), zkInfo.getRetryIntervalMs()));\n    +curatorFramework.start();\n    +    }\n<p>    +<br/>\n    +    private void initializeKinesisClient () </p>\n{\n    +kinesisClient = new AmazonKinesisClient(config.getKinesisConnectionInfo().getCredentialsProvider(), config.getKinesisConnectionInfo().getClientConfiguration());\n    +kinesisClient.setRegion(Region.getRegion(config.getKinesisConnectionInfo().getRegion()));\n    +    }\n<p>    +<br/>\n    +    private void shutdownCurator () </p>\n{\n    +curatorFramework.close();\n    +    }\n<p>    +<br/>\n    +    private void shutdownKinesisClient () </p>\n{\n    +kinesisClient.shutdown();\n    +    }\n<p>    +<br/>\n    +}<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    This is big file thats doing lot of things. We should some of these methods into Utils class or something  like zk related methods into its own class.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907835/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907838","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907838","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907838,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4Mzg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:45:24Z","updated_at":"2025-01-24T16:18:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72300543\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72300543</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ZkInfo.java &#8212;<br/>\n    @@ -0,0 +1,153 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +<br/>\n    +public class ZkInfo implements Serializable {<br/>\n    +    // comma separated list of zk connect strings to connect to zookeeper e.g. localhost:2181<br/>\n    +    private final String zkUrl;<br/>\n    +    // zk node under which to commit the sequence number of messages. e.g. /committed_sequence_numbers<br/>\n    +    private final String zkNode;<br/>\n    +    // zk session timeout in milliseconds<br/>\n    +    private final Integer sessionTimeoutMs;<br/>\n    +    // zk connection timeout in milliseconds<br/>\n    +    private final Integer connectionTimeoutMs;<br/>\n    +    // interval at which to commit offsets to zk in milliseconds<br/>\n    +    private final Long commitIntervalMs;<br/>\n    +    // number of retry attempts for zk<br/>\n    +    private final Integer retryAttempts;<br/>\n    +    // time to sleep between retries in milliseconds<br/>\n    +    private final Integer retryIntervalMs;<br/>\n    +<br/>\n    +    /**<br/>\n    +     * Default constructor that uses defaults for a local setup<br/>\n    +     */<br/>\n    +    public ZkInfo () {<br/>\n    +this(\"localhost:2181\", \"/kinesisOffsets\", 20000, 15000, 10000L, 3, 2000);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I think this is useful for testing but I can see users tripping over this <img class=\"emoticon\" src=\"https://issues.apache.org/jira/images/icons/emoticons/smile.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/> so can we remove this.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907838/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907842","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907842","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907842,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4NDI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:45:44Z","updated_at":"2025-01-24T16:18:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72300622\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72300622</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ZkInfo.java &#8212;<br/>\n    @@ -0,0 +1,153 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +<br/>\n    +public class ZkInfo implements Serializable {<br/>\n    +    // comma separated list of zk connect strings to connect to zookeeper e.g. localhost:2181<br/>\n    +    private final String zkUrl;<br/>\n    +    // zk node under which to commit the sequence number of messages. e.g. /committed_sequence_numbers<br/>\n    +    private final String zkNode;<br/>\n    +    // zk session timeout in milliseconds<br/>\n    +    private final Integer sessionTimeoutMs;<br/>\n    +    // zk connection timeout in milliseconds<br/>\n    +    private final Integer connectionTimeoutMs;<br/>\n    +    // interval at which to commit offsets to zk in milliseconds<br/>\n    +    private final Long commitIntervalMs;<br/>\n    +    // number of retry attempts for zk<br/>\n    +    private final Integer retryAttempts;<br/>\n    +    // time to sleep between retries in milliseconds<br/>\n    +    private final Integer retryIntervalMs;<br/>\n    +<br/>\n    +    /**<br/>\n    +     * Default constructor that uses defaults for a local setup<br/>\n    +     */<br/>\n    +    public ZkInfo () </p>\n{\n    +this(\"localhost:2181\", \"/kinesisOffsets\", 20000, 15000, 10000L, 3, 2000);\n    +    }\n<p>    +<br/>\n    +    public ZkInfo (String zkUrl, String zkNode, Integer sessionTimeoutMs, Integer connectionTimeoutMs, Long commitIntervalMs, Integer retryAttempts, Integer<br/>\n    +    retryIntervalMs) </p>\n{\n    +this.zkUrl = zkUrl;\n    +this.zkNode = zkNode;\n    +this.sessionTimeoutMs = sessionTimeoutMs;\n    +this.connectionTimeoutMs = connectionTimeoutMs;\n    +this.commitIntervalMs = commitIntervalMs;\n    +this.retryAttempts = retryAttempts;\n    +this.retryIntervalMs = retryIntervalMs;\n    +validate();\n    +    }\n<p>    +<br/>\n    +    public String getZkUrl() </p>\n{\n    +return zkUrl;\n    +    }\n<p>    +<br/>\n    +    public String getZkNode() </p>\n{\n    +return zkNode;\n    +    }\n<p>    +<br/>\n    +    public Integer getSessionTimeoutMs() </p>\n{\n    +return sessionTimeoutMs;\n    +    }\n<p>    +<br/>\n    +    public Integer getConnectionTimeoutMs() </p>\n{\n    +return connectionTimeoutMs;\n    +    }\n<p>    +<br/>\n    +    public Long getCommitIntervalMs() </p>\n{\n    +return commitIntervalMs;\n    +    }\n<p>    +<br/>\n    +    public Integer getRetryAttempts() </p>\n{\n    +return retryAttempts;\n    +    }\n<p>    +<br/>\n    +    public Integer getRetryIntervalMs() </p>\n{\n    +return retryIntervalMs;\n    +    }\n<p>    +<br/>\n    +    private void validate () {<br/>\n    +<br/>\n    +if (zkUrl == null || zkUrl.length() < 1) </p>\n{\n    +    throw new IllegalArgumentException(\"zkUrl must be specified to connect to zookeeper\");\n    +}\n<p>    +if (zkNode == null || zkNode.length() < 1) </p>\n{\n    +    throw new IllegalArgumentException(\"zkNode must be specified\");\n    +}\n<p>    +checkPositive(sessionTimeoutMs, \"sessionTimeoutMs\");<br/>\n    +checkPositive(connectionTimeoutMs, \"connectionTimeoutMs\");<br/>\n    +checkPositive(commitIntervalMs, \"commitIntervalMs\");<br/>\n    +checkPositive(retryAttempts, \"retryAttempts\");<br/>\n    +checkPositive(retryIntervalMs, \"retryIntervalMs\");<br/>\n    +    }<br/>\n    +<br/>\n    +    private void checkPositive (Integer argument, String name) {<br/>\n    +if (argument == null && argument <= 0) </p>\n{\n    +    throw new IllegalArgumentException(name + \" must be positive\");\n    +}<br/>\n    +    }<br/>\n    +    private void checkPositive (Long argument, String name) {<br/>\n    +if (argument == null && argument <= 0) {    +    throw new IllegalArgumentException(name + \" must be positive\");    +}\n<p>    +    }<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public String toString() {<br/>\n    +return \"ZkInfo</p>\n{\" +\n    +\"zkUrl='\" + zkUrl + '\\'' +\n    +\", zkNode='\" + zkNode + '\\'' +\n    +\", sessionTimeoutMs=\" + sessionTimeoutMs +\n    +\", connectionTimeoutMs=\" + connectionTimeoutMs +\n    +\", commitIntervalMs=\" + commitIntervalMs +\n    +\", retryAttempts=\" + retryAttempts +\n    +\", retryIntervalMs=\" + retryIntervalMs +\n    +'}\n<p>';<br/>\n    +    }<br/>\n    +<br/>\n    +    @Override<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    remove these as well.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907842/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/235348075","html_url":"https://github.com/apache/storm/pull/1586#issuecomment-235348075","issue_url":"https://api.github.com/repos/apache/storm/issues/1586","id":235348075,"node_id":"MDEyOklzc3VlQ29tbWVudDIzNTM0ODA3NQ==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:46:45Z","updated_at":"2016-07-26T17:46:45Z","author_association":"CONTRIBUTOR","body":"@priyank5485 looks great!. Mostly nit-picks. I'll go over the retry handle one more time and add any comments if needed. \n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/235348075/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907850","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907850","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907850,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4NTA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:46:46Z","updated_at":"2025-01-24T16:18:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586</a></p>\n\n<p>    @priyank5485 looks great!. Mostly nit-picks. I'll go over the retry handle one more time and add any comments if needed. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907850/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907855","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907855","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907855,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4NTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:57:55Z","updated_at":"2025-01-24T16:18:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72302997\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72302997</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisConnectionInfo.java &#8212;<br/>\n    @@ -0,0 +1,137 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.ClientConfiguration;<br/>\n    +import com.amazonaws.auth.AWSCredentialsProvider;<br/>\n    +import com.amazonaws.regions.Regions;<br/>\n    +import com.esotericsoftware.kryo.Kryo;<br/>\n    +import com.esotericsoftware.kryo.io.Input;<br/>\n    +import com.esotericsoftware.kryo.io.Output;<br/>\n    +import org.objenesis.strategy.StdInstantiatorStrategy;<br/>\n    +<br/>\n    +import java.io.ByteArrayInputStream;<br/>\n    +import java.io.ByteArrayOutputStream;<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Arrays;<br/>\n    +<br/>\n    +public class KinesisConnectionInfo implements Serializable {<br/>\n    +    private final byte[] serializedKinesisCredsProvider;<br/>\n    +    private final byte[] serializedkinesisClientConfig;<br/>\n    +    private final Integer recordsLimit;<br/>\n    +    private final Regions region;<br/>\n    +<br/>\n    +    private transient AWSCredentialsProvider credentialsProvider;<br/>\n    +    private transient ClientConfiguration clientConfiguration;<br/>\n    +<br/>\n    +    /**<br/>\n    +     *<br/>\n    +     * @param credentialsProvider implementation to provide credentials to connect to kinesis<br/>\n    +     * @param clientConfiguration client configuration to pass to kinesis client<br/>\n    +     * @param region region to connect to<br/>\n    +     * @param recordsLimit max records to be fetched in a getRecords request to kinesis<br/>\n    +     */<br/>\n    +    public KinesisConnectionInfo (AWSCredentialsProvider credentialsProvider, ClientConfiguration clientConfiguration, Regions region, Integer recordsLimit) {<br/>\n    +if (recordsLimit == null || recordsLimit <= 0) </p>\n{\n    +    throw new IllegalArgumentException(\"recordsLimit has to be a positive integer\");\n    +}\n<p>    +if (region == null) </p>\n{\n    +    throw new IllegalArgumentException(\"region cannot be null\");\n    +}\n<p>    +serializedKinesisCredsProvider = getKryoSerializedBytes(credentialsProvider);<br/>\n    +serializedkinesisClientConfig = getKryoSerializedBytes(clientConfiguration);<br/>\n    +this.recordsLimit = recordsLimit;<br/>\n    +this.region = region;<br/>\n    +<br/>\n    +this.credentialsProvider = null;<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Will change it</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907855/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907859","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907859","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907859,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4NTk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T17:58:04Z","updated_at":"2025-01-24T16:18:53Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72303034\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72303034</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisConnectionInfo.java &#8212;<br/>\n    @@ -0,0 +1,137 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.ClientConfiguration;<br/>\n    +import com.amazonaws.auth.AWSCredentialsProvider;<br/>\n    +import com.amazonaws.regions.Regions;<br/>\n    +import com.esotericsoftware.kryo.Kryo;<br/>\n    +import com.esotericsoftware.kryo.io.Input;<br/>\n    +import com.esotericsoftware.kryo.io.Output;<br/>\n    +import org.objenesis.strategy.StdInstantiatorStrategy;<br/>\n    +<br/>\n    +import java.io.ByteArrayInputStream;<br/>\n    +import java.io.ByteArrayOutputStream;<br/>\n    +import java.io.Serializable;<br/>\n    +import java.util.Arrays;<br/>\n    +<br/>\n    +public class KinesisConnectionInfo implements Serializable {<br/>\n    +    private final byte[] serializedKinesisCredsProvider;<br/>\n    +    private final byte[] serializedkinesisClientConfig;<br/>\n    +    private final Integer recordsLimit;<br/>\n    +    private final Regions region;<br/>\n    +<br/>\n    +    private transient AWSCredentialsProvider credentialsProvider;<br/>\n    +    private transient ClientConfiguration clientConfiguration;<br/>\n    +<br/>\n    +    /**<br/>\n    +     *<br/>\n    +     * @param credentialsProvider implementation to provide credentials to connect to kinesis<br/>\n    +     * @param clientConfiguration client configuration to pass to kinesis client<br/>\n    +     * @param region region to connect to<br/>\n    +     * @param recordsLimit max records to be fetched in a getRecords request to kinesis<br/>\n    +     */<br/>\n    +    public KinesisConnectionInfo (AWSCredentialsProvider credentialsProvider, ClientConfiguration clientConfiguration, Regions region, Integer recordsLimit) {<br/>\n    +if (recordsLimit == null || recordsLimit <= 0) </p>\n{\n    +    throw new IllegalArgumentException(\"recordsLimit has to be a positive integer\");\n    +}\n<p>    +if (region == null) </p>\n{\n    +    throw new IllegalArgumentException(\"region cannot be null\");\n    +}\n<p>    +serializedKinesisCredsProvider = getKryoSerializedBytes(credentialsProvider);<br/>\n    +serializedkinesisClientConfig = getKryoSerializedBytes(clientConfiguration);<br/>\n    +this.recordsLimit = recordsLimit;<br/>\n    +this.region = region;<br/>\n    +<br/>\n    +this.credentialsProvider = null;<br/>\n    +this.clientConfiguration = null;<br/>\n    +    }<br/>\n    +<br/>\n    +    public Integer getRecordsLimit() </p>\n{\n    +return recordsLimit;\n    +    }\n<p>    +<br/>\n    +    public AWSCredentialsProvider getCredentialsProvider() {<br/>\n    +if (credentialsProvider == null) </p>\n{\n    +    credentialsProvider = (AWSCredentialsProvider) this.getKryoDeserializedObject(serializedKinesisCredsProvider);\n    +}\n<p>    +return credentialsProvider;<br/>\n    +    }<br/>\n    +<br/>\n    +    public ClientConfiguration getClientConfiguration() {<br/>\n    +if (clientConfiguration == null) </p>\n{\n    +    clientConfiguration = (ClientConfiguration) this.getKryoDeserializedObject(serializedkinesisClientConfig);\n    +}\n<p>    +return clientConfiguration;<br/>\n    +    }<br/>\n    +<br/>\n    +    public Regions getRegion() </p>\n{\n    +return region;\n    +    }\n<p>    +<br/>\n    +    private byte[] getKryoSerializedBytes (final Object obj) </p>\n{\n    +final Kryo kryo = new Kryo();\n    +final ByteArrayOutputStream os = new ByteArrayOutputStream();\n    +final Output output = new Output(os);\n    +kryo.setInstantiatorStrategy(new StdInstantiatorStrategy());\n    +kryo.writeClassAndObject(output, obj);\n    +output.flush();\n    +return os.toByteArray();\n    +    }\n<p>    +<br/>\n    +    private Object getKryoDeserializedObject (final byte[] ser) </p>\n{\n    +final Kryo kryo = new Kryo();\n    +final Input input = new Input(new ByteArrayInputStream(ser));\n    +kryo.setInstantiatorStrategy(new StdInstantiatorStrategy());\n    +return kryo.readClassAndObject(input);\n    +    }\n<p>    +<br/>\n    +    @Override<br/>\n    +    public boolean equals(Object o) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Will change it</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907859/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928409","html_url":"https://github.com/apache/storm/issues/5761#issuecomment-2612928409","issue_url":"https://api.github.com/repos/apache/storm/issues/5761","id":2612928409,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjg0MDk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:02:57Z","updated_at":"2025-01-24T16:29:02Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1583#discussion_r72303978\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1583#discussion_r72303978</a></p>\n\n<p>    &#8212; Diff: external/storm-druid/src/main/java/org/apache/storm/druid/bolt/DruidBeamBolt.java &#8212;<br/>\n    @@ -0,0 +1,115 @@<br/>\n    +/*<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing,<br/>\n    + * software distributed under the License is distributed on an<br/>\n    + * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<br/>\n    + * KIND, either express or implied.  See the License for the<br/>\n    + * specific language governing permissions and limitations<br/>\n    + * under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.druid.bolt;<br/>\n    +<br/>\n    +import com.metamx.tranquility.tranquilizer.MessageDroppedException;<br/>\n    +import com.metamx.tranquility.tranquilizer.Tranquilizer;<br/>\n    +import com.twitter.util.Future;<br/>\n    +import com.twitter.util.FutureEventListener;<br/>\n    +import org.apache.storm.task.OutputCollector;<br/>\n    +import org.apache.storm.task.TopologyContext;<br/>\n    +import org.apache.storm.topology.OutputFieldsDeclarer;<br/>\n    +import org.apache.storm.topology.base.BaseRichBolt;<br/>\n    +import org.apache.storm.tuple.Tuple;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.util.Map;<br/>\n    +<br/>\n    +/**<br/>\n    + * Basic bolt implementation for storing data to Druid datastore.<br/>\n    + * <p/><br/>\n    + * This implementation uses Druid's Tranquility library (<a href=\"https://github.com/druid-io/tranquility\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/druid-io/tranquility</a>)<br/>\n    + * to send to druid store.<br/>\n    + * Some of the concepts are borrowed from Tranquility storm connector implementation.<br/>\n    + * (<a href=\"https://github.com/druid-io/tranquility/blob/master/docs/storm.md\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/druid-io/tranquility/blob/master/docs/storm.md</a>)<br/>\n    + *<br/>\n    + * This Bolt expects to receive tuples in which the zeroth element is your event type.<br/>\n    + * <p/><br/>\n    + *<br/>\n    + */<br/>\n    +public class DruidBeamBolt<E> extends BaseRichBolt {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(DruidBeamBolt.class);<br/>\n    +<br/>\n    +    private volatile  OutputCollector collector;<br/>\n    +    private DruidBeamFactory<E> beamFactory = null;<br/>\n    +    private int batchSize;<br/>\n    +    private Tranquilizer<E> tranquilizer = null;<br/>\n    +<br/>\n    +    public DruidBeamBolt(DruidBeamFactory<E> beamFactory) </p>\n{\n    +this(beamFactory, 2000);\n    +    }\n<p>    +<br/>\n    +    public DruidBeamBolt(DruidBeamFactory<E> beamFactory, int batchSize) </p>\n{\n    +this.beamFactory = beamFactory;\n    +this.batchSize = batchSize;\n    +    }\n<p>    +<br/>\n    +    @Override<br/>\n    +    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) </p>\n{\n    +this.collector = collector;\n    +tranquilizer = Tranquilizer.create(\n    +beamFactory.makeBeam(stormConf, context),\n    +batchSize,\n    +Tranquilizer.DefaultMaxPendingBatches(),\n    +Tranquilizer.DefaultLingerMillis());\n    +this.tranquilizer.start();\n    +\n    +    }\n<p>    +<br/>\n    +    @Override<br/>\n    +    public void execute(final Tuple tuple) {<br/>\n    +      Future future = tranquilizer.send((E)tuple.getValue(0));<br/>\n    +      future.addEventListener(new FutureEventListener() {<br/>\n    +  @Override<br/>\n    +  public void onFailure(Throwable cause) {<br/>\n    +      if(cause instanceof MessageDroppedException) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I am +1 on @satishd recommendation. Atleast we can drive through configuration i.e druid can discard messages and we can provide discard stream of sorts via config if users configures enableDiscardStream and discardStream=\"druid-discard-stream\" than you write the tuples there. Logging on druid is great but this will allow users to act on them immediately.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928409/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928413","html_url":"https://github.com/apache/storm/issues/5761#issuecomment-2612928413","issue_url":"https://api.github.com/repos/apache/storm/issues/5761","id":2612928413,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjg0MTM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:05:21Z","updated_at":"2025-01-24T16:29:02Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1583#discussion_r72304436\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1583#discussion_r72304436</a></p>\n\n<p>    &#8212; Diff: external/storm-druid/pom.xml &#8212;<br/>\n    @@ -0,0 +1,88 @@<br/>\n    +<?xml version=\"1.0\" encoding=\"UTF-8\"?><br/>\n    +<!--<br/>\n    + Licensed to the Apache Software Foundation (ASF) under one or more<br/>\n    + contributor license agreements.  See the NOTICE file distributed with<br/>\n    + this work for additional information regarding copyright ownership.<br/>\n    + The ASF licenses this file to You under the Apache License, Version 2.0<br/>\n    + (the \"License\"); you may not use this file except in compliance with<br/>\n    + the License.  You may obtain a copy of the License at<br/>\n    +<br/>\n    +     <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    +<br/>\n    + Unless required by applicable law or agreed to in writing, software<br/>\n    + distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + See the License for the specific language governing permissions and<br/>\n    + limitations under the License.<br/>\n    +--><br/>\n    +<br/>\n    +<project xmlns=\"http://maven.apache.org/POM/4.0.0\"<br/>\n    + xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"<br/>\n    + xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 <a href=\"http://maven.apache.org/xsd/maven-4.0.0.xsd\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://maven.apache.org/xsd/maven-4.0.0.xsd</a>\"><br/>\n    +    <parent><br/>\n    +<artifactId>storm</artifactId><br/>\n    +<groupId>org.apache.storm</groupId><br/>\n    +<version>2.0.0-SNAPSHOT</version><br/>\n    +<relativePath>../../pom.xml</relativePath><br/>\n    +    </parent><br/>\n    +    <modelVersion>4.0.0</modelVersion><br/>\n    +<br/>\n    +    <artifactId>storm-druid</artifactId><br/>\n    +<br/>\n    +    <dependencies><br/>\n    +<dependency><br/>\n    +    <groupId>org.apache.storm</groupId><br/>\n    +    <artifactId>storm-core</artifactId><br/>\n    +    <version>${project.version}</version><br/>\n    +    <scope>provided</scope><br/>\n    +</dependency><br/>\n    +<dependency><br/>\n    +    <groupId>io.druid</groupId><br/>\n    +    <artifactId>tranquility-core_2.11</artifactId><br/>\n    +    <version>0.8.2</version><br/>\n    +</dependency><br/>\n    +<dependency><br/>\n    +    <groupId>org.scala-lang</groupId><br/>\n    +    <artifactId>scala-library</artifactId><br/>\n    +    <version>2.11.8</version><br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I take back the earlier comment. sorry about that,  the dependencies shouldn't be provided as we don't want to package them into the druid jar.<br/>\n    also can we drive these versions from parent pom.xml so that we can configure better. Also make the scala version 2.10.5 unless druid recommends 2.11.8.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928413/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928419","html_url":"https://github.com/apache/storm/issues/5761#issuecomment-2612928419","issue_url":"https://api.github.com/repos/apache/storm/issues/5761","id":2612928419,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjg0MTk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:06:58Z","updated_at":"2025-01-24T16:29:02Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1583#discussion_r72304747\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1583#discussion_r72304747</a></p>\n\n<p>    &#8212; Diff: external/storm-druid/src/main/java/org/apache/storm/druid/trident/DruidBeamState.java &#8212;<br/>\n    @@ -0,0 +1,73 @@<br/>\n    +/*<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing,<br/>\n    + * software distributed under the License is distributed on an<br/>\n    + * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<br/>\n    + * KIND, either express or implied.  See the License for the<br/>\n    + * specific language governing permissions and limitations<br/>\n    + * under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.druid.trident;<br/>\n    +<br/>\n    +import com.metamx.tranquility.beam.Beam;<br/>\n    +import com.twitter.util.Await;<br/>\n    +import org.apache.storm.trident.state.State;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import scala.collection.JavaConversions;<br/>\n    +<br/>\n    +import java.util.List;<br/>\n    +<br/>\n    +<br/>\n    +/**<br/>\n    + * Trident </p>\n{@link State}\n<p> implementation for Druid.<br/>\n    + */<br/>\n    +public class DruidBeamState<E> implements State  {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(DruidBeamState.class);<br/>\n    +<br/>\n    +    Beam<E> beam = null;<br/>\n    +<br/>\n    +    public DruidBeamState(Beam<E> beam) </p>\n{\n    +this.beam = beam;\n    +    }\n<p>    +<br/>\n    +    public void send(List<E> events ) {<br/>\n    +try </p>\n{\n    +    LOG.info(\"Sending %d events\", events.size());\n    +    Await.result(beam.sendBatch(JavaConversions.collectionAsScalaIterable(events).toList()));\n    +}\n<p> catch (Exception e) {<br/>\n    +    final String errorMsg = \"Failed in writing messages to Druid\";<br/>\n    +    LOG.error(errorMsg, e);<br/>\n    +    throw new RuntimeException(errorMsg);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    do we want to throw the run-time exception. What if this is a temporary failure and on a re-try we might succeed in those cases throwing run time exception will kill the worker JVM itself.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928419/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928422","html_url":"https://github.com/apache/storm/issues/5761#issuecomment-2612928422","issue_url":"https://api.github.com/repos/apache/storm/issues/5761","id":2612928422,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjg0MjI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:07:20Z","updated_at":"2025-01-24T16:29:02Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1583#discussion_r72304830\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1583#discussion_r72304830</a></p>\n\n<p>    &#8212; Diff: external/storm-druid/src/main/java/org/apache/storm/druid/trident/DruidBeamState.java &#8212;<br/>\n    @@ -0,0 +1,73 @@<br/>\n    +/*<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing,<br/>\n    + * software distributed under the License is distributed on an<br/>\n    + * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<br/>\n    + * KIND, either express or implied.  See the License for the<br/>\n    + * specific language governing permissions and limitations<br/>\n    + * under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.druid.trident;<br/>\n    +<br/>\n    +import com.metamx.tranquility.beam.Beam;<br/>\n    +import com.twitter.util.Await;<br/>\n    +import org.apache.storm.trident.state.State;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import scala.collection.JavaConversions;<br/>\n    +<br/>\n    +import java.util.List;<br/>\n    +<br/>\n    +<br/>\n    +/**<br/>\n    + * Trident </p>\n{@link State}\n<p> implementation for Druid.<br/>\n    + */<br/>\n    +public class DruidBeamState<E> implements State  {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(DruidBeamState.class);<br/>\n    +<br/>\n    +    Beam<E> beam = null;<br/>\n    +<br/>\n    +    public DruidBeamState(Beam<E> beam) </p>\n{\n    +this.beam = beam;\n    +    }\n<p>    +<br/>\n    +    public void send(List<E> events ) {<br/>\n    +try </p>\n{\n    +    LOG.info(\"Sending %d events\", events.size());\n    +    Await.result(beam.sendBatch(JavaConversions.collectionAsScalaIterable(events).toList()));\n    +}\n<p> catch (Exception e) </p>\n{\n    +    final String errorMsg = \"Failed in writing messages to Druid\";\n    +    LOG.error(errorMsg, e);\n    +    throw new RuntimeException(errorMsg);\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    public void close() {<br/>\n    +try </p>\n{\n    +    Await.result(beam.close());\n    +}\n<p> catch (Exception e) {<br/>\n    +    final String errorMsg = \"Error while closing Druid beam client\";<br/>\n    +    LOG.error(errorMsg, e);<br/>\n    +    throw new RuntimeException(errorMsg);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    same as above. we shouldn't be throwing run-time exceptions when close is called.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928422/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928425","html_url":"https://github.com/apache/storm/issues/5761#issuecomment-2612928425","issue_url":"https://api.github.com/repos/apache/storm/issues/5761","id":2612928425,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjg0MjU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:08:03Z","updated_at":"2025-01-24T16:29:02Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1583#discussion_r72304984\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1583#discussion_r72304984</a></p>\n\n<p>    &#8212; Diff: external/storm-druid/src/main/java/org/apache/storm/druid/trident/DruidBeamState.java &#8212;<br/>\n    @@ -0,0 +1,73 @@<br/>\n    +/*<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing,<br/>\n    + * software distributed under the License is distributed on an<br/>\n    + * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<br/>\n    + * KIND, either express or implied.  See the License for the<br/>\n    + * specific language governing permissions and limitations<br/>\n    + * under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.druid.trident;<br/>\n    +<br/>\n    +import com.metamx.tranquility.beam.Beam;<br/>\n    +import com.twitter.util.Await;<br/>\n    +import org.apache.storm.trident.state.State;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import scala.collection.JavaConversions;<br/>\n    +<br/>\n    +import java.util.List;<br/>\n    +<br/>\n    +<br/>\n    +/**<br/>\n    + * Trident </p>\n{@link State}\n<p> implementation for Druid.<br/>\n    + */<br/>\n    +public class DruidBeamState<E> implements State  {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(DruidBeamState.class);<br/>\n    +<br/>\n    +    Beam<E> beam = null;<br/>\n    +<br/>\n    +    public DruidBeamState(Beam<E> beam) </p>\n{\n    +this.beam = beam;\n    +    }\n<p>    +<br/>\n    +    public void send(List<E> events ) {<br/>\n    +try </p>\n{\n    +    LOG.info(\"Sending %d events\", events.size());\n    +    Await.result(beam.sendBatch(JavaConversions.collectionAsScalaIterable(events).toList()));\n    +}\n<p> catch (Exception e) </p>\n{\n    +    final String errorMsg = \"Failed in writing messages to Druid\";\n    +    LOG.error(errorMsg, e);\n    +    throw new RuntimeException(errorMsg);\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    public void close() {<br/>\n    +try </p>\n{\n    +    Await.result(beam.close());\n    +}\n<p> catch (Exception e) </p>\n{\n    +    final String errorMsg = \"Error while closing Druid beam client\";\n    +    LOG.error(errorMsg, e);\n    +    throw new RuntimeException(errorMsg);\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public void beginCommit(Long txid) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    @arunmahadevan I remember you recommended that we should make all trident states to implement beginCommit. Can you add details if we can do this here.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928425/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928430","html_url":"https://github.com/apache/storm/issues/5761#issuecomment-2612928430","issue_url":"https://api.github.com/repos/apache/storm/issues/5761","id":2612928430,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjg0MzA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:08:43Z","updated_at":"2025-01-24T16:29:03Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1583#discussion_r72305132\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1583#discussion_r72305132</a></p>\n\n<p>    &#8212; Diff: external/storm-druid/src/test/java/org/apache/storm/druid/SampleDruidBeamFactoryImpl.java &#8212;<br/>\n    @@ -0,0 +1,116 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + * <p><br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + * <p><br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.druid;<br/>\n    +<br/>\n    +import com.google.common.collect.ImmutableList;<br/>\n    +import com.metamx.common.Granularity;<br/>\n    +import com.metamx.tranquility.beam.Beam;<br/>\n    +import com.metamx.tranquility.beam.ClusteredBeamTuning;<br/>\n    +import com.metamx.tranquility.druid.DruidBeams;<br/>\n    +import com.metamx.tranquility.druid.DruidDimensions;<br/>\n    +import com.metamx.tranquility.druid.DruidLocation;<br/>\n    +import com.metamx.tranquility.druid.DruidRollup;<br/>\n    +import com.metamx.tranquility.typeclass.Timestamper;<br/>\n    +import io.druid.data.input.impl.TimestampSpec;<br/>\n    +import io.druid.granularity.QueryGranularities;<br/>\n    +import io.druid.query.aggregation.AggregatorFactory;<br/>\n    +import io.druid.query.aggregation.CountAggregatorFactory;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.ExponentialBackoffRetry;<br/>\n    +import org.apache.storm.druid.bolt.DruidBeamFactory;<br/>\n    +import org.apache.storm.task.IMetricsContext;<br/>\n    +import org.joda.time.DateTime;<br/>\n    +import org.joda.time.Period;<br/>\n    +<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +<br/>\n    +/**<br/>\n    + * Druid bolt must be supplied with a BeamFactory. You can implement one of these using the<br/>\n    + * <span class=\"error\">&#91;DruidBeams builder&#39;s&#93;</span> (<a href=\"https://github.com/druid-io/tranquility/blob/master/core/src/main/scala/com/metamx/tranquility/druid/DruidBeams.scala\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/druid-io/tranquility/blob/master/core/src/main/scala/com/metamx/tranquility/druid/DruidBeams.scala</a>)<br/>\n    + * \"buildBeam()\" method. See the <span class=\"error\">&#91;Configuration documentation&#93;</span> (<a href=\"https://github.com/druid-io/tranquility/blob/master/docs/configuration.md\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/druid-io/tranquility/blob/master/docs/configuration.md</a>) for details.<br/>\n    + * For more details refer <span class=\"error\">&#91;Tranquility library&#93;</span> (<a href=\"https://github.com/druid-io/tranquility\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/druid-io/tranquility</a>) docs.<br/>\n    + */<br/>\n    +public class SampleDruidBeamFactoryImpl implements DruidBeamFactory<Map<String, Object>> {<br/>\n    +    Map<String, Object> factoryConf = null;<br/>\n    +<br/>\n    +<br/>\n    +    public SampleDruidBeamFactoryImpl(Map<String, Object> factoryConf) </p>\n{\n    +this.factoryConf = factoryConf; // This can be used to pass config values\n    +    }\n<p>    +<br/>\n    +    @Override<br/>\n    +    public Beam<Map<String, Object>> makeBeam(Map<?, ?> conf, IMetricsContext metrics) {<br/>\n    +<br/>\n    +<br/>\n    +final String indexService = \"druid/overlord\"; // Your overlord's druid.service<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    should we make these as configurable options ? and alos there is no leading / here </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928430/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907862","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907862","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907862,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4NjI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:09:04Z","updated_at":"2025-01-24T16:18:53Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72305189\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72305189</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}\n<p>    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) </p>\n{\n    +    fetchFailedRecords(failedMessageId);\n    +}\n<p>    +if (emitFailedRecord(collector, failedMessageId)) {<br/>\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);<br/>\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);<br/>\n    +    return;<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I thought about it but if i try to reduce the return statements it will create more if else statements. If its not a big issue we can keep as is.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907862/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907871","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907871","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907871,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4NzE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:10:03Z","updated_at":"2025-01-24T16:18:53Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72305349\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72305349</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}\n<p>    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) </p>\n{\n    +    fetchFailedRecords(failedMessageId);\n    +}\n<p>    +if (emitFailedRecord(collector, failedMessageId)) </p>\n{\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);\n    +    return;\n    +}\n<p> else </p>\n{\n    +    LOG.debug(\"failedMessageEmitted not called on retrier for \" + failedMessageId + \". This can happen a few times but should not happen \" +\n    +    \"infinitely\");\n    +}\n<p>    +    } else </p>\n{\n    +LOG.debug(\"failedPerShard does not contain \" + failedMessageId + \". This should never happen.\");\n    +    }\n<p>    +}<br/>\n    +LOG.debug(\"No failed record to emit for now. Hence will try to emit new records\");<br/>\n    +// if maximum uncommitted records count has reached, so dont emit any new records and return<br/>\n    +if (!(getUncommittedRecordsCount() < config.getMaxUncommittedRecords())) </p>\n{\n    +    LOG.debug(\"maximum uncommitted records count has reached. so not emitting any new records and returning\");\n    +    return;\n    +}\n<p>    +// early return as no shard is assigned - probably because number of executors > number of shards<br/>\n    +if (toEmitPerShard.isEmpty()) </p>\n{\n    +    LOG.debug(\"No shard is assigned to this task. Hence not emitting any tuple.\");\n    +    return;\n    +}\n<p>    +<br/>\n    +if (shouldFetchNewRecords()) </p>\n{\n    +    fetchNewRecords();\n    +}\n<p>    +emitNewRecord(collector);<br/>\n    +    }<br/>\n    +<br/>\n    +    void ack (KinesisMessageId kinesisMessageId) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I documented the logic in the commit method since thats where it writes to zookeeper. Let me know if that is not enough or if i should move it to somewhere else.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907871/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907877","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907877","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907877,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4Nzc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:10:38Z","updated_at":"2025-01-24T16:18:53Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72305457\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72305457</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/README.md &#8212;<br/>\n    @@ -0,0 +1,139 @@<br/>\n    +#Storm Kinesis Spout<br/>\n    +Provides core storm spout for consuming data from a stream in Amazon Kinesis Streams. It stores the sequence numbers that can be committed in zookeeper and <br/>\n    +starts consuming records after that sequence number on restart by default. Below is the code sample to create a sample topology that uses the spout. Each <br/>\n    +object used in configuring the spout is explained below. Ideally, the number of spout tasks should be equal to number of shards in kinesis. However each task <br/>\n    +can read from more than one shard.<br/>\n    +<br/>\n    +```java<br/>\n    +public class KinesisSpoutTopology {<br/>\n    +    public static void main (String args[]) throws InvalidTopologyException, AuthorizationException, AlreadyAliveException </p>\n{\n    +String topologyName = args[0];\n    +RecordToTupleMapper recordToTupleMapper = new TestRecordToTupleMapper();\n    +KinesisConnectionInfo kinesisConnectionInfo = new KinesisConnectionInfo(new CredentialsProviderChain(), new ClientConfiguration(), Regions.US_WEST_2,\n    +1000);\n    +org.apache.storm.kinesis.spout.Config config = new org.apache.storm.kinesis.spout.Config(args[1], ShardIteratorType.TRIM_HORIZON,\n    +recordToTupleMapper, new Date(), new ExponentialBackoffRetrier(), new ZkInfo(), kinesisConnectionInfo, 10000L);\n    +KinesisSpout kinesisSpout = new KinesisSpout(config);\n    +TopologyBuilder topologyBuilder = new TopologyBuilder();\n    +topologyBuilder.setSpout(\"spout\", kinesisSpout, 3);\n    +topologyBuilder.setBolt(\"bolt\", new KinesisBoltTest(), 1).shuffleGrouping(\"spout\");\n    +Config topologyConfig = new Config();\n    +topologyConfig.setDebug(true);\n    +topologyConfig.setNumWorkers(3);\n    +StormSubmitter.submitTopology(topologyName, topologyConfig, topologyBuilder.createTopology());\n    +    }\n<p>    +}<br/>\n    +```<br/>\n    +As you can see above the spout takes an object of Config in its constructor. The constructor of Config takes 8 objects as explained below.<br/>\n    +<br/>\n    +#### `String` streamName<br/>\n    +name of kinesis stream to consume data from<br/>\n    +<br/>\n    +#### `ShardIteratorType` shardIteratorType<br/>\n    +3 types are supported - TRIM_HORIZON(beginning of shard), LATEST and AT_TIMESTAMP. By default this argument is ignored if state for shards <br/>\n    +is found in zookeeper. Hence they will apply the first time a topology is started. If you want to use any of these in subsequent runs of the topology, you <br/>\n    +will need to clear the state of zookeeper node used for storing sequence numbers<br/>\n    +#### `RecordToTupleMapper` recordToTupleMapper<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Will change it</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907877/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928432","html_url":"https://github.com/apache/storm/issues/5761#issuecomment-2612928432","issue_url":"https://api.github.com/repos/apache/storm/issues/5761","id":2612928432,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5Mjg0MzI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:11:28Z","updated_at":"2025-01-24T16:29:03Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1583#discussion_r72305621\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1583#discussion_r72305621</a></p>\n\n<p>    &#8212; Diff: external/storm-druid/src/main/java/org/apache/storm/druid/trident/DruidBeamState.java &#8212;<br/>\n    @@ -0,0 +1,73 @@<br/>\n    +/*<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing,<br/>\n    + * software distributed under the License is distributed on an<br/>\n    + * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY<br/>\n    + * KIND, either express or implied.  See the License for the<br/>\n    + * specific language governing permissions and limitations<br/>\n    + * under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.druid.trident;<br/>\n    +<br/>\n    +import com.metamx.tranquility.beam.Beam;<br/>\n    +import com.twitter.util.Await;<br/>\n    +import org.apache.storm.trident.state.State;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import scala.collection.JavaConversions;<br/>\n    +<br/>\n    +import java.util.List;<br/>\n    +<br/>\n    +<br/>\n    +/**<br/>\n    + * Trident </p>\n{@link State}\n<p> implementation for Druid.<br/>\n    + */<br/>\n    +public class DruidBeamState<E> implements State  {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(DruidBeamState.class);<br/>\n    +<br/>\n    +    Beam<E> beam = null;<br/>\n    +<br/>\n    +    public DruidBeamState(Beam<E> beam) </p>\n{\n    +this.beam = beam;\n    +    }\n<p>    +<br/>\n    +    public void send(List<E> events ) {<br/>\n    +try {<br/>\n    +    LOG.info(\"Sending %d events\", events.size());<br/>\n    +    Await.result(beam.sendBatch(JavaConversions.collectionAsScalaIterable(events).toList()));<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    looks like indentation missed here</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612928432/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907880","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907880","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907880,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4ODA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:14:33Z","updated_at":"2025-01-24T16:18:53Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72306241\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72306241</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/KinesisRecordsManager.java &#8212;<br/>\n    @@ -0,0 +1,566 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import com.amazonaws.regions.Region;<br/>\n    +import com.amazonaws.services.kinesis.AmazonKinesisClient;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.DescribeStreamResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ExpiredIteratorException;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetRecordsResult;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorRequest;<br/>\n    +import com.amazonaws.services.kinesis.model.GetShardIteratorResult;<br/>\n    +import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;<br/>\n    +import com.amazonaws.services.kinesis.model.Record;<br/>\n    +import com.amazonaws.services.kinesis.model.Shard;<br/>\n    +import com.amazonaws.services.kinesis.model.ShardIteratorType;<br/>\n    +import org.apache.curator.framework.CuratorFramework;<br/>\n    +import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n    +import org.apache.curator.retry.RetryNTimes;<br/>\n    +import org.apache.storm.spout.SpoutOutputCollector;<br/>\n    +import org.apache.zookeeper.CreateMode;<br/>\n    +import org.json.simple.JSONValue;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +<br/>\n    +import java.math.BigInteger;<br/>\n    +import java.nio.charset.Charset;<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Date;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.Iterator;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.TreeSet;<br/>\n    +<br/>\n    +class KinesisRecordsManager {<br/>\n    +    private static final Logger LOG = LoggerFactory.getLogger(KinesisRecordsManager.class);<br/>\n    +    // zk interaction object<br/>\n    +    private transient CuratorFramework curatorFramework;<br/>\n    +    // Kinesis Spout Config object<br/>\n    +    private transient final Config config;<br/>\n    +    // Queue of records per shard fetched from kinesis and are waiting to be emitted<br/>\n    +    private transient Map<String, LinkedList<Record>> toEmitPerShard = new HashMap<>();<br/>\n    +    // Map of records  that were fetched from kinesis as a result of failure and are waiting to be emitted<br/>\n    +    private transient Map<KinesisMessageId, Record> failedandFetchedRecords = new HashMap<>();<br/>\n    +    // Sequence numbers per shard that have been emitted. LinkedHashSet as we need to remove on ack or fail. At the same time order is needed to figure out the<br/>\n    +    // sequence number to commit. Logic explained in commit<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> emittedPerShard = new HashMap<>();<br/>\n    +    // sorted acked sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> ackedPerShard = new HashMap<>();<br/>\n    +    // sorted failed sequence numbers - needed to figure out what sequence number can be committed<br/>\n    +    private transient Map<String, TreeSet<BigInteger>> failedPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for new messages<br/>\n    +    private transient Map<String, String> shardIteratorPerShard = new HashMap<>();<br/>\n    +    // last fetched sequence number corresponding to position in shard<br/>\n    +    private transient Map<String, String> fetchedSequenceNumberPerShard = new HashMap<>();<br/>\n    +    // shard iterator corresponding to position in shard for failed messages<br/>\n    +    private transient Map<KinesisMessageId, String> shardIteratorPerFailedMessage = new HashMap<>();<br/>\n    +    // timestamp to decide when to commit to zk again<br/>\n    +    private transient long lastCommitTime;<br/>\n    +    // boolean to track deactivated state<br/>\n    +    private transient boolean deactivated;<br/>\n    +    private transient AmazonKinesisClient kinesisClient;<br/>\n    +<br/>\n    +    KinesisRecordsManager (Config config) </p>\n{\n    +this.config = config;\n    +    }\n<p>    +<br/>\n    +    void initialize (int myTaskIndex, int totalTasks) {<br/>\n    +deactivated = false;<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +initializeKinesisClient();<br/>\n    +initializeCurator();<br/>\n    +List<Shard> shards = this.getShards();<br/>\n    +LOG.info(\"myTaskIndex is \" + myTaskIndex);<br/>\n    +LOG.info(\"totalTasks is \" + totalTasks);<br/>\n    +int i = myTaskIndex;<br/>\n    +while (i < shards.size()) </p>\n{\n    +    LOG.info(\"Shard id \" + shards.get(i).getShardId() + \" assigned to task \" + myTaskIndex);\n    +    toEmitPerShard.put(shards.get(i).getShardId(), new LinkedList<Record>());\n    +    i += totalTasks;\n    +}\n<p>    +initializeFetchedSequenceNumbers();<br/>\n    +refreshShardIteratorsForNewRecords();<br/>\n    +    }<br/>\n    +<br/>\n    +    void next (SpoutOutputCollector collector) {<br/>\n    +if (shouldCommit()) </p>\n{\n    +    commit();\n    +}<br/>\n    +KinesisMessageId failedMessageId = config.getFailedMessageRetryHandler().getNextFailedMessageToRetry();<br/>\n    +if (failedMessageId  != null) {<br/>\n    +    // if the retry service returns a message that is not in failed set then ignore it. should never happen<br/>\n    +    BigInteger failedSequenceNumber = new BigInteger(failedMessageId.getSequenceNumber());<br/>\n    +    if (failedPerShard.containsKey(failedMessageId.getShardId()) && failedPerShard.get(failedMessageId.getShardId()).contains(failedSequenceNumber)) {<br/>\n    +if (!failedandFetchedRecords.containsKey(failedMessageId)) {\n    +    fetchFailedRecords(failedMessageId);\n    +}<br/>\n    +if (emitFailedRecord(collector, failedMessageId)) {\n    +    failedPerShard.get(failedMessageId.getShardId()).remove(failedSequenceNumber);\n    +    config.getFailedMessageRetryHandler().failedMessageEmitted(failedMessageId);\n    +    return;\n    +} else {\n    +    LOG.debug(\"failedMessageEmitted not called on retrier for \" + failedMessageId + \". This can happen a few times but should not happen \" +\n    +    \"infinitely\");\n    +}<br/>\n    +    } else {\n    +LOG.debug(\"failedPerShard does not contain \" + failedMessageId + \". This should never happen.\");\n    +    }<br/>\n    +}<br/>\n    +LOG.debug(\"No failed record to emit for now. Hence will try to emit new records\");<br/>\n    +// if maximum uncommitted records count has reached, so dont emit any new records and return<br/>\n    +if (!(getUncommittedRecordsCount() < config.getMaxUncommittedRecords())) {\n    +    LOG.debug(\"maximum uncommitted records count has reached. so not emitting any new records and returning\");\n    +    return;\n    +}<br/>\n    +// early return as no shard is assigned - probably because number of executors > number of shards<br/>\n    +if (toEmitPerShard.isEmpty()) {\n    +    LOG.debug(\"No shard is assigned to this task. Hence not emitting any tuple.\");\n    +    return;\n    +}<br/>\n    +<br/>\n    +if (shouldFetchNewRecords()) {\n    +    fetchNewRecords();\n    +}<br/>\n    +emitNewRecord(collector);<br/>\n    +    }<br/>\n    +<br/>\n    +    void ack (KinesisMessageId kinesisMessageId) {<br/>\n    +// for an acked message add it to acked set and remove it from emitted and failed<br/>\n    +String shardId = kinesisMessageId.getShardId();<br/>\n    +BigInteger sequenceNumber = new BigInteger(kinesisMessageId.getSequenceNumber());<br/>\n    +LOG.debug(\"Ack received for shardId: \" + shardId + \" sequenceNumber: \" + sequenceNumber);<br/>\n    +if (!ackedPerShard.containsKey(shardId)) {\n    +    ackedPerShard.put(shardId, new TreeSet<BigInteger>());\n    +}<br/>\n    +ackedPerShard.get(shardId).add(sequenceNumber);<br/>\n    +if (emittedPerShard.containsKey(shardId)) {\n    +    TreeSet<BigInteger> emitted = emittedPerShard.get(shardId);\n    +    emitted.remove(sequenceNumber);\n    +}<br/>\n    +if (failedPerShard.containsKey(shardId)) {\n    +    failedPerShard.get(shardId).remove(sequenceNumber);\n    +}<br/>\n    +if (failedandFetchedRecords.containsKey(kinesisMessageId)) {\n    +    config.getFailedMessageRetryHandler().acked(kinesisMessageId);\n    +    failedandFetchedRecords.remove(kinesisMessageId);\n    +}<br/>\n    +// keep committing when topology is deactivated since ack and fail keep getting called on deactivated topology<br/>\n    +if (deactivated) {    +    commit();    +}\n<p>    +    }<br/>\n    +<br/>\n    +    void fail (KinesisMessageId kinesisMessageId) {<br/>\n    +String shardId = kinesisMessageId.getShardId();<br/>\n    +BigInteger sequenceNumber = new BigInteger(kinesisMessageId.getSequenceNumber());<br/>\n    +LOG.debug(\"Fail received for shardId: \" + shardId + \" sequenceNumber: \" + sequenceNumber);<br/>\n    +// for a failed message add it to failed set if it will be retried, otherwise ack it; remove from emitted either way<br/>\n    +if (config.getFailedMessageRetryHandler().failed(kinesisMessageId)) {<br/>\n    +    if (!failedPerShard.containsKey(shardId)) </p>\n{\n    +failedPerShard.put(shardId, new TreeSet<BigInteger>());\n    +    }\n<p>    +    failedPerShard.get(shardId).add(sequenceNumber);<br/>\n    +    TreeSet<BigInteger> emitted = emittedPerShard.get(shardId);<br/>\n    +    emitted.remove(sequenceNumber);<br/>\n    +} else </p>\n{\n    +    ack(kinesisMessageId);\n    +}\n<p>    +// keep committing when topology is deactivated since ack and fail keep getting called on deactivated topology<br/>\n    +if (deactivated) </p>\n{\n    +    commit();\n    +}\n<p>    +    }<br/>\n    +<br/>\n    +    void commit () {<br/>\n    +// Logic for deciding what sequence number to ack is find the highest sequence number from acked called X such that there is no sequence number Y in<br/>\n    +// emitted or failed that satisfies X > Y. For e.g. is acked is 1,3,5. Emitted is 2,4,6 then we can only commit 1 and not 3 because 2 is still pending<br/>\n    +for (String shardId: toEmitPerShard.keySet()) {<br/>\n    +    if (ackedPerShard.containsKey(shardId)) {<br/>\n    +BigInteger commitSequenceNumberBound = null;<br/>\n    +if (failedPerShard.containsKey(shardId) && !failedPerShard.get(shardId).isEmpty()) </p>\n{\n    +    commitSequenceNumberBound = failedPerShard.get(shardId).first();\n    +}\n<p>    +if (emittedPerShard.containsKey(shardId) && !emittedPerShard.get(shardId).isEmpty()) {<br/>\n    +    BigInteger smallestEmittedSequenceNumber = emittedPerShard.get(shardId).first();<br/>\n    +    if (commitSequenceNumberBound == null || (commitSequenceNumberBound.compareTo(smallestEmittedSequenceNumber) == 1)) </p>\n{\n    +commitSequenceNumberBound = smallestEmittedSequenceNumber;\n    +    }\n<p>    +}<br/>\n    +Iterator<BigInteger> ackedSequenceNumbers = ackedPerShard.get(shardId).iterator();<br/>\n    +BigInteger ackedSequenceNumberToCommit = null;<br/>\n    +while (ackedSequenceNumbers.hasNext()) {<br/>\n    +    BigInteger ackedSequenceNumber = ackedSequenceNumbers.next();<br/>\n    +    if (commitSequenceNumberBound == null || (commitSequenceNumberBound.compareTo(ackedSequenceNumber) == 1)) </p>\n{\n    +ackedSequenceNumberToCommit = ackedSequenceNumber;\n    +ackedSequenceNumbers.remove();\n    +    }\n<p> else </p>\n{\n    +break;\n    +    }\n<p>    +}<br/>\n    +if (ackedSequenceNumberToCommit != null) </p>\n{\n    +    Map<Object, Object> state = new HashMap<>();\n    +    state.put(\"committedSequenceNumber\", ackedSequenceNumberToCommit.toString());\n    +    LOG.debug(\"Committing sequence number \" + ackedSequenceNumberToCommit.toString() + \" for shardId \" + shardId);\n    +    String path = getZkPath(shardId);\n    +    commitState(path, state);\n    +}\n<p>    +    }<br/>\n    +}<br/>\n    +lastCommitTime = System.currentTimeMillis();<br/>\n    +    }<br/>\n    +<br/>\n    +    void activate () </p>\n{\n    +LOG.info(\"Activate called\");\n    +deactivated = false;\n    +initializeKinesisClient();\n    +    }\n<p>    +<br/>\n    +    void deactivate () </p>\n{\n    +LOG.info(\"Deactivate called\");\n    +deactivated = true;\n    +commit();\n    +shutdownKinesisClient();\n    +    }\n<p>    +<br/>\n    +    void close () </p>\n{\n    +commit();\n    +shutdownKinesisClient();\n    +shutdownCurator();\n    +    }\n<p>    +<br/>\n    +    private String getZkPath (String shardId) {<br/>\n    +String path = \"\";<br/>\n    +if (!config.getZkInfo().getZkNode().startsWith(\"/\")) </p>\n{\n    +    path += \"/\";\n    +}<br/>\n    +path += config.getZkInfo().getZkNode();<br/>\n    +if (!config.getZkInfo().getZkNode().endsWith(\"/\")) {    +    path += \"/\";    +}\n<p>    +path += (config.getStreamName() + \"/\" + shardId);<br/>\n    +return path;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void commitState (String path, Map<Object, Object> state) {<br/>\n    +byte[] bytes = JSONValue.toJSONString(state).getBytes(Charset.forName(\"UTF-8\"));<br/>\n    +try {<br/>\n    +    if (curatorFramework.checkExists().forPath(path) == null) </p>\n{\n    +curatorFramework.create()\n    +.creatingParentsIfNeeded()\n    +.withMode(CreateMode.PERSISTENT)\n    +.forPath(path, bytes);\n    +    }\n<p> else </p>\n{\n    +curatorFramework.setData().forPath(path, bytes);\n    +    }\n<p>    +} catch (Exception e) </p>\n{\n    +    throw new RuntimeException(e);\n    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Object, Object> readState (String path) {<br/>\n    +try {<br/>\n    +    Map<Object, Object> state = null;<br/>\n    +    byte[] b = null;<br/>\n    +    if (curatorFramework.checkExists().forPath(path) != null) {\n    +b = curatorFramework.getData().forPath(path);\n    +    }<br/>\n    +    if (b != null) {\n    +state = (Map<Object, Object>) JSONValue.parse(new String(b, \"UTF-8\"));\n    +    }<br/>\n    +    return state;<br/>\n    +} catch (Exception e) {    +    throw new RuntimeException(e);    +}\n<p>    +    }<br/>\n    +<br/>\n    +    // fetch records from kinesis starting at sequence number for message passed as argument. Any other messages fetched and are in the failed queue will also<br/>\n    +    // be kept in memory to avoid going to kinesis again for retry<br/>\n    +    private void fetchFailedRecords (KinesisMessageId kinesisMessageId) {<br/>\n    +// if shard iterator not present for this message, get it<br/>\n    +if (!shardIteratorPerFailedMessage.containsKey(kinesisMessageId)) </p>\n{\n    +    refreshShardIteratorForFailedRecord(kinesisMessageId);\n    +}\n<p>    +String shardIterator = shardIteratorPerFailedMessage.get(kinesisMessageId);<br/>\n    +LOG.debug(\"Fetching failed records for shard id :\" + kinesisMessageId.getShardId() + \" at sequence number \" + kinesisMessageId.getSequenceNumber() +<br/>\n    +\" using shardIterator \" + shardIterator);<br/>\n    +try {<br/>\n    +    GetRecordsResult getRecordsResult = fetchRecords(shardIterator);<br/>\n    +    if (getRecordsResult != null) {<br/>\n    +List<Record> records = getRecordsResult.getRecords();<br/>\n    +LOG.debug(\"Records size from fetchFailedRecords is \" + records.size());<br/>\n    +// update the shard iterator to next one in case this fetch does not give the message.<br/>\n    +shardIteratorPerFailedMessage.put(kinesisMessageId, getRecordsResult.getNextShardIterator());<br/>\n    +if (records.size() == 0) {<br/>\n    +    LOG.debug(\"No records returned from kinesis. Hence sleeping for 1 second\");<br/>\n    +    Thread.sleep(1000);<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    I would prefer this to be not configurable. Reason is kinesis api somewhere mentioned in their documentation that if you dont receive any records it is good to sleep for a second. Reason is that they some limits for GetRecords request per second and it will throw an exception if that limit is reached or violated. Although I am catching that exception I wanted to avoid that. Making it configurable and go beyond 1 second can slow down the spout in some cases as well. For example, sometimes it takes multiple requests to get to the portion of the shard where the message at a sequence number you want to read is present. In that case it does not make sense to backoff in an exponential fashion. You just want to make sure you get there sooner without violating the limit.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907880/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907887","html_url":"https://github.com/apache/storm/issues/5622#issuecomment-2612907887","issue_url":"https://api.github.com/repos/apache/storm/issues/5622","id":2612907887,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDc4ODc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-26T18:15:41Z","updated_at":"2025-01-24T16:18:53Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user priyank5485 commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1586#discussion_r72306421\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1586#discussion_r72306421</a></p>\n\n<p>    &#8212; Diff: external/storm-kinesis/src/main/java/org/apache/storm/kinesis/spout/ZkInfo.java &#8212;<br/>\n    @@ -0,0 +1,153 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +<br/>\n    +package org.apache.storm.kinesis.spout;<br/>\n    +<br/>\n    +import java.io.Serializable;<br/>\n    +<br/>\n    +public class ZkInfo implements Serializable {<br/>\n    +    // comma separated list of zk connect strings to connect to zookeeper e.g. localhost:2181<br/>\n    +    private final String zkUrl;<br/>\n    +    // zk node under which to commit the sequence number of messages. e.g. /committed_sequence_numbers<br/>\n    +    private final String zkNode;<br/>\n    +    // zk session timeout in milliseconds<br/>\n    +    private final Integer sessionTimeoutMs;<br/>\n    +    // zk connection timeout in milliseconds<br/>\n    +    private final Integer connectionTimeoutMs;<br/>\n    +    // interval at which to commit offsets to zk in milliseconds<br/>\n    +    private final Long commitIntervalMs;<br/>\n    +    // number of retry attempts for zk<br/>\n    +    private final Integer retryAttempts;<br/>\n    +    // time to sleep between retries in milliseconds<br/>\n    +    private final Integer retryIntervalMs;<br/>\n    +<br/>\n    +    /**<br/>\n    +     * Default constructor that uses defaults for a local setup<br/>\n    +     */<br/>\n    +    public ZkInfo () </p>\n{\n    +this(\"localhost:2181\", \"/kinesisOffsets\", 20000, 15000, 10000L, 3, 2000);\n    +    }\n<p>    +<br/>\n    +    public ZkInfo (String zkUrl, String zkNode, Integer sessionTimeoutMs, Integer connectionTimeoutMs, Long commitIntervalMs, Integer retryAttempts, Integer<br/>\n    +    retryIntervalMs) </p>\n{\n    +this.zkUrl = zkUrl;\n    +this.zkNode = zkNode;\n    +this.sessionTimeoutMs = sessionTimeoutMs;\n    +this.connectionTimeoutMs = connectionTimeoutMs;\n    +this.commitIntervalMs = commitIntervalMs;\n    +this.retryAttempts = retryAttempts;\n    +this.retryIntervalMs = retryIntervalMs;\n    +validate();\n    +    }\n<p>    +<br/>\n    +    public String getZkUrl() </p>\n{\n    +return zkUrl;\n    +    }\n<p>    +<br/>\n    +    public String getZkNode() </p>\n{\n    +return zkNode;\n    +    }\n<p>    +<br/>\n    +    public Integer getSessionTimeoutMs() </p>\n{\n    +return sessionTimeoutMs;\n    +    }\n<p>    +<br/>\n    +    public Integer getConnectionTimeoutMs() </p>\n{\n    +return connectionTimeoutMs;\n    +    }\n<p>    +<br/>\n    +    public Long getCommitIntervalMs() </p>\n{\n    +return commitIntervalMs;\n    +    }\n<p>    +<br/>\n    +    public Integer getRetryAttempts() </p>\n{\n    +return retryAttempts;\n    +    }\n<p>    +<br/>\n    +    public Integer getRetryIntervalMs() </p>\n{\n    +return retryIntervalMs;\n    +    }\n<p>    +<br/>\n    +    private void validate () {<br/>\n    +<br/>\n    +if (zkUrl == null || zkUrl.length() < 1) </p>\n{\n    +    throw new IllegalArgumentException(\"zkUrl must be specified to connect to zookeeper\");\n    +}\n<p>    +if (zkNode == null || zkNode.length() < 1) </p>\n{\n    +    throw new IllegalArgumentException(\"zkNode must be specified\");\n    +}\n<p>    +checkPositive(sessionTimeoutMs, \"sessionTimeoutMs\");<br/>\n    +checkPositive(connectionTimeoutMs, \"connectionTimeoutMs\");<br/>\n    +checkPositive(commitIntervalMs, \"commitIntervalMs\");<br/>\n    +checkPositive(retryAttempts, \"retryAttempts\");<br/>\n    +checkPositive(retryIntervalMs, \"retryIntervalMs\");<br/>\n    +    }<br/>\n    +<br/>\n    +    private void checkPositive (Integer argument, String name) {<br/>\n    +if (argument == null && argument <= 0) </p>\n{\n    +    throw new IllegalArgumentException(name + \" must be positive\");\n    +}<br/>\n    +    }<br/>\n    +    private void checkPositive (Long argument, String name) {<br/>\n    +if (argument == null && argument <= 0) {    +    throw new IllegalArgumentException(name + \" must be positive\");    +}\n<p>    +    }<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public String toString() {<br/>\n    +return \"ZkInfo</p>\n{\" +\n    +\"zkUrl='\" + zkUrl + '\\'' +\n    +\", zkNode='\" + zkNode + '\\'' +\n    +\", sessionTimeoutMs=\" + sessionTimeoutMs +\n    +\", connectionTimeoutMs=\" + connectionTimeoutMs +\n    +\", commitIntervalMs=\" + commitIntervalMs +\n    +\", retryAttempts=\" + retryAttempts +\n    +\", retryIntervalMs=\" + retryIntervalMs +\n    +'}\n<p>';<br/>\n    +    }<br/>\n    +<br/>\n    +    @Override<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Will change it</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612907887/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]