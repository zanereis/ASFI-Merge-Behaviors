[{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/823627270","html_url":"https://github.com/apache/iceberg/pull/2466#issuecomment-823627270","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2466","id":823627270,"node_id":"MDEyOklzc3VlQ29tbWVudDgyMzYyNzI3MA==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-20T21:59:43Z","updated_at":"2021-04-20T21:59:43Z","author_association":"CONTRIBUTOR","body":"I am closing this one in favor of #2500.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/823627270/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/823634268","html_url":"https://github.com/apache/iceberg/pull/2352#issuecomment-823634268","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2352","id":823634268,"node_id":"MDEyOklzc3VlQ29tbWVudDgyMzYzNDI2OA==","user":{"login":"rzhang10","id":75445426,"node_id":"MDQ6VXNlcjc1NDQ1NDI2","avatar_url":"https://avatars.githubusercontent.com/u/75445426?v=4","gravatar_id":"","url":"https://api.github.com/users/rzhang10","html_url":"https://github.com/rzhang10","followers_url":"https://api.github.com/users/rzhang10/followers","following_url":"https://api.github.com/users/rzhang10/following{/other_user}","gists_url":"https://api.github.com/users/rzhang10/gists{/gist_id}","starred_url":"https://api.github.com/users/rzhang10/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rzhang10/subscriptions","organizations_url":"https://api.github.com/users/rzhang10/orgs","repos_url":"https://api.github.com/users/rzhang10/repos","events_url":"https://api.github.com/users/rzhang10/events{/privacy}","received_events_url":"https://api.github.com/users/rzhang10/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-20T22:15:19Z","updated_at":"2021-04-20T23:00:35Z","author_association":"CONTRIBUTOR","body":"@rdblue Hey Ryan, I feel what causes the confusion here is the class `GetProjectedIds` 's name, if dig into the code of this class you'll find it actually doesn't do field projection, what it does is it tries to get extract all the internal ids from complex types (struct, map, list) out, such that the returned set of ids only maps to primitive type fields. However, the corner case it is missing is exactly the empty struct case, where the struct field itself should be kept. If you take a look at the code, the `GetProjectedIds` only gets used by `TypeUtil.selectNot` function which calls `select()` to really gets the projection, but via another visitor called `PruneColumns`.\r\n\r\nSo I believe my code is handling the corner case correctly. cc @shardulm94 @wmoustafa","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/823634268/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/823656457","html_url":"https://github.com/apache/iceberg/pull/2501#issuecomment-823656457","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2501","id":823656457,"node_id":"MDEyOklzc3VlQ29tbWVudDgyMzY1NjQ1Nw==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-20T23:02:18Z","updated_at":"2021-04-20T23:02:18Z","author_association":"MEMBER","body":"I added a bunch of folks but please anyone who is interested comment. Especially those planning writing their own platform specific implementations or new compaction strategies in the future","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/823656457/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/823917318","html_url":"https://github.com/apache/iceberg/pull/2502#issuecomment-823917318","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2502","id":823917318,"node_id":"MDEyOklzc3VlQ29tbWVudDgyMzkxNzMxOA==","user":{"login":"marton-bod","id":19599214,"node_id":"MDQ6VXNlcjE5NTk5MjE0","avatar_url":"https://avatars.githubusercontent.com/u/19599214?v=4","gravatar_id":"","url":"https://api.github.com/users/marton-bod","html_url":"https://github.com/marton-bod","followers_url":"https://api.github.com/users/marton-bod/followers","following_url":"https://api.github.com/users/marton-bod/following{/other_user}","gists_url":"https://api.github.com/users/marton-bod/gists{/gist_id}","starred_url":"https://api.github.com/users/marton-bod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marton-bod/subscriptions","organizations_url":"https://api.github.com/users/marton-bod/orgs","repos_url":"https://api.github.com/users/marton-bod/repos","events_url":"https://api.github.com/users/marton-bod/events{/privacy}","received_events_url":"https://api.github.com/users/marton-bod/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T09:24:04Z","updated_at":"2021-04-21T09:24:04Z","author_association":"COLLABORATOR","body":"@pvary @lcspinter can you please take a look? Thanks!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/823917318/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/823963431","html_url":"https://github.com/apache/iceberg/pull/2499#issuecomment-823963431","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2499","id":823963431,"node_id":"MDEyOklzc3VlQ29tbWVudDgyMzk2MzQzMQ==","user":{"login":"szehon-ho","id":20555759,"node_id":"MDQ6VXNlcjIwNTU1NzU5","avatar_url":"https://avatars.githubusercontent.com/u/20555759?v=4","gravatar_id":"","url":"https://api.github.com/users/szehon-ho","html_url":"https://github.com/szehon-ho","followers_url":"https://api.github.com/users/szehon-ho/followers","following_url":"https://api.github.com/users/szehon-ho/following{/other_user}","gists_url":"https://api.github.com/users/szehon-ho/gists{/gist_id}","starred_url":"https://api.github.com/users/szehon-ho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szehon-ho/subscriptions","organizations_url":"https://api.github.com/users/szehon-ho/orgs","repos_url":"https://api.github.com/users/szehon-ho/repos","events_url":"https://api.github.com/users/szehon-ho/events{/privacy}","received_events_url":"https://api.github.com/users/szehon-ho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T10:41:38Z","updated_at":"2021-04-21T10:41:38Z","author_association":"COLLABORATOR","body":"Hi @aokolnychyi @RussellSpitzer , change is ready if you guys have some time to take a look, thanks","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/823963431/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824210180","html_url":"https://github.com/apache/iceberg/pull/2286#issuecomment-824210180","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2286","id":824210180,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDIxMDE4MA==","user":{"login":"mayursrivastava","id":8659624,"node_id":"MDQ6VXNlcjg2NTk2MjQ=","avatar_url":"https://avatars.githubusercontent.com/u/8659624?v=4","gravatar_id":"","url":"https://api.github.com/users/mayursrivastava","html_url":"https://github.com/mayursrivastava","followers_url":"https://api.github.com/users/mayursrivastava/followers","following_url":"https://api.github.com/users/mayursrivastava/following{/other_user}","gists_url":"https://api.github.com/users/mayursrivastava/gists{/gist_id}","starred_url":"https://api.github.com/users/mayursrivastava/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayursrivastava/subscriptions","organizations_url":"https://api.github.com/users/mayursrivastava/orgs","repos_url":"https://api.github.com/users/mayursrivastava/repos","events_url":"https://api.github.com/users/mayursrivastava/events{/privacy}","received_events_url":"https://api.github.com/users/mayursrivastava/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T16:51:37Z","updated_at":"2021-04-21T16:53:51Z","author_association":"CONTRIBUTOR","body":"`\r\n./gradlew :iceberg-spark:jmh -PjmhIncludeRegex=VectorizedReadFlatParquetDataBenchmark -PjmhOutputPath=benchmark/results.txt\r\n`\r\n\r\n@rymurr, is this :iceberg-spark2:jmh? Looks like this requires Java8 runtime. Am I right? I ran it on the master branch (without my changes), but it fails with the following error. Does it need a powerful machine?\r\n\r\n`\r\nJMH version: 1.21\r\nVM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\nVM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\nVM options: <none>\r\nWarmup: 3 iterations, single-shot each\r\nMeasurement: 5 iterations, single-shot each\r\nTimeout: 10 min per iteration\r\nThreads: 1 thread\r\nBenchmark mode: Single shot invocation time\r\nBenchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.readDatesIcebergVectorized5k\r\n\r\nRun progress: 0.00% complete, ETA 00:00:00\r\nFork: 1 of 1\r\nWarmup Iteration   1: (*interrupt*) <failure>\r\n\r\njava.lang.InterruptedException\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\r\n        at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:206)\r\n        at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:222)\r\n        at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:157)\r\n        at org.apache.spark.util.ThreadUtils$.awaitReady(ThreadUtils.scala:243)\r\n        at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:750)\r\n        at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n        at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.doExecute(WriteToDataSourceV2Exec.scala:64)\r\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n        at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:83)\r\n        at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:81)\r\n        at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:696)\r\n        at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:696)\r\n        at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\r\n        at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\r\n        at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\r\n        at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:696)\r\n        at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:280)\r\n        at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:249)\r\n        at org.apache.iceberg.spark.source.IcebergSourceBenchmark.appendAsFile(IcebergSourceBenchmark.java:130)\r\n        at org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.appendData(VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java:82)\r\n        at org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.setupBenchmark(VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java:56)\r\n        at org.apache.iceberg.spark.source.parquet.vectorized.generated.VectorizedReadDictionaryEncodedFlatParquetDataBenchmark_readDatesIcebergVectorized5k_jmhTest._jmh_tryInit_f_vectorizedreaddictionaryencodedflatparquetdatabenchmark0_G(VectorizedReadDictionaryEncodedFlatParquetDataBenchmark_readDatesIcebergVectorized5k_jmhTest.java:438)\r\n        at org.apache.iceberg.spark.source.parquet.vectorized.generated.VectorizedReadDictionaryEncodedFlatParquetDataBenchmark_readDatesIcebergVectorized5k_jmhTest.readDatesIcebergVectorized5k_SingleShotTime(VectorizedReadDictionaryEncodedFlatParquetDataBenchmark_readDatesIcebergVectorized5k_jmhTest.java:363)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:453)\r\n        at org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:437)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\nBenchmark had encountered error, and fail on error was requested\r\n`","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824210180/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824213194","html_url":"https://github.com/apache/iceberg/pull/2286#issuecomment-824213194","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2286","id":824213194,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDIxMzE5NA==","user":{"login":"rymurr","id":2022305,"node_id":"MDQ6VXNlcjIwMjIzMDU=","avatar_url":"https://avatars.githubusercontent.com/u/2022305?v=4","gravatar_id":"","url":"https://api.github.com/users/rymurr","html_url":"https://github.com/rymurr","followers_url":"https://api.github.com/users/rymurr/followers","following_url":"https://api.github.com/users/rymurr/following{/other_user}","gists_url":"https://api.github.com/users/rymurr/gists{/gist_id}","starred_url":"https://api.github.com/users/rymurr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymurr/subscriptions","organizations_url":"https://api.github.com/users/rymurr/orgs","repos_url":"https://api.github.com/users/rymurr/repos","events_url":"https://api.github.com/users/rymurr/events{/privacy}","received_events_url":"https://api.github.com/users/rymurr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T16:56:12Z","updated_at":"2021-04-21T16:56:12Z","author_association":"CONTRIBUTOR","body":"Yeah, tahts the right benchmark and right jvm. Haven't seen it encounter that error before. Does it run on `master` branch?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824213194/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824214891","html_url":"https://github.com/apache/iceberg/pull/2501#issuecomment-824214891","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2501","id":824214891,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDIxNDg5MQ==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T16:58:56Z","updated_at":"2021-04-21T16:58:56Z","author_association":"CONTRIBUTOR","body":"I had only minor questions/comments. Let's hear from other folks before updating. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824214891/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824225827","html_url":"https://github.com/apache/iceberg/pull/2286#issuecomment-824225827","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2286","id":824225827,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDIyNTgyNw==","user":{"login":"mayursrivastava","id":8659624,"node_id":"MDQ6VXNlcjg2NTk2MjQ=","avatar_url":"https://avatars.githubusercontent.com/u/8659624?v=4","gravatar_id":"","url":"https://api.github.com/users/mayursrivastava","html_url":"https://github.com/mayursrivastava","followers_url":"https://api.github.com/users/mayursrivastava/followers","following_url":"https://api.github.com/users/mayursrivastava/following{/other_user}","gists_url":"https://api.github.com/users/mayursrivastava/gists{/gist_id}","starred_url":"https://api.github.com/users/mayursrivastava/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayursrivastava/subscriptions","organizations_url":"https://api.github.com/users/mayursrivastava/orgs","repos_url":"https://api.github.com/users/mayursrivastava/repos","events_url":"https://api.github.com/users/mayursrivastava/events{/privacy}","received_events_url":"https://api.github.com/users/mayursrivastava/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T17:17:18Z","updated_at":"2021-04-21T17:21:57Z","author_association":"CONTRIBUTOR","body":"Hi @rymurr, for me the benchmark is failing on the master. Currently, I'm running on wsl2/ubuntu. I'll provision another linux machine to try it again - this may take a couple of days.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824225827/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824287364","html_url":"https://github.com/apache/iceberg/pull/2500#issuecomment-824287364","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2500","id":824287364,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDI4NzM2NA==","user":{"login":"flyrain","id":1322359,"node_id":"MDQ6VXNlcjEzMjIzNTk=","avatar_url":"https://avatars.githubusercontent.com/u/1322359?v=4","gravatar_id":"","url":"https://api.github.com/users/flyrain","html_url":"https://github.com/flyrain","followers_url":"https://api.github.com/users/flyrain/followers","following_url":"https://api.github.com/users/flyrain/following{/other_user}","gists_url":"https://api.github.com/users/flyrain/gists{/gist_id}","starred_url":"https://api.github.com/users/flyrain/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/flyrain/subscriptions","organizations_url":"https://api.github.com/users/flyrain/orgs","repos_url":"https://api.github.com/users/flyrain/repos","events_url":"https://api.github.com/users/flyrain/events{/privacy}","received_events_url":"https://api.github.com/users/flyrain/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T19:00:10Z","updated_at":"2021-04-21T19:00:10Z","author_association":"CONTRIBUTOR","body":"Can we have a unit test testing method `commitRewrite(Table table, Set<String> fileSetIDs)` with multiple fileSetIDs? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824287364/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824290222","html_url":"https://github.com/apache/iceberg/issues/2194#issuecomment-824290222","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2194","id":824290222,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDI5MDIyMg==","user":{"login":"alec-heif","id":5010391,"node_id":"MDQ6VXNlcjUwMTAzOTE=","avatar_url":"https://avatars.githubusercontent.com/u/5010391?v=4","gravatar_id":"","url":"https://api.github.com/users/alec-heif","html_url":"https://github.com/alec-heif","followers_url":"https://api.github.com/users/alec-heif/followers","following_url":"https://api.github.com/users/alec-heif/following{/other_user}","gists_url":"https://api.github.com/users/alec-heif/gists{/gist_id}","starred_url":"https://api.github.com/users/alec-heif/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alec-heif/subscriptions","organizations_url":"https://api.github.com/users/alec-heif/orgs","repos_url":"https://api.github.com/users/alec-heif/repos","events_url":"https://api.github.com/users/alec-heif/events{/privacy}","received_events_url":"https://api.github.com/users/alec-heif/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T19:05:14Z","updated_at":"2021-04-21T19:05:14Z","author_association":"CONTRIBUTOR","body":"+1 for this, it seems to have been available for quite a while now so hopefully is out of the pure \"development only\" stage?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824290222/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824374666","html_url":"https://github.com/apache/iceberg/pull/2500#issuecomment-824374666","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2500","id":824374666,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDM3NDY2Ng==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T21:40:01Z","updated_at":"2021-04-21T21:40:01Z","author_association":"CONTRIBUTOR","body":"@flyrain, added a unit test that commits multiple rewrites at the same time.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824374666/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824377479","html_url":"https://github.com/apache/iceberg/pull/2496#issuecomment-824377479","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2496","id":824377479,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDM3NzQ3OQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T21:42:08Z","updated_at":"2021-04-21T21:42:08Z","author_association":"MEMBER","body":"Are complex types allowed to have defaults? Just wondering how complicated this can get","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824377479/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824384686","html_url":"https://github.com/apache/iceberg/pull/2496#issuecomment-824384686","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2496","id":824384686,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDM4NDY4Ng==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T21:56:56Z","updated_at":"2021-04-21T21:56:56Z","author_association":"MEMBER","body":"I can't remember the details of this, but I remember a few sync's back we were discussing this behavior for the general case and were worried about spark losing field properties... I think. Does anyone else remember the details?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824384686/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824430614","html_url":"https://github.com/apache/iceberg/pull/2501#issuecomment-824430614","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2501","id":824430614,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDQzMDYxNA==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-21T23:30:42Z","updated_at":"2021-04-21T23:30:42Z","author_association":"CONTRIBUTOR","body":"cc @rymurr @chenjunjiedada @flyrain @karuppayya @jackye1995 @kbendick ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824430614/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824442288","html_url":"https://github.com/apache/iceberg/pull/2465#issuecomment-824442288","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2465","id":824442288,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDQ0MjI4OA==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-22T00:05:36Z","updated_at":"2021-04-22T00:08:34Z","author_association":"CONTRIBUTOR","body":"@rdblue @openinx sorry for the delayed update, I tried multiple different ways to implement this and went back and forth, and in the end the cleanest one I found was to use name to record all the identifier fields set, and at `applyChange` time, deletion of identifier column is checked before generating the new schema struct to validate deletion of identifier field, other validations are done after the new schema struct is generated.\r\n\r\nRyan talked about using 2 sets, one for existing IDs and one for new names. The issue with that approach was that the validation checks done for the 2 sets are very similar. For existing IDs, I need to check recursively that all the parents of the field up to root are struct, which can be done using `idToParent` index. For new names, I need to do something very similar, but also merge the `IdToParent` with the parent information of newly added fields. So in the end the code was very similar to just creating a new schema and recreating the `IdToParent` index and a bit redundant. Combining those two facts, I think it is much cleaner to just store everything as name and then validate name and resolve back to ID after the new schema struct is generated.\r\n\r\nRyan also talked about building an index of added name to ID when adding new columns, and with this approach that is not needed because the new schema would have that index when calling `findField`. I think that is a win to not increase complexity in `addColumn` and avoid new indexes in `UpdateSchema`.\r\n\r\nI can also do the `deletes` check in the validation function, but in the end I chose to do it in a separated code block before generating the schema struct, because doing it in the validation method requires passing in many arguments, and that flow was not intuitive to code readers, it only increased the complexity of the code and reduced readability.\r\n\r\nThere are some other methods I tried, such as filtering all potential identifier fields in schema and then check if the identifiers are in that potential set. But that approach could not produce informative error message so I did not go with that route.\r\n\r\nI have added some more tests to cover all possible use cases, please let me know if you have any additional concern with the approach.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824442288/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824467832","html_url":"https://github.com/apache/iceberg/pull/2372#issuecomment-824467832","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2372","id":824467832,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDQ2NzgzMg==","user":{"login":"chenjunjiedada","id":3960228,"node_id":"MDQ6VXNlcjM5NjAyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3960228?v=4","gravatar_id":"","url":"https://api.github.com/users/chenjunjiedada","html_url":"https://github.com/chenjunjiedada","followers_url":"https://api.github.com/users/chenjunjiedada/followers","following_url":"https://api.github.com/users/chenjunjiedada/following{/other_user}","gists_url":"https://api.github.com/users/chenjunjiedada/gists{/gist_id}","starred_url":"https://api.github.com/users/chenjunjiedada/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chenjunjiedada/subscriptions","organizations_url":"https://api.github.com/users/chenjunjiedada/orgs","repos_url":"https://api.github.com/users/chenjunjiedada/repos","events_url":"https://api.github.com/users/chenjunjiedada/events{/privacy}","received_events_url":"https://api.github.com/users/chenjunjiedada/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-22T01:22:52Z","updated_at":"2021-04-22T01:22:52Z","author_association":"COLLABORATOR","body":"cc @aokolnychyi @RussellSpitzer as well. You guys may want to take a look at the delete file as well.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824467832/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824582275","html_url":"https://github.com/apache/iceberg/issues/2504#issuecomment-824582275","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2504","id":824582275,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDU4MjI3NQ==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-22T06:40:38Z","updated_at":"2021-04-22T06:40:38Z","author_association":"MEMBER","body":"@ayush-san ,  I think that's because we've maintained all the keys that come from the same checkpoint in a __in-memory__  HashMap, it mainly used to locate the `<file_id, pos>` for the rows that was written in the current checkpoint before.  In the long run, we need to change this HashMap to a Map that can spill to disk or replace it with an embedded KV lib, so that we can take on a larger number of rows in a single checkpoint.  [This](https://docs.google.com/presentation/d/18xL5hhGfJKEVJyv-fbfoLYWgioRMqoEutpKFDjXhyKA/edit#slide=id.gb479a3dd40_0_948) would be a good document to describe the current design.\r\n\r\nFYI @rdblue .","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824582275/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824615294","html_url":"https://github.com/apache/iceberg/issues/2504#issuecomment-824615294","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2504","id":824615294,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDYxNTI5NA==","user":{"login":"ayush-san","id":57655135,"node_id":"MDQ6VXNlcjU3NjU1MTM1","avatar_url":"https://avatars.githubusercontent.com/u/57655135?v=4","gravatar_id":"","url":"https://api.github.com/users/ayush-san","html_url":"https://github.com/ayush-san","followers_url":"https://api.github.com/users/ayush-san/followers","following_url":"https://api.github.com/users/ayush-san/following{/other_user}","gists_url":"https://api.github.com/users/ayush-san/gists{/gist_id}","starred_url":"https://api.github.com/users/ayush-san/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ayush-san/subscriptions","organizations_url":"https://api.github.com/users/ayush-san/orgs","repos_url":"https://api.github.com/users/ayush-san/repos","events_url":"https://api.github.com/users/ayush-san/events{/privacy}","received_events_url":"https://api.github.com/users/ayush-san/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-22T07:37:27Z","updated_at":"2021-04-22T07:37:49Z","author_association":"NONE","body":"@openinx What should be the immediate solution for now? I can think of two ways\r\n* Increase the job and task manager memory and keep the checkpoint the same\r\n* During the initial few hours, reduce the checkpoint to 1 min or 2 mins","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824615294/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824981288","html_url":"https://github.com/apache/iceberg/pull/2500#issuecomment-824981288","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2500","id":824981288,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNDk4MTI4OA==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-22T16:13:53Z","updated_at":"2021-04-22T16:13:53Z","author_association":"CONTRIBUTOR","body":"Thanks for reviewing, @flyrain @RussellSpitzer @szehon-ho! I'll merge this to unblock subsequent PRs.\r\n\r\nIf there are any late comments, I'll address them in a follow-up.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/824981288/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825059274","html_url":"https://github.com/apache/iceberg/pull/2494#issuecomment-825059274","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2494","id":825059274,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNTA1OTI3NA==","user":{"login":"marton-bod","id":19599214,"node_id":"MDQ6VXNlcjE5NTk5MjE0","avatar_url":"https://avatars.githubusercontent.com/u/19599214?v=4","gravatar_id":"","url":"https://api.github.com/users/marton-bod","html_url":"https://github.com/marton-bod","followers_url":"https://api.github.com/users/marton-bod/followers","following_url":"https://api.github.com/users/marton-bod/following{/other_user}","gists_url":"https://api.github.com/users/marton-bod/gists{/gist_id}","starred_url":"https://api.github.com/users/marton-bod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marton-bod/subscriptions","organizations_url":"https://api.github.com/users/marton-bod/orgs","repos_url":"https://api.github.com/users/marton-bod/repos","events_url":"https://api.github.com/users/marton-bod/events{/privacy}","received_events_url":"https://api.github.com/users/marton-bod/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-22T17:48:47Z","updated_at":"2021-04-22T17:48:47Z","author_association":"COLLABORATOR","body":"@aokolnychyi @RussellSpitzer Thanks for reviewing this!\r\nAs I see it now, the only outstanding thing is deprecating this method and otherwise good to go? https://github.com/apache/iceberg/pull/2494/commits/3d499cda445adbaf7c6ce7a529169a2d256e5159#diff-e9befa3e2e58983fca27df05bd7d62b673c327261522e3894bb5fc6d4800f17dR270\r\nThank you! cc @lcspinter ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825059274/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825356399","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-825356399","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":825356399,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNTM1NjM5OQ==","user":{"login":"chenjunjiedada","id":3960228,"node_id":"MDQ6VXNlcjM5NjAyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3960228?v=4","gravatar_id":"","url":"https://api.github.com/users/chenjunjiedada","html_url":"https://github.com/chenjunjiedada","followers_url":"https://api.github.com/users/chenjunjiedada/followers","following_url":"https://api.github.com/users/chenjunjiedada/following{/other_user}","gists_url":"https://api.github.com/users/chenjunjiedada/gists{/gist_id}","starred_url":"https://api.github.com/users/chenjunjiedada/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chenjunjiedada/subscriptions","organizations_url":"https://api.github.com/users/chenjunjiedada/orgs","repos_url":"https://api.github.com/users/chenjunjiedada/repos","events_url":"https://api.github.com/users/chenjunjiedada/events{/privacy}","received_events_url":"https://api.github.com/users/chenjunjiedada/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-23T03:15:24Z","updated_at":"2021-04-23T03:15:24Z","author_association":"COLLABORATOR","body":"I thought it is caused by the `ManifestFileUtil` bug. But we had fixed that issue internally.  After digging more, we found this is caused by our internal flink iceberg sink which appends manifest without partition summary. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825356399/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825365008","html_url":"https://github.com/apache/iceberg/pull/2465#issuecomment-825365008","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2465","id":825365008,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNTM2NTAwOA==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-23T03:45:29Z","updated_at":"2021-04-23T03:45:29Z","author_association":"MEMBER","body":"The current patch looks good to me overall,  I just left few minor comments.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825365008/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825419521","html_url":"https://github.com/apache/iceberg/pull/2465#issuecomment-825419521","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2465","id":825419521,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNTQxOTUyMQ==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-23T06:21:55Z","updated_at":"2021-04-23T06:21:55Z","author_association":"CONTRIBUTOR","body":"@openinx thanks, fixed based on your comments","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825419521/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825548700","html_url":"https://github.com/apache/iceberg/pull/2499#issuecomment-825548700","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2499","id":825548700,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNTU0ODcwMA==","user":{"login":"szehon-ho","id":20555759,"node_id":"MDQ6VXNlcjIwNTU1NzU5","avatar_url":"https://avatars.githubusercontent.com/u/20555759?v=4","gravatar_id":"","url":"https://api.github.com/users/szehon-ho","html_url":"https://github.com/szehon-ho","followers_url":"https://api.github.com/users/szehon-ho/followers","following_url":"https://api.github.com/users/szehon-ho/following{/other_user}","gists_url":"https://api.github.com/users/szehon-ho/gists{/gist_id}","starred_url":"https://api.github.com/users/szehon-ho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szehon-ho/subscriptions","organizations_url":"https://api.github.com/users/szehon-ho/orgs","repos_url":"https://api.github.com/users/szehon-ho/repos","events_url":"https://api.github.com/users/szehon-ho/events{/privacy}","received_events_url":"https://api.github.com/users/szehon-ho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-23T10:01:50Z","updated_at":"2021-04-23T10:01:50Z","author_association":"COLLABORATOR","body":"Hi Russell, yea its just a code cleanup.\r\n\r\nBoth the aforementioned PR's (#2362 and #2240) noticed there's 4 versions of the SparkAppenderFactory  Constructor and that it becomes harder and harder to add new things, and can be cleaner like this.\r\n\r\nI noticed that I added an extraneous sort-order pointer as part of copy and paste from my PR (#2240), and removed it as its now redundant with the table added by the #2362, updated the PR with the small fix \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825548700/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825573758","html_url":"https://github.com/apache/iceberg/pull/2496#issuecomment-825573758","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2496","id":825573758,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNTU3Mzc1OA==","user":{"login":"rymurr","id":2022305,"node_id":"MDQ6VXNlcjIwMjIzMDU=","avatar_url":"https://avatars.githubusercontent.com/u/2022305?v=4","gravatar_id":"","url":"https://api.github.com/users/rymurr","html_url":"https://github.com/rymurr","followers_url":"https://api.github.com/users/rymurr/followers","following_url":"https://api.github.com/users/rymurr/following{/other_user}","gists_url":"https://api.github.com/users/rymurr/gists{/gist_id}","starred_url":"https://api.github.com/users/rymurr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymurr/subscriptions","organizations_url":"https://api.github.com/users/rymurr/orgs","repos_url":"https://api.github.com/users/rymurr/repos","events_url":"https://api.github.com/users/rymurr/events{/privacy}","received_events_url":"https://api.github.com/users/rymurr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-23T10:48:50Z","updated_at":"2021-04-23T10:48:50Z","author_association":"CONTRIBUTOR","body":"I agree w/ @RussellSpitzer on complex types. How would a deeply nested structure look w/ default types?\r\n\r\nI can definitely see the value in default values but I am having a hard time figuring out all the downstream effects: how does Spark handle these, how do they work in the Arrow based vectorised readers etc. Some more context on the effects on other systems would be useful for me to understand this change better.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825573758/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825662958","html_url":"https://github.com/apache/iceberg/pull/2304#issuecomment-825662958","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2304","id":825662958,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNTY2Mjk1OA==","user":{"login":"rymurr","id":2022305,"node_id":"MDQ6VXNlcjIwMjIzMDU=","avatar_url":"https://avatars.githubusercontent.com/u/2022305?v=4","gravatar_id":"","url":"https://api.github.com/users/rymurr","html_url":"https://github.com/rymurr","followers_url":"https://api.github.com/users/rymurr/followers","following_url":"https://api.github.com/users/rymurr/following{/other_user}","gists_url":"https://api.github.com/users/rymurr/gists{/gist_id}","starred_url":"https://api.github.com/users/rymurr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymurr/subscriptions","organizations_url":"https://api.github.com/users/rymurr/orgs","repos_url":"https://api.github.com/users/rymurr/repos","events_url":"https://api.github.com/users/rymurr/events{/privacy}","received_events_url":"https://api.github.com/users/rymurr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-23T13:35:28Z","updated_at":"2021-04-23T13:35:28Z","author_association":"CONTRIBUTOR","body":"ping @rdblue was wondering what you thought of this.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825662958/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825742484","html_url":"https://github.com/apache/iceberg/issues/2435#issuecomment-825742484","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2435","id":825742484,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNTc0MjQ4NA==","user":{"login":"szehon-ho","id":20555759,"node_id":"MDQ6VXNlcjIwNTU1NzU5","avatar_url":"https://avatars.githubusercontent.com/u/20555759?v=4","gravatar_id":"","url":"https://api.github.com/users/szehon-ho","html_url":"https://github.com/szehon-ho","followers_url":"https://api.github.com/users/szehon-ho/followers","following_url":"https://api.github.com/users/szehon-ho/following{/other_user}","gists_url":"https://api.github.com/users/szehon-ho/gists{/gist_id}","starred_url":"https://api.github.com/users/szehon-ho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szehon-ho/subscriptions","organizations_url":"https://api.github.com/users/szehon-ho/orgs","repos_url":"https://api.github.com/users/szehon-ho/repos","events_url":"https://api.github.com/users/szehon-ho/events{/privacy}","received_events_url":"https://api.github.com/users/szehon-ho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-23T15:37:35Z","updated_at":"2021-04-23T15:37:45Z","author_association":"COLLABORATOR","body":"Hi guys, looking through the code there doesn't seem any good way other than making a new kind of FileScanTask, that not only has Files but also the ManifestFile it came from (so that during the spark job, it can identify the manifestFile as updated).\r\n\r\nIf you guys have time to see, is it in line with your thoughts and if there are any clean way to do it?  Putting it in BaseFileScanTask is acceptable? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825742484/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825745780","html_url":"https://github.com/apache/iceberg/issues/2435#issuecomment-825745780","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2435","id":825745780,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNTc0NTc4MA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-23T15:42:46Z","updated_at":"2021-04-23T15:42:46Z","author_association":"MEMBER","body":"@szehon-ho I'm not sure I understand what you are asking?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825745780/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825992281","html_url":"https://github.com/apache/iceberg/pull/2286#issuecomment-825992281","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2286","id":825992281,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNTk5MjI4MQ==","user":{"login":"mayursrivastava","id":8659624,"node_id":"MDQ6VXNlcjg2NTk2MjQ=","avatar_url":"https://avatars.githubusercontent.com/u/8659624?v=4","gravatar_id":"","url":"https://api.github.com/users/mayursrivastava","html_url":"https://github.com/mayursrivastava","followers_url":"https://api.github.com/users/mayursrivastava/followers","following_url":"https://api.github.com/users/mayursrivastava/following{/other_user}","gists_url":"https://api.github.com/users/mayursrivastava/gists{/gist_id}","starred_url":"https://api.github.com/users/mayursrivastava/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayursrivastava/subscriptions","organizations_url":"https://api.github.com/users/mayursrivastava/orgs","repos_url":"https://api.github.com/users/mayursrivastava/repos","events_url":"https://api.github.com/users/mayursrivastava/events{/privacy}","received_events_url":"https://api.github.com/users/mayursrivastava/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-23T23:32:44Z","updated_at":"2021-04-23T23:32:44Z","author_association":"CONTRIBUTOR","body":"Hi @rymurr, I ran the benchmark and the results are listed below.  \r\n\r\nCommand:\r\n\r\n```\r\n./gradlew :iceberg-spark2:jmh -PjmhIncludeRegex=VectorizedReadFlatParquetDataBenchmark -PjmhOutputPath=benchmark/results.txt\r\n```\r\n\r\nResults:\r\n\r\n```\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDatesIcebergVectorized5k\r\n\r\n# Run progress: 0.00% complete, ETA 00:00:00\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 2.089 s/op\r\n# Warmup Iteration   2: 1.616 s/op\r\n# Warmup Iteration   3: 1.539 s/op\r\nIteration   1: 1.561 s/op\r\nIteration   2: 1.453 s/op\r\nIteration   3: 1.483 s/op\r\nIteration   4: 1.444 s/op\r\nIteration   5: 1.482 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDatesIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      1.485 (99.9%) 0.178 s/op\r\n\r\n  Histogram, s/op:\r\n    [1.400, 1.413) = 0 \r\n    [1.413, 1.425) = 0 \r\n    [1.425, 1.438) = 0 \r\n    [1.438, 1.450) = 1 \r\n    [1.450, 1.463) = 1 \r\n    [1.463, 1.475) = 0 \r\n    [1.475, 1.488) = 2 \r\n    [1.488, 1.500) = 0 \r\n    [1.500, 1.513) = 0 \r\n    [1.513, 1.525) = 0 \r\n    [1.525, 1.538) = 0 \r\n    [1.538, 1.550) = 0 \r\n    [1.550, 1.563) = 1 \r\n    [1.563, 1.575) = 0 \r\n    [1.575, 1.588) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      1.444 s/op\r\n     p(50.0000) =      1.482 s/op\r\n     p(90.0000) =      1.561 s/op\r\n     p(95.0000) =      1.561 s/op\r\n     p(99.0000) =      1.561 s/op\r\n     p(99.9000) =      1.561 s/op\r\n     p(99.9900) =      1.561 s/op\r\n     p(99.9990) =      1.561 s/op\r\n     p(99.9999) =      1.561 s/op\r\n    p(100.0000) =      1.561 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDatesSparkVectorized5k\r\n\r\n# Run progress: 6.25% complete, ETA 00:52:39\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 1.971 s/op\r\n# Warmup Iteration   2: 1.503 s/op\r\n# Warmup Iteration   3: 1.522 s/op\r\nIteration   1: 1.476 s/op\r\nIteration   2: 1.448 s/op\r\nIteration   3: 1.490 s/op\r\nIteration   4: 1.421 s/op\r\nIteration   5: 1.480 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDatesSparkVectorized5k\":\r\n  N = 5\r\n  mean =      1.463 (99.9%) 0.108 s/op\r\n\r\n  Histogram, s/op:\r\n    [1.420, 1.425) = 1 \r\n    [1.425, 1.430) = 0 \r\n    [1.430, 1.435) = 0 \r\n    [1.435, 1.440) = 0 \r\n    [1.440, 1.445) = 0 \r\n    [1.445, 1.450) = 1 \r\n    [1.450, 1.455) = 0 \r\n    [1.455, 1.460) = 0 \r\n    [1.460, 1.465) = 0 \r\n    [1.465, 1.470) = 0 \r\n    [1.470, 1.475) = 0 \r\n    [1.475, 1.480) = 2 \r\n    [1.480, 1.485) = 0 \r\n    [1.485, 1.490) = 0 \r\n    [1.490, 1.495) = 1 \r\n    [1.495, 1.500) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      1.421 s/op\r\n     p(50.0000) =      1.476 s/op\r\n     p(90.0000) =      1.490 s/op\r\n     p(95.0000) =      1.490 s/op\r\n     p(99.0000) =      1.490 s/op\r\n     p(99.9000) =      1.490 s/op\r\n     p(99.9900) =      1.490 s/op\r\n     p(99.9990) =      1.490 s/op\r\n     p(99.9999) =      1.490 s/op\r\n    p(100.0000) =      1.490 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDecimalsIcebergVectorized5k\r\n\r\n# Run progress: 12.50% complete, ETA 00:50:03\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 9.773 s/op\r\n# Warmup Iteration   2: 9.007 s/op\r\n# Warmup Iteration   3: 8.929 s/op\r\nIteration   1: 8.875 s/op\r\nIteration   2: 8.893 s/op\r\nIteration   3: 8.946 s/op\r\nIteration   4: 8.916 s/op\r\nIteration   5: 8.880 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDecimalsIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      8.902 (99.9%) 0.112 s/op\r\n\r\n  Histogram, s/op:\r\n    [8.870, 8.875) = 0 \r\n    [8.875, 8.880) = 1 \r\n    [8.880, 8.885) = 1 \r\n    [8.885, 8.890) = 0 \r\n    [8.890, 8.895) = 1 \r\n    [8.895, 8.900) = 0 \r\n    [8.900, 8.905) = 0 \r\n    [8.905, 8.910) = 0 \r\n    [8.910, 8.915) = 0 \r\n    [8.915, 8.920) = 1 \r\n    [8.920, 8.925) = 0 \r\n    [8.925, 8.930) = 0 \r\n    [8.930, 8.935) = 0 \r\n    [8.935, 8.940) = 0 \r\n    [8.940, 8.945) = 0 \r\n    [8.945, 8.950) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      8.875 s/op\r\n     p(50.0000) =      8.893 s/op\r\n     p(90.0000) =      8.946 s/op\r\n     p(95.0000) =      8.946 s/op\r\n     p(99.0000) =      8.946 s/op\r\n     p(99.9000) =      8.946 s/op\r\n     p(99.9900) =      8.946 s/op\r\n     p(99.9990) =      8.946 s/op\r\n     p(99.9999) =      8.946 s/op\r\n    p(100.0000) =      8.946 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDecimalsSparkVectorized5k\r\n\r\n# Run progress: 18.75% complete, ETA 00:50:50\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 9.365 s/op\r\n# Warmup Iteration   2: 8.648 s/op\r\n# Warmup Iteration   3: 8.669 s/op\r\nIteration   1: 8.648 s/op\r\nIteration   2: 8.612 s/op\r\nIteration   3: 8.655 s/op\r\nIteration   4: 8.630 s/op\r\nIteration   5: 8.647 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDecimalsSparkVectorized5k\":\r\n  N = 5\r\n  mean =      8.638 (99.9%) 0.067 s/op\r\n\r\n  Histogram, s/op:\r\n    [8.610, 8.615) = 1 \r\n    [8.615, 8.620) = 0 \r\n    [8.620, 8.625) = 0 \r\n    [8.625, 8.630) = 0 \r\n    [8.630, 8.635) = 1 \r\n    [8.635, 8.640) = 0 \r\n    [8.640, 8.645) = 0 \r\n    [8.645, 8.650) = 2 \r\n    [8.650, 8.655) = 1 \r\n    [8.655, 8.660) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      8.612 s/op\r\n     p(50.0000) =      8.647 s/op\r\n     p(90.0000) =      8.655 s/op\r\n     p(95.0000) =      8.655 s/op\r\n     p(99.0000) =      8.655 s/op\r\n     p(99.9000) =      8.655 s/op\r\n     p(99.9900) =      8.655 s/op\r\n     p(99.9990) =      8.655 s/op\r\n     p(99.9999) =      8.655 s/op\r\n    p(100.0000) =      8.655 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDoublesIcebergVectorized5k\r\n\r\n# Run progress: 25.00% complete, ETA 00:48:46\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.312 s/op\r\n# Warmup Iteration   2: 2.751 s/op\r\n# Warmup Iteration   3: 2.661 s/op\r\nIteration   1: 2.567 s/op\r\nIteration   2: 2.612 s/op\r\nIteration   3: 2.659 s/op\r\nIteration   4: 2.594 s/op\r\nIteration   5: 2.632 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDoublesIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      2.613 (99.9%) 0.135 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.560, 2.570) = 1 \r\n    [2.570, 2.580) = 0 \r\n    [2.580, 2.590) = 0 \r\n    [2.590, 2.600) = 1 \r\n    [2.600, 2.610) = 0 \r\n    [2.610, 2.620) = 1 \r\n    [2.620, 2.630) = 0 \r\n    [2.630, 2.640) = 1 \r\n    [2.640, 2.650) = 0 \r\n    [2.650, 2.660) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.567 s/op\r\n     p(50.0000) =      2.612 s/op\r\n     p(90.0000) =      2.659 s/op\r\n     p(95.0000) =      2.659 s/op\r\n     p(99.0000) =      2.659 s/op\r\n     p(99.9000) =      2.659 s/op\r\n     p(99.9900) =      2.659 s/op\r\n     p(99.9990) =      2.659 s/op\r\n     p(99.9999) =      2.659 s/op\r\n    p(100.0000) =      2.659 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDoublesSparkVectorized5k\r\n\r\n# Run progress: 31.25% complete, ETA 00:43:59\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.136 s/op\r\n# Warmup Iteration   2: 2.547 s/op\r\n# Warmup Iteration   3: 2.515 s/op\r\nIteration   1: 2.479 s/op\r\nIteration   2: 2.409 s/op\r\nIteration   3: 2.420 s/op\r\nIteration   4: 2.394 s/op\r\nIteration   5: 2.404 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDoublesSparkVectorized5k\":\r\n  N = 5\r\n  mean =      2.421 (99.9%) 0.131 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.390, 2.395) = 1 \r\n    [2.395, 2.400) = 0 \r\n    [2.400, 2.405) = 1 \r\n    [2.405, 2.410) = 1 \r\n    [2.410, 2.415) = 0 \r\n    [2.415, 2.420) = 1 \r\n    [2.420, 2.425) = 0 \r\n    [2.425, 2.430) = 0 \r\n    [2.430, 2.435) = 0 \r\n    [2.435, 2.440) = 0 \r\n    [2.440, 2.445) = 0 \r\n    [2.445, 2.450) = 0 \r\n    [2.450, 2.455) = 0 \r\n    [2.455, 2.460) = 0 \r\n    [2.460, 2.465) = 0 \r\n    [2.465, 2.470) = 0 \r\n    [2.470, 2.475) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.394 s/op\r\n     p(50.0000) =      2.409 s/op\r\n     p(90.0000) =      2.479 s/op\r\n     p(95.0000) =      2.479 s/op\r\n     p(99.0000) =      2.479 s/op\r\n     p(99.9000) =      2.479 s/op\r\n     p(99.9900) =      2.479 s/op\r\n     p(99.9990) =      2.479 s/op\r\n     p(99.9999) =      2.479 s/op\r\n    p(100.0000) =      2.479 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readFloatsIcebergVectorized5k\r\n\r\n# Run progress: 37.50% complete, ETA 00:39:34\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.092 s/op\r\n# Warmup Iteration   2: 2.515 s/op\r\n# Warmup Iteration   3: 2.491 s/op\r\nIteration   1: 2.455 s/op\r\nIteration   2: 2.465 s/op\r\nIteration   3: 2.482 s/op\r\nIteration   4: 2.434 s/op\r\nIteration   5: 2.418 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readFloatsIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      2.451 (99.9%) 0.098 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.410, 2.415) = 0 \r\n    [2.415, 2.420) = 1 \r\n    [2.420, 2.425) = 0 \r\n    [2.425, 2.430) = 0 \r\n    [2.430, 2.435) = 1 \r\n    [2.435, 2.440) = 0 \r\n    [2.440, 2.445) = 0 \r\n    [2.445, 2.450) = 0 \r\n    [2.450, 2.455) = 0 \r\n    [2.455, 2.460) = 1 \r\n    [2.460, 2.465) = 0 \r\n    [2.465, 2.470) = 1 \r\n    [2.470, 2.475) = 0 \r\n    [2.475, 2.480) = 0 \r\n    [2.480, 2.485) = 1 \r\n    [2.485, 2.490) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.418 s/op\r\n     p(50.0000) =      2.455 s/op\r\n     p(90.0000) =      2.482 s/op\r\n     p(95.0000) =      2.482 s/op\r\n     p(99.0000) =      2.482 s/op\r\n     p(99.9000) =      2.482 s/op\r\n     p(99.9900) =      2.482 s/op\r\n     p(99.9990) =      2.482 s/op\r\n     p(99.9999) =      2.482 s/op\r\n    p(100.0000) =      2.482 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readFloatsSparkVectorized5k\r\n\r\n# Run progress: 43.75% complete, ETA 00:35:22\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.106 s/op\r\n# Warmup Iteration   2: 2.391 s/op\r\n# Warmup Iteration   3: 2.364 s/op\r\nIteration   1: 2.317 s/op\r\nIteration   2: 2.261 s/op\r\nIteration   3: 2.306 s/op\r\nIteration   4: 2.272 s/op\r\nIteration   5: 2.291 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readFloatsSparkVectorized5k\":\r\n  N = 5\r\n  mean =      2.289 (99.9%) 0.089 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.260, 2.265) = 1 \r\n    [2.265, 2.270) = 0 \r\n    [2.270, 2.275) = 1 \r\n    [2.275, 2.280) = 0 \r\n    [2.280, 2.285) = 0 \r\n    [2.285, 2.290) = 0 \r\n    [2.290, 2.295) = 1 \r\n    [2.295, 2.300) = 0 \r\n    [2.300, 2.305) = 0 \r\n    [2.305, 2.310) = 1 \r\n    [2.310, 2.315) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.261 s/op\r\n     p(50.0000) =      2.291 s/op\r\n     p(90.0000) =      2.317 s/op\r\n     p(95.0000) =      2.317 s/op\r\n     p(99.0000) =      2.317 s/op\r\n     p(99.9000) =      2.317 s/op\r\n     p(99.9900) =      2.317 s/op\r\n     p(99.9990) =      2.317 s/op\r\n     p(99.9999) =      2.317 s/op\r\n    p(100.0000) =      2.317 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readIntegersIcebergVectorized5k\r\n\r\n# Run progress: 50.00% complete, ETA 00:31:14\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.161 s/op\r\n# Warmup Iteration   2: 2.559 s/op\r\n# Warmup Iteration   3: 2.539 s/op\r\nIteration   1: 2.449 s/op\r\nIteration   2: 2.454 s/op\r\nIteration   3: 2.527 s/op\r\nIteration   4: 2.474 s/op\r\nIteration   5: 2.503 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readIntegersIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      2.481 (99.9%) 0.128 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.440, 2.445) = 0 \r\n    [2.445, 2.450) = 1 \r\n    [2.450, 2.455) = 1 \r\n    [2.455, 2.460) = 0 \r\n    [2.460, 2.465) = 0 \r\n    [2.465, 2.470) = 0 \r\n    [2.470, 2.475) = 1 \r\n    [2.475, 2.480) = 0 \r\n    [2.480, 2.485) = 0 \r\n    [2.485, 2.490) = 0 \r\n    [2.490, 2.495) = 0 \r\n    [2.495, 2.500) = 0 \r\n    [2.500, 2.505) = 1 \r\n    [2.505, 2.510) = 0 \r\n    [2.510, 2.515) = 0 \r\n    [2.515, 2.520) = 0 \r\n    [2.520, 2.525) = 0 \r\n    [2.525, 2.530) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.449 s/op\r\n     p(50.0000) =      2.474 s/op\r\n     p(90.0000) =      2.527 s/op\r\n     p(95.0000) =      2.527 s/op\r\n     p(99.0000) =      2.527 s/op\r\n     p(99.9000) =      2.527 s/op\r\n     p(99.9900) =      2.527 s/op\r\n     p(99.9990) =      2.527 s/op\r\n     p(99.9999) =      2.527 s/op\r\n    p(100.0000) =      2.527 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readIntegersSparkVectorized5k\r\n\r\n# Run progress: 56.25% complete, ETA 00:27:11\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.138 s/op\r\n# Warmup Iteration   2: 2.358 s/op\r\n# Warmup Iteration   3: 2.344 s/op\r\nIteration   1: 2.272 s/op\r\nIteration   2: 2.251 s/op\r\nIteration   3: 2.277 s/op\r\nIteration   4: 2.233 s/op\r\nIteration   5: 2.238 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readIntegersSparkVectorized5k\":\r\n  N = 5\r\n  mean =      2.254 (99.9%) 0.076 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.230, 2.235) = 1 \r\n    [2.235, 2.240) = 1 \r\n    [2.240, 2.245) = 0 \r\n    [2.245, 2.250) = 0 \r\n    [2.250, 2.255) = 1 \r\n    [2.255, 2.260) = 0 \r\n    [2.260, 2.265) = 0 \r\n    [2.265, 2.270) = 0 \r\n    [2.270, 2.275) = 1 \r\n    [2.275, 2.280) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.233 s/op\r\n     p(50.0000) =      2.251 s/op\r\n     p(90.0000) =      2.277 s/op\r\n     p(95.0000) =      2.277 s/op\r\n     p(99.0000) =      2.277 s/op\r\n     p(99.9000) =      2.277 s/op\r\n     p(99.9900) =      2.277 s/op\r\n     p(99.9990) =      2.277 s/op\r\n     p(99.9999) =      2.277 s/op\r\n    p(100.0000) =      2.277 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readLongsIcebergVectorized5k\r\n\r\n# Run progress: 62.50% complete, ETA 00:23:12\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.201 s/op\r\n# Warmup Iteration   2: 2.687 s/op\r\n# Warmup Iteration   3: 2.602 s/op\r\nIteration   1: 2.505 s/op\r\nIteration   2: 2.506 s/op\r\nIteration   3: 2.585 s/op\r\nIteration   4: 2.512 s/op\r\nIteration   5: 2.565 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readLongsIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      2.535 (99.9%) 0.144 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.500, 2.505) = 0 \r\n    [2.505, 2.510) = 2 \r\n    [2.510, 2.515) = 1 \r\n    [2.515, 2.520) = 0 \r\n    [2.520, 2.525) = 0 \r\n    [2.525, 2.530) = 0 \r\n    [2.530, 2.535) = 0 \r\n    [2.535, 2.540) = 0 \r\n    [2.540, 2.545) = 0 \r\n    [2.545, 2.550) = 0 \r\n    [2.550, 2.555) = 0 \r\n    [2.555, 2.560) = 0 \r\n    [2.560, 2.565) = 1 \r\n    [2.565, 2.570) = 0 \r\n    [2.570, 2.575) = 0 \r\n    [2.575, 2.580) = 0 \r\n    [2.580, 2.585) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.505 s/op\r\n     p(50.0000) =      2.512 s/op\r\n     p(90.0000) =      2.585 s/op\r\n     p(95.0000) =      2.585 s/op\r\n     p(99.0000) =      2.585 s/op\r\n     p(99.9000) =      2.585 s/op\r\n     p(99.9900) =      2.585 s/op\r\n     p(99.9990) =      2.585 s/op\r\n     p(99.9999) =      2.585 s/op\r\n    p(100.0000) =      2.585 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readLongsSparkVectorized5k\r\n\r\n# Run progress: 68.75% complete, ETA 00:19:18\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.144 s/op\r\n# Warmup Iteration   2: 2.515 s/op\r\n# Warmup Iteration   3: 2.425 s/op\r\nIteration   1: 2.421 s/op\r\nIteration   2: 2.354 s/op\r\nIteration   3: 2.362 s/op\r\nIteration   4: 2.355 s/op\r\nIteration   5: 2.328 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readLongsSparkVectorized5k\":\r\n  N = 5\r\n  mean =      2.364 (99.9%) 0.132 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.320, 2.330) = 1 \r\n    [2.330, 2.340) = 0 \r\n    [2.340, 2.350) = 0 \r\n    [2.350, 2.360) = 2 \r\n    [2.360, 2.370) = 1 \r\n    [2.370, 2.380) = 0 \r\n    [2.380, 2.390) = 0 \r\n    [2.390, 2.400) = 0 \r\n    [2.400, 2.410) = 0 \r\n    [2.410, 2.420) = 0 \r\n    [2.420, 2.430) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.328 s/op\r\n     p(50.0000) =      2.355 s/op\r\n     p(90.0000) =      2.421 s/op\r\n     p(95.0000) =      2.421 s/op\r\n     p(99.0000) =      2.421 s/op\r\n     p(99.9000) =      2.421 s/op\r\n     p(99.9900) =      2.421 s/op\r\n     p(99.9990) =      2.421 s/op\r\n     p(99.9999) =      2.421 s/op\r\n    p(100.0000) =      2.421 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readStringsIcebergVectorized5k\r\n\r\n# Run progress: 75.00% complete, ETA 00:15:25\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 4.920 s/op\r\n# Warmup Iteration   2: 4.326 s/op\r\n# Warmup Iteration   3: 4.209 s/op\r\nIteration   1: 4.156 s/op\r\nIteration   2: 4.128 s/op\r\nIteration   3: 4.224 s/op\r\nIteration   4: 4.189 s/op\r\nIteration   5: 4.182 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readStringsIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      4.176 (99.9%) 0.139 s/op\r\n\r\n  Histogram, s/op:\r\n    [4.120, 4.130) = 1 \r\n    [4.130, 4.140) = 0 \r\n    [4.140, 4.150) = 0 \r\n    [4.150, 4.160) = 1 \r\n    [4.160, 4.170) = 0 \r\n    [4.170, 4.180) = 0 \r\n    [4.180, 4.190) = 2 \r\n    [4.190, 4.200) = 0 \r\n    [4.200, 4.210) = 0 \r\n    [4.210, 4.220) = 0 \r\n    [4.220, 4.230) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      4.128 s/op\r\n     p(50.0000) =      4.182 s/op\r\n     p(90.0000) =      4.224 s/op\r\n     p(95.0000) =      4.224 s/op\r\n     p(99.0000) =      4.224 s/op\r\n     p(99.9000) =      4.224 s/op\r\n     p(99.9900) =      4.224 s/op\r\n     p(99.9990) =      4.224 s/op\r\n     p(99.9999) =      4.224 s/op\r\n    p(100.0000) =      4.224 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readStringsSparkVectorized5k\r\n\r\n# Run progress: 81.25% complete, ETA 00:11:36\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 4.754 s/op\r\n# Warmup Iteration   2: 4.098 s/op\r\n# Warmup Iteration   3: 4.068 s/op\r\nIteration   1: 4.017 s/op\r\nIteration   2: 3.976 s/op\r\nIteration   3: 3.989 s/op\r\nIteration   4: 3.976 s/op\r\nIteration   5: 3.989 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readStringsSparkVectorized5k\":\r\n  N = 5\r\n  mean =      3.989 (99.9%) 0.065 s/op\r\n\r\n  Histogram, s/op:\r\n    [3.970, 3.975) = 0 \r\n    [3.975, 3.980) = 2 \r\n    [3.980, 3.985) = 0 \r\n    [3.985, 3.990) = 2 \r\n    [3.990, 3.995) = 0 \r\n    [3.995, 4.000) = 0 \r\n    [4.000, 4.005) = 0 \r\n    [4.005, 4.010) = 0 \r\n    [4.010, 4.015) = 0 \r\n    [4.015, 4.020) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      3.976 s/op\r\n     p(50.0000) =      3.989 s/op\r\n     p(90.0000) =      4.017 s/op\r\n     p(95.0000) =      4.017 s/op\r\n     p(99.0000) =      4.017 s/op\r\n     p(99.9000) =      4.017 s/op\r\n     p(99.9900) =      4.017 s/op\r\n     p(99.9990) =      4.017 s/op\r\n     p(99.9999) =      4.017 s/op\r\n    p(100.0000) =      4.017 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readTimestampsIcebergVectorized5k\r\n\r\n# Run progress: 87.50% complete, ETA 00:07:45\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 2.098 s/op\r\n# Warmup Iteration   2: 1.681 s/op\r\n# Warmup Iteration   3: 1.606 s/op\r\nIteration   1: 1.543 s/op\r\nIteration   2: 1.495 s/op\r\nIteration   3: 1.554 s/op\r\nIteration   4: 1.550 s/op\r\nIteration   5: 1.530 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readTimestampsIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      1.534 (99.9%) 0.091 s/op\r\n\r\n  Histogram, s/op:\r\n    [1.490, 1.495) = 0 \r\n    [1.495, 1.500) = 1 \r\n    [1.500, 1.505) = 0 \r\n    [1.505, 1.510) = 0 \r\n    [1.510, 1.515) = 0 \r\n    [1.515, 1.520) = 0 \r\n    [1.520, 1.525) = 0 \r\n    [1.525, 1.530) = 1 \r\n    [1.530, 1.535) = 0 \r\n    [1.535, 1.540) = 0 \r\n    [1.540, 1.545) = 1 \r\n    [1.545, 1.550) = 1 \r\n    [1.550, 1.555) = 1 \r\n    [1.555, 1.560) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      1.495 s/op\r\n     p(50.0000) =      1.543 s/op\r\n     p(90.0000) =      1.554 s/op\r\n     p(95.0000) =      1.554 s/op\r\n     p(99.0000) =      1.554 s/op\r\n     p(99.9000) =      1.554 s/op\r\n     p(99.9900) =      1.554 s/op\r\n     p(99.9990) =      1.554 s/op\r\n     p(99.9999) =      1.554 s/op\r\n    p(100.0000) =      1.554 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readTimestampsSparkVectorized5k\r\n\r\n# Run progress: 93.75% complete, ETA 00:03:51\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 2.094 s/op\r\n# Warmup Iteration   2: 1.539 s/op\r\n# Warmup Iteration   3: 1.491 s/op\r\nIteration   1: 1.493 s/op\r\nIteration   2: 1.455 s/op\r\nIteration   3: 1.482 s/op\r\nIteration   4: 1.458 s/op\r\nIteration   5: 1.416 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readTimestampsSparkVectorized5k\":\r\n  N = 5\r\n  mean =      1.461 (99.9%) 0.114 s/op\r\n\r\n  Histogram, s/op:\r\n    [1.410, 1.415) = 0 \r\n    [1.415, 1.420) = 1 \r\n    [1.420, 1.425) = 0 \r\n    [1.425, 1.430) = 0 \r\n    [1.430, 1.435) = 0 \r\n    [1.435, 1.440) = 0 \r\n    [1.440, 1.445) = 0 \r\n    [1.445, 1.450) = 0 \r\n    [1.450, 1.455) = 0 \r\n    [1.455, 1.460) = 2 \r\n    [1.460, 1.465) = 0 \r\n    [1.465, 1.470) = 0 \r\n    [1.470, 1.475) = 0 \r\n    [1.475, 1.480) = 0 \r\n    [1.480, 1.485) = 1 \r\n    [1.485, 1.490) = 0 \r\n    [1.490, 1.495) = 1 \r\n    [1.495, 1.500) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      1.416 s/op\r\n     p(50.0000) =      1.458 s/op\r\n     p(90.0000) =      1.493 s/op\r\n     p(95.0000) =      1.493 s/op\r\n     p(99.0000) =      1.493 s/op\r\n     p(99.9000) =      1.493 s/op\r\n     p(99.9900) =      1.493 s/op\r\n     p(99.9990) =      1.493 s/op\r\n     p(99.9999) =      1.493 s/op\r\n    p(100.0000) =      1.493 s/op\r\n\r\n\r\n# Run complete. Total time: 01:01:35\r\n\r\nREMEMBER: The numbers below are just data. To gain reusable insights, you need to follow up on\r\nwhy the numbers are the way they are. Use profilers (see -prof, -lprof), design factorial\r\nexperiments, perform baseline and negative tests that provide experimental control, make sure\r\nthe benchmarking environment is safe on JVM/OS/HW level, ask for reviews from the domain experts.\r\nDo not assume the numbers tell you what you want them to tell.\r\n\r\nBenchmark                                                                 Mode  Cnt  Score   Error  Units\r\nVectorizedReadFlatParquetDataBenchmark.readDatesIcebergVectorized5k         ss    5  1.485  0.178   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readDatesSparkVectorized5k           ss    5  1.463  0.108   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readDecimalsIcebergVectorized5k      ss    5  8.902  0.112   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readDecimalsSparkVectorized5k        ss    5  8.638  0.067   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readDoublesIcebergVectorized5k       ss    5  2.613  0.135   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readDoublesSparkVectorized5k         ss    5  2.421  0.131   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readFloatsIcebergVectorized5k        ss    5  2.451  0.098   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readFloatsSparkVectorized5k          ss    5  2.289  0.089   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readIntegersIcebergVectorized5k      ss    5  2.481  0.128   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readIntegersSparkVectorized5k        ss    5  2.254  0.076   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readLongsIcebergVectorized5k         ss    5  2.535  0.144   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readLongsSparkVectorized5k           ss    5  2.364  0.132   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readStringsIcebergVectorized5k       ss    5  4.176  0.139   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readStringsSparkVectorized5k         ss    5  3.989  0.065   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readTimestampsIcebergVectorized5k    ss    5  1.534  0.091   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readTimestampsSparkVectorized5k      ss    5  1.461  0.114   s/op\r\n\r\nBenchmark result is saved to XXX/spark2/build/reports/jmh/results.txt\r\n\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/825992281/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826044912","html_url":"https://github.com/apache/iceberg/pull/2506#issuecomment-826044912","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2506","id":826044912,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjA0NDkxMg==","user":{"login":"findepi","id":144328,"node_id":"MDQ6VXNlcjE0NDMyOA==","avatar_url":"https://avatars.githubusercontent.com/u/144328?v=4","gravatar_id":"","url":"https://api.github.com/users/findepi","html_url":"https://github.com/findepi","followers_url":"https://api.github.com/users/findepi/followers","following_url":"https://api.github.com/users/findepi/following{/other_user}","gists_url":"https://api.github.com/users/findepi/gists{/gist_id}","starred_url":"https://api.github.com/users/findepi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/findepi/subscriptions","organizations_url":"https://api.github.com/users/findepi/orgs","repos_url":"https://api.github.com/users/findepi/repos","events_url":"https://api.github.com/users/findepi/events{/privacy}","received_events_url":"https://api.github.com/users/findepi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-24T06:42:59Z","updated_at":"2021-04-24T06:42:59Z","author_association":"MEMBER","body":"> The likelihood of the error is the same 1 over size of long right?\r\n\r\nSeems so. In fact, I don't know enough about UUID internal structure to judge this, so it could be also impossible.\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826044912/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826281826","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-826281826","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":826281826,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjI4MTgyNg==","user":{"login":"chenjunjiedada","id":3960228,"node_id":"MDQ6VXNlcjM5NjAyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3960228?v=4","gravatar_id":"","url":"https://api.github.com/users/chenjunjiedada","html_url":"https://github.com/chenjunjiedada","followers_url":"https://api.github.com/users/chenjunjiedada/followers","following_url":"https://api.github.com/users/chenjunjiedada/following{/other_user}","gists_url":"https://api.github.com/users/chenjunjiedada/gists{/gist_id}","starred_url":"https://api.github.com/users/chenjunjiedada/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chenjunjiedada/subscriptions","organizations_url":"https://api.github.com/users/chenjunjiedada/orgs","repos_url":"https://api.github.com/users/chenjunjiedada/repos","events_url":"https://api.github.com/users/chenjunjiedada/events{/privacy}","received_events_url":"https://api.github.com/users/chenjunjiedada/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-25T08:23:54Z","updated_at":"2021-04-25T08:35:18Z","author_association":"COLLABORATOR","body":"Still hit this problem.  Now I know how to reproduce this.\r\n\r\n1. Write the iceberg table with the 0.10.0 version.\r\n2. Read the iceberg table manifests with the 0.11.1 version.\r\n\r\n`ManifestTable.partitionSummarirsToRows` puts `summary.containsNaN()`,  which is null,  to the spark row that will be parsed to `Boolean` class and show out.\r\n\r\nThe following code could fix the issue but I think we should consider with #2495 as well:\r\n```\r\n--- a/api/src/main/java/org/apache/iceberg/ManifestFile.java\r\n+++ b/api/src/main/java/org/apache/iceberg/ManifestFile.java\r\n@@ -207,7 +207,7 @@ public interface ManifestFile {\r\n      * Default to return null to ensure backward compatibility.\r\n      */\r\n     default Boolean containsNaN() {\r\n-      return null;\r\n+      return true;\r\n     }\r\n \r\n     /**\r\n--- a/core/src/main/java/org/apache/iceberg/GenericPartitionFieldSummary.java\r\n+++ b/core/src/main/java/org/apache/iceberg/GenericPartitionFieldSummary.java\r\n@@ -121,7 +121,7 @@ public class GenericPartitionFieldSummary\r\n \r\n   @Override\r\n   public Boolean containsNaN() {\r\n-    return containsNaN;\r\n+    return containsNaN == null || containsNull;\r\n   }\r\n```\r\n\r\n@RussellSpitzer @yyanyy ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826281826/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826359240","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-826359240","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":826359240,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjM1OTI0MA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-25T17:27:27Z","updated_at":"2021-04-25T17:27:27Z","author_association":"MEMBER","body":"I think I have this fixed in #2495\n\nSent from my iPhone\n\n> On Apr 25, 2021, at 3:24 AM, Chen, Junjie ***@***.***> wrote:\n> \n> \n> Still hit this problem. Now I know how to reproduce this.\n> \n> Write the iceberg table with the 0.10.0 version.\n> Read the iceberg table manifests with the 0.11.1 version.\n> The following code could fix the issue:\n> \n> --- a/core/src/main/java/org/apache/iceberg/GenericPartitionFieldSummary.java\n> +++ b/core/src/main/java/org/apache/iceberg/GenericPartitionFieldSummary.java\n> @@ -121,7 +121,7 @@ public class GenericPartitionFieldSummary\n>  \n>    @Override\n>    public Boolean containsNaN() {\n> -    return containsNaN;\n> +    return containsNaN == null || containsNull;\n>    }\n> @RussellSpitzer @yyanyy, We may need to re-consider this with #2492 again.\n> \n> \n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or unsubscribe.\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826359240/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826398213","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-826398213","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":826398213,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjM5ODIxMw==","user":{"login":"yyanyy","id":71906210,"node_id":"MDQ6VXNlcjcxOTA2MjEw","avatar_url":"https://avatars.githubusercontent.com/u/71906210?v=4","gravatar_id":"","url":"https://api.github.com/users/yyanyy","html_url":"https://github.com/yyanyy","followers_url":"https://api.github.com/users/yyanyy/followers","following_url":"https://api.github.com/users/yyanyy/following{/other_user}","gists_url":"https://api.github.com/users/yyanyy/gists{/gist_id}","starred_url":"https://api.github.com/users/yyanyy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yyanyy/subscriptions","organizations_url":"https://api.github.com/users/yyanyy/orgs","repos_url":"https://api.github.com/users/yyanyy/repos","events_url":"https://api.github.com/users/yyanyy/events{/privacy}","received_events_url":"https://api.github.com/users/yyanyy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-25T22:12:38Z","updated_at":"2021-04-25T22:12:38Z","author_association":"CONTRIBUTOR","body":"I think it's expected that `summary.containsNaN()` could return null? looking from the code it seems that `StaticDataTask.Row` should also be able to handle null? when does the issue occur? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826398213/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826402145","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-826402145","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":826402145,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjQwMjE0NQ==","user":{"login":"chenjunjiedada","id":3960228,"node_id":"MDQ6VXNlcjM5NjAyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3960228?v=4","gravatar_id":"","url":"https://api.github.com/users/chenjunjiedada","html_url":"https://github.com/chenjunjiedada","followers_url":"https://api.github.com/users/chenjunjiedada/followers","following_url":"https://api.github.com/users/chenjunjiedada/following{/other_user}","gists_url":"https://api.github.com/users/chenjunjiedada/gists{/gist_id}","starred_url":"https://api.github.com/users/chenjunjiedada/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chenjunjiedada/subscriptions","organizations_url":"https://api.github.com/users/chenjunjiedada/orgs","repos_url":"https://api.github.com/users/chenjunjiedada/repos","events_url":"https://api.github.com/users/chenjunjiedada/events{/privacy}","received_events_url":"https://api.github.com/users/chenjunjiedada/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-25T22:46:35Z","updated_at":"2021-04-25T23:07:40Z","author_association":"COLLABORATOR","body":"@RussellSpitzer, `summary.containsNaN()` is called in two places, #2495 fixes one place. Another place is in #2509.\r\n\r\n@yyanyy , I thought not return null in `summary.containsNaN()` may fix the problem for all places, while I don't want to break the original assumption. There is also a unit test for the null value. This issue happens when reading manifests as a table.\r\n\r\n> ManifestTable.partitionSummarirsToRows puts summary.containsNaN(), which is null, to the spark row that will be parsed to Boolean class and show out.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826402145/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826402826","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-826402826","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":826402826,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjQwMjgyNg==","user":{"login":"chenjunjiedada","id":3960228,"node_id":"MDQ6VXNlcjM5NjAyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3960228?v=4","gravatar_id":"","url":"https://api.github.com/users/chenjunjiedada","html_url":"https://github.com/chenjunjiedada","followers_url":"https://api.github.com/users/chenjunjiedada/followers","following_url":"https://api.github.com/users/chenjunjiedada/following{/other_user}","gists_url":"https://api.github.com/users/chenjunjiedada/gists{/gist_id}","starred_url":"https://api.github.com/users/chenjunjiedada/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chenjunjiedada/subscriptions","organizations_url":"https://api.github.com/users/chenjunjiedada/orgs","repos_url":"https://api.github.com/users/chenjunjiedada/repos","events_url":"https://api.github.com/users/chenjunjiedada/events{/privacy}","received_events_url":"https://api.github.com/users/chenjunjiedada/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-25T22:52:50Z","updated_at":"2021-04-25T22:52:50Z","author_association":"COLLABORATOR","body":"@yyanyy Looks like `StaticDataTask.Row` doesn't handle the null case. Do you think we should fix in that?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826402826/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826456799","html_url":"https://github.com/apache/iceberg/pull/2509#issuecomment-826456799","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2509","id":826456799,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjQ1Njc5OQ==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T02:19:15Z","updated_at":"2021-04-26T02:19:15Z","author_association":"MEMBER","body":"@chenjunjiedada ,  Is it possible to provide an unit tests to covert the case ?  I'd like to understand the internal reason that why do we need to fix this.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826456799/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826460930","html_url":"https://github.com/apache/iceberg/pull/2510#issuecomment-826460930","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2510","id":826460930,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjQ2MDkzMA==","user":{"login":"coolderli","id":38486782,"node_id":"MDQ6VXNlcjM4NDg2Nzgy","avatar_url":"https://avatars.githubusercontent.com/u/38486782?v=4","gravatar_id":"","url":"https://api.github.com/users/coolderli","html_url":"https://github.com/coolderli","followers_url":"https://api.github.com/users/coolderli/followers","following_url":"https://api.github.com/users/coolderli/following{/other_user}","gists_url":"https://api.github.com/users/coolderli/gists{/gist_id}","starred_url":"https://api.github.com/users/coolderli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/coolderli/subscriptions","organizations_url":"https://api.github.com/users/coolderli/orgs","repos_url":"https://api.github.com/users/coolderli/repos","events_url":"https://api.github.com/users/coolderli/events{/privacy}","received_events_url":"https://api.github.com/users/coolderli/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T02:34:26Z","updated_at":"2021-04-26T02:34:26Z","author_association":"CONTRIBUTOR","body":"@rdblue  @openinx could you help me review it? thanks","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826460930/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826461024","html_url":"https://github.com/apache/iceberg/pull/2511#issuecomment-826461024","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2511","id":826461024,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjQ2MTAyNA==","user":{"login":"coolderli","id":38486782,"node_id":"MDQ6VXNlcjM4NDg2Nzgy","avatar_url":"https://avatars.githubusercontent.com/u/38486782?v=4","gravatar_id":"","url":"https://api.github.com/users/coolderli","html_url":"https://github.com/coolderli","followers_url":"https://api.github.com/users/coolderli/followers","following_url":"https://api.github.com/users/coolderli/following{/other_user}","gists_url":"https://api.github.com/users/coolderli/gists{/gist_id}","starred_url":"https://api.github.com/users/coolderli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/coolderli/subscriptions","organizations_url":"https://api.github.com/users/coolderli/orgs","repos_url":"https://api.github.com/users/coolderli/repos","events_url":"https://api.github.com/users/coolderli/events{/privacy}","received_events_url":"https://api.github.com/users/coolderli/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T02:34:44Z","updated_at":"2021-04-26T02:34:44Z","author_association":"CONTRIBUTOR","body":"@rdblue  @openinx could you help me review it? thanks","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826461024/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826463184","html_url":"https://github.com/apache/iceberg/issues/2482#issuecomment-826463184","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2482","id":826463184,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjQ2MzE4NA==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T02:41:59Z","updated_at":"2021-04-26T02:41:59Z","author_association":"MEMBER","body":"I checked the [place](https://github.com/apache/iceberg/blob/aba898b1a2ea15fd091228626b6887a5a72800c0/core/src/main/java/org/apache/iceberg/MergingSnapshotProducer.java#L258) that throw the ValidationException.    The reason that we encountered this because we've expired the several latest snapshots, then there must be a snapshot whose parent snapshot is not null but we could not find the snapshot entry in `TableMetadata#snapshotById`.    \r\n\r\nFor this issue, I think we should fix the problem from two aspects: \r\n1.  The `validateDataFilesExist` should stop to traverse the null snapshot even if it's a parent of others. ( I will close the #2511 because it's not the correct direction I think )\r\n2.  The `ExpireSnapshotsSparkAction` will need to consider the format v2,  I'm still not sure whether will it be able to expire the snapshots in v2.    FYI @aokolnychyi \r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826463184/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826463290","html_url":"https://github.com/apache/iceberg/pull/2511#issuecomment-826463290","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2511","id":826463290,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjQ2MzI5MA==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T02:42:24Z","updated_at":"2021-04-26T02:42:24Z","author_association":"MEMBER","body":"Closed this via [comment](https://github.com/apache/iceberg/issues/2482#issuecomment-826463184)","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826463290/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826479272","html_url":"https://github.com/apache/iceberg/pull/2510#issuecomment-826479272","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2510","id":826479272,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjQ3OTI3Mg==","user":{"login":"coolderli","id":38486782,"node_id":"MDQ6VXNlcjM4NDg2Nzgy","avatar_url":"https://avatars.githubusercontent.com/u/38486782?v=4","gravatar_id":"","url":"https://api.github.com/users/coolderli","html_url":"https://github.com/coolderli","followers_url":"https://api.github.com/users/coolderli/followers","following_url":"https://api.github.com/users/coolderli/following{/other_user}","gists_url":"https://api.github.com/users/coolderli/gists{/gist_id}","starred_url":"https://api.github.com/users/coolderli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/coolderli/subscriptions","organizations_url":"https://api.github.com/users/coolderli/orgs","repos_url":"https://api.github.com/users/coolderli/repos","events_url":"https://api.github.com/users/coolderli/events{/privacy}","received_events_url":"https://api.github.com/users/coolderli/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T03:39:31Z","updated_at":"2021-04-26T03:39:31Z","author_association":"CONTRIBUTOR","body":"@openinx I want to support the expiring snapshot  of the V2 table\r\nAfter we rewrite the data file and the delete file in #2303, we can delete the corresponding data files and delete files through manifest when expiring the snapshot. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826479272/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826483934","html_url":"https://github.com/apache/iceberg/pull/2510#issuecomment-826483934","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2510","id":826483934,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjQ4MzkzNA==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T03:58:52Z","updated_at":"2021-04-26T03:58:52Z","author_association":"MEMBER","body":"So why need to add the extra nested field in table schema ?  I still not get the point.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826483934/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826486019","html_url":"https://github.com/apache/iceberg/pull/2512#issuecomment-826486019","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2512","id":826486019,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjQ4NjAxOQ==","user":{"login":"wypoon","id":3925490,"node_id":"MDQ6VXNlcjM5MjU0OTA=","avatar_url":"https://avatars.githubusercontent.com/u/3925490?v=4","gravatar_id":"","url":"https://api.github.com/users/wypoon","html_url":"https://github.com/wypoon","followers_url":"https://api.github.com/users/wypoon/followers","following_url":"https://api.github.com/users/wypoon/following{/other_user}","gists_url":"https://api.github.com/users/wypoon/gists{/gist_id}","starred_url":"https://api.github.com/users/wypoon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wypoon/subscriptions","organizations_url":"https://api.github.com/users/wypoon/orgs","repos_url":"https://api.github.com/users/wypoon/repos","events_url":"https://api.github.com/users/wypoon/events{/privacy}","received_events_url":"https://api.github.com/users/wypoon/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T04:07:23Z","updated_at":"2021-04-26T04:07:23Z","author_association":"CONTRIBUTOR","body":"@RussellSpitzer @rdblue can you please review and suggest what to do on the build side? I am not very familiar with gradle and am also not sure how we want to do this.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826486019/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826536901","html_url":"https://github.com/apache/iceberg/pull/2465#issuecomment-826536901","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2465","id":826536901,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjUzNjkwMQ==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T06:15:09Z","updated_at":"2021-04-26T06:15:09Z","author_association":"MEMBER","body":"@rdblue ,  would you have any other concern ?  If no,  I will plan to get this merged.  Thanks.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826536901/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826669837","html_url":"https://github.com/apache/iceberg/issues/2435#issuecomment-826669837","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2435","id":826669837,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjY2OTgzNw==","user":{"login":"szehon-ho","id":20555759,"node_id":"MDQ6VXNlcjIwNTU1NzU5","avatar_url":"https://avatars.githubusercontent.com/u/20555759?v=4","gravatar_id":"","url":"https://api.github.com/users/szehon-ho","html_url":"https://github.com/szehon-ho","followers_url":"https://api.github.com/users/szehon-ho/followers","following_url":"https://api.github.com/users/szehon-ho/following{/other_user}","gists_url":"https://api.github.com/users/szehon-ho/gists{/gist_id}","starred_url":"https://api.github.com/users/szehon-ho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szehon-ho/subscriptions","organizations_url":"https://api.github.com/users/szehon-ho/orgs","repos_url":"https://api.github.com/users/szehon-ho/repos","events_url":"https://api.github.com/users/szehon-ho/events{/privacy}","received_events_url":"https://api.github.com/users/szehon-ho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T09:25:25Z","updated_at":"2021-04-26T09:25:25Z","author_association":"COLLABORATOR","body":"Ah sorry I was not clear, I was looking through the code brainstorming about the implementation and the problem was this:\r\n\r\n-Currently ManifestGroup::planFiles() returns iterable of FileScanTask (actual class BaseFileScanTask)\r\n-But FileScanTask has only list of DataFiles.\r\n\r\nSo if for RepairManifest, we launch a Spark job on FileScanTasks like for normal scans, we will lose track of the ManifestFile that each DataFile belonged to, which we need after we collect the result to repair the relevant ManifestFIle.  So my idea is either:\r\n\r\n- Add ManifestFile as a member of BaseFileScanTask (it's available in ManifestGroup::planFiles but just not added).  This would increase the memory usage a bit for general scan planning.\r\n- Have a new specialized type of BaseFileScanTask that has this ManifestFile field.  But then it's a bit awkward to have it returned only by ManifestGroup::planFiles only for RepairManifestAction (flag based, or separate method).  Thanks\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826669837/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826691629","html_url":"https://github.com/apache/iceberg/pull/2324#issuecomment-826691629","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2324","id":826691629,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjY5MTYyOQ==","user":{"login":"rymurr","id":2022305,"node_id":"MDQ6VXNlcjIwMjIzMDU=","avatar_url":"https://avatars.githubusercontent.com/u/2022305?v=4","gravatar_id":"","url":"https://api.github.com/users/rymurr","html_url":"https://github.com/rymurr","followers_url":"https://api.github.com/users/rymurr/followers","following_url":"https://api.github.com/users/rymurr/following{/other_user}","gists_url":"https://api.github.com/users/rymurr/gists{/gist_id}","starred_url":"https://api.github.com/users/rymurr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymurr/subscriptions","organizations_url":"https://api.github.com/users/rymurr/orgs","repos_url":"https://api.github.com/users/rymurr/repos","events_url":"https://api.github.com/users/rymurr/events{/privacy}","received_events_url":"https://api.github.com/users/rymurr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T09:52:45Z","updated_at":"2021-04-26T09:52:45Z","author_association":"CONTRIBUTOR","body":"closed in favor of #2515","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826691629/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826703041","html_url":"https://github.com/apache/iceberg/pull/2494#issuecomment-826703041","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2494","id":826703041,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjcwMzA0MQ==","user":{"login":"lcspinter","id":47777102,"node_id":"MDQ6VXNlcjQ3Nzc3MTAy","avatar_url":"https://avatars.githubusercontent.com/u/47777102?v=4","gravatar_id":"","url":"https://api.github.com/users/lcspinter","html_url":"https://github.com/lcspinter","followers_url":"https://api.github.com/users/lcspinter/followers","following_url":"https://api.github.com/users/lcspinter/following{/other_user}","gists_url":"https://api.github.com/users/lcspinter/gists{/gist_id}","starred_url":"https://api.github.com/users/lcspinter/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lcspinter/subscriptions","organizations_url":"https://api.github.com/users/lcspinter/orgs","repos_url":"https://api.github.com/users/lcspinter/repos","events_url":"https://api.github.com/users/lcspinter/events{/privacy}","received_events_url":"https://api.github.com/users/lcspinter/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T10:07:40Z","updated_at":"2021-04-26T10:11:22Z","author_association":"CONTRIBUTOR","body":"@RussellSpitzer @aokolnychyi I've marked the methods as deprecated. \r\nWhat is left if to solve this [issue](https://github.com/apache/iceberg/pull/2494#discussion_r616607521) in a separate PR. With rowCount set to 0, the hive table migration works perfectly, but I'm not sure how will affect other use cases. Do you happen to know some other solution? Thanks","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826703041/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826789046","html_url":"https://github.com/apache/iceberg/pull/2510#issuecomment-826789046","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2510","id":826789046,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjc4OTA0Ng==","user":{"login":"coolderli","id":38486782,"node_id":"MDQ6VXNlcjM4NDg2Nzgy","avatar_url":"https://avatars.githubusercontent.com/u/38486782?v=4","gravatar_id":"","url":"https://api.github.com/users/coolderli","html_url":"https://github.com/coolderli","followers_url":"https://api.github.com/users/coolderli/followers","following_url":"https://api.github.com/users/coolderli/following{/other_user}","gists_url":"https://api.github.com/users/coolderli/gists{/gist_id}","starred_url":"https://api.github.com/users/coolderli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/coolderli/subscriptions","organizations_url":"https://api.github.com/users/coolderli/orgs","repos_url":"https://api.github.com/users/coolderli/repos","events_url":"https://api.github.com/users/coolderli/events{/privacy}","received_events_url":"https://api.github.com/users/coolderli/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T12:17:44Z","updated_at":"2021-04-26T12:17:44Z","author_association":"CONTRIBUTOR","body":"Sorry, I didn't make it clear. This patch is actually a part of #2518.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826789046/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826858440","html_url":"https://github.com/apache/iceberg/issues/2435#issuecomment-826858440","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2435","id":826858440,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjg1ODQ0MA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T13:59:24Z","updated_at":"2021-04-26T13:59:24Z","author_association":"MEMBER","body":"Ah yeah, I think we usually do new custom Scan's, See\r\nhttps://github.com/apache/iceberg/blob/master/core/src/main/java/org/apache/iceberg/ManifestEntriesTable.java#L96-L140\r\nFor example. I would hesitate to touch anything around \"planFiles\" for this and would instead op for reading the manifest files directly","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826858440/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826860482","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-826860482","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":826860482,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjg2MDQ4Mg==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T14:02:05Z","updated_at":"2021-04-26T14:02:05Z","author_association":"MEMBER","body":"@chenjunjiedada Good catch, we should definitely fix that, I also was a little worried about keeping the boxed boolean as the return value in containsNaN since we usually treat the parameter as a primitive, but I'm ok with just fixing the other occurrence for now, wdyt?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826860482/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826881569","html_url":"https://github.com/apache/iceberg/pull/2512#issuecomment-826881569","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2512","id":826881569,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjg4MTU2OQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T14:29:50Z","updated_at":"2021-04-26T14:30:53Z","author_association":"MEMBER","body":"Took a brief look but I think once the gradle fixes are in there will be more changes to make so I didn't go over the whole thing.\r\n\r\nI think what we'll need to do is make a new configuration for Spark3.1 Testing (and maybe a new integration configuration for Spark3-Runtime)\r\n\r\nsomething like\r\n\r\n```\r\n  configurations {\r\n     spark30test extends from testRuntime\r\n     spark31test extends from testRuntime\r\n   }\r\n```\r\nThen in dependencies add the Spark dependency you want to each of those configurations.\r\n\r\nThat's at least how I would do it if we want 1 jar that runs against both versions of Spark even though it's only compiled against one.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826881569/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826903986","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-826903986","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":826903986,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjkwMzk4Ng==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T14:58:24Z","updated_at":"2021-04-26T14:58:24Z","author_association":"MEMBER","body":"I think if we make the changes @chenjunjiedada suggests (which I think are a good idea too), we should probably just change the signature to be a primitive and not the Boxed bool.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826903986/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826924919","html_url":"https://github.com/apache/iceberg/pull/2499#issuecomment-826924919","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2499","id":826924919,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjkyNDkxOQ==","user":{"login":"szehon-ho","id":20555759,"node_id":"MDQ6VXNlcjIwNTU1NzU5","avatar_url":"https://avatars.githubusercontent.com/u/20555759?v=4","gravatar_id":"","url":"https://api.github.com/users/szehon-ho","html_url":"https://github.com/szehon-ho","followers_url":"https://api.github.com/users/szehon-ho/followers","following_url":"https://api.github.com/users/szehon-ho/following{/other_user}","gists_url":"https://api.github.com/users/szehon-ho/gists{/gist_id}","starred_url":"https://api.github.com/users/szehon-ho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szehon-ho/subscriptions","organizations_url":"https://api.github.com/users/szehon-ho/orgs","repos_url":"https://api.github.com/users/szehon-ho/repos","events_url":"https://api.github.com/users/szehon-ho/events{/privacy}","received_events_url":"https://api.github.com/users/szehon-ho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T15:19:58Z","updated_at":"2021-04-26T15:19:58Z","author_association":"COLLABORATOR","body":"Thanks for taking a look and the clarification of what should not be null @openinx , i made the suggested changes if you want to take another look.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826924919/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826927825","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-826927825","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":826927825,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjkyNzgyNQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T15:24:02Z","updated_at":"2021-04-26T15:25:11Z","author_association":"MEMBER","body":"I think for the StaticDataRow error we should be changing the Schema of Manifests table to mark containsNan as Optional since in this context we are actually reading the value out, and it isn't necessarily true, it may be missing.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826927825/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826975106","html_url":"https://github.com/apache/iceberg/pull/2512#issuecomment-826975106","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2512","id":826975106,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNjk3NTEwNg==","user":{"login":"wypoon","id":3925490,"node_id":"MDQ6VXNlcjM5MjU0OTA=","avatar_url":"https://avatars.githubusercontent.com/u/3925490?v=4","gravatar_id":"","url":"https://api.github.com/users/wypoon","html_url":"https://github.com/wypoon","followers_url":"https://api.github.com/users/wypoon/followers","following_url":"https://api.github.com/users/wypoon/following{/other_user}","gists_url":"https://api.github.com/users/wypoon/gists{/gist_id}","starred_url":"https://api.github.com/users/wypoon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wypoon/subscriptions","organizations_url":"https://api.github.com/users/wypoon/orgs","repos_url":"https://api.github.com/users/wypoon/repos","events_url":"https://api.github.com/users/wypoon/events{/privacy}","received_events_url":"https://api.github.com/users/wypoon/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T16:23:42Z","updated_at":"2021-04-26T16:23:42Z","author_association":"CONTRIBUTOR","body":"@RussellSpitzer thanks for taking a look and the pointer. It doesn't make immediate sense to me (that's how little I know about gradle), but I'll do some research.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/826975106/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827106131","html_url":"https://github.com/apache/iceberg/issues/2517#issuecomment-827106131","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2517","id":827106131,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzEwNjEzMQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T20:00:24Z","updated_at":"2021-04-26T20:00:24Z","author_association":"MEMBER","body":"The pushdown information is in the BatchScan info ```[filters=orderpriority IS NOT NULL, orderpriority = '1-URGENT']``` which shows the filters as presented to the Iceberg Table.\r\n\r\nSee\r\nhttps://github.com/apache/iceberg/blob/master/spark3/src/main/java/org/apache/iceberg/spark/source/SparkBatchScan.java#L210-L214\r\n\r\nWhich get's put into DSV2 ScanExec (Spark)\r\n```\r\n  override def simpleString(maxFields: Int): String = {\r\n    val result =\r\n      s\"$nodeName${truncatedString(output, \"[\", \", \", \"]\", maxFields)} ${scan.description()}\"\r\n    redact(result)\r\n  }\r\n```\r\n\r\nNode name is the physical plan node name which in this case is BatchScanExec (also Spark)\r\n```\r\nPhysical plan node for scanning a batch of data from a data source v2.\r\n```\r\n\r\nSo everything is according to plan here","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827106131/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827167227","html_url":"https://github.com/apache/iceberg/issues/2517#issuecomment-827167227","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2517","id":827167227,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzE2NzIyNw==","user":{"login":"nvitucci","id":1252064,"node_id":"MDQ6VXNlcjEyNTIwNjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1252064?v=4","gravatar_id":"","url":"https://api.github.com/users/nvitucci","html_url":"https://github.com/nvitucci","followers_url":"https://api.github.com/users/nvitucci/followers","following_url":"https://api.github.com/users/nvitucci/following{/other_user}","gists_url":"https://api.github.com/users/nvitucci/gists{/gist_id}","starred_url":"https://api.github.com/users/nvitucci/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nvitucci/subscriptions","organizations_url":"https://api.github.com/users/nvitucci/orgs","repos_url":"https://api.github.com/users/nvitucci/repos","events_url":"https://api.github.com/users/nvitucci/events{/privacy}","received_events_url":"https://api.github.com/users/nvitucci/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T21:48:44Z","updated_at":"2021-04-26T21:48:44Z","author_association":"NONE","body":"Thanks for your reply. I was expecting some more information in the Iceberg node, a bit like you would see if you were to run the same query on the original table:\r\n\r\n```\r\n...\r\n   +- FileScan csv [orderkey#0,custkey#1,orderstatus#2,totalprice#3,orderdate#4,orderpriority#5,clerk#6,shippriority#7,comment#8] Batched: false, DataFilters: [isnotnull(orderpriority#5), (orderpriority#5 = 1-URGENT)], Format: CSV, Location: InMemoryFileIndex[file:/Users/nvitucci/temp/tpch-kit/generated-data/orders.tbl], PartitionFilters: [], PushedFilters: [IsNotNull(orderpriority), EqualTo(orderpriority,1-URGENT)], ReadSchema: struct<orderkey:string,custkey:string,orderstatus:string,totalprice:double,orderdate:date,orderpr...\r\n```\r\n\r\nor like in #1483, where `iceberg` is clearly visible in the nodes it is related to along with path information (although I now realize that it is probably a Spark 2-only behaviour).\r\n\r\nSince a filter on a non-partition column results in basically the same plan, is there another way to see that the partition filter is actually being used for pruning? In other words, how can I programmatically check that only the files in the selected partition are being read?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827167227/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827169378","html_url":"https://github.com/apache/iceberg/issues/2517#issuecomment-827169378","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2517","id":827169378,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzE2OTM3OA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T21:53:22Z","updated_at":"2021-04-26T21:53:22Z","author_association":"MEMBER","body":"I think we could definitely add some more details there to the description, pull requests are welcome :) We basically have full control over everything that gets printed after the Spark \"BatchScan Info\"\r\n\r\nI think currently the only way to really tell is to check the partitions being created for the read, the (Spark) partition information should have listings of all the files required to load that particular table. So I would probably start tinkering around with that but it would require a bit of digging. \r\n\r\nProbably something like DF.rdd. traverse to the parent Scan RDD, partitions foreach println","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827169378/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827171072","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-827171072","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":827171072,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzE3MTA3Mg==","user":{"login":"yyanyy","id":71906210,"node_id":"MDQ6VXNlcjcxOTA2MjEw","avatar_url":"https://avatars.githubusercontent.com/u/71906210?v=4","gravatar_id":"","url":"https://api.github.com/users/yyanyy","html_url":"https://github.com/yyanyy","followers_url":"https://api.github.com/users/yyanyy/followers","following_url":"https://api.github.com/users/yyanyy/following{/other_user}","gists_url":"https://api.github.com/users/yyanyy/gists{/gist_id}","starred_url":"https://api.github.com/users/yyanyy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yyanyy/subscriptions","organizations_url":"https://api.github.com/users/yyanyy/orgs","repos_url":"https://api.github.com/users/yyanyy/repos","events_url":"https://api.github.com/users/yyanyy/events{/privacy}","received_events_url":"https://api.github.com/users/yyanyy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T21:57:16Z","updated_at":"2021-04-26T21:57:16Z","author_association":"CONTRIBUTOR","body":"I think the `required` keyword in manifests table @RussellSpitzer pointed out is the culprit, I think `StaticDataTask.Row` should be able to handle null but since we marked `containsNan` as required in manifests table, it then throws the exception. And I agree with Russell that at least for showing manifest table, we probably don't want to mark `containsNan` as true if originally it's null/missing as it could be misleading.\r\n\r\nIf we indeed want to make `containsNan` a primitive everywhere, there would be other places to change including a [public facing interface](https://github.com/apache/iceberg/blob/master/api/src/main/java/org/apache/iceberg/ManifestFile.java#L209-L211) that are introduced in #1872 and [a case](https://github.com/apache/iceberg/blob/master/api/src/main/java/org/apache/iceberg/expressions/ManifestEvaluator.java#L164) that will produce less accurate result. However we haven't specify if we want `contains_nan` to be nullable or not [in spec](https://iceberg.apache.org/spec/#manifest-lists) so this decision might still be revertible.\r\n\r\nI'll submit a PR to fix `required` field in manifests table and a separate PR to update spec so that we can have a wider audience and make a decision there. Meanwhile @RussellSpitzer @chenjunjiedada please let me know if you have further comments/concerns, and sorry for causing the issue!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827171072/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827171835","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-827171835","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":827171835,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzE3MTgzNQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T21:59:08Z","updated_at":"2021-04-26T21:59:08Z","author_association":"MEMBER","body":"@yyanyy np :) It's a team effort. I think i'm pro just changing required -> Optional and in the future i'm going to be very strict about anyone using boxed primitives :P","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827171835/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827177905","html_url":"https://github.com/apache/iceberg/issues/2517#issuecomment-827177905","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2517","id":827177905,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzE3NzkwNQ==","user":{"login":"nvitucci","id":1252064,"node_id":"MDQ6VXNlcjEyNTIwNjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1252064?v=4","gravatar_id":"","url":"https://api.github.com/users/nvitucci","html_url":"https://github.com/nvitucci","followers_url":"https://api.github.com/users/nvitucci/followers","following_url":"https://api.github.com/users/nvitucci/following{/other_user}","gists_url":"https://api.github.com/users/nvitucci/gists{/gist_id}","starred_url":"https://api.github.com/users/nvitucci/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nvitucci/subscriptions","organizations_url":"https://api.github.com/users/nvitucci/orgs","repos_url":"https://api.github.com/users/nvitucci/repos","events_url":"https://api.github.com/users/nvitucci/events{/privacy}","received_events_url":"https://api.github.com/users/nvitucci/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-26T22:13:30Z","updated_at":"2021-04-26T22:13:30Z","author_association":"NONE","body":"Thanks for the pointers, I'll take a look and report back.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827177905/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827222241","html_url":"https://github.com/apache/iceberg/issues/2405#issuecomment-827222241","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2405","id":827222241,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzIyMjI0MQ==","user":{"login":"yyanyy","id":71906210,"node_id":"MDQ6VXNlcjcxOTA2MjEw","avatar_url":"https://avatars.githubusercontent.com/u/71906210?v=4","gravatar_id":"","url":"https://api.github.com/users/yyanyy","html_url":"https://github.com/yyanyy","followers_url":"https://api.github.com/users/yyanyy/followers","following_url":"https://api.github.com/users/yyanyy/following{/other_user}","gists_url":"https://api.github.com/users/yyanyy/gists{/gist_id}","starred_url":"https://api.github.com/users/yyanyy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yyanyy/subscriptions","organizations_url":"https://api.github.com/users/yyanyy/orgs","repos_url":"https://api.github.com/users/yyanyy/repos","events_url":"https://api.github.com/users/yyanyy/events{/privacy}","received_events_url":"https://api.github.com/users/yyanyy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T00:22:27Z","updated_at":"2021-04-27T00:22:27Z","author_association":"CONTRIBUTOR","body":"Apologies for the delay, #2521 contains the two changes I planned to include as mentioned earlier, please take a look when you have time @RussellSpitzer @chenjunjiedada Thank you! ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827222241/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827222973","html_url":"https://github.com/apache/iceberg/pull/2509#issuecomment-827222973","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2509","id":827222973,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzIyMjk3Mw==","user":{"login":"yyanyy","id":71906210,"node_id":"MDQ6VXNlcjcxOTA2MjEw","avatar_url":"https://avatars.githubusercontent.com/u/71906210?v=4","gravatar_id":"","url":"https://api.github.com/users/yyanyy","html_url":"https://github.com/yyanyy","followers_url":"https://api.github.com/users/yyanyy/followers","following_url":"https://api.github.com/users/yyanyy/following{/other_user}","gists_url":"https://api.github.com/users/yyanyy/gists{/gist_id}","starred_url":"https://api.github.com/users/yyanyy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yyanyy/subscriptions","organizations_url":"https://api.github.com/users/yyanyy/orgs","repos_url":"https://api.github.com/users/yyanyy/repos","events_url":"https://api.github.com/users/yyanyy/events{/privacy}","received_events_url":"https://api.github.com/users/yyanyy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T00:24:38Z","updated_at":"2021-04-27T00:24:38Z","author_association":"CONTRIBUTOR","body":"I have raised a separate PR with a slightly different approach and some spec update in #2521, more context on why we need this change could be found in #2405. Thanks! ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827222973/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827254021","html_url":"https://github.com/apache/iceberg/pull/2465#issuecomment-827254021","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2465","id":827254021,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzI1NDAyMQ==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T01:56:56Z","updated_at":"2021-04-27T01:56:56Z","author_association":"CONTRIBUTOR","body":"@rdblue updated based on your comments. For `Set` versus `List` or anything else in the API, please let me know what you think should be the general guidance for this type of change in Iceberg.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827254021/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827262965","html_url":"https://github.com/apache/iceberg/pull/2506#issuecomment-827262965","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2506","id":827262965,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzI2Mjk2NQ==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T02:14:45Z","updated_at":"2021-04-27T02:14:45Z","author_association":"MEMBER","body":"Got this merged,  thanks @findepi for contributing, and thanks @RussellSpitzer for reviewing.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827262965/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827265037","html_url":"https://github.com/apache/iceberg/pull/2521#issuecomment-827265037","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2521","id":827265037,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzI2NTAzNw==","user":{"login":"chenjunjiedada","id":3960228,"node_id":"MDQ6VXNlcjM5NjAyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3960228?v=4","gravatar_id":"","url":"https://api.github.com/users/chenjunjiedada","html_url":"https://github.com/chenjunjiedada","followers_url":"https://api.github.com/users/chenjunjiedada/followers","following_url":"https://api.github.com/users/chenjunjiedada/following{/other_user}","gists_url":"https://api.github.com/users/chenjunjiedada/gists{/gist_id}","starred_url":"https://api.github.com/users/chenjunjiedada/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chenjunjiedada/subscriptions","organizations_url":"https://api.github.com/users/chenjunjiedada/orgs","repos_url":"https://api.github.com/users/chenjunjiedada/repos","events_url":"https://api.github.com/users/chenjunjiedada/events{/privacy}","received_events_url":"https://api.github.com/users/chenjunjiedada/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T02:21:32Z","updated_at":"2021-04-27T02:21:32Z","author_association":"COLLABORATOR","body":"Should we add a unit test to read a v1 manifest file?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827265037/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827265790","html_url":"https://github.com/apache/iceberg/pull/2522#issuecomment-827265790","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2522","id":827265790,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzI2NTc5MA==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T02:23:48Z","updated_at":"2021-04-27T02:23:48Z","author_association":"CONTRIBUTOR","body":"I found that this pr seems to be  duplicate. I found other similar pr (https://github.com/apache/iceberg/pull/2275 ,https://github.com/apache/iceberg/pull/2096). I will close this pr, but I think we should add test cases for different computing engines (spark, flink, hive) so that they can works correctly.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827265790/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827274959","html_url":"https://github.com/apache/iceberg/pull/2521#issuecomment-827274959","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2521","id":827274959,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzI3NDk1OQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T02:51:06Z","updated_at":"2021-04-27T02:51:06Z","author_association":"MEMBER","body":"> Should we add a unit test to read a v1 manifest file?\r\n\r\nI would also like to see this, but I think we probably need a dedicated backwards compatibility suite somewhere","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827274959/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827279964","html_url":"https://github.com/apache/iceberg/pull/2521#issuecomment-827279964","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2521","id":827279964,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzI3OTk2NA==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T03:05:12Z","updated_at":"2021-04-27T03:05:12Z","author_association":"CONTRIBUTOR","body":"> we probably need a dedicated backwards compatibility suite somewhere\r\n\r\n+1. As we are thinking about v3 now, I am trying to implement this in a way that can be flexible for future spec versions, will send a PR about this soon.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827279964/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827287688","html_url":"https://github.com/apache/iceberg/pull/2454#issuecomment-827287688","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2454","id":827287688,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzI4NzY4OA==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T03:31:05Z","updated_at":"2021-04-27T03:31:05Z","author_association":"CONTRIBUTOR","body":"+1 that we should not change the behavior of the partition spec visitor interface. We can return something like `Expressions.apply(\"alwaysNull\", Expressions.column(sourceName))` for always null and check that instead.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827287688/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827348534","html_url":"https://github.com/apache/iceberg/pull/2523#issuecomment-827348534","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2523","id":827348534,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzM0ODUzNA==","user":{"login":"pan3793","id":26535726,"node_id":"MDQ6VXNlcjI2NTM1NzI2","avatar_url":"https://avatars.githubusercontent.com/u/26535726?v=4","gravatar_id":"","url":"https://api.github.com/users/pan3793","html_url":"https://github.com/pan3793","followers_url":"https://api.github.com/users/pan3793/followers","following_url":"https://api.github.com/users/pan3793/following{/other_user}","gists_url":"https://api.github.com/users/pan3793/gists{/gist_id}","starred_url":"https://api.github.com/users/pan3793/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pan3793/subscriptions","organizations_url":"https://api.github.com/users/pan3793/orgs","repos_url":"https://api.github.com/users/pan3793/repos","events_url":"https://api.github.com/users/pan3793/events{/privacy}","received_events_url":"https://api.github.com/users/pan3793/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T06:28:28Z","updated_at":"2021-04-27T06:28:28Z","author_association":"MEMBER","body":"I guess `gradlePluginPortal()` is same as `maven { url \"https://plugins.gradle.org/m2/\" }`, why both there?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827348534/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827375959","html_url":"https://github.com/apache/iceberg/issues/2525#issuecomment-827375959","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2525","id":827375959,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzM3NTk1OQ==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T07:19:23Z","updated_at":"2021-04-27T07:19:23Z","author_association":"MEMBER","body":"Looks like the current `remove_orphan_files` procedure are depending on the [hadoop fs](https://github.com/apache/iceberg/blob/1f77257fc24891f3e66a6c162ac239afd6ae8d72/spark/src/main/java/org/apache/iceberg/spark/actions/BaseRemoveOrphanFilesSparkAction.java#L178) to get all the files,  while if we did not add the `oss` hadoop fs implementation, then the spark could not remove those orphan files.  Then for the people that want to put their data on the cloud storage services,  they have to implement both the `FileIO` and `org.apache.hadoop.fs.FileSystem` interfaces,  seems much redundant.   Is it possible to add a  `list` interfaces in the `FileIO` classes and it is only allowed to used for data management procedures  (it isn't allowed to used for table read/write path) ?  In this way, we could remove the hadoop fs dependency I think.\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827375959/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827410148","html_url":"https://github.com/apache/iceberg/issues/2525#issuecomment-827410148","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2525","id":827410148,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzQxMDE0OA==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T08:11:40Z","updated_at":"2021-04-27T08:11:40Z","author_association":"MEMBER","body":"The expire snapshots procedure also need hadoop fs: \r\n\r\n```\r\nspark-sql> CALL dlf_catalog.system.expire_snapshots(table => 'dlf_db.sample', older_than => 1619510640306, retain_last => 5);\r\n\r\norg.apache.iceberg.exceptions.RuntimeIOException: Failed to get file system for path: oss://iceberg-test/warehouse/dlf_db.db/sample/metadata/00424-85a395fe-5385-4fb1-a3c2-5d45c4db2aac.metadata.json\r\n\tat org.apache.iceberg.hadoop.Util.getFs(Util.java:50)\r\n\tat org.apache.iceberg.hadoop.HadoopInputFile.fromLocation(HadoopInputFile.java:54)\r\n\tat org.apache.iceberg.hadoop.HadoopFileIO.newInputFile(HadoopFileIO.java:59)\r\n\tat org.apache.iceberg.TableMetadataParser.read(TableMetadataParser.java:252)\r\n\tat org.apache.iceberg.StaticTableOperations.current(StaticTableOperations.java:53)\r\n\tat org.apache.iceberg.hadoop.HadoopTables.loadMetadataTable(HadoopTables.java:122)\r\n\tat org.apache.iceberg.hadoop.HadoopTables.load(HadoopTables.java:82)\r\n\tat org.apache.iceberg.spark.SparkCatalog.load(SparkCatalog.java:454)\r\n\tat org.apache.iceberg.spark.SparkCatalog.loadTable(SparkCatalog.java:116)\r\n\tat org.apache.iceberg.spark.SparkCatalog.loadTable(SparkCatalog.java:79)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$1(DataFrameReader.scala:271)\r\n\tat scala.Option.map(Option.scala:230)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:248)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:232)\r\n\tat org.apache.iceberg.spark.actions.BaseSparkAction.loadMetadataTable(BaseSparkAction.java:205)\r\n\tat org.apache.iceberg.spark.actions.BaseSparkAction.buildValidDataFileDF(BaseSparkAction.java:156)\r\n\tat org.apache.iceberg.spark.actions.BaseExpireSnapshotsSparkAction.buildValidFileDF(BaseExpireSnapshotsSparkAction.java:203)\r\n\tat org.apache.iceberg.spark.actions.BaseExpireSnapshotsSparkAction.expire(BaseExpireSnapshotsSparkAction.java:154)\r\n\tat org.apache.iceberg.spark.actions.BaseExpireSnapshotsSparkAction.doExecute(BaseExpireSnapshotsSparkAction.java:193)\r\n\tat org.apache.iceberg.spark.actions.BaseSparkAction.withJobGroupInfo(BaseSparkAction.java:102)\r\n\tat org.apache.iceberg.spark.actions.BaseExpireSnapshotsSparkAction.execute(BaseExpireSnapshotsSparkAction.java:185)\r\n\tat org.apache.iceberg.spark.actions.BaseExpireSnapshotsSparkAction.execute(BaseExpireSnapshotsSparkAction.java:65)\r\n\tat org.apache.iceberg.spark.procedures.ExpireSnapshotsProcedure.lambda$call$0(ExpireSnapshotsProcedure.java:94)\r\n\tat org.apache.iceberg.spark.procedures.BaseProcedure.execute(BaseProcedure.java:85)\r\n\tat org.apache.iceberg.spark.procedures.BaseProcedure.modifyIcebergTable(BaseProcedure.java:74)\r\n\tat org.apache.iceberg.spark.procedures.ExpireSnapshotsProcedure.call(ExpireSnapshotsProcedure.java:83)\r\n\tat org.apache.spark.sql.execution.datasources.v2.CallExec.run(CallExec.scala:33)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:45)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:229)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\r\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:229)\r\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\r\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:607)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\r\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:602)\r\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:650)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLDriver.run(SparkSQLDriver.scala:63)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:377)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.$anonfun$processLine$1(SparkSQLCLIDriver.scala:496)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.$anonfun$processLine$1$adapted(SparkSQLCLIDriver.scala:490)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\r\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\r\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\r\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processLine(SparkSQLCLIDriver.scala:490)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:282)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.IOException: No FileSystem for scheme: oss\r\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\r\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\r\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\r\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\r\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\r\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\r\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\r\n\tat org.apache.iceberg.hadoop.Util.getFs(Util.java:48)\r\n\t... 70 more\r\norg.apache.iceberg.exceptions.RuntimeIOException: Failed to get file system for path: oss://iceberg-test/warehouse/dlf_db.db/sample/metadata/00424-85a395fe-5385-4fb1-a3c2-5d45c4db2aac.metadata.json\r\n\tat org.apache.iceberg.hadoop.Util.getFs(Util.java:50)\r\n\tat org.apache.iceberg.hadoop.HadoopInputFile.fromLocation(HadoopInputFile.java:54)\r\n\tat org.apache.iceberg.hadoop.HadoopFileIO.newInputFile(HadoopFileIO.java:59)\r\n\tat org.apache.iceberg.TableMetadataParser.read(TableMetadataParser.java:252)\r\n\tat org.apache.iceberg.StaticTableOperations.current(StaticTableOperations.java:53)\r\n\tat org.apache.iceberg.hadoop.HadoopTables.loadMetadataTable(HadoopTables.java:122)\r\n\tat org.apache.iceberg.hadoop.HadoopTables.load(HadoopTables.java:82)\r\n\tat org.apache.iceberg.spark.SparkCatalog.load(SparkCatalog.java:454)\r\n\tat org.apache.iceberg.spark.SparkCatalog.loadTable(SparkCatalog.java:116)\r\n\tat org.apache.iceberg.spark.SparkCatalog.loadTable(SparkCatalog.java:79)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$1(DataFrameReader.scala:271)\r\n\tat scala.Option.map(Option.scala:230)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:248)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:232)\r\n\tat org.apache.iceberg.spark.actions.BaseSparkAction.loadMetadataTable(BaseSparkAction.java:205)\r\n\tat org.apache.iceberg.spark.actions.BaseSparkAction.buildValidDataFileDF(BaseSparkAction.java:156)\r\n\tat org.apache.iceberg.spark.actions.BaseExpireSnapshotsSparkAction.buildValidFileDF(BaseExpireSnapshotsSparkAction.java:203)\r\n\tat org.apache.iceberg.spark.actions.BaseExpireSnapshotsSparkAction.expire(BaseExpireSnapshotsSparkAction.java:154)\r\n\tat org.apache.iceberg.spark.actions.BaseExpireSnapshotsSparkAction.doExecute(BaseExpireSnapshotsSparkAction.java:193)\r\n\tat org.apache.iceberg.spark.actions.BaseSparkAction.withJobGroupInfo(BaseSparkAction.java:102)\r\n\tat org.apache.iceberg.spark.actions.BaseExpireSnapshotsSparkAction.execute(BaseExpireSnapshotsSparkAction.java:185)\r\n\tat org.apache.iceberg.spark.actions.BaseExpireSnapshotsSparkAction.execute(BaseExpireSnapshotsSparkAction.java:65)\r\n\tat org.apache.iceberg.spark.procedures.ExpireSnapshotsProcedure.lambda$call$0(ExpireSnapshotsProcedure.java:94)\r\n\tat org.apache.iceberg.spark.procedures.BaseProcedure.execute(BaseProcedure.java:85)\r\n\tat org.apache.iceberg.spark.procedures.BaseProcedure.modifyIcebergTable(BaseProcedure.java:74)\r\n\tat org.apache.iceberg.spark.procedures.ExpireSnapshotsProcedure.call(ExpireSnapshotsProcedure.java:83)\r\n\tat org.apache.spark.sql.execution.datasources.v2.CallExec.run(CallExec.scala:33)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:45)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:229)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\r\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:229)\r\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\r\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:607)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\r\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:602)\r\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:650)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLDriver.run(SparkSQLDriver.scala:63)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:377)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.$anonfun$processLine$1(SparkSQLCLIDriver.scala:496)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.$anonfun$processLine$1$adapted(SparkSQLCLIDriver.scala:490)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\r\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\r\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\r\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processLine(SparkSQLCLIDriver.scala:490)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:282)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.IOException: No FileSystem for scheme: oss\r\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\r\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\r\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\r\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\r\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\r\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\r\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\r\n\tat org.apache.iceberg.hadoop.Util.getFs(Util.java:48)\r\n\t... 70 more\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827410148/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827524605","html_url":"https://github.com/apache/iceberg/pull/2499#issuecomment-827524605","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2499","id":827524605,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzUyNDYwNQ==","user":{"login":"szehon-ho","id":20555759,"node_id":"MDQ6VXNlcjIwNTU1NzU5","avatar_url":"https://avatars.githubusercontent.com/u/20555759?v=4","gravatar_id":"","url":"https://api.github.com/users/szehon-ho","html_url":"https://github.com/szehon-ho","followers_url":"https://api.github.com/users/szehon-ho/followers","following_url":"https://api.github.com/users/szehon-ho/following{/other_user}","gists_url":"https://api.github.com/users/szehon-ho/gists{/gist_id}","starred_url":"https://api.github.com/users/szehon-ho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szehon-ho/subscriptions","organizations_url":"https://api.github.com/users/szehon-ho/orgs","repos_url":"https://api.github.com/users/szehon-ho/repos","events_url":"https://api.github.com/users/szehon-ho/events{/privacy}","received_events_url":"https://api.github.com/users/szehon-ho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T11:09:25Z","updated_at":"2021-04-27T11:09:25Z","author_association":"COLLABORATOR","body":"@openinx thanks again, yea I missed it","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827524605/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827525819","html_url":"https://github.com/apache/iceberg/pull/2499#issuecomment-827525819","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2499","id":827525819,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzUyNTgxOQ==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T11:11:36Z","updated_at":"2021-04-27T11:11:36Z","author_association":"MEMBER","body":"Got this merged, thanks @szehon-ho for contributing.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827525819/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827551334","html_url":"https://github.com/apache/iceberg/issues/2526#issuecomment-827551334","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2526","id":827551334,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzU1MTMzNA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T12:00:59Z","updated_at":"2021-04-27T12:00:59Z","author_association":"MEMBER","body":"Looks like a typo to me","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827551334/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827552075","html_url":"https://github.com/apache/iceberg/issues/2524#issuecomment-827552075","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2524","id":827552075,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzU1MjA3NQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T12:02:24Z","updated_at":"2021-04-27T12:02:24Z","author_association":"MEMBER","body":"#2453 I think","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827552075/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827656513","html_url":"https://github.com/apache/iceberg/issues/2527#issuecomment-827656513","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2527","id":827656513,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzY1NjUxMw==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T14:36:08Z","updated_at":"2021-04-27T14:36:08Z","author_association":"MEMBER","body":"I don't think that it's incompatible with Iceberg from the source\r\n\r\nIf i'm reading this correctly:\r\n\r\nhttps://github.com/apache/spark/blob/19c7d2f3d8cda8d9bc5dfc1a0bf5d46845b1bc2f/sql/core/src/main/scala/org/apache/spark/sql/execution/dynamicpruning/PartitionPruning.scala#L130-L132\r\n\r\nThere are basically two ways of estimating the filtering effectiveness\r\n   * a stats based one which you are correct we would not trigger as we don't keep \"distinct count\" stats\r\n   * a fallback method which just uses a user defined constant\r\n     *. conf.dynamicPartitionPruningFallbackFilterRatio\r\n     \r\nIn either case it then multiples the effectiveness against the size the plan reports (which we do report)\r\n\r\nhttps://github.com/apache/spark/blob/19c7d2f3d8cda8d9bc5dfc1a0bf5d46845b1bc2f/sql/core/src/main/scala/org/apache/spark/sql/execution/dynamicpruning/PartitionPruning.scala#L154\r\n\r\n  \r\n   \r\n   ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827656513/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827669164","html_url":"https://github.com/apache/iceberg/pull/2494#issuecomment-827669164","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2494","id":827669164,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzY2OTE2NA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T14:52:55Z","updated_at":"2021-04-27T14:52:55Z","author_association":"MEMBER","body":"@lcspinter I have no problem keeping the behavior of with the -1 as is for now even if it's broken. We should fix it when we get real working avro tests, which we probably can do in the integration suite I setup. It shouldn't have the same classloader baggage our normal test classpath has.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827669164/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827669731","html_url":"https://github.com/apache/iceberg/pull/2494#issuecomment-827669731","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2494","id":827669731,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzY2OTczMQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T14:53:36Z","updated_at":"2021-04-27T14:53:36Z","author_association":"MEMBER","body":"I think everyone's given their +1's so i'm going to merge this. Thanks for the contribution @lcspinter !","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827669731/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827729244","html_url":"https://github.com/apache/iceberg/issues/2527#issuecomment-827729244","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2527","id":827729244,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzcyOTI0NA==","user":{"login":"cccs-jc","id":56140112,"node_id":"MDQ6VXNlcjU2MTQwMTEy","avatar_url":"https://avatars.githubusercontent.com/u/56140112?v=4","gravatar_id":"","url":"https://api.github.com/users/cccs-jc","html_url":"https://github.com/cccs-jc","followers_url":"https://api.github.com/users/cccs-jc/followers","following_url":"https://api.github.com/users/cccs-jc/following{/other_user}","gists_url":"https://api.github.com/users/cccs-jc/gists{/gist_id}","starred_url":"https://api.github.com/users/cccs-jc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cccs-jc/subscriptions","organizations_url":"https://api.github.com/users/cccs-jc/orgs","repos_url":"https://api.github.com/users/cccs-jc/repos","events_url":"https://api.github.com/users/cccs-jc/events{/privacy}","received_events_url":"https://api.github.com/users/cccs-jc/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T16:08:23Z","updated_at":"2021-04-27T16:08:23Z","author_association":"CONTRIBUTOR","body":"Ha okay, I'm now setting the filter ratio\r\n\r\n`.config(\"spark.sql.optimizer.dynamicPartitionPruning.fallbackFilterRatio\", 0.001)`\r\nor\r\n` .config(\"spark.sql.optimizer.dynamicPartitionPruning.fallbackFilterRatio\", 100)`\r\n\r\nTrying to determine if filters will be pushed down. Should I see them pushed down in the BatchScan for the probing table. My explain plan does not show any pushed down filters\r\n\r\n`BatchScan[rrname#293, timeperiod#296] test_table1 [filters=]`","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827729244/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827738852","html_url":"https://github.com/apache/iceberg/issues/644#issuecomment-827738852","issue_url":"https://api.github.com/repos/apache/iceberg/issues/644","id":827738852,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzczODg1Mg==","user":{"login":"rymurr","id":2022305,"node_id":"MDQ6VXNlcjIwMjIzMDU=","avatar_url":"https://avatars.githubusercontent.com/u/2022305?v=4","gravatar_id":"","url":"https://api.github.com/users/rymurr","html_url":"https://github.com/rymurr","followers_url":"https://api.github.com/users/rymurr/followers","following_url":"https://api.github.com/users/rymurr/following{/other_user}","gists_url":"https://api.github.com/users/rymurr/gists{/gist_id}","starred_url":"https://api.github.com/users/rymurr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymurr/subscriptions","organizations_url":"https://api.github.com/users/rymurr/orgs","repos_url":"https://api.github.com/users/rymurr/repos","events_url":"https://api.github.com/users/rymurr/events{/privacy}","received_events_url":"https://api.github.com/users/rymurr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T16:22:12Z","updated_at":"2021-04-27T16:22:12Z","author_association":"CONTRIBUTOR","body":"@jzhuge We would be interested in views. I would be happy to help where I can to get your impl into iceberg.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827738852/reactions","total_count":6,"+1":6,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827756309","html_url":"https://github.com/apache/iceberg/issues/2528#issuecomment-827756309","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2528","id":827756309,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzc1NjMwOQ==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T16:49:35Z","updated_at":"2021-04-27T16:49:35Z","author_association":"CONTRIBUTOR","body":"I thought about that, I think the situations are a bit different between the 2 cases.\r\n\r\nFor sort order and partition spec, it has an internal reference of the updated schema which is defined only locally by the caller. So new columns can be assigned any ID. When building the replacement based on the last schema, the `assignFreshIds` is called to assign the correct ID to each new column. Then the spec and order needs to be updated with those information.\r\n\r\nFor identifier, it is always referencing the schema it sits in. The identifier field ID is always resolved after the actual schema is built, so the field ID is already fresh.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827756309/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827770002","html_url":"https://github.com/apache/iceberg/pull/2531#issuecomment-827770002","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2531","id":827770002,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzc3MDAwMg==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T17:10:31Z","updated_at":"2021-04-27T17:10:31Z","author_association":"CONTRIBUTOR","body":"duplicate of #2521 ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827770002/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827771270","html_url":"https://github.com/apache/iceberg/issues/2527#issuecomment-827771270","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2527","id":827771270,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzc3MTI3MA==","user":{"login":"cccs-jc","id":56140112,"node_id":"MDQ6VXNlcjU2MTQwMTEy","avatar_url":"https://avatars.githubusercontent.com/u/56140112?v=4","gravatar_id":"","url":"https://api.github.com/users/cccs-jc","html_url":"https://github.com/cccs-jc","followers_url":"https://api.github.com/users/cccs-jc/followers","following_url":"https://api.github.com/users/cccs-jc/following{/other_user}","gists_url":"https://api.github.com/users/cccs-jc/gists{/gist_id}","starred_url":"https://api.github.com/users/cccs-jc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cccs-jc/subscriptions","organizations_url":"https://api.github.com/users/cccs-jc/orgs","repos_url":"https://api.github.com/users/cccs-jc/repos","events_url":"https://api.github.com/users/cccs-jc/events{/privacy}","received_events_url":"https://api.github.com/users/cccs-jc/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T17:12:33Z","updated_at":"2021-04-27T17:12:33Z","author_association":"CONTRIBUTOR","body":"I was able to reproduce my issue with just parquet files (no iceberg). I saw the sizes in the plan.\r\n\r\nSo looks like it's an issue in Spark or a miss-configuration on my part. I've reported my example to Spark.\r\n\r\nhttps://issues.apache.org/jira/browse/SPARK-35245\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827771270/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827785132","html_url":"https://github.com/apache/iceberg/pull/2510#issuecomment-827785132","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2510","id":827785132,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzc4NTEzMg==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T17:34:02Z","updated_at":"2021-04-27T17:34:02Z","author_association":"CONTRIBUTOR","body":"Sorry for the back and forth, now I think about it, the files table has this in schema:\r\n\r\n```java\r\noptional(134, \"content\", IntegerType.get(), \"Contents of the file: 0=data, 1=position deletes, 2=equality deletes\");\r\n```\r\n\r\nSo it would make more sense to use int also for manifest, but we should add a doc similar to the files table like:\r\n\r\n```java\r\noptional(14, \"content\", IntegerType.get(), \"Contents of the manifest: 0=data, 1=deletes\");\r\n```\r\n\r\nso that people know what the values mean.\r\n\r\nApart from that, I don't have any further comments, thanks for the work.\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827785132/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827798130","html_url":"https://github.com/apache/iceberg/pull/2520#issuecomment-827798130","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2520","id":827798130,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzc5ODEzMA==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T17:53:59Z","updated_at":"2021-04-27T17:53:59Z","author_association":"CONTRIBUTOR","body":"> The change from OutputFile to EncryptedOutputFile everywhere looks a little odd to me because I know sometimes our output will not be encrypted even though we use that class.\r\n\r\n@RussellSpitzer I think this pattern is also used currently by data files, where all files are encrypted before written and go through the OutputFileFactory to get the output file instances:\r\n\r\nhttps://github.com/apache/iceberg/blob/master/core/src/main/java/org/apache/iceberg/io/OutputFileFactory.java#L106-L118\r\n\r\nAnd we are not encrypting the file only because we are using the PlainTextEncryptionManager. The change here is to try achieving the same effect.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827798130/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827809329","html_url":"https://github.com/apache/iceberg/pull/2523#issuecomment-827809329","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2523","id":827809329,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzgwOTMyOQ==","user":{"login":"wypoon","id":3925490,"node_id":"MDQ6VXNlcjM5MjU0OTA=","avatar_url":"https://avatars.githubusercontent.com/u/3925490?v=4","gravatar_id":"","url":"https://api.github.com/users/wypoon","html_url":"https://github.com/wypoon","followers_url":"https://api.github.com/users/wypoon/followers","following_url":"https://api.github.com/users/wypoon/following{/other_user}","gists_url":"https://api.github.com/users/wypoon/gists{/gist_id}","starred_url":"https://api.github.com/users/wypoon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wypoon/subscriptions","organizations_url":"https://api.github.com/users/wypoon/orgs","repos_url":"https://api.github.com/users/wypoon/repos","events_url":"https://api.github.com/users/wypoon/events{/privacy}","received_events_url":"https://api.github.com/users/wypoon/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T18:11:17Z","updated_at":"2021-04-27T18:11:17Z","author_association":"CONTRIBUTOR","body":"> I guess `gradlePluginPortal()` is same as `maven { url \"https://plugins.gradle.org/m2/\" }`, why both there?\r\n\r\nI didn't know that. They are both there from before, I wonder why?\r\nAnyway, no problem, I can remove the latter.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827809329/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827897536","html_url":"https://github.com/apache/iceberg/pull/2521#issuecomment-827897536","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2521","id":827897536,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzg5NzUzNg==","user":{"login":"yyanyy","id":71906210,"node_id":"MDQ6VXNlcjcxOTA2MjEw","avatar_url":"https://avatars.githubusercontent.com/u/71906210?v=4","gravatar_id":"","url":"https://api.github.com/users/yyanyy","html_url":"https://github.com/yyanyy","followers_url":"https://api.github.com/users/yyanyy/followers","following_url":"https://api.github.com/users/yyanyy/following{/other_user}","gists_url":"https://api.github.com/users/yyanyy/gists{/gist_id}","starred_url":"https://api.github.com/users/yyanyy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yyanyy/subscriptions","organizations_url":"https://api.github.com/users/yyanyy/orgs","repos_url":"https://api.github.com/users/yyanyy/repos","events_url":"https://api.github.com/users/yyanyy/events{/privacy}","received_events_url":"https://api.github.com/users/yyanyy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T20:11:01Z","updated_at":"2021-04-27T20:11:01Z","author_association":"CONTRIBUTOR","body":"Thank you for the quick review and feedback everyone!\r\n\r\nRegarding backward compatibility tests for reading manifest files, I think there are a few things worth mentioning:\r\n1) Iceberg does have dedicated tests on verifying backwards compatibility for both [manifest file](https://github.com/apache/iceberg/blob/master/core/src/test/java/org/apache/iceberg/TestManifestWriterVersions.java) and [manifest list](https://github.com/apache/iceberg/blob/master/core/src/test/java/org/apache/iceberg/TestManifestListVersions.java).\r\n2) even with these backward compatible tests, this issue can still occur (I did update the [test](https://github.com/apache/iceberg/blob/master/core/src/test/java/org/apache/iceberg/TestManifestListVersions.java#L221-L222) in the original PR). The reason is I think these are two separate issues:\r\n    - My understanding of the problem that's fixed by this specific PR is not related to generally reading of the manifest files/manifest list itself, but rather the display of a metadata table `manifests table` which is a separate logic. \r\n    -  The problem before the fix was that the schema we specified for this manifest table is [wrong](https://github.com/apache/iceberg/blob/master/core/src/main/java/org/apache/iceberg/ManifestsTable.java#L41) comparing to the correct specification we have for the actual requirement of manifest files [here](https://github.com/apache/iceberg/blob/master/api/src/main/java/org/apache/iceberg/ManifestFile.java#L58), and this mismatch caused the NPE problem since we require an originally nullable field to be not null. \r\n    - If we reused the schema construct we defined from `ManifestFile` (which is the source of truth in persisting manifest list file) in `ManifestsTable` we can avoid this problem completely, but currently `ManifestFile` doesn't want to expose them out, and has to specifically define the ID to ensure there's no duplication. I think we can still reuse them if we want, but that requires some code changes, and the current approach of duplicating definition of the same concepts in multiple places seems like a more widely adopted approach across Iceberg project. \r\n    - I think the ultimate way of preventing this specific problem is to create tests around metadata tables, and for this specific problem, we create v1 and v2 normal table, write data to them, and then query the manifest table and ensure output meets expected. However I think we don't have any test around metadata tables today. \r\n\r\nI think the follow up item after this PR should be to create an issue to add metadata tables tests to make sure they don't break when reading different versions of tables. Any comment/feedback/suggestions? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827897536/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827965017","html_url":"https://github.com/apache/iceberg/issues/2327#issuecomment-827965017","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2327","id":827965017,"node_id":"MDEyOklzc3VlQ29tbWVudDgyNzk2NTAxNw==","user":{"login":"nvitucci","id":1252064,"node_id":"MDQ6VXNlcjEyNTIwNjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1252064?v=4","gravatar_id":"","url":"https://api.github.com/users/nvitucci","html_url":"https://github.com/nvitucci","followers_url":"https://api.github.com/users/nvitucci/followers","following_url":"https://api.github.com/users/nvitucci/following{/other_user}","gists_url":"https://api.github.com/users/nvitucci/gists{/gist_id}","starred_url":"https://api.github.com/users/nvitucci/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nvitucci/subscriptions","organizations_url":"https://api.github.com/users/nvitucci/orgs","repos_url":"https://api.github.com/users/nvitucci/repos","events_url":"https://api.github.com/users/nvitucci/events{/privacy}","received_events_url":"https://api.github.com/users/nvitucci/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-27T22:01:08Z","updated_at":"2021-04-27T22:01:08Z","author_association":"NONE","body":"Same for me, although I applied an `ADD` first and a `DROP` on the same field afterwards.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/827965017/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828066579","html_url":"https://github.com/apache/iceberg/issues/2530#issuecomment-828066579","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2530","id":828066579,"node_id":"MDEyOklzc3VlQ29tbWVudDgyODA2NjU3OQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-28T01:13:49Z","updated_at":"2021-04-28T01:13:49Z","author_association":"MEMBER","body":"https://issues.apache.org/jira/browse/SPARK-26902 Makes me think we will probably have to support local date as well ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828066579/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828074025","html_url":"https://github.com/apache/iceberg/pull/2521#issuecomment-828074025","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2521","id":828074025,"node_id":"MDEyOklzc3VlQ29tbWVudDgyODA3NDAyNQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-28T01:35:16Z","updated_at":"2021-04-28T01:35:16Z","author_association":"MEMBER","body":"I was wondering about the other NPE in #2495, i was hoping that would have been caught by some backwards compatibility tests. I also have no problem with doing more testing and such in another pr","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828074025/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828086527","html_url":"https://github.com/apache/iceberg/issues/2528#issuecomment-828086527","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2528","id":828086527,"node_id":"MDEyOklzc3VlQ29tbWVudDgyODA4NjUyNw==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-28T02:07:47Z","updated_at":"2021-04-28T02:08:52Z","author_association":"CONTRIBUTOR","body":"Sorry I think I misunderstood what you meant a bit. So I agree that the identifier should be recreated after a new struct is created in `TypeUtil#assignFreshIds`. I thought you were talking about refreshing the identifier at the same place as sort order in `TableMetadat#buildReplacement`, sorry for the misunderstanding.\r\n\r\nThe new `Schema` created in that method should use the constructor `new Schema(struct, identfierFieldIds)` instead of the current `new Schema(struct)`, and the identifier will be refreshed at that point of time. That will be done as a part of the subsequent PR, because there are many places using the schema constructors, I plan to change them in a single pass.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828086527/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828088687","html_url":"https://github.com/apache/iceberg/issues/2528#issuecomment-828088687","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2528","id":828088687,"node_id":"MDEyOklzc3VlQ29tbWVudDgyODA4ODY4Nw==","user":{"login":"dixingxing0","id":1303530,"node_id":"MDQ6VXNlcjEzMDM1MzA=","avatar_url":"https://avatars.githubusercontent.com/u/1303530?v=4","gravatar_id":"","url":"https://api.github.com/users/dixingxing0","html_url":"https://github.com/dixingxing0","followers_url":"https://api.github.com/users/dixingxing0/followers","following_url":"https://api.github.com/users/dixingxing0/following{/other_user}","gists_url":"https://api.github.com/users/dixingxing0/gists{/gist_id}","starred_url":"https://api.github.com/users/dixingxing0/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dixingxing0/subscriptions","organizations_url":"https://api.github.com/users/dixingxing0/orgs","repos_url":"https://api.github.com/users/dixingxing0/repos","events_url":"https://api.github.com/users/dixingxing0/events{/privacy}","received_events_url":"https://api.github.com/users/dixingxing0/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-28T02:13:56Z","updated_at":"2021-04-28T02:13:56Z","author_association":"CONTRIBUTOR","body":"Yes, i've changed the comment to avoid misleading, i'm looking forward to see the subsequent PR.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828088687/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828108799","html_url":"https://github.com/apache/iceberg/pull/2510#issuecomment-828108799","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2510","id":828108799,"node_id":"MDEyOklzc3VlQ29tbWVudDgyODEwODc5OQ==","user":{"login":"coolderli","id":38486782,"node_id":"MDQ6VXNlcjM4NDg2Nzgy","avatar_url":"https://avatars.githubusercontent.com/u/38486782?v=4","gravatar_id":"","url":"https://api.github.com/users/coolderli","html_url":"https://github.com/coolderli","followers_url":"https://api.github.com/users/coolderli/followers","following_url":"https://api.github.com/users/coolderli/following{/other_user}","gists_url":"https://api.github.com/users/coolderli/gists{/gist_id}","starred_url":"https://api.github.com/users/coolderli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/coolderli/subscriptions","organizations_url":"https://api.github.com/users/coolderli/orgs","repos_url":"https://api.github.com/users/coolderli/repos","events_url":"https://api.github.com/users/coolderli/events{/privacy}","received_events_url":"https://api.github.com/users/coolderli/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-28T03:10:48Z","updated_at":"2021-04-28T03:10:48Z","author_association":"CONTRIBUTOR","body":"@jackye1995 Thank you for reviewing the code.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828108799/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828118230","html_url":"https://github.com/apache/iceberg/pull/2508#issuecomment-828118230","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2508","id":828118230,"node_id":"MDEyOklzc3VlQ29tbWVudDgyODExODIzMA==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-28T03:40:08Z","updated_at":"2021-04-28T03:40:08Z","author_association":"CONTRIBUTOR","body":"the issues of test case in [PR 2196](https://github.com/apache/iceberg/pull/2196):\r\n\r\nWe set the targetSizeInBytes to filesize of max filesize - 10, but there is no data in the last 10 bytes of this largest file, so in this case the largest file is not  split, and the newly generated file will be the same size as the original file. So I set targetSizeInBytes to half of the maximum file size, so this largest file will be split into two files, and finally three datafiles will be generated\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828118230/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828333492","html_url":"https://github.com/apache/iceberg/issues/2535#issuecomment-828333492","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2535","id":828333492,"node_id":"MDEyOklzc3VlQ29tbWVudDgyODMzMzQ5Mg==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-28T10:10:03Z","updated_at":"2021-04-28T10:10:03Z","author_association":"MEMBER","body":"Okay, sounds like the correct way to query external table in hive is: \r\n\r\n```sql\r\nSET iceberg.catalog=dlf_catalog;\r\nSET iceberg.catalog.dlf_catalog.type=dlf;\r\nSET iceberg.catalog.dlf_catalog.io-impl=org.apache.iceberg.aliyun.oss.OSSFileIO;\r\nSET iceberg.catalog.dlf_catalog.oss.endpoint=*******************************;\r\nSET iceberg.catalog.dlf_catalog.access.key.id=*******************************;\r\nSET iceberg.catalog.dlf_catalog.access.key.secret=*******************************;\r\nSET iceberg.catalog.dlf_catalog.catalog-impl=org.apache.iceberg.aliyun.dlf.DlfCatalog;\r\nSET iceberg.catalog.dlf_catalog.warehouse=oss://iceberg-test/warehouse;\r\nSET iceberg.catalog.dlf_catalog.dlf.catalog-id=*************************;\r\nSET iceberg.catalog.dlf_catalog.dlf.endpoint=*************************;\r\nSET iceberg.catalog.dlf_catalog.dlf.region-id=*************************;\r\n\r\nCREATE EXTERNAL TABLE dlf_db.spark_test\r\nSTORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'\r\nTBLPROPERTIES ('iceberg.catalog'='dlf_catalog');\r\n\r\nSELECT * FROM spark_test;\r\n```\r\n\r\n@jackye1995 ,  I would suggest to add a document for the hive+aws glue + aws s3 integration work,  I mean add a section to describe how to use HIVE to query tables located in aws glue and aws s3, :-).\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828333492/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828386504","html_url":"https://github.com/apache/iceberg/pull/2286#issuecomment-828386504","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2286","id":828386504,"node_id":"MDEyOklzc3VlQ29tbWVudDgyODM4NjUwNA==","user":{"login":"rymurr","id":2022305,"node_id":"MDQ6VXNlcjIwMjIzMDU=","avatar_url":"https://avatars.githubusercontent.com/u/2022305?v=4","gravatar_id":"","url":"https://api.github.com/users/rymurr","html_url":"https://github.com/rymurr","followers_url":"https://api.github.com/users/rymurr/followers","following_url":"https://api.github.com/users/rymurr/following{/other_user}","gists_url":"https://api.github.com/users/rymurr/gists{/gist_id}","starred_url":"https://api.github.com/users/rymurr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymurr/subscriptions","organizations_url":"https://api.github.com/users/rymurr/orgs","repos_url":"https://api.github.com/users/rymurr/repos","events_url":"https://api.github.com/users/rymurr/events{/privacy}","received_events_url":"https://api.github.com/users/rymurr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-28T11:42:50Z","updated_at":"2021-04-28T11:43:02Z","author_association":"CONTRIBUTOR","body":"Thanks @mayursrivastava these look semsible. I am trying to compare locally w/ the master branch to ensure there is no regression. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828386504/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828391883","html_url":"https://github.com/apache/iceberg/pull/2286#issuecomment-828391883","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2286","id":828391883,"node_id":"MDEyOklzc3VlQ29tbWVudDgyODM5MTg4Mw==","user":{"login":"mayursrivastava","id":8659624,"node_id":"MDQ6VXNlcjg2NTk2MjQ=","avatar_url":"https://avatars.githubusercontent.com/u/8659624?v=4","gravatar_id":"","url":"https://api.github.com/users/mayursrivastava","html_url":"https://github.com/mayursrivastava","followers_url":"https://api.github.com/users/mayursrivastava/followers","following_url":"https://api.github.com/users/mayursrivastava/following{/other_user}","gists_url":"https://api.github.com/users/mayursrivastava/gists{/gist_id}","starred_url":"https://api.github.com/users/mayursrivastava/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mayursrivastava/subscriptions","organizations_url":"https://api.github.com/users/mayursrivastava/orgs","repos_url":"https://api.github.com/users/mayursrivastava/repos","events_url":"https://api.github.com/users/mayursrivastava/events{/privacy}","received_events_url":"https://api.github.com/users/mayursrivastava/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-28T11:52:23Z","updated_at":"2021-04-28T11:52:23Z","author_association":"CONTRIBUTOR","body":"Hi @rymurr, I recorded results from master branch as well. Here's the result:\r\n\r\n```\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDatesIcebergVectorized5k\r\n\r\n# Run progress: 0.00% complete, ETA 00:00:00\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 1.761 s/op\r\n# Warmup Iteration   2: 1.464 s/op\r\n# Warmup Iteration   3: 1.621 s/op\r\nIteration   1: 1.545 s/op\r\nIteration   2: 1.493 s/op\r\nIteration   3: 1.479 s/op\r\nIteration   4: 1.460 s/op\r\nIteration   5: 1.471 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDatesIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      1.490 (99.9%) 0.128 s/op\r\n\r\n  Histogram, s/op:\r\n    [1.460, 1.465) = 1 \r\n    [1.465, 1.470) = 0 \r\n    [1.470, 1.475) = 1 \r\n    [1.475, 1.480) = 1 \r\n    [1.480, 1.485) = 0 \r\n    [1.485, 1.490) = 0 \r\n    [1.490, 1.495) = 1 \r\n    [1.495, 1.500) = 0 \r\n    [1.500, 1.505) = 0 \r\n    [1.505, 1.510) = 0 \r\n    [1.510, 1.515) = 0 \r\n    [1.515, 1.520) = 0 \r\n    [1.520, 1.525) = 0 \r\n    [1.525, 1.530) = 0 \r\n    [1.530, 1.535) = 0 \r\n    [1.535, 1.540) = 0 \r\n    [1.540, 1.545) = 0 \r\n    [1.545, 1.550) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      1.460 s/op\r\n     p(50.0000) =      1.479 s/op\r\n     p(90.0000) =      1.545 s/op\r\n     p(95.0000) =      1.545 s/op\r\n     p(99.0000) =      1.545 s/op\r\n     p(99.9000) =      1.545 s/op\r\n     p(99.9900) =      1.545 s/op\r\n     p(99.9990) =      1.545 s/op\r\n     p(99.9999) =      1.545 s/op\r\n    p(100.0000) =      1.545 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDatesSparkVectorized5k\r\n\r\n# Run progress: 6.25% complete, ETA 00:49:08\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 1.683 s/op\r\n# Warmup Iteration   2: 1.314 s/op\r\n# Warmup Iteration   3: 1.309 s/op\r\nIteration   1: 1.329 s/op\r\nIteration   2: 1.319 s/op\r\nIteration   3: 1.289 s/op\r\nIteration   4: 1.264 s/op\r\nIteration   5: 1.271 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDatesSparkVectorized5k\":\r\n  N = 5\r\n  mean =      1.294 (99.9%) 0.111 s/op\r\n\r\n  Histogram, s/op:\r\n    [1.260, 1.265) = 1 \r\n    [1.265, 1.270) = 0 \r\n    [1.270, 1.275) = 1 \r\n    [1.275, 1.280) = 0 \r\n    [1.280, 1.285) = 0 \r\n    [1.285, 1.290) = 1 \r\n    [1.290, 1.295) = 0 \r\n    [1.295, 1.300) = 0 \r\n    [1.300, 1.305) = 0 \r\n    [1.305, 1.310) = 0 \r\n    [1.310, 1.315) = 0 \r\n    [1.315, 1.320) = 1 \r\n    [1.320, 1.325) = 0 \r\n    [1.325, 1.330) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      1.264 s/op\r\n     p(50.0000) =      1.289 s/op\r\n     p(90.0000) =      1.329 s/op\r\n     p(95.0000) =      1.329 s/op\r\n     p(99.0000) =      1.329 s/op\r\n     p(99.9000) =      1.329 s/op\r\n     p(99.9900) =      1.329 s/op\r\n     p(99.9990) =      1.329 s/op\r\n     p(99.9999) =      1.329 s/op\r\n    p(100.0000) =      1.329 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDecimalsIcebergVectorized5k\r\n\r\n# Run progress: 12.50% complete, ETA 00:45:16\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 8.414 s/op\r\n# Warmup Iteration   2: 7.756 s/op\r\n# Warmup Iteration   3: 7.869 s/op\r\nIteration   1: 8.740 s/op\r\nIteration   2: 8.667 s/op\r\nIteration   3: 8.597 s/op\r\nIteration   4: 8.597 s/op\r\nIteration   5: 8.610 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDecimalsIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      8.642 (99.9%) 0.239 s/op\r\n\r\n  Histogram, s/op:\r\n    [8.500, 8.525) = 0 \r\n    [8.525, 8.550) = 0 \r\n    [8.550, 8.575) = 0 \r\n    [8.575, 8.600) = 2 \r\n    [8.600, 8.625) = 1 \r\n    [8.625, 8.650) = 0 \r\n    [8.650, 8.675) = 1 \r\n    [8.675, 8.700) = 0 \r\n    [8.700, 8.725) = 0 \r\n    [8.725, 8.750) = 1 \r\n    [8.750, 8.775) = 0 \r\n    [8.775, 8.800) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      8.597 s/op\r\n     p(50.0000) =      8.610 s/op\r\n     p(90.0000) =      8.740 s/op\r\n     p(95.0000) =      8.740 s/op\r\n     p(99.0000) =      8.740 s/op\r\n     p(99.9000) =      8.740 s/op\r\n     p(99.9900) =      8.740 s/op\r\n     p(99.9990) =      8.740 s/op\r\n     p(99.9999) =      8.740 s/op\r\n    p(100.0000) =      8.740 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDecimalsSparkVectorized5k\r\n\r\n# Run progress: 18.75% complete, ETA 00:45:51\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 9.147 s/op\r\n# Warmup Iteration   2: 8.526 s/op\r\n# Warmup Iteration   3: 8.513 s/op\r\nIteration   1: 8.478 s/op\r\nIteration   2: 8.419 s/op\r\nIteration   3: 8.455 s/op\r\nIteration   4: 8.421 s/op\r\nIteration   5: 8.450 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDecimalsSparkVectorized5k\":\r\n  N = 5\r\n  mean =      8.444 (99.9%) 0.096 s/op\r\n\r\n  Histogram, s/op:\r\n    [8.410, 8.415) = 0 \r\n    [8.415, 8.420) = 1 \r\n    [8.420, 8.425) = 1 \r\n    [8.425, 8.430) = 0 \r\n    [8.430, 8.435) = 0 \r\n    [8.435, 8.440) = 0 \r\n    [8.440, 8.445) = 0 \r\n    [8.445, 8.450) = 1 \r\n    [8.450, 8.455) = 0 \r\n    [8.455, 8.460) = 1 \r\n    [8.460, 8.465) = 0 \r\n    [8.465, 8.470) = 0 \r\n    [8.470, 8.475) = 0 \r\n    [8.475, 8.480) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      8.419 s/op\r\n     p(50.0000) =      8.450 s/op\r\n     p(90.0000) =      8.478 s/op\r\n     p(95.0000) =      8.478 s/op\r\n     p(99.0000) =      8.478 s/op\r\n     p(99.9000) =      8.478 s/op\r\n     p(99.9900) =      8.478 s/op\r\n     p(99.9990) =      8.478 s/op\r\n     p(99.9999) =      8.478 s/op\r\n    p(100.0000) =      8.478 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDoublesIcebergVectorized5k\r\n\r\n# Run progress: 25.00% complete, ETA 00:45:34\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.148 s/op\r\n# Warmup Iteration   2: 2.701 s/op\r\n# Warmup Iteration   3: 2.624 s/op\r\nIteration   1: 2.559 s/op\r\nIteration   2: 2.559 s/op\r\nIteration   3: 2.532 s/op\r\nIteration   4: 2.481 s/op\r\nIteration   5: 2.658 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDoublesIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      2.558 (99.9%) 0.248 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.400, 2.425) = 0 \r\n    [2.425, 2.450) = 0 \r\n    [2.450, 2.475) = 0 \r\n    [2.475, 2.500) = 1 \r\n    [2.500, 2.525) = 0 \r\n    [2.525, 2.550) = 1 \r\n    [2.550, 2.575) = 2 \r\n    [2.575, 2.600) = 0 \r\n    [2.600, 2.625) = 0 \r\n    [2.625, 2.650) = 0 \r\n    [2.650, 2.675) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.481 s/op\r\n     p(50.0000) =      2.559 s/op\r\n     p(90.0000) =      2.658 s/op\r\n     p(95.0000) =      2.658 s/op\r\n     p(99.0000) =      2.658 s/op\r\n     p(99.9000) =      2.658 s/op\r\n     p(99.9900) =      2.658 s/op\r\n     p(99.9990) =      2.658 s/op\r\n     p(99.9999) =      2.658 s/op\r\n    p(100.0000) =      2.658 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDoublesSparkVectorized5k\r\n\r\n# Run progress: 31.25% complete, ETA 00:41:41\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.058 s/op\r\n# Warmup Iteration   2: 2.484 s/op\r\n# Warmup Iteration   3: 2.453 s/op\r\nIteration   1: 2.407 s/op\r\nIteration   2: 2.359 s/op\r\nIteration   3: 2.380 s/op\r\nIteration   4: 2.342 s/op\r\nIteration   5: 2.373 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readDoublesSparkVectorized5k\":\r\n  N = 5\r\n  mean =      2.372 (99.9%) 0.093 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.340, 2.345) = 1 \r\n    [2.345, 2.350) = 0 \r\n    [2.350, 2.355) = 0 \r\n    [2.355, 2.360) = 1 \r\n    [2.360, 2.365) = 0 \r\n    [2.365, 2.370) = 0 \r\n    [2.370, 2.375) = 1 \r\n    [2.375, 2.380) = 0 \r\n    [2.380, 2.385) = 1 \r\n    [2.385, 2.390) = 0 \r\n    [2.390, 2.395) = 0 \r\n    [2.395, 2.400) = 0 \r\n    [2.400, 2.405) = 0 \r\n    [2.405, 2.410) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.342 s/op\r\n     p(50.0000) =      2.373 s/op\r\n     p(90.0000) =      2.407 s/op\r\n     p(95.0000) =      2.407 s/op\r\n     p(99.0000) =      2.407 s/op\r\n     p(99.9000) =      2.407 s/op\r\n     p(99.9900) =      2.407 s/op\r\n     p(99.9990) =      2.407 s/op\r\n     p(99.9999) =      2.407 s/op\r\n    p(100.0000) =      2.407 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readFloatsIcebergVectorized5k\r\n\r\n# Run progress: 37.50% complete, ETA 00:37:45\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.058 s/op\r\n# Warmup Iteration   2: 2.513 s/op\r\n# Warmup Iteration   3: 2.499 s/op\r\nIteration   1: 2.392 s/op\r\nIteration   2: 2.402 s/op\r\nIteration   3: 2.346 s/op\r\nIteration   4: 2.378 s/op\r\nIteration   5: 2.371 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readFloatsIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      2.378 (99.9%) 0.083 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.340, 2.345) = 0 \r\n    [2.345, 2.350) = 1 \r\n    [2.350, 2.355) = 0 \r\n    [2.355, 2.360) = 0 \r\n    [2.360, 2.365) = 0 \r\n    [2.365, 2.370) = 0 \r\n    [2.370, 2.375) = 1 \r\n    [2.375, 2.380) = 1 \r\n    [2.380, 2.385) = 0 \r\n    [2.385, 2.390) = 0 \r\n    [2.390, 2.395) = 1 \r\n    [2.395, 2.400) = 0 \r\n    [2.400, 2.405) = 1 \r\n    [2.405, 2.410) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.346 s/op\r\n     p(50.0000) =      2.378 s/op\r\n     p(90.0000) =      2.402 s/op\r\n     p(95.0000) =      2.402 s/op\r\n     p(99.0000) =      2.402 s/op\r\n     p(99.9000) =      2.402 s/op\r\n     p(99.9900) =      2.402 s/op\r\n     p(99.9990) =      2.402 s/op\r\n     p(99.9999) =      2.402 s/op\r\n    p(100.0000) =      2.402 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readFloatsSparkVectorized5k\r\n\r\n# Run progress: 43.75% complete, ETA 00:33:53\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 2.855 s/op\r\n# Warmup Iteration   2: 2.304 s/op\r\n# Warmup Iteration   3: 2.241 s/op\r\nIteration   1: 2.252 s/op\r\nIteration   2: 2.181 s/op\r\nIteration   3: 2.219 s/op\r\nIteration   4: 2.197 s/op\r\nIteration   5: 2.190 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readFloatsSparkVectorized5k\":\r\n  N = 5\r\n  mean =      2.208 (99.9%) 0.110 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.180, 2.185) = 1 \r\n    [2.185, 2.190) = 1 \r\n    [2.190, 2.195) = 0 \r\n    [2.195, 2.200) = 1 \r\n    [2.200, 2.205) = 0 \r\n    [2.205, 2.210) = 0 \r\n    [2.210, 2.215) = 0 \r\n    [2.215, 2.220) = 1 \r\n    [2.220, 2.225) = 0 \r\n    [2.225, 2.230) = 0 \r\n    [2.230, 2.235) = 0 \r\n    [2.235, 2.240) = 0 \r\n    [2.240, 2.245) = 0 \r\n    [2.245, 2.250) = 0 \r\n    [2.250, 2.255) = 1 \r\n    [2.255, 2.260) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.181 s/op\r\n     p(50.0000) =      2.197 s/op\r\n     p(90.0000) =      2.252 s/op\r\n     p(95.0000) =      2.252 s/op\r\n     p(99.0000) =      2.252 s/op\r\n     p(99.9000) =      2.252 s/op\r\n     p(99.9900) =      2.252 s/op\r\n     p(99.9990) =      2.252 s/op\r\n     p(99.9999) =      2.252 s/op\r\n    p(100.0000) =      2.252 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readIntegersIcebergVectorized5k\r\n\r\n# Run progress: 50.00% complete, ETA 00:30:02\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.129 s/op\r\n# Warmup Iteration   2: 2.522 s/op\r\n# Warmup Iteration   3: 2.564 s/op\r\nIteration   1: 2.434 s/op\r\nIteration   2: 2.478 s/op\r\nIteration   3: 2.394 s/op\r\nIteration   4: 2.419 s/op\r\nIteration   5: 2.425 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readIntegersIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      2.430 (99.9%) 0.118 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.390, 2.395) = 1 \r\n    [2.395, 2.400) = 0 \r\n    [2.400, 2.405) = 0 \r\n    [2.405, 2.410) = 0 \r\n    [2.410, 2.415) = 0 \r\n    [2.415, 2.420) = 1 \r\n    [2.420, 2.425) = 0 \r\n    [2.425, 2.430) = 1 \r\n    [2.430, 2.435) = 1 \r\n    [2.435, 2.440) = 0 \r\n    [2.440, 2.445) = 0 \r\n    [2.445, 2.450) = 0 \r\n    [2.450, 2.455) = 0 \r\n    [2.455, 2.460) = 0 \r\n    [2.460, 2.465) = 0 \r\n    [2.465, 2.470) = 0 \r\n    [2.470, 2.475) = 0 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.394 s/op\r\n     p(50.0000) =      2.425 s/op\r\n     p(90.0000) =      2.478 s/op\r\n     p(95.0000) =      2.478 s/op\r\n     p(99.0000) =      2.478 s/op\r\n     p(99.9000) =      2.478 s/op\r\n     p(99.9900) =      2.478 s/op\r\n     p(99.9990) =      2.478 s/op\r\n     p(99.9999) =      2.478 s/op\r\n    p(100.0000) =      2.478 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readIntegersSparkVectorized5k\r\n\r\n# Run progress: 56.25% complete, ETA 00:26:23\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.047 s/op\r\n# Warmup Iteration   2: 2.405 s/op\r\n# Warmup Iteration   3: 2.374 s/op\r\nIteration   1: 2.341 s/op\r\nIteration   2: 2.271 s/op\r\nIteration   3: 2.329 s/op\r\nIteration   4: 2.268 s/op\r\nIteration   5: 2.300 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readIntegersSparkVectorized5k\":\r\n  N = 5\r\n  mean =      2.302 (99.9%) 0.126 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.260, 2.265) = 0 \r\n    [2.265, 2.270) = 1 \r\n    [2.270, 2.275) = 1 \r\n    [2.275, 2.280) = 0 \r\n    [2.280, 2.285) = 0 \r\n    [2.285, 2.290) = 0 \r\n    [2.290, 2.295) = 0 \r\n    [2.295, 2.300) = 0 \r\n    [2.300, 2.305) = 1 \r\n    [2.305, 2.310) = 0 \r\n    [2.310, 2.315) = 0 \r\n    [2.315, 2.320) = 0 \r\n    [2.320, 2.325) = 0 \r\n    [2.325, 2.330) = 1 \r\n    [2.330, 2.335) = 0 \r\n    [2.335, 2.340) = 0 \r\n    [2.340, 2.345) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.268 s/op\r\n     p(50.0000) =      2.300 s/op\r\n     p(90.0000) =      2.341 s/op\r\n     p(95.0000) =      2.341 s/op\r\n     p(99.0000) =      2.341 s/op\r\n     p(99.9000) =      2.341 s/op\r\n     p(99.9900) =      2.341 s/op\r\n     p(99.9990) =      2.341 s/op\r\n     p(99.9999) =      2.341 s/op\r\n    p(100.0000) =      2.341 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readLongsIcebergVectorized5k\r\n\r\n# Run progress: 62.50% complete, ETA 00:22:36\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.328 s/op\r\n# Warmup Iteration   2: 2.795 s/op\r\n# Warmup Iteration   3: 2.839 s/op\r\nIteration   1: 2.648 s/op\r\nIteration   2: 3.041 s/op\r\nIteration   3: 2.635 s/op\r\nIteration   4: 2.645 s/op\r\nIteration   5: 2.689 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readLongsIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      2.732 (99.9%) 0.671 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.600, 2.650) = 3 \r\n    [2.650, 2.700) = 1 \r\n    [2.700, 2.750) = 0 \r\n    [2.750, 2.800) = 0 \r\n    [2.800, 2.850) = 0 \r\n    [2.850, 2.900) = 0 \r\n    [2.900, 2.950) = 0 \r\n    [2.950, 3.000) = 0 \r\n    [3.000, 3.050) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.635 s/op\r\n     p(50.0000) =      2.648 s/op\r\n     p(90.0000) =      3.041 s/op\r\n     p(95.0000) =      3.041 s/op\r\n     p(99.0000) =      3.041 s/op\r\n     p(99.9000) =      3.041 s/op\r\n     p(99.9900) =      3.041 s/op\r\n     p(99.9990) =      3.041 s/op\r\n     p(99.9999) =      3.041 s/op\r\n    p(100.0000) =      3.041 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readLongsSparkVectorized5k\r\n\r\n# Run progress: 68.75% complete, ETA 00:18:52\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 3.161 s/op\r\n# Warmup Iteration   2: 2.457 s/op\r\n# Warmup Iteration   3: 2.408 s/op\r\nIteration   1: 2.344 s/op\r\nIteration   2: 2.322 s/op\r\nIteration   3: 2.351 s/op\r\nIteration   4: 2.307 s/op\r\nIteration   5: 2.310 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readLongsSparkVectorized5k\":\r\n  N = 5\r\n  mean =      2.327 (99.9%) 0.076 s/op\r\n\r\n  Histogram, s/op:\r\n    [2.300, 2.305) = 0 \r\n    [2.305, 2.310) = 1 \r\n    [2.310, 2.315) = 1 \r\n    [2.315, 2.320) = 0 \r\n    [2.320, 2.325) = 1 \r\n    [2.325, 2.330) = 0 \r\n    [2.330, 2.335) = 0 \r\n    [2.335, 2.340) = 0 \r\n    [2.340, 2.345) = 1 \r\n    [2.345, 2.350) = 0 \r\n    [2.350, 2.355) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      2.307 s/op\r\n     p(50.0000) =      2.322 s/op\r\n     p(90.0000) =      2.351 s/op\r\n     p(95.0000) =      2.351 s/op\r\n     p(99.0000) =      2.351 s/op\r\n     p(99.9000) =      2.351 s/op\r\n     p(99.9900) =      2.351 s/op\r\n     p(99.9990) =      2.351 s/op\r\n     p(99.9999) =      2.351 s/op\r\n    p(100.0000) =      2.351 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readStringsIcebergVectorized5k\r\n\r\n# Run progress: 75.00% complete, ETA 00:15:07\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 4.964 s/op\r\n# Warmup Iteration   2: 4.274 s/op\r\n# Warmup Iteration   3: 4.244 s/op\r\nIteration   1: 4.167 s/op\r\nIteration   2: 4.172 s/op\r\nIteration   3: 4.127 s/op\r\nIteration   4: 4.146 s/op\r\nIteration   5: 4.169 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readStringsIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      4.156 (99.9%) 0.075 s/op\r\n\r\n  Histogram, s/op:\r\n    [4.120, 4.125) = 0 \r\n    [4.125, 4.130) = 1 \r\n    [4.130, 4.135) = 0 \r\n    [4.135, 4.140) = 0 \r\n    [4.140, 4.145) = 0 \r\n    [4.145, 4.150) = 1 \r\n    [4.150, 4.155) = 0 \r\n    [4.155, 4.160) = 0 \r\n    [4.160, 4.165) = 0 \r\n    [4.165, 4.170) = 2 \r\n    [4.170, 4.175) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      4.127 s/op\r\n     p(50.0000) =      4.167 s/op\r\n     p(90.0000) =      4.172 s/op\r\n     p(95.0000) =      4.172 s/op\r\n     p(99.0000) =      4.172 s/op\r\n     p(99.9000) =      4.172 s/op\r\n     p(99.9900) =      4.172 s/op\r\n     p(99.9990) =      4.172 s/op\r\n     p(99.9999) =      4.172 s/op\r\n    p(100.0000) =      4.172 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readStringsSparkVectorized5k\r\n\r\n# Run progress: 81.25% complete, ETA 00:11:22\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 4.747 s/op\r\n# Warmup Iteration   2: 4.092 s/op\r\n# Warmup Iteration   3: 4.072 s/op\r\nIteration   1: 4.013 s/op\r\nIteration   2: 3.928 s/op\r\nIteration   3: 4.017 s/op\r\nIteration   4: 3.945 s/op\r\nIteration   5: 3.990 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readStringsSparkVectorized5k\":\r\n  N = 5\r\n  mean =      3.978 (99.9%) 0.155 s/op\r\n\r\n  Histogram, s/op:\r\n    [3.920, 3.930) = 1 \r\n    [3.930, 3.940) = 0 \r\n    [3.940, 3.950) = 1 \r\n    [3.950, 3.960) = 0 \r\n    [3.960, 3.970) = 0 \r\n    [3.970, 3.980) = 0 \r\n    [3.980, 3.990) = 0 \r\n    [3.990, 4.000) = 1 \r\n    [4.000, 4.010) = 0 \r\n    [4.010, 4.020) = 2 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      3.928 s/op\r\n     p(50.0000) =      3.990 s/op\r\n     p(90.0000) =      4.017 s/op\r\n     p(95.0000) =      4.017 s/op\r\n     p(99.0000) =      4.017 s/op\r\n     p(99.9000) =      4.017 s/op\r\n     p(99.9900) =      4.017 s/op\r\n     p(99.9990) =      4.017 s/op\r\n     p(99.9999) =      4.017 s/op\r\n    p(100.0000) =      4.017 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readTimestampsIcebergVectorized5k\r\n\r\n# Run progress: 87.50% complete, ETA 00:07:36\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 2.066 s/op\r\n# Warmup Iteration   2: 1.622 s/op\r\n# Warmup Iteration   3: 1.602 s/op\r\nIteration   1: 1.546 s/op\r\nIteration   2: 1.503 s/op\r\nIteration   3: 1.542 s/op\r\nIteration   4: 1.507 s/op\r\nIteration   5: 1.599 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readTimestampsIcebergVectorized5k\":\r\n  N = 5\r\n  mean =      1.539 (99.9%) 0.150 s/op\r\n\r\n  Histogram, s/op:\r\n    [1.500, 1.510) = 2 \r\n    [1.510, 1.520) = 0 \r\n    [1.520, 1.530) = 0 \r\n    [1.530, 1.540) = 0 \r\n    [1.540, 1.550) = 2 \r\n    [1.550, 1.560) = 0 \r\n    [1.560, 1.570) = 0 \r\n    [1.570, 1.580) = 0 \r\n    [1.580, 1.590) = 0 \r\n    [1.590, 1.600) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      1.503 s/op\r\n     p(50.0000) =      1.542 s/op\r\n     p(90.0000) =      1.599 s/op\r\n     p(95.0000) =      1.599 s/op\r\n     p(99.0000) =      1.599 s/op\r\n     p(99.9000) =      1.599 s/op\r\n     p(99.9900) =      1.599 s/op\r\n     p(99.9990) =      1.599 s/op\r\n     p(99.9999) =      1.599 s/op\r\n    p(100.0000) =      1.599 s/op\r\n\r\n\r\n# JMH version: 1.21\r\n# VM version: JDK 1.8.0_282, OpenJDK 64-Bit Server VM, 25.282-b08\r\n# VM invoker: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n# VM options: <none>\r\n# Warmup: 3 iterations, single-shot each\r\n# Measurement: 5 iterations, single-shot each\r\n# Timeout: 10 min per iteration\r\n# Threads: 1 thread\r\n# Benchmark mode: Single shot invocation time\r\n# Benchmark: org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readTimestampsSparkVectorized5k\r\n\r\n# Run progress: 93.75% complete, ETA 00:03:47\r\n# Fork: 1 of 1\r\n# Warmup Iteration   1: 2.126 s/op\r\n# Warmup Iteration   2: 1.573 s/op\r\n# Warmup Iteration   3: 1.538 s/op\r\nIteration   1: 1.509 s/op\r\nIteration   2: 1.482 s/op\r\nIteration   3: 1.497 s/op\r\nIteration   4: 1.487 s/op\r\nIteration   5: 1.447 s/op\r\n\r\n\r\nResult \"org.apache.iceberg.spark.source.parquet.vectorized.VectorizedReadFlatParquetDataBenchmark.readTimestampsSparkVectorized5k\":\r\n  N = 5\r\n  mean =      1.485 (99.9%) 0.090 s/op\r\n\r\n  Histogram, s/op:\r\n    [1.440, 1.445) = 0 \r\n    [1.445, 1.450) = 1 \r\n    [1.450, 1.455) = 0 \r\n    [1.455, 1.460) = 0 \r\n    [1.460, 1.465) = 0 \r\n    [1.465, 1.470) = 0 \r\n    [1.470, 1.475) = 0 \r\n    [1.475, 1.480) = 0 \r\n    [1.480, 1.485) = 1 \r\n    [1.485, 1.490) = 1 \r\n    [1.490, 1.495) = 0 \r\n    [1.495, 1.500) = 1 \r\n    [1.500, 1.505) = 0 \r\n    [1.505, 1.510) = 1 \r\n\r\n  Percentiles, s/op:\r\n      p(0.0000) =      1.447 s/op\r\n     p(50.0000) =      1.487 s/op\r\n     p(90.0000) =      1.509 s/op\r\n     p(95.0000) =      1.509 s/op\r\n     p(99.0000) =      1.509 s/op\r\n     p(99.9000) =      1.509 s/op\r\n     p(99.9900) =      1.509 s/op\r\n     p(99.9990) =      1.509 s/op\r\n     p(99.9999) =      1.509 s/op\r\n    p(100.0000) =      1.509 s/op\r\n\r\n\r\n# Run complete. Total time: 01:00:29\r\n\r\nREMEMBER: The numbers below are just data. To gain reusable insights, you need to follow up on\r\nwhy the numbers are the way they are. Use profilers (see -prof, -lprof), design factorial\r\nexperiments, perform baseline and negative tests that provide experimental control, make sure\r\nthe benchmarking environment is safe on JVM/OS/HW level, ask for reviews from the domain experts.\r\nDo not assume the numbers tell you what you want them to tell.\r\n\r\nBenchmark                                                                 Mode  Cnt  Score   Error  Units\r\nVectorizedReadFlatParquetDataBenchmark.readDatesIcebergVectorized5k         ss    5  1.490  0.128   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readDatesSparkVectorized5k           ss    5  1.294  0.111   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readDecimalsIcebergVectorized5k      ss    5  8.642  0.239   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readDecimalsSparkVectorized5k        ss    5  8.444  0.096   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readDoublesIcebergVectorized5k       ss    5  2.558  0.248   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readDoublesSparkVectorized5k         ss    5  2.372  0.093   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readFloatsIcebergVectorized5k        ss    5  2.378  0.083   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readFloatsSparkVectorized5k          ss    5  2.208  0.110   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readIntegersIcebergVectorized5k      ss    5  2.430  0.118   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readIntegersSparkVectorized5k        ss    5  2.302  0.126   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readLongsIcebergVectorized5k         ss    5  2.732  0.671   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readLongsSparkVectorized5k           ss    5  2.327  0.076   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readStringsIcebergVectorized5k       ss    5  4.156  0.075   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readStringsSparkVectorized5k         ss    5  3.978  0.155   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readTimestampsIcebergVectorized5k    ss    5  1.539  0.150   s/op\r\nVectorizedReadFlatParquetDataBenchmark.readTimestampsSparkVectorized5k      ss    5  1.485  0.090   s/op\r\n\r\nBenchmark result is saved to XXX/iceberg_master/spark2/build/reports/jmh/results.txt\r\n\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/828391883/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]