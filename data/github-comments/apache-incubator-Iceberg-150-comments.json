[{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046123195","html_url":"https://github.com/apache/iceberg/issues/2456#issuecomment-1046123195","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2456","id":1046123195,"node_id":"IC_kwDOCW7NX84-WpK7","user":{"login":"vikrambohra","id":24703997,"node_id":"MDQ6VXNlcjI0NzAzOTk3","avatar_url":"https://avatars.githubusercontent.com/u/24703997?v=4","gravatar_id":"","url":"https://api.github.com/users/vikrambohra","html_url":"https://github.com/vikrambohra","followers_url":"https://api.github.com/users/vikrambohra/followers","following_url":"https://api.github.com/users/vikrambohra/following{/other_user}","gists_url":"https://api.github.com/users/vikrambohra/gists{/gist_id}","starred_url":"https://api.github.com/users/vikrambohra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vikrambohra/subscriptions","organizations_url":"https://api.github.com/users/vikrambohra/orgs","repos_url":"https://api.github.com/users/vikrambohra/repos","events_url":"https://api.github.com/users/vikrambohra/events{/privacy}","received_events_url":"https://api.github.com/users/vikrambohra/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-19T23:22:21Z","updated_at":"2022-02-19T23:22:21Z","author_association":"NONE","body":"@rdblue  \r\nI am seeing the same issue when writing a dataframe with df.write.format(\"orc\").save(path) and then reading it back with df.read.format(\"orc\").load(path) even when setting the check-nullability to false when writing the dataframe to iceberg.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046123195/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046123271","html_url":"https://github.com/apache/iceberg/issues/2456#issuecomment-1046123271","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2456","id":1046123271,"node_id":"IC_kwDOCW7NX84-WpMH","user":{"login":"vikrambohra","id":24703997,"node_id":"MDQ6VXNlcjI0NzAzOTk3","avatar_url":"https://avatars.githubusercontent.com/u/24703997?v=4","gravatar_id":"","url":"https://api.github.com/users/vikrambohra","html_url":"https://github.com/vikrambohra","followers_url":"https://api.github.com/users/vikrambohra/followers","following_url":"https://api.github.com/users/vikrambohra/following{/other_user}","gists_url":"https://api.github.com/users/vikrambohra/gists{/gist_id}","starred_url":"https://api.github.com/users/vikrambohra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vikrambohra/subscriptions","organizations_url":"https://api.github.com/users/vikrambohra/orgs","repos_url":"https://api.github.com/users/vikrambohra/repos","events_url":"https://api.github.com/users/vikrambohra/events{/privacy}","received_events_url":"https://api.github.com/users/vikrambohra/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-19T23:22:59Z","updated_at":"2022-02-19T23:23:49Z","author_association":"NONE","body":"@bgt-cdedels @coolderli @grantatspothero Did you find a way to overcome this problem?\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046123271/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046134798","html_url":"https://github.com/apache/iceberg/issues/2456#issuecomment-1046134798","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2456","id":1046134798,"node_id":"IC_kwDOCW7NX84-WsAO","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T00:58:24Z","updated_at":"2022-02-20T00:58:24Z","author_association":"CONTRIBUTOR","body":"@vikrambohra, I was just working on a similar problem and to fix it, I'm adding a table property that allows you to disable Spark's checks and use Iceberg's instead. Take a look at the changes in #4154.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046134798/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046135149","html_url":"https://github.com/apache/iceberg/pull/4154#issuecomment-1046135149","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4154","id":1046135149,"node_id":"IC_kwDOCW7NX84-WsFt","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T01:01:33Z","updated_at":"2022-02-20T01:01:33Z","author_association":"CONTRIBUTOR","body":"@aokolnychyi can you have another look? I got this working and added tests.\r\n\r\nI had to update a couple of the classes that handle Spark types to support dataset schemas with extra fields, but it was a very simple update.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046135149/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046139018","html_url":"https://github.com/apache/iceberg/issues/2456#issuecomment-1046139018","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2456","id":1046139018,"node_id":"IC_kwDOCW7NX84-WtCK","user":{"login":"vikrambohra","id":24703997,"node_id":"MDQ6VXNlcjI0NzAzOTk3","avatar_url":"https://avatars.githubusercontent.com/u/24703997?v=4","gravatar_id":"","url":"https://api.github.com/users/vikrambohra","html_url":"https://github.com/vikrambohra","followers_url":"https://api.github.com/users/vikrambohra/followers","following_url":"https://api.github.com/users/vikrambohra/following{/other_user}","gists_url":"https://api.github.com/users/vikrambohra/gists{/gist_id}","starred_url":"https://api.github.com/users/vikrambohra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vikrambohra/subscriptions","organizations_url":"https://api.github.com/users/vikrambohra/orgs","repos_url":"https://api.github.com/users/vikrambohra/repos","events_url":"https://api.github.com/users/vikrambohra/events{/privacy}","received_events_url":"https://api.github.com/users/vikrambohra/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T01:33:33Z","updated_at":"2022-02-20T01:33:33Z","author_association":"NONE","body":"Thanks for the reply @rdblue. We are on spark 2.3 at the moment. Will this change be back-ported to spark 2.3? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046139018/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046159290","html_url":"https://github.com/apache/iceberg/issues/4159#issuecomment-1046159290","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4159","id":1046159290,"node_id":"IC_kwDOCW7NX84-Wx-6","user":{"login":"amogh-jahagirdar","id":87500546,"node_id":"MDQ6VXNlcjg3NTAwNTQ2","avatar_url":"https://avatars.githubusercontent.com/u/87500546?v=4","gravatar_id":"","url":"https://api.github.com/users/amogh-jahagirdar","html_url":"https://github.com/amogh-jahagirdar","followers_url":"https://api.github.com/users/amogh-jahagirdar/followers","following_url":"https://api.github.com/users/amogh-jahagirdar/following{/other_user}","gists_url":"https://api.github.com/users/amogh-jahagirdar/gists{/gist_id}","starred_url":"https://api.github.com/users/amogh-jahagirdar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amogh-jahagirdar/subscriptions","organizations_url":"https://api.github.com/users/amogh-jahagirdar/orgs","repos_url":"https://api.github.com/users/amogh-jahagirdar/repos","events_url":"https://api.github.com/users/amogh-jahagirdar/events{/privacy}","received_events_url":"https://api.github.com/users/amogh-jahagirdar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T04:11:48Z","updated_at":"2022-02-20T15:09:39Z","author_association":"CONTRIBUTOR","body":"For expire snapshots, I think it's possible that we do not delete any manifest or data files in the case that those files are still referenced by later snapshots. If we don't allow expiring snapshots when gc.enabled is false, we would prevent users from performing the metadata update to remove snapshots which may be limiting.\r\n\r\nShould we differentiate between performing the metadata operation to expire snapshots and performing the following deletion of unreachable files due to the expiration? Tbh I can't really think of a solid use case where someone would want this differentiation for expiring snapshots, but just bringing it up while we're having this discussion.Please let me know if I misunderstood something!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046159290/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046172956","html_url":"https://github.com/apache/iceberg/issues/4159#issuecomment-1046172956","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4159","id":1046172956,"node_id":"IC_kwDOCW7NX84-W1Uc","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T06:26:26Z","updated_at":"2022-02-20T18:04:11Z","author_association":"CONTRIBUTOR","body":"Thanks for raising this thread! I was also planning to raise the same discussion but had some thoughts to finalize. I have been thinking about this question quite a lot recently, here are my current thoughts:\r\n\r\n## 1. gc.enabled\r\n\r\nI think as of today almost all the Iceberg users that tune this parameter are interpreting `gc.enabled=false` as \"disallow removal of data and delete files\" as @aokolnychyi suggested, so it only makes sense for us to throw exception in every place that deletes data of a table if `gc.enabled` is false. \r\n\r\nI think there are only 2 cases we need to consider:\r\n1. remove reacheable files, which includes\r\n  1. purge table\r\n  2. expire snapshot\r\n  3. any file deletion based on the Iceberg metadata tree\r\n2. remove orphan files\r\n\r\nFor 1, we should follow the definition of `gc.enabled` and throw for all cases.\r\nFor 2, see section 3, I think this is not really a table related operation.\r\n\r\n## 2. Remove metadata files by config\r\n\r\nThe current behavior in `CatalogUtil` of keeping data while removing metadata feels quite odd to me. If metadata is removed maybe the result data is still useful and can be reconstructed as a Hive table, but when object storage mode is enabled, it's basically not possible to track down the file locations, making everything just orphan files. @aokolnychyi you said:\r\n\r\n> However, we may consider allowing removal of metadata when gc.enabled is false. One may argue that metadata files are always owned by the table. We should also make our action configurable so that it can delete only data or metadata files.\r\n\r\nCould you provide some use cases where this is useful in addition to the recovery as a Hive table?\r\n\r\n## 3. Table location ownership\r\n\r\nAt a first glance, defining table prefix location is the best way to proceed forward, but when I think more, I start to realize that it defining ownership for a set of location prefixes in a table is not really needed for the use cases we want to achieve. Here are the 2 big use cases I considered so far:\r\n\r\n### remove orphan files\r\n\r\nThe fact that remove orphan files needs root location definition seems to be a circular argument. We exposes the action `remove_orphan_files(table)` with the assumption that table files are under the same root prefix, which works for Hive-like Iceberg tables. But after all orphan file removal is not a table operation, but a storage operation. Once a file is orphan, it no longer belongs to a table. We remove orphan files to save storage cost, not to make any aspect of the table better. We just remove by table using an assumption that is for Hive table, and now we try to make the Iceberg spec work with it.\r\n\r\nI think the correct way to run remove orphan files is to do it for the entire warehouse. I talked about my idea a bit in https://apache-iceberg.slack.com/archives/C025PH0G1D4/p1645203709220099. Most storage services have the ability to provide the full listing of files and it can be delivered much more efficiently than a ListFiles API, e.g. S3 inventory list. And Iceberg provides an efficient way to query Iceberg files metadata through system table. That means we can perform an efficient distributed join and find out the orphan files of the entire warehouse. I think thatâ€™s all what the data warehouse admin needs if we provide the feature.\r\n\r\nThis is basically talking about the `VACUUM` command without referring to a table. I think that's also what most managed data warehouse products on the market offer for storage cleanup. `VACUUM table` only makes sense for things like snapshot expiration, index cleanup, which do not rely on table root location mutual exclusion. If it's across storage you just do it for each. At least we will start to propose and provide such a feature for S3, for the other storage I think it's also not hard to provide an implementation once the interface is solidified.\r\n\r\n### table access permission\r\n\r\nAnother use case of table root location definition I can think of is for table access control. Admin might configure user access based on the table locations in storage. However, using file path access control to achieve that is just a storage-specific implementation which does not necessarily need to be true to support Iceberg table access management. For example, in S3 people can tag all the files it writes, and control access of that using S3 bucket policy. This allows multiple Iceberg tables to store files under the same bucket, but access control is still intact.\r\n\r\nTherefore from security perspective, table root path based file ownership should just be a type of ownership mode.\r\n\r\n### The problem of declaring table location ownership\r\n\r\nFrom S3 object storage mode usage reports from customers, most people still want to store data files in the same shared root bucket to minimize throttling as long as the above 2 issues I describe can be solved. \r\n\r\nIf an exclusive root location has to be declared for each table, then files of the table has to share certain part of the S3 prefix, and the throttling issue comes back, where a table not accessed for a year is guaranteed to be in a cold S3 partition and get throttled heavily when new traffic comes.\r\n\r\nMaybe S3 can in the future solve the cold partition issue with some keep-warm feature, but it will come with a pricing cost for sure, and my biggest concern is that people will start to build tools that only work for tables with declared root locations (we already see this in Trino), which creates difference in table behavior at spec level that optimizes for a certain storage layout. I don't know what's the future of storage, maybe a new product will come in the market with a completely different access pattern. Currently Iceberg's minimum storage feature requirement is very resilient to integrate with any storage, adding the concept of prefix ownership is basically preferring a file-system like storage.\r\n\r\nThere are also some areas that I have not finalized my thoughts yet, such as when data is replicated, should the replicated locations, quick access layer locations, archival locations also be declared as owned in Iceberg, and how should we provide tools to continuously track down those aspects. This feels to me like too much storage implementation details to handle from the table spec layer.\r\n\r\nI think it would be better to delegate to FileIOs to tackle those issues, as that is the actual vendor integration layer provided by Iceberg, where people choose which storage to use and what fits their bill, and storage frameworks and products can compete with the same set of rules. At least all the features I described for S3 are planned to be added, and I think there are GCS and HDFS equivalents that people can implement if feeling the need to reach feature parity.\r\n\r\nOne valuable thing to add in the Iceberg spec is the list (or set?) of all the table locations used. I think that could be used by a specific storage to do whatever is needed based on the information, such as removing all data in all directory. But in general we should be cautious about saying that all the locations are owned by a table.\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046172956/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046194306","html_url":"https://github.com/apache/iceberg/pull/4118#issuecomment-1046194306","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4118","id":1046194306,"node_id":"IC_kwDOCW7NX84-W6iC","user":{"login":"pan3793","id":26535726,"node_id":"MDQ6VXNlcjI2NTM1NzI2","avatar_url":"https://avatars.githubusercontent.com/u/26535726?v=4","gravatar_id":"","url":"https://api.github.com/users/pan3793","html_url":"https://github.com/pan3793","followers_url":"https://api.github.com/users/pan3793/followers","following_url":"https://api.github.com/users/pan3793/following{/other_user}","gists_url":"https://api.github.com/users/pan3793/gists{/gist_id}","starred_url":"https://api.github.com/users/pan3793/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pan3793/subscriptions","organizations_url":"https://api.github.com/users/pan3793/orgs","repos_url":"https://api.github.com/users/pan3793/repos","events_url":"https://api.github.com/users/pan3793/events{/privacy}","received_events_url":"https://api.github.com/users/pan3793/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T09:06:49Z","updated_at":"2022-02-20T09:06:49Z","author_association":"MEMBER","body":"> The changes look good, but this affects the LICENSE files as well. Can you remove the ANTLR section from the spark-runtime LICENSE files?\r\n\r\nThanks for review, updated.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046194306/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046272265","html_url":"https://github.com/apache/iceberg/issues/2456#issuecomment-1046272265","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2456","id":1046272265,"node_id":"IC_kwDOCW7NX84-XNkJ","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:23:06Z","updated_at":"2022-02-20T16:23:06Z","author_association":"CONTRIBUTOR","body":"@vikrambohra, Spark 2.3 doesn't hit this issue because this is caused by Spark adding schema validation in 3.0 and later. If you're using 2.x, then you should already be using Iceberg schema checking and you can turn off the nullability check directly.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046272265/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046272702","html_url":"https://github.com/apache/iceberg/pull/4172#issuecomment-1046272702","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4172","id":1046272702,"node_id":"IC_kwDOCW7NX84-XNq-","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:25:21Z","updated_at":"2022-02-20T16:25:21Z","author_association":"CONTRIBUTOR","body":"Thanks, @pan3793!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046272702/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046272849","html_url":"https://github.com/apache/iceberg/pull/4171#issuecomment-1046272849","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4171","id":1046272849,"node_id":"IC_kwDOCW7NX84-XNtR","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:26:03Z","updated_at":"2022-02-20T16:26:03Z","author_association":"CONTRIBUTOR","body":"Thanks, @hililiwei!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046272849/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046273072","html_url":"https://github.com/apache/iceberg/pull/4169#issuecomment-1046273072","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4169","id":1046273072,"node_id":"IC_kwDOCW7NX84-XNww","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:27:22Z","updated_at":"2022-02-20T16:27:22Z","author_association":"CONTRIBUTOR","body":"I think it's fine not to redact the filters. Thanks for working on this, @szehon-ho!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046273072/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046274286","html_url":"https://github.com/apache/iceberg/pull/4141#issuecomment-1046274286","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4141","id":1046274286,"node_id":"IC_kwDOCW7NX84-XODu","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:33:51Z","updated_at":"2022-02-20T16:33:51Z","author_association":"CONTRIBUTOR","body":"Looks like everything has been addressed so I'll merge this. Thanks, @szehon-ho!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046274286/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046274818","html_url":"https://github.com/apache/iceberg/pull/4146#issuecomment-1046274818","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4146","id":1046274818,"node_id":"IC_kwDOCW7NX84-XOMC","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:36:48Z","updated_at":"2022-02-20T16:36:48Z","author_association":"CONTRIBUTOR","body":"Thanks, @yittg!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046274818/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046275040","html_url":"https://github.com/apache/iceberg/pull/4170#issuecomment-1046275040","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4170","id":1046275040,"node_id":"IC_kwDOCW7NX84-XOPg","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:38:01Z","updated_at":"2022-02-20T16:38:01Z","author_association":"CONTRIBUTOR","body":"@samredai, do we sync this over to the iceberg-docs repo?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046275040/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046276436","html_url":"https://github.com/apache/iceberg/pull/4166#issuecomment-1046276436","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4166","id":1046276436,"node_id":"IC_kwDOCW7NX84-XOlU","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:45:30Z","updated_at":"2022-02-20T16:45:30Z","author_association":"CONTRIBUTOR","body":"> Now we don't really need a lock manager if lock-impl is not set.\r\n\r\nTrue, but since this is using reflection and may not actually call `versionId` I think we need to be careful. We could check whether `LOAD_VERSION_ID` is a noop and require a lock implementation.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046276436/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046277195","html_url":"https://github.com/apache/iceberg/pull/4162#issuecomment-1046277195","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4162","id":1046277195,"node_id":"IC_kwDOCW7NX84-XOxL","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:49:02Z","updated_at":"2022-02-20T16:49:02Z","author_association":"CONTRIBUTOR","body":"@wuwenchi, was there a problem that this caused? Can you update the description with what this is fixing besides trying to be slightly more permissive?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046277195/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046278630","html_url":"https://github.com/apache/iceberg/pull/4157#issuecomment-1046278630","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4157","id":1046278630,"node_id":"IC_kwDOCW7NX84-XPHm","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:57:17Z","updated_at":"2022-02-20T16:57:17Z","author_association":"CONTRIBUTOR","body":"Thanks, @openinx! Good to have this ready for when Flink supports 2.13.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046278630/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046279023","html_url":"https://github.com/apache/iceberg/pull/4158#issuecomment-1046279023","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4158","id":1046279023,"node_id":"IC_kwDOCW7NX84-XPNv","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T16:59:29Z","updated_at":"2022-02-20T16:59:29Z","author_association":"CONTRIBUTOR","body":"@openinx can you raise this as a discussion thread on the mailing list? Originally, we wanted to avoid changing the modules that users depend on and opted not to rename. If we want to revisit that decision I'm fine with it, but we should make sure there's broader consensus.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046279023/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046279554","html_url":"https://github.com/apache/iceberg/pull/4170#issuecomment-1046279554","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4170","id":1046279554,"node_id":"IC_kwDOCW7NX84-XPWC","user":{"login":"samredai","id":43911210,"node_id":"MDQ6VXNlcjQzOTExMjEw","avatar_url":"https://avatars.githubusercontent.com/u/43911210?v=4","gravatar_id":"","url":"https://api.github.com/users/samredai","html_url":"https://github.com/samredai","followers_url":"https://api.github.com/users/samredai/followers","following_url":"https://api.github.com/users/samredai/following{/other_user}","gists_url":"https://api.github.com/users/samredai/gists{/gist_id}","starred_url":"https://api.github.com/users/samredai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/samredai/subscriptions","organizations_url":"https://api.github.com/users/samredai/orgs","repos_url":"https://api.github.com/users/samredai/repos","events_url":"https://api.github.com/users/samredai/events{/privacy}","received_events_url":"https://api.github.com/users/samredai/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T17:02:13Z","updated_at":"2022-02-20T17:02:13Z","author_association":"CONTRIBUTOR","body":"@rdblue Yes since we wouldn't want to wait until the next version release for this to get out, we should merge this commit into the main branch on the iceberg-docs repo where it will auto-deploy.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046279554/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046280307","html_url":"https://github.com/apache/iceberg/pull/4151#issuecomment-1046280307","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4151","id":1046280307,"node_id":"IC_kwDOCW7NX84-XPhz","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T17:05:38Z","updated_at":"2022-02-20T17:05:38Z","author_association":"CONTRIBUTOR","body":"Thanks, @happyprg!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046280307/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046280560","html_url":"https://github.com/apache/iceberg/pull/4121#issuecomment-1046280560","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4121","id":1046280560,"node_id":"IC_kwDOCW7NX84-XPlw","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T17:06:44Z","updated_at":"2022-02-20T17:06:44Z","author_association":"CONTRIBUTOR","body":"Thanks, @SreeramGarlapati!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046280560/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046281073","html_url":"https://github.com/apache/iceberg/pull/4118#issuecomment-1046281073","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4118","id":1046281073,"node_id":"IC_kwDOCW7NX84-XPtx","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T17:08:59Z","updated_at":"2022-02-20T17:08:59Z","author_association":"CONTRIBUTOR","body":"Thanks, @pan3793!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046281073/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046283062","html_url":"https://github.com/apache/iceberg/pull/4115#issuecomment-1046283062","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4115","id":1046283062,"node_id":"IC_kwDOCW7NX84-XQM2","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T17:18:22Z","updated_at":"2022-02-20T17:18:22Z","author_association":"CONTRIBUTOR","body":"I'm going to close this because it is superceded by #4145 and its subtasks. Thanks for working on this, @yittg, this is really valuable!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046283062/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046283292","html_url":"https://github.com/apache/iceberg/pull/4149#issuecomment-1046283292","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4149","id":1046283292,"node_id":"IC_kwDOCW7NX84-XQQc","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T17:19:16Z","updated_at":"2022-02-20T17:19:16Z","author_association":"CONTRIBUTOR","body":"@nastra or @RussellSpitzer, can you review this one? Thank you!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046283292/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046285206","html_url":"https://github.com/apache/iceberg/pull/4170#issuecomment-1046285206","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4170","id":1046285206,"node_id":"IC_kwDOCW7NX84-XQuW","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T17:29:38Z","updated_at":"2022-02-20T17:29:38Z","author_association":"CONTRIBUTOR","body":"Probably good to consider moving these PRs over to the docs repo then.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046285206/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046287488","html_url":"https://github.com/apache/iceberg/pull/4119#issuecomment-1046287488","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4119","id":1046287488,"node_id":"IC_kwDOCW7NX84-XRSA","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T17:44:00Z","updated_at":"2022-02-20T17:44:00Z","author_association":"CONTRIBUTOR","body":"Thanks, @Zhangg7723!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046287488/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046292111","html_url":"https://github.com/apache/iceberg/pull/4071#issuecomment-1046292111","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4071","id":1046292111,"node_id":"IC_kwDOCW7NX84-XSaP","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T18:10:56Z","updated_at":"2022-02-20T18:10:56Z","author_association":"CONTRIBUTOR","body":"> Going back to the cherry-picking related operations, the fundamental difference of it from the other ones is that it produces a new snapshot with a new manifest list based on the cherry-picked snapshot information. What exactly is our semantics for cherry-picking?\r\n\r\nThis is a great question. Right now, cherry picking is not like git. Git cherry picking re-applies a diff, but makes no guarantee about the semantic changes. Iceberg cherry picking (so far) gives the same semantics. That's why we currently only support append and overwrites that are replace partitions. For those, we can check that the changes can still be safely applied by re-validating the commit checks. For append, there are no checks so it is safe. For replace partitions, we validate that no new files have been added to the replaced partitions.\r\n\r\nIceberg doesn't currently support cherry-picking snapshots that require knowing more about the original operation. For example, DeleteFiles using a filter would need to store the filter and validate that no other data files were added that match the delete filter. Or maybe it would just run the delete filter again. My plan is to add these when people start asking for them.\r\n\r\nFor now, I think cherrypickAll would just run `cherrypick` in a loop. The main benefit would be keeping track of where the branch diverged. But this is probably more advanced than we need for now. In the short term, I'd focus on getting the branching and tagging parts in. Cherry picking a branch is something we can add later.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046292111/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046292399","html_url":"https://github.com/apache/iceberg/pull/4071#issuecomment-1046292399","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4071","id":1046292399,"node_id":"IC_kwDOCW7NX84-XSev","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T18:12:29Z","updated_at":"2022-02-20T18:12:29Z","author_association":"CONTRIBUTOR","body":"@amogh-jahagirdar, I think we're in agreement on how to handle create/remove/replace operations. Would you like to adapt this PR to add those to the `ManageSnapshots` API?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046292399/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046302323","html_url":"https://github.com/apache/iceberg/pull/4174#issuecomment-1046302323","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4174","id":1046302323,"node_id":"IC_kwDOCW7NX84-XU5z","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T19:12:29Z","updated_at":"2022-02-20T19:12:29Z","author_association":"CONTRIBUTOR","body":"@CircArgs, FYI. I tried to open a PR against your branch, but I couldn't so I had to create a new PR.\r\n\r\nFeel free to pick the changes into your branch if you want to commit the other PR.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046302323/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046303190","html_url":"https://github.com/apache/iceberg/pull/4070#issuecomment-1046303190","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4070","id":1046303190,"node_id":"IC_kwDOCW7NX84-XVHW","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-20T19:17:52Z","updated_at":"2022-02-20T19:17:52Z","author_association":"CONTRIBUTOR","body":"Thanks, @puchengy!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046303190/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046370161","html_url":"https://github.com/apache/iceberg/pull/4175#issuecomment-1046370161","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4175","id":1046370161,"node_id":"IC_kwDOCW7NX84-Xldx","user":{"login":"arminnajafi","id":9739243,"node_id":"MDQ6VXNlcjk3MzkyNDM=","avatar_url":"https://avatars.githubusercontent.com/u/9739243?v=4","gravatar_id":"","url":"https://api.github.com/users/arminnajafi","html_url":"https://github.com/arminnajafi","followers_url":"https://api.github.com/users/arminnajafi/followers","following_url":"https://api.github.com/users/arminnajafi/following{/other_user}","gists_url":"https://api.github.com/users/arminnajafi/gists{/gist_id}","starred_url":"https://api.github.com/users/arminnajafi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arminnajafi/subscriptions","organizations_url":"https://api.github.com/users/arminnajafi/orgs","repos_url":"https://api.github.com/users/arminnajafi/repos","events_url":"https://api.github.com/users/arminnajafi/events{/privacy}","received_events_url":"https://api.github.com/users/arminnajafi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T00:56:57Z","updated_at":"2022-02-21T00:56:57Z","author_association":"CONTRIBUTOR","body":"@jackye1995 @amogh-jahagirdar ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046370161/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046392866","html_url":"https://github.com/apache/iceberg/issues/4161#issuecomment-1046392866","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4161","id":1046392866,"node_id":"IC_kwDOCW7NX84-XrAi","user":{"login":"felixYyu","id":3785228,"node_id":"MDQ6VXNlcjM3ODUyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3785228?v=4","gravatar_id":"","url":"https://api.github.com/users/felixYyu","html_url":"https://github.com/felixYyu","followers_url":"https://api.github.com/users/felixYyu/followers","following_url":"https://api.github.com/users/felixYyu/following{/other_user}","gists_url":"https://api.github.com/users/felixYyu/gists{/gist_id}","starred_url":"https://api.github.com/users/felixYyu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/felixYyu/subscriptions","organizations_url":"https://api.github.com/users/felixYyu/orgs","repos_url":"https://api.github.com/users/felixYyu/repos","events_url":"https://api.github.com/users/felixYyu/events{/privacy}","received_events_url":"https://api.github.com/users/felixYyu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T01:47:53Z","updated_at":"2022-02-21T01:47:53Z","author_association":"CONTRIBUTOR","body":"thanks @ajantha-bhat .\r\na.it is sequential operation, order of expire_snapshots->rewrite_data_files->rewrite_manifests->remove_orphan_files.\r\nb.I only test for table in hadoop catalog.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046392866/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046421160","html_url":"https://github.com/apache/iceberg/issues/4176#issuecomment-1046421160","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4176","id":1046421160,"node_id":"IC_kwDOCW7NX84-Xx6o","user":{"login":"coolderli","id":38486782,"node_id":"MDQ6VXNlcjM4NDg2Nzgy","avatar_url":"https://avatars.githubusercontent.com/u/38486782?v=4","gravatar_id":"","url":"https://api.github.com/users/coolderli","html_url":"https://github.com/coolderli","followers_url":"https://api.github.com/users/coolderli/followers","following_url":"https://api.github.com/users/coolderli/following{/other_user}","gists_url":"https://api.github.com/users/coolderli/gists{/gist_id}","starred_url":"https://api.github.com/users/coolderli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/coolderli/subscriptions","organizations_url":"https://api.github.com/users/coolderli/orgs","repos_url":"https://api.github.com/users/coolderli/repos","events_url":"https://api.github.com/users/coolderli/events{/privacy}","received_events_url":"https://api.github.com/users/coolderli/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T02:54:35Z","updated_at":"2022-02-21T02:54:35Z","author_association":"CONTRIBUTOR","body":"@rdblue @RussellSpitzer Can you take a look, thanks.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046421160/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046425824","html_url":"https://github.com/apache/iceberg/pull/4158#issuecomment-1046425824","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4158","id":1046425824,"node_id":"IC_kwDOCW7NX84-XzDg","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T03:05:49Z","updated_at":"2022-02-21T03:05:49Z","author_association":"MEMBER","body":"> @openinx can you raise this as a discussion thread on the mailing list? Originally, we wanted to avoid changing the modules that users depend on and opted not to rename. If we want to revisit that decision I'm fine with it, but we should make sure there's broader consensus.\r\n\r\nYes, I've just posted a discussion to iceberg-dev mail list. https://lists.apache.org/thread/cwhqktpw0f89gg7hx6fol4dgfkb1t6ny","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046425824/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046427956","html_url":"https://github.com/apache/iceberg/pull/4147#issuecomment-1046427956","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4147","id":1046427956,"node_id":"IC_kwDOCW7NX84-Xzk0","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T03:10:20Z","updated_at":"2022-02-21T03:10:20Z","author_association":"CONTRIBUTOR","body":"Thanks @kbendick @rdblue , i've updated the changes to make it more clear.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046427956/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046428453","html_url":"https://github.com/apache/iceberg/pull/4158#issuecomment-1046428453","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4158","id":1046428453,"node_id":"IC_kwDOCW7NX84-Xzsl","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T03:11:17Z","updated_at":"2022-02-21T03:11:17Z","author_association":"MEMBER","body":"@pan3793 I think you are right, we don't need to attach the scala suffix for spark 2.4. Thanks. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046428453/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046430517","html_url":"https://github.com/apache/iceberg/issues/4046#issuecomment-1046430517","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4046","id":1046430517,"node_id":"IC_kwDOCW7NX84-X0M1","user":{"login":"flyrain","id":1322359,"node_id":"MDQ6VXNlcjEzMjIzNTk=","avatar_url":"https://avatars.githubusercontent.com/u/1322359?v=4","gravatar_id":"","url":"https://api.github.com/users/flyrain","html_url":"https://github.com/flyrain","followers_url":"https://api.github.com/users/flyrain/followers","following_url":"https://api.github.com/users/flyrain/following{/other_user}","gists_url":"https://api.github.com/users/flyrain/gists{/gist_id}","starred_url":"https://api.github.com/users/flyrain/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/flyrain/subscriptions","organizations_url":"https://api.github.com/users/flyrain/orgs","repos_url":"https://api.github.com/users/flyrain/repos","events_url":"https://api.github.com/users/flyrain/events{/privacy}","received_events_url":"https://api.github.com/users/flyrain/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T03:15:43Z","updated_at":"2022-02-21T03:15:43Z","author_association":"CONTRIBUTOR","body":"As @RussellSpitzer mentioned in https://apache-iceberg.slack.com/archives/C025PH0G1D4/p1645289087247769, the MOR deletes make the metrics unreliable. In that case, we still need to read data files.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046430517/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046431890","html_url":"https://github.com/apache/iceberg/issues/3968#issuecomment-1046431890","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3968","id":1046431890,"node_id":"IC_kwDOCW7NX84-X0iS","user":{"login":"qq240035000","id":32573841,"node_id":"MDQ6VXNlcjMyNTczODQx","avatar_url":"https://avatars.githubusercontent.com/u/32573841?v=4","gravatar_id":"","url":"https://api.github.com/users/qq240035000","html_url":"https://github.com/qq240035000","followers_url":"https://api.github.com/users/qq240035000/followers","following_url":"https://api.github.com/users/qq240035000/following{/other_user}","gists_url":"https://api.github.com/users/qq240035000/gists{/gist_id}","starred_url":"https://api.github.com/users/qq240035000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qq240035000/subscriptions","organizations_url":"https://api.github.com/users/qq240035000/orgs","repos_url":"https://api.github.com/users/qq240035000/repos","events_url":"https://api.github.com/users/qq240035000/events{/privacy}","received_events_url":"https://api.github.com/users/qq240035000/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T03:18:33Z","updated_at":"2022-02-21T03:18:33Z","author_association":"NONE","body":"I want it too","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046431890/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046435491","html_url":"https://github.com/apache/iceberg/pull/4141#issuecomment-1046435491","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4141","id":1046435491,"node_id":"IC_kwDOCW7NX84-X1aj","user":{"login":"szehon-ho","id":20555759,"node_id":"MDQ6VXNlcjIwNTU1NzU5","avatar_url":"https://avatars.githubusercontent.com/u/20555759?v=4","gravatar_id":"","url":"https://api.github.com/users/szehon-ho","html_url":"https://github.com/szehon-ho","followers_url":"https://api.github.com/users/szehon-ho/followers","following_url":"https://api.github.com/users/szehon-ho/following{/other_user}","gists_url":"https://api.github.com/users/szehon-ho/gists{/gist_id}","starred_url":"https://api.github.com/users/szehon-ho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szehon-ho/subscriptions","organizations_url":"https://api.github.com/users/szehon-ho/orgs","repos_url":"https://api.github.com/users/szehon-ho/repos","events_url":"https://api.github.com/users/szehon-ho/events{/privacy}","received_events_url":"https://api.github.com/users/szehon-ho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T03:24:36Z","updated_at":"2022-02-21T03:24:36Z","author_association":"COLLABORATOR","body":"Thanks @RussellSpitzer , @kbendick , @aokolnychyi  for reviews, and @rdblue  for the weekend merge !","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046435491/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046435769","html_url":"https://github.com/apache/iceberg/pull/4152#issuecomment-1046435769","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4152","id":1046435769,"node_id":"IC_kwDOCW7NX84-X1e5","user":{"login":"0xffmeta","id":98149057,"node_id":"U_kgDOBdmiwQ","avatar_url":"https://avatars.githubusercontent.com/u/98149057?v=4","gravatar_id":"","url":"https://api.github.com/users/0xffmeta","html_url":"https://github.com/0xffmeta","followers_url":"https://api.github.com/users/0xffmeta/followers","following_url":"https://api.github.com/users/0xffmeta/following{/other_user}","gists_url":"https://api.github.com/users/0xffmeta/gists{/gist_id}","starred_url":"https://api.github.com/users/0xffmeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/0xffmeta/subscriptions","organizations_url":"https://api.github.com/users/0xffmeta/orgs","repos_url":"https://api.github.com/users/0xffmeta/repos","events_url":"https://api.github.com/users/0xffmeta/events{/privacy}","received_events_url":"https://api.github.com/users/0xffmeta/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T03:25:03Z","updated_at":"2022-02-21T03:25:03Z","author_association":"CONTRIBUTOR","body":"Just rebase the commits to resolve a conflict in master.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046435769/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046469605","html_url":"https://github.com/apache/iceberg/issues/4176#issuecomment-1046469605","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4176","id":1046469605,"node_id":"IC_kwDOCW7NX84-X9vl","user":{"login":"pan3793","id":26535726,"node_id":"MDQ6VXNlcjI2NTM1NzI2","avatar_url":"https://avatars.githubusercontent.com/u/26535726?v=4","gravatar_id":"","url":"https://api.github.com/users/pan3793","html_url":"https://github.com/pan3793","followers_url":"https://api.github.com/users/pan3793/followers","following_url":"https://api.github.com/users/pan3793/following{/other_user}","gists_url":"https://api.github.com/users/pan3793/gists{/gist_id}","starred_url":"https://api.github.com/users/pan3793/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pan3793/subscriptions","organizations_url":"https://api.github.com/users/pan3793/orgs","repos_url":"https://api.github.com/users/pan3793/repos","events_url":"https://api.github.com/users/pan3793/events{/privacy}","received_events_url":"https://api.github.com/users/pan3793/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T04:43:40Z","updated_at":"2022-02-21T04:43:40Z","author_association":"MEMBER","body":"The restriction comes from Spark, Spark does not allow change a nullable column to not nullable.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046469605/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046483986","html_url":"https://github.com/apache/iceberg/issues/4176#issuecomment-1046483986","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4176","id":1046483986,"node_id":"IC_kwDOCW7NX84-YBQS","user":{"login":"coolderli","id":38486782,"node_id":"MDQ6VXNlcjM4NDg2Nzgy","avatar_url":"https://avatars.githubusercontent.com/u/38486782?v=4","gravatar_id":"","url":"https://api.github.com/users/coolderli","html_url":"https://github.com/coolderli","followers_url":"https://api.github.com/users/coolderli/followers","following_url":"https://api.github.com/users/coolderli/following{/other_user}","gists_url":"https://api.github.com/users/coolderli/gists{/gist_id}","starred_url":"https://api.github.com/users/coolderli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/coolderli/subscriptions","organizations_url":"https://api.github.com/users/coolderli/orgs","repos_url":"https://api.github.com/users/coolderli/repos","events_url":"https://api.github.com/users/coolderli/events{/privacy}","received_events_url":"https://api.github.com/users/coolderli/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T05:17:11Z","updated_at":"2022-02-21T05:17:11Z","author_association":"CONTRIBUTOR","body":"Do we need to modify the document to explain it?\r\n![image](https://user-images.githubusercontent.com/38486782/154893741-fa9727d1-1999-4a05-af4e-b8a801d47e44.png)\r\nhttps://iceberg.apache.org/docs/latest/spark-ddl/#alter-table--alter-column","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046483986/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046531282","html_url":"https://github.com/apache/iceberg/pull/3797#issuecomment-1046531282","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3797","id":1046531282,"node_id":"IC_kwDOCW7NX84-YMzS","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T06:58:45Z","updated_at":"2022-02-21T06:58:45Z","author_association":"CONTRIBUTOR","body":"close this one due to prefer #4177","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046531282/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046544706","html_url":"https://github.com/apache/iceberg/pull/4165#issuecomment-1046544706","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4165","id":1046544706,"node_id":"IC_kwDOCW7NX84-YQFC","user":{"login":"nastra","id":271029,"node_id":"MDQ6VXNlcjI3MTAyOQ==","avatar_url":"https://avatars.githubusercontent.com/u/271029?v=4","gravatar_id":"","url":"https://api.github.com/users/nastra","html_url":"https://github.com/nastra","followers_url":"https://api.github.com/users/nastra/followers","following_url":"https://api.github.com/users/nastra/following{/other_user}","gists_url":"https://api.github.com/users/nastra/gists{/gist_id}","starred_url":"https://api.github.com/users/nastra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nastra/subscriptions","organizations_url":"https://api.github.com/users/nastra/orgs","repos_url":"https://api.github.com/users/nastra/repos","events_url":"https://api.github.com/users/nastra/events{/privacy}","received_events_url":"https://api.github.com/users/nastra/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T07:18:37Z","updated_at":"2022-02-21T07:18:37Z","author_association":"CONTRIBUTOR","body":"Failed spark test looks rather unrelated\r\n```\r\norg.apache.iceberg.spark.actions.TestRemoveOrphanFilesAction3 > orphanedFileRemovedWithParallelTasks FAILED\r\n    java.lang.AssertionError: Should delete 4 files expected:<4> but was:<3>\r\n        at org.junit.Assert.fail(Assert.java:89)\r\n        at org.junit.Assert.failNotEquals(Assert.java:835)\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046544706/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046609038","html_url":"https://github.com/apache/iceberg/issues/2575#issuecomment-1046609038","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2575","id":1046609038,"node_id":"IC_kwDOCW7NX84-YfyO","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T08:44:27Z","updated_at":"2022-02-21T08:44:27Z","author_association":"CONTRIBUTOR","body":"I encountered this failed test case twice, and i think i reproduced it locally.\r\n\r\nBefore diving it deeply, i think it's better to share the log here, \r\nand at first glance it looks like it is different from [the conclusion](https://github.com/apache/iceberg/pull/4117#issuecomment-1042701849).\r\n\r\nThe following is the detail:\r\n\r\n```\r\n[Source: Values(tuples=[[{ 1, _UTF-16LE'aaa' }, { 1, _UTF-16LE'bbb' }, { 1, _UTF-16LE'ccc' }, { 2, _UTF-16LE'aaa' }, { 2, _UTF-16LE'bbb' }, { 2, _UTF-16LE'ccc' }, { 3, _UTF-16LE'aaa' }, { 3, _UTF-16LE'bbb' }, { 3, _UTF-16LE'ccc' }]]) (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Source: Values(tuples=[[{ 1, _UTF-16LE'aaa' }, { 1, _UTF-16LE'bbb' }, { 1, _UTF-16LE'ccc' }, { 2, _UTF-16LE'aaa' }, { 2, _UTF-16LE'bbb' }, { 2, _UTF-16LE'ccc' }, { 3, _UTF-16LE'aaa' }, { 3, _UTF-16LE'bbb' }, { 3, _UTF-16LE'ccc' }]]) (1/1)#0 (c3d03556514594e8aff0175bbd12d35e) switched from INITIALIZING to RUNNING.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Values(tuples=[[{ 1, _UTF-16LE'aaa' }, { 1, _UTF-16LE'bbb' }, { 1, _UTF-16LE'ccc' }, { 2, _UTF-16LE'aaa' }, { 2, _UTF-16LE'bbb' }, { 2, _UTF-16LE'ccc' }, { 3, _UTF-16LE'aaa' }, { 3, _UTF-16LE'bbb' }, { 3, _UTF-16LE'ccc' }]]) (1/1) (c3d03556514594e8aff0175bbd12d35e) switched from INITIALIZING to RUNNING.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/metadata/00000-e773c6cb-c67a-422d-9c56-8c68d3d2d64b.metadata.json\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: testhive.db.test_hash_distribution_mode\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergStreamWriter (1/1)#0 (e863df4f3c93498a6d45488a9898774b) switched from INITIALIZING to RUNNING.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergStreamWriter (1/1) (e863df4f3c93498a6d45488a9898774b) switched from INITIALIZING to RUNNING.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 (4154094a26a2ffc60623d0ec10172143) switched from INITIALIZING to RUNNING.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1) (4154094a26a2ffc60623d0ec10172143) switched from INITIALIZING to RUNNING.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Triggering checkpoint 1 (type=CHECKPOINT) @ 1645431273362 for job 32b28d9a2d686b0cb1ed6efb940781b5.\r\n[Source: Values(tuples=[[{ 1, _UTF-16LE'aaa' }, { 1, _UTF-16LE'bbb' }, { 1, _UTF-16LE'ccc' }, { 2, _UTF-16LE'aaa' }, { 2, _UTF-16LE'bbb' }, { 2, _UTF-16LE'ccc' }, { 3, _UTF-16LE'aaa' }, { 3, _UTF-16LE'bbb' }, { 3, _UTF-16LE'ccc' }]]) (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Source: Values(tuples=[[{ 1, _UTF-16LE'aaa' }, { 1, _UTF-16LE'bbb' }, { 1, _UTF-16LE'ccc' }, { 2, _UTF-16LE'aaa' }, { 2, _UTF-16LE'bbb' }, { 2, _UTF-16LE'ccc' }, { 3, _UTF-16LE'aaa' }, { 3, _UTF-16LE'bbb' }, { 3, _UTF-16LE'ccc' }]]) (1/1)#0 (c3d03556514594e8aff0175bbd12d35e) switched from RUNNING to FINISHED.\r\n[Source: Values(tuples=[[{ 1, _UTF-16LE'aaa' }, { 1, _UTF-16LE'bbb' }, { 1, _UTF-16LE'ccc' }, { 2, _UTF-16LE'aaa' }, { 2, _UTF-16LE'bbb' }, { 2, _UTF-16LE'ccc' }, { 3, _UTF-16LE'aaa' }, { 3, _UTF-16LE'bbb' }, { 3, _UTF-16LE'ccc' }]]) (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Values(tuples=[[{ 1, _UTF-16LE'aaa' }, { 1, _UTF-16LE'bbb' }, { 1, _UTF-16LE'ccc' }, { 2, _UTF-16LE'aaa' }, { 2, _UTF-16LE'bbb' }, { 2, _UTF-16LE'ccc' }, { 3, _UTF-16LE'aaa' }, { 3, _UTF-16LE'bbb' }, { 3, _UTF-16LE'ccc' }]]) (1/1)#0 (c3d03556514594e8aff0175bbd12d35e).\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Values(tuples=[[{ 1, _UTF-16LE'aaa' }, { 1, _UTF-16LE'bbb' }, { 1, _UTF-16LE'ccc' }, { 2, _UTF-16LE'aaa' }, { 2, _UTF-16LE'bbb' }, { 2, _UTF-16LE'ccc' }, { 3, _UTF-16LE'aaa' }, { 3, _UTF-16LE'bbb' }, { 3, _UTF-16LE'ccc' }]]) (1/1)#0 c3d03556514594e8aff0175bbd12d35e.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Values(tuples=[[{ 1, _UTF-16LE'aaa' }, { 1, _UTF-16LE'bbb' }, { 1, _UTF-16LE'ccc' }, { 2, _UTF-16LE'aaa' }, { 2, _UTF-16LE'bbb' }, { 2, _UTF-16LE'ccc' }, { 3, _UTF-16LE'aaa' }, { 3, _UTF-16LE'bbb' }, { 3, _UTF-16LE'ccc' }]]) (1/1) (c3d03556514594e8aff0175bbd12d35e) switched from RUNNING to FINISHED.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.HadoopShimsPre2_7 - Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00001.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.WriterImpl - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00001.orc with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=bbb/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00002.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.WriterImpl - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=bbb/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00002.orc with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=ccc/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00003.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.WriterImpl - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=ccc/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00003.orc with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00004.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Start to flush snapshot state to state backend, table: testhive.db.test_hash_distribution_mode, checkpointId: 1\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.WriterImpl - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00004.orc with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergStreamWriter (1/1)#0 (e863df4f3c93498a6d45488a9898774b) switched from RUNNING to FINISHED.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for IcebergStreamWriter (1/1)#0 (e863df4f3c93498a6d45488a9898774b).\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task IcebergStreamWriter (1/1)#0 e863df4f3c93498a6d45488a9898774b.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergStreamWriter (1/1) (e863df4f3c93498a6d45488a9898774b) switched from RUNNING to FINISHED.\r\n[jobmanager-io-thread-5] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Completed checkpoint 1 for job 32b28d9a2d686b0cb1ed6efb940781b5 (3397 bytes, checkpointDuration=908 ms, finalizationTime=4 ms).\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Committing append with 4 data files and 0 delete files to table testhive.db.test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 alter_table: db=db tbl=test_hash_distribution_mode newtbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 alter_table: db=db tbl=test_hash_distribution_mode newtbl=test_hash_distribution_mode\t\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 32b28d9a2d686b0cb1ed6efb940781b5 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table testhive.db.test_hash_distribution_mode in 105 ms\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.SnapshotProducer - Committed snapshot 1987697929173874507 (MergeAppend)\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/metadata/00001-6d7501d3-28cb-4ec2-bdb8-51c3b948589e.metadata.json\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Committed in 225 ms\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 (4154094a26a2ffc60623d0ec10172143) switched from RUNNING to FINISHED.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 (4154094a26a2ffc60623d0ec10172143).\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 4154094a26a2ffc60623d0ec10172143.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1) (4154094a26a2ffc60623d0ec10172143) switched from RUNNING to FINISHED.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager - Clearing resource requirements of job 32b28d9a2d686b0cb1ed6efb940781b5\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job insert-into_testhive.db.test_hash_distribution_mode (32b28d9a2d686b0cb1ed6efb940781b5) switched from state RUNNING to FINISHED.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Stopping checkpoint coordinator for job 32b28d9a2d686b0cb1ed6efb940781b5.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Job 32b28d9a2d686b0cb1ed6efb940781b5 reached terminal state FINISHED.\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.jobmaster.JobMaster - Stopping the JobMaster for job 'insert-into_testhive.db.test_hash_distribution_mode' (32b28d9a2d686b0cb1ed6efb940781b5).\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore - Shutting down\r\n```\r\n\r\nThe result as expected\r\n```\r\nThere should be 1 data file in partition 'aaa' expected:<1> but was:<2>\r\nExpected :1\r\nActual   :2\r\n<Click to see difference>\r\n\r\njava.lang.AssertionError: There should be 1 data file in partition 'aaa' expected:<1> but was:<2>\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046609038/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046609770","html_url":"https://github.com/apache/iceberg/pull/4117#issuecomment-1046609770","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4117","id":1046609770,"node_id":"IC_kwDOCW7NX84-Yf9q","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T08:45:19Z","updated_at":"2022-02-21T08:45:19Z","author_association":"CONTRIBUTOR","body":"@openinx @rdblue i add some log [here](https://github.com/apache/iceberg/issues/2575#issuecomment-1046609038) about this PR","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046609770/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046640345","html_url":"https://github.com/apache/iceberg/pull/4149#issuecomment-1046640345","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4149","id":1046640345,"node_id":"IC_kwDOCW7NX84-YnbZ","user":{"login":"nastra","id":271029,"node_id":"MDQ6VXNlcjI3MTAyOQ==","avatar_url":"https://avatars.githubusercontent.com/u/271029?v=4","gravatar_id":"","url":"https://api.github.com/users/nastra","html_url":"https://github.com/nastra","followers_url":"https://api.github.com/users/nastra/followers","following_url":"https://api.github.com/users/nastra/following{/other_user}","gists_url":"https://api.github.com/users/nastra/gists{/gist_id}","starred_url":"https://api.github.com/users/nastra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nastra/subscriptions","organizations_url":"https://api.github.com/users/nastra/orgs","repos_url":"https://api.github.com/users/nastra/repos","events_url":"https://api.github.com/users/nastra/events{/privacy}","received_events_url":"https://api.github.com/users/nastra/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T09:17:22Z","updated_at":"2022-02-21T09:17:22Z","author_association":"CONTRIBUTOR","body":"@rdblue or @RussellSpitzer when you merge this one, please also merge https://github.com/apache/iceberg/pull/3910 as it fixes the same issue for Spark 3.2 benchmarks","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046640345/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046645510","html_url":"https://github.com/apache/iceberg/pull/4166#issuecomment-1046645510","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4166","id":1046645510,"node_id":"IC_kwDOCW7NX84-YosG","user":{"login":"rajarshisarkar","id":4561678,"node_id":"MDQ6VXNlcjQ1NjE2Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/4561678?v=4","gravatar_id":"","url":"https://api.github.com/users/rajarshisarkar","html_url":"https://github.com/rajarshisarkar","followers_url":"https://api.github.com/users/rajarshisarkar/followers","following_url":"https://api.github.com/users/rajarshisarkar/following{/other_user}","gists_url":"https://api.github.com/users/rajarshisarkar/gists{/gist_id}","starred_url":"https://api.github.com/users/rajarshisarkar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rajarshisarkar/subscriptions","organizations_url":"https://api.github.com/users/rajarshisarkar/orgs","repos_url":"https://api.github.com/users/rajarshisarkar/repos","events_url":"https://api.github.com/users/rajarshisarkar/events{/privacy}","received_events_url":"https://api.github.com/users/rajarshisarkar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T09:22:31Z","updated_at":"2022-02-21T09:22:31Z","author_association":"CONTRIBUTOR","body":"> Now we don't really need a lock manager if lock-impl is not set. I think using a in-memory lock is also not needed. \r\nIf we implement a no-op lock manager for GlueCatalog and use that instead of the default in-memory lock manager if user did not specify any lock configuration. Any thoughts about this?\r\n\r\nYes, we shouldn't require any lock managers unless we encounter the noop scenario. We can fallback to in-memory lock manager in that case.\r\n\r\n> True, but since this is using reflection and may not actually call versionId I think we need to be careful. We could check whether LOAD_VERSION_ID is a noop and require a lock implementation.\r\n\r\nYes, I agree.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046645510/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046664018","html_url":"https://github.com/apache/iceberg/issues/2575#issuecomment-1046664018","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2575","id":1046664018,"node_id":"IC_kwDOCW7NX84-YtNS","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T09:39:42Z","updated_at":"2022-02-21T09:39:42Z","author_association":"MEMBER","body":"Thanks for the detailed log message,  Did you find the way to reproduce this failure in you local host?  ( I still can not reproduce).\r\n\r\nI read the log message carefully, it's quite strange that producing 4 data files in a single checkpoint. \r\n\r\n```\r\nâžœ  ~ cat Untitled-2 | grep 'org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path'\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00001.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=bbb/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00002.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=ccc/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00003.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit9733325594032949849/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-0e650bad-9e4f-4953-b2f6-3a99868aa38a-00004.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n```\r\n\r\nOnly the partition 'aaa' produces two orc data files. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046664018/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046674747","html_url":"https://github.com/apache/iceberg/pull/4180#issuecomment-1046674747","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4180","id":1046674747,"node_id":"IC_kwDOCW7NX84-Yv07","user":{"login":"rajarshisarkar","id":4561678,"node_id":"MDQ6VXNlcjQ1NjE2Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/4561678?v=4","gravatar_id":"","url":"https://api.github.com/users/rajarshisarkar","html_url":"https://github.com/rajarshisarkar","followers_url":"https://api.github.com/users/rajarshisarkar/followers","following_url":"https://api.github.com/users/rajarshisarkar/following{/other_user}","gists_url":"https://api.github.com/users/rajarshisarkar/gists{/gist_id}","starred_url":"https://api.github.com/users/rajarshisarkar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rajarshisarkar/subscriptions","organizations_url":"https://api.github.com/users/rajarshisarkar/orgs","repos_url":"https://api.github.com/users/rajarshisarkar/repos","events_url":"https://api.github.com/users/rajarshisarkar/events{/privacy}","received_events_url":"https://api.github.com/users/rajarshisarkar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T09:50:56Z","updated_at":"2022-02-21T09:50:56Z","author_association":"CONTRIBUTOR","body":"cc: @jackye1995 @arminnajafi @singhpk234 @amogh-jahagirdar @xiaoxuandev @yyanyy","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046674747/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046695750","html_url":"https://github.com/apache/iceberg/issues/2575#issuecomment-1046695750","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2575","id":1046695750,"node_id":"IC_kwDOCW7NX84-Y09G","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T10:11:06Z","updated_at":"2022-02-21T10:11:06Z","author_association":"CONTRIBUTOR","body":"@openinx i can not reproduce it stably for now,\r\nI think you can just repeat it multiple times, for example, by generating thousands of `parameters`, or script.\r\nAnd i think decreasing the checkpoint interval can help reproducing it, for example, to 100ms.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046695750/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046751435","html_url":"https://github.com/apache/iceberg/pull/4151#issuecomment-1046751435","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4151","id":1046751435,"node_id":"IC_kwDOCW7NX84-ZCjL","user":{"login":"happyprg","id":779556,"node_id":"MDQ6VXNlcjc3OTU1Ng==","avatar_url":"https://avatars.githubusercontent.com/u/779556?v=4","gravatar_id":"","url":"https://api.github.com/users/happyprg","html_url":"https://github.com/happyprg","followers_url":"https://api.github.com/users/happyprg/followers","following_url":"https://api.github.com/users/happyprg/following{/other_user}","gists_url":"https://api.github.com/users/happyprg/gists{/gist_id}","starred_url":"https://api.github.com/users/happyprg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/happyprg/subscriptions","organizations_url":"https://api.github.com/users/happyprg/orgs","repos_url":"https://api.github.com/users/happyprg/repos","events_url":"https://api.github.com/users/happyprg/events{/privacy}","received_events_url":"https://api.github.com/users/happyprg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T11:01:41Z","updated_at":"2022-02-21T11:01:41Z","author_association":"CONTRIBUTOR","body":"> Thanks, @happyprg!\r\n\r\nThank you for approving my PR @rdblue @dramaticlly \r\nMay I ask you the schedule for merging this PR?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046751435/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046757683","html_url":"https://github.com/apache/iceberg/pull/4162#issuecomment-1046757683","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4162","id":1046757683,"node_id":"IC_kwDOCW7NX84-ZEEz","user":{"login":"wuwenchi","id":19755729,"node_id":"MDQ6VXNlcjE5NzU1NzI5","avatar_url":"https://avatars.githubusercontent.com/u/19755729?v=4","gravatar_id":"","url":"https://api.github.com/users/wuwenchi","html_url":"https://github.com/wuwenchi","followers_url":"https://api.github.com/users/wuwenchi/followers","following_url":"https://api.github.com/users/wuwenchi/following{/other_user}","gists_url":"https://api.github.com/users/wuwenchi/gists{/gist_id}","starred_url":"https://api.github.com/users/wuwenchi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wuwenchi/subscriptions","organizations_url":"https://api.github.com/users/wuwenchi/orgs","repos_url":"https://api.github.com/users/wuwenchi/repos","events_url":"https://api.github.com/users/wuwenchi/events{/privacy}","received_events_url":"https://api.github.com/users/wuwenchi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T11:07:49Z","updated_at":"2022-02-21T11:07:49Z","author_association":"CONTRIBUTOR","body":"> @wuwenchi, was there a problem that this caused? Can you update the description with what this is fixing besides trying to be slightly more permissive?\r\n\r\n@rdblue \r\nWhen doing rewrite, it will cause a parquet file to be completely rewritten, generating a new file that is exactly the same as the source file. I think this is unnecessary.\r\n\r\nJust like the testRewriteDataFilesForLargeFile use case in the previous spark2.4. There are 3 files in the table:\r\nbig_a.parquet : 50k\r\nsmall_b.parquet : 2k\r\nsmall_c.parquet : 2k\r\n\r\nSet targetSize = 40k for rewrite,\r\nSo two tasks will be generated here:\r\ntask1 : big_a.parquet\r\ntask2 : small_b.parquet + small_c.parquet\r\n\r\nWhat we expect is that task1 is filtered out because it has only one file.\r\nBut in fact this file may also be split, so it is necessary to judge whether it is a file split or not. \r\nThe second filter condition will determine whether the file needs to be split. Because of the error in the judgment of the parquet format file, this task is retained, so finally big_a.parquet is copied again and a new file is generated. \r\n\r\nSo I increased the judgment of the parquet file, so that the task1 can be deleted.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046757683/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046759080","html_url":"https://github.com/apache/iceberg/pull/4162#issuecomment-1046759080","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4162","id":1046759080,"node_id":"IC_kwDOCW7NX84-ZEao","user":{"login":"wuwenchi","id":19755729,"node_id":"MDQ6VXNlcjE5NzU1NzI5","avatar_url":"https://avatars.githubusercontent.com/u/19755729?v=4","gravatar_id":"","url":"https://api.github.com/users/wuwenchi","html_url":"https://github.com/wuwenchi","followers_url":"https://api.github.com/users/wuwenchi/followers","following_url":"https://api.github.com/users/wuwenchi/following{/other_user}","gists_url":"https://api.github.com/users/wuwenchi/gists{/gist_id}","starred_url":"https://api.github.com/users/wuwenchi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wuwenchi/subscriptions","organizations_url":"https://api.github.com/users/wuwenchi/orgs","repos_url":"https://api.github.com/users/wuwenchi/repos","events_url":"https://api.github.com/users/wuwenchi/events{/privacy}","received_events_url":"https://api.github.com/users/wuwenchi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T11:09:09Z","updated_at":"2022-02-21T11:09:09Z","author_association":"CONTRIBUTOR","body":"> Thanks for posting this @wuwenchi!This seems rather important. Can you please get the Spark2 tests working? It seems related.\r\n> \r\n> It would also be very helpful if you could add a test to demonstrate that this fixes the issue (something that breaks before that doesn't break after).\r\n\r\nThe test case already exists, called testRewriteAvoidRepeatCompress.\r\nHowever, there are some problems in the writing of this test case, which leads to the fact that the offset list of parquet is not updated, and the wrong file length is obtained.\r\nThe wrong file length, coupled with the wrong judgment process, has obtained the expected correct result.\r\nSo I directly modify this test case.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046759080/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046814641","html_url":"https://github.com/apache/iceberg/issues/2796#issuecomment-1046814641","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2796","id":1046814641,"node_id":"IC_kwDOCW7NX84-ZR-x","user":{"login":"otayel","id":11511576,"node_id":"MDQ6VXNlcjExNTExNTc2","avatar_url":"https://avatars.githubusercontent.com/u/11511576?v=4","gravatar_id":"","url":"https://api.github.com/users/otayel","html_url":"https://github.com/otayel","followers_url":"https://api.github.com/users/otayel/followers","following_url":"https://api.github.com/users/otayel/following{/other_user}","gists_url":"https://api.github.com/users/otayel/gists{/gist_id}","starred_url":"https://api.github.com/users/otayel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/otayel/subscriptions","organizations_url":"https://api.github.com/users/otayel/orgs","repos_url":"https://api.github.com/users/otayel/repos","events_url":"https://api.github.com/users/otayel/events{/privacy}","received_events_url":"https://api.github.com/users/otayel/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T12:14:59Z","updated_at":"2022-02-21T12:14:59Z","author_association":"NONE","body":"Adding some update from my side. So this was happening to me consistently when I am trying to run a sql query from spark to delete some entries.  reading more online, usually this exception is tied when s3 fails to upload a file due to network issue and retries again using the data from buffer but if the data was too bigger than buffer size (default 128kb) then it throws the above exception. Looking the EMR cluster logs, I noticed exceptions happening before this one related to s3 throttling `S3Exception: Please reduce your request rate.` which have might resulted in retry and thus the  `Resetting to invalid mark` exception. \r\n\r\nI have addressed this issue for now by doing two things so far:\r\n- Increasing the buffer size to 512MB + 1 byte by setting the system property `com.amazonaws.sdk.s3.defaultStreamBufferSize`. The 512MB is coming from that we compact the data early on by `rewriteDataFiles` which has default max file size of 512MB.\r\n- Decreasing the EMR cluster size on my side to try and avoid the s3 throttling exception.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046814641/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046845868","html_url":"https://github.com/apache/iceberg/issues/2575#issuecomment-1046845868","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2575","id":1046845868,"node_id":"IC_kwDOCW7NX84-ZZms","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T12:52:41Z","updated_at":"2022-02-21T12:53:33Z","author_association":"MEMBER","body":"Here we have only 1 parallelism in this unit test to write records in this stream flow: \r\n\r\n```\r\nSource -> Shuffle -> IcebergStreamWriter -> IcebergFilesCommitter.\r\n```\r\n\r\nAnd we have the following records that need to write into the partitioned table (partition field is `data`):\r\n\r\n```\r\n(1, 'aaa'), (1, 'bbb'), (1, 'ccc')\r\n(2, 'aaa'), (2, 'bbb'), (2, 'ccc')\r\n(3, 'aaa'), (3, 'bbb'), (3, 'ccc')\r\n```\r\n\r\nThen: \r\n\r\n**Step#1**  we write the following records into orc files: \r\n\r\n```\r\n(1, 'aaa'), (1, 'bbb'), (1, 'ccc')\r\n(2, 'aaa'), (2, 'bbb'), (2, 'ccc')\r\n(3, 'bbb'), (3, 'ccc')\r\n\r\n# Notice: the record (3, 'aaa') was not emitted to the orc file in the checkpoint#1 \r\n```\r\n\r\n**Step#2**  checkpoint barrier was encountered, so the IcebergStreamWriter emits the `1.orc`, `2.orc`, `3.orc` to IcebergFilesCommitter.\r\n**Step#3**  IcebergFilesCommitter was trying to execute `snapshotState`;\r\n**Step#4**  The IcebergStreamWriter emitted a `4.orc` with `(3, 'aaa')` included (endInput), and then close itself. \r\n**Step#5**  The IcebergFilesCommitter commit the transaction with 4 orc data files. (notifyCheckpointComplete)\r\n\r\nThe log message seems did the above steps, and finally commit all the 4 orc data files in a single transaction. But in fact, the flink  IcebergFilesCommitter won't accept any new file (`4.orc`) to the pending transaction when it is executing the `snapshotState` in **Step#3** because the flink's `StreamTask` is a single thread consuming message from a FIFO queue. I think there must be other wrong thing but I cannot reproduce this thing.\r\n\r\nAnyway, the root cause for this failure unit test is: we don't control all the events precisely in a single checkpoint (In this case, few records are accumulated in one checkpoint, but there is still someone which was remained for the `endInput` to emit).  So I think the solution I proposed in this https://github.com/apache/iceberg/pull/4117#issuecomment-1042718844 should still work to fix it fundamentally. \r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1046845868/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047007418","html_url":"https://github.com/apache/iceberg/pull/4071#issuecomment-1047007418","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4071","id":1047007418,"node_id":"IC_kwDOCW7NX84-aBC6","user":{"login":"amogh-jahagirdar","id":87500546,"node_id":"MDQ6VXNlcjg3NTAwNTQ2","avatar_url":"https://avatars.githubusercontent.com/u/87500546?v=4","gravatar_id":"","url":"https://api.github.com/users/amogh-jahagirdar","html_url":"https://github.com/amogh-jahagirdar","followers_url":"https://api.github.com/users/amogh-jahagirdar/followers","following_url":"https://api.github.com/users/amogh-jahagirdar/following{/other_user}","gists_url":"https://api.github.com/users/amogh-jahagirdar/gists{/gist_id}","starred_url":"https://api.github.com/users/amogh-jahagirdar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amogh-jahagirdar/subscriptions","organizations_url":"https://api.github.com/users/amogh-jahagirdar/orgs","repos_url":"https://api.github.com/users/amogh-jahagirdar/repos","events_url":"https://api.github.com/users/amogh-jahagirdar/events{/privacy}","received_events_url":"https://api.github.com/users/amogh-jahagirdar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T15:39:28Z","updated_at":"2022-02-21T15:39:28Z","author_association":"CONTRIBUTOR","body":"@rdblue Sure, I have some local changes for these operations. I can update this PR for adding those to the ManageSnapshots API !","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047007418/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047093842","html_url":"https://github.com/apache/iceberg/pull/4180#issuecomment-1047093842","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4180","id":1047093842,"node_id":"IC_kwDOCW7NX84-aWJS","user":{"login":"singhpk234","id":35593236,"node_id":"MDQ6VXNlcjM1NTkzMjM2","avatar_url":"https://avatars.githubusercontent.com/u/35593236?v=4","gravatar_id":"","url":"https://api.github.com/users/singhpk234","html_url":"https://github.com/singhpk234","followers_url":"https://api.github.com/users/singhpk234/followers","following_url":"https://api.github.com/users/singhpk234/following{/other_user}","gists_url":"https://api.github.com/users/singhpk234/gists{/gist_id}","starred_url":"https://api.github.com/users/singhpk234/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/singhpk234/subscriptions","organizations_url":"https://api.github.com/users/singhpk234/orgs","repos_url":"https://api.github.com/users/singhpk234/repos","events_url":"https://api.github.com/users/singhpk234/events{/privacy}","received_events_url":"https://api.github.com/users/singhpk234/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T17:20:14Z","updated_at":"2022-02-21T17:20:14Z","author_association":"CONTRIBUTOR","body":"Thanks @rajarshisarkar , Looks good to me :) !!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047093842/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047116823","html_url":"https://github.com/apache/iceberg/issues/3941#issuecomment-1047116823","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3941","id":1047116823,"node_id":"IC_kwDOCW7NX84-abwX","user":{"login":"donatobarone","id":12485295,"node_id":"MDQ6VXNlcjEyNDg1Mjk1","avatar_url":"https://avatars.githubusercontent.com/u/12485295?v=4","gravatar_id":"","url":"https://api.github.com/users/donatobarone","html_url":"https://github.com/donatobarone","followers_url":"https://api.github.com/users/donatobarone/followers","following_url":"https://api.github.com/users/donatobarone/following{/other_user}","gists_url":"https://api.github.com/users/donatobarone/gists{/gist_id}","starred_url":"https://api.github.com/users/donatobarone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/donatobarone/subscriptions","organizations_url":"https://api.github.com/users/donatobarone/orgs","repos_url":"https://api.github.com/users/donatobarone/repos","events_url":"https://api.github.com/users/donatobarone/events{/privacy}","received_events_url":"https://api.github.com/users/donatobarone/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T17:54:36Z","updated_at":"2022-02-21T17:54:36Z","author_association":"NONE","body":"+1 we have started to investigate iceberg internally and we realised that the CDC available today was just for append operations, which is definitely not ideal as processes will have to be built around the point in time functionalities to be able to get the changes. \r\nGreat that the community is looking into this","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047116823/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047145707","html_url":"https://github.com/apache/iceberg/pull/4169#issuecomment-1047145707","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4169","id":1047145707,"node_id":"IC_kwDOCW7NX84-aizr","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T18:39:53Z","updated_at":"2022-02-21T18:39:53Z","author_association":"CONTRIBUTOR","body":"Thanks, @szehon-ho!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047145707/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047151047","html_url":"https://github.com/apache/iceberg/pull/4147#issuecomment-1047151047","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4147","id":1047151047,"node_id":"IC_kwDOCW7NX84-akHH","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T18:50:31Z","updated_at":"2022-02-21T18:50:31Z","author_association":"CONTRIBUTOR","body":"Thanks, @yittg! Nice work.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047151047/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047152945","html_url":"https://github.com/apache/iceberg/issues/4145#issuecomment-1047152945","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4145","id":1047152945,"node_id":"IC_kwDOCW7NX84-akkx","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T18:54:12Z","updated_at":"2022-02-21T18:54:12Z","author_association":"CONTRIBUTOR","body":"Thanks for getting these in!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047152945/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":1,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047163392","html_url":"https://github.com/apache/iceberg/issues/4168#issuecomment-1047163392","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4168","id":1047163392,"node_id":"IC_kwDOCW7NX84-anIA","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T19:11:37Z","updated_at":"2022-02-21T19:11:37Z","author_association":"CONTRIBUTOR","body":"cc @danielcweeks do you see similar issues in your environment for S3FileIO? Sounds like we might be swallowing some exceptions in the progress multi-part upload logic","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047163392/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047222405","html_url":"https://github.com/apache/iceberg/pull/4175#issuecomment-1047222405","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4175","id":1047222405,"node_id":"IC_kwDOCW7NX84-a1iF","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T20:55:25Z","updated_at":"2022-02-21T20:55:25Z","author_association":"CONTRIBUTOR","body":"cc @rajarshisarkar @singhpk234 @xiaoxuandev @yyanyy @natsukawa-kanou ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047222405/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047224924","html_url":"https://github.com/apache/iceberg/pull/4175#issuecomment-1047224924","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4175","id":1047224924,"node_id":"IC_kwDOCW7NX84-a2Jc","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T21:01:10Z","updated_at":"2022-02-21T21:01:10Z","author_association":"CONTRIBUTOR","body":"Thanks for the fix, to provide more context to other people who are interested, when 2 AWS clients inherit the same HTTP client, AWS will choose to not close the HTTP client to be safe. However, this means users will never have the ability to close the underlying HTTP client in this case, because the client is private. This fix allows users to at least be able to control the lifecycle of the HTTP client and have the option to close the HTTP client as a part of the AWS client if necessary.\r\n\r\nHowever, @arminnajafi one of the experiment we did was that the if the HTTP client is passed in in this way of `someAwsClient.builder().httpClient(...)`, it's still treated as external and not closed. Can you see if there is another way to make sure the AWS client and the underlying HTTP client can be closed at the same time when `someAwsClient.close()` is called?\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047224924/reactions","total_count":4,"+1":4,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047267442","html_url":"https://github.com/apache/iceberg/pull/4151#issuecomment-1047267442","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4151","id":1047267442,"node_id":"IC_kwDOCW7NX84-bAhy","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T22:22:40Z","updated_at":"2022-02-21T22:22:40Z","author_association":"CONTRIBUTOR","body":"Sorry, I thought I already had. Thanks for pinging me.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047267442/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047268252","html_url":"https://github.com/apache/iceberg/pull/4149#issuecomment-1047268252","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4149","id":1047268252,"node_id":"IC_kwDOCW7NX84-bAuc","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T22:24:14Z","updated_at":"2022-02-21T22:24:14Z","author_association":"CONTRIBUTOR","body":"Thanks, @yaooqinn!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047268252/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047268745","html_url":"https://github.com/apache/iceberg/pull/3910#issuecomment-1047268745","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3910","id":1047268745,"node_id":"IC_kwDOCW7NX84-bA2J","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-21T22:25:16Z","updated_at":"2022-02-21T22:25:16Z","author_association":"CONTRIBUTOR","body":"@zhongyujiang, @nastra, does this need to be rebased now that $4149 is in? I think that fixed some of the same issues.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047268745/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047317828","html_url":"https://github.com/apache/iceberg/pull/4037#issuecomment-1047317828","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4037","id":1047317828,"node_id":"IC_kwDOCW7NX84-bM1E","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T00:27:52Z","updated_at":"2022-02-22T00:27:52Z","author_association":"CONTRIBUTOR","body":"Thanks, @kbendick! I think this covers all of the review items so I'll merge this. I'm sure there will be stuff to fix in follow ups, but it's good to get this in and be able to build on top of it. Thanks!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047317828/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047339125","html_url":"https://github.com/apache/iceberg/pull/4182#issuecomment-1047339125","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4182","id":1047339125,"node_id":"IC_kwDOCW7NX84-bSB1","user":{"login":"szehon-ho","id":20555759,"node_id":"MDQ6VXNlcjIwNTU1NzU5","avatar_url":"https://avatars.githubusercontent.com/u/20555759?v=4","gravatar_id":"","url":"https://api.github.com/users/szehon-ho","html_url":"https://github.com/szehon-ho","followers_url":"https://api.github.com/users/szehon-ho/followers","following_url":"https://api.github.com/users/szehon-ho/following{/other_user}","gists_url":"https://api.github.com/users/szehon-ho/gists{/gist_id}","starred_url":"https://api.github.com/users/szehon-ho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szehon-ho/subscriptions","organizations_url":"https://api.github.com/users/szehon-ho/orgs","repos_url":"https://api.github.com/users/szehon-ho/repos","events_url":"https://api.github.com/users/szehon-ho/events{/privacy}","received_events_url":"https://api.github.com/users/szehon-ho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T01:18:48Z","updated_at":"2022-02-22T01:18:48Z","author_association":"COLLABORATOR","body":"Thanks for the fast review!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047339125/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047376334","html_url":"https://github.com/apache/iceberg/pull/4016#issuecomment-1047376334","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4016","id":1047376334,"node_id":"IC_kwDOCW7NX84-bbHO","user":{"login":"CircArgs","id":35903677,"node_id":"MDQ6VXNlcjM1OTAzNjc3","avatar_url":"https://avatars.githubusercontent.com/u/35903677?v=4","gravatar_id":"","url":"https://api.github.com/users/CircArgs","html_url":"https://github.com/CircArgs","followers_url":"https://api.github.com/users/CircArgs/followers","following_url":"https://api.github.com/users/CircArgs/following{/other_user}","gists_url":"https://api.github.com/users/CircArgs/gists{/gist_id}","starred_url":"https://api.github.com/users/CircArgs/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CircArgs/subscriptions","organizations_url":"https://api.github.com/users/CircArgs/orgs","repos_url":"https://api.github.com/users/CircArgs/repos","events_url":"https://api.github.com/users/CircArgs/events{/privacy}","received_events_url":"https://api.github.com/users/CircArgs/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T02:53:38Z","updated_at":"2022-02-22T02:53:38Z","author_association":"CONTRIBUTOR","body":"> @CircArgs, FYI. I tried to open a PR against your branch, but I couldn't so I had to create a new PR.\r\n> \r\n> Feel free to pick the changes into your branch if you want to commit the other PR.\r\n\r\nThanks a lot @rdblue. I've pulled in your commits here. Sorry I wasn't quite on the same page with what you were thinking, makes sense with the flag in your changes","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047376334/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047381823","html_url":"https://github.com/apache/iceberg/pull/4174#issuecomment-1047381823","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4174","id":1047381823,"node_id":"IC_kwDOCW7NX84-bcc_","user":{"login":"samredai","id":43911210,"node_id":"MDQ6VXNlcjQzOTExMjEw","avatar_url":"https://avatars.githubusercontent.com/u/43911210?v=4","gravatar_id":"","url":"https://api.github.com/users/samredai","html_url":"https://github.com/samredai","followers_url":"https://api.github.com/users/samredai/followers","following_url":"https://api.github.com/users/samredai/following{/other_user}","gists_url":"https://api.github.com/users/samredai/gists{/gist_id}","starred_url":"https://api.github.com/users/samredai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/samredai/subscriptions","organizations_url":"https://api.github.com/users/samredai/orgs","repos_url":"https://api.github.com/users/samredai/repos","events_url":"https://api.github.com/users/samredai/events{/privacy}","received_events_url":"https://api.github.com/users/samredai/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T03:06:55Z","updated_at":"2022-02-22T03:06:55Z","author_association":"CONTRIBUTOR","body":"LGTM! I think it'd be helpful to describe the design we settled on here to achieve singleton behavior, possibly in the module level docstring. That's nothing that needs to hold this PR up though and actually I can include that in a future PR I'm planning which adds docstrings in some other files.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047381823/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047383065","html_url":"https://github.com/apache/iceberg/pull/4016#issuecomment-1047383065","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4016","id":1047383065,"node_id":"IC_kwDOCW7NX84-bcwZ","user":{"login":"samredai","id":43911210,"node_id":"MDQ6VXNlcjQzOTExMjEw","avatar_url":"https://avatars.githubusercontent.com/u/43911210?v=4","gravatar_id":"","url":"https://api.github.com/users/samredai","html_url":"https://github.com/samredai","followers_url":"https://api.github.com/users/samredai/followers","following_url":"https://api.github.com/users/samredai/following{/other_user}","gists_url":"https://api.github.com/users/samredai/gists{/gist_id}","starred_url":"https://api.github.com/users/samredai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/samredai/subscriptions","organizations_url":"https://api.github.com/users/samredai/orgs","repos_url":"https://api.github.com/users/samredai/repos","events_url":"https://api.github.com/users/samredai/events{/privacy}","received_events_url":"https://api.github.com/users/samredai/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T03:09:36Z","updated_at":"2022-02-22T03:09:36Z","author_association":"CONTRIBUTOR","body":"I [commented](https://github.com/apache/iceberg/pull/4174#issuecomment-1047381823) in the other PR and I see those commits were added here, this LGTM. Thanks @CircArgs and @rdblue!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047383065/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047395323","html_url":"https://github.com/apache/iceberg/pull/3784#issuecomment-1047395323","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3784","id":1047395323,"node_id":"IC_kwDOCW7NX84-bfv7","user":{"login":"liubo1022126","id":47106533,"node_id":"MDQ6VXNlcjQ3MTA2NTMz","avatar_url":"https://avatars.githubusercontent.com/u/47106533?v=4","gravatar_id":"","url":"https://api.github.com/users/liubo1022126","html_url":"https://github.com/liubo1022126","followers_url":"https://api.github.com/users/liubo1022126/followers","following_url":"https://api.github.com/users/liubo1022126/following{/other_user}","gists_url":"https://api.github.com/users/liubo1022126/gists{/gist_id}","starred_url":"https://api.github.com/users/liubo1022126/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liubo1022126/subscriptions","organizations_url":"https://api.github.com/users/liubo1022126/orgs","repos_url":"https://api.github.com/users/liubo1022126/repos","events_url":"https://api.github.com/users/liubo1022126/events{/privacy}","received_events_url":"https://api.github.com/users/liubo1022126/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T03:39:28Z","updated_at":"2022-02-22T03:39:28Z","author_association":"NONE","body":"@coolderli yes, parquet query performance is worse than orc when select by trino.\r\n\r\n@hililiwei and does this pr have any remaining unfinished work? I want merge this pr to my branch.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047395323/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047402711","html_url":"https://github.com/apache/iceberg/pull/2807#issuecomment-1047402711","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2807","id":1047402711,"node_id":"IC_kwDOCW7NX84-bhjX","user":{"login":"wang-x-xia","id":83057695,"node_id":"MDQ6VXNlcjgzMDU3Njk1","avatar_url":"https://avatars.githubusercontent.com/u/83057695?v=4","gravatar_id":"","url":"https://api.github.com/users/wang-x-xia","html_url":"https://github.com/wang-x-xia","followers_url":"https://api.github.com/users/wang-x-xia/followers","following_url":"https://api.github.com/users/wang-x-xia/following{/other_user}","gists_url":"https://api.github.com/users/wang-x-xia/gists{/gist_id}","starred_url":"https://api.github.com/users/wang-x-xia/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wang-x-xia/subscriptions","organizations_url":"https://api.github.com/users/wang-x-xia/orgs","repos_url":"https://api.github.com/users/wang-x-xia/repos","events_url":"https://api.github.com/users/wang-x-xia/events{/privacy}","received_events_url":"https://api.github.com/users/wang-x-xia/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T04:01:10Z","updated_at":"2022-02-22T04:01:10Z","author_association":"CONTRIBUTOR","body":"> @wang-x-xia Ecs support hudi?\r\n\r\nUse S3 protocol. Apache Hudi uses the HDFS as its storage abstraction. So it won't use additional benefits from ECS.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047402711/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047432236","html_url":"https://github.com/apache/iceberg/issues/2575#issuecomment-1047432236","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2575","id":1047432236,"node_id":"IC_kwDOCW7NX84-bows","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T05:13:07Z","updated_at":"2022-02-22T05:13:07Z","author_association":"CONTRIBUTOR","body":"The following test can easily failed, i think it is equivalent to the original IIUC. It will lead to different kinds of error:\r\n1. Committing with more than one files in one snapshot;\r\n2. Committing with one file in each snapshot, but failed on the final assert.\r\n\r\nHope it can help, @openinx.\r\n\r\n```\r\n  @Test\r\n  public void testHashDistributeMode() throws Exception {\r\n    String tableName = \"test_hash_distribution_mode\";\r\n    Map<String, String> tableProps = ImmutableMap.of(\r\n        \"write.format.default\", format.name(),\r\n        TableProperties.WRITE_DISTRIBUTION_MODE, DistributionMode.HASH.modeName()\r\n    );\r\n    sql(\"CREATE TABLE default_catalog.default_database.src (id INT) WITH %s\",\r\n        toWithClause(ImmutableMap.of(\r\n            \"connector\",\"datagen\",\r\n            \"number-of-rows\", \"100000\",\r\n            \"rows-per-second\", \"100000\",\r\n            \"fields.id.kind\", \"sequence\",\r\n            \"fields.id.start\", \"1\",\r\n            \"fields.id.end\", \"100000\")));\r\n    sql(\"CREATE TABLE %s(id INT, data VARCHAR) PARTITIONED BY (data) WITH %s\",\r\n        tableName, toWithClause(tableProps));\r\n\r\n    try {\r\n      // Insert data set.\r\n\r\n      sql(\"INSERT INTO %s SELECT id, 'aaa' as data FROM default_catalog.default_database.src\", tableName);\r\n\r\n      Table table = validationCatalog.loadTable(TableIdentifier.of(icebergNamespace, tableName));\r\n\r\n      // Sometimes we will have more than one checkpoint if we pass the auto checkpoint interval,\r\n      // thus producing multiple snapshots.  Here we assert that each snapshot has only 1 file per partition.\r\n      Map<Long, List<DataFile>> snapshotToDataFiles = SimpleDataUtil.snapshotToDataFiles(table);\r\n      for (List<DataFile> dataFiles : snapshotToDataFiles.values()) {\r\n        Assert.assertEquals(\"There should be 1 data file in partition 'aaa'\", 1,\r\n            SimpleDataUtil.matchingPartitions(dataFiles, table.spec(), ImmutableMap.of(\"data\", \"aaa\")).size());\r\n      }\r\n    } finally {\r\n      sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, tableName);\r\n    }\r\n  }\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047432236/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047432423","html_url":"https://github.com/apache/iceberg/pull/4186#issuecomment-1047432423","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4186","id":1047432423,"node_id":"IC_kwDOCW7NX84-bozn","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T05:13:30Z","updated_at":"2022-02-22T05:13:30Z","author_association":"CONTRIBUTOR","body":"cc @rdblue. I was working on this PR for `RESTCatalogConfiguration` and I noticed that this schema in the rest open-api doc didn't have examples or the `additionalProperties` weirdness that indicates that it's an arbitrary string-to-string map. So I added them. https://github.com/apache/iceberg/pull/4184\r\n\r\nThis isn't doesn't change the spec at all. I'll also update the response to match the name `RESTCatalogConfigResponse`.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047432423/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047433769","html_url":"https://github.com/apache/iceberg/pull/4177#issuecomment-1047433769","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4177","id":1047433769,"node_id":"IC_kwDOCW7NX84-bpIp","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T05:16:25Z","updated_at":"2022-02-22T05:16:25Z","author_association":"CONTRIBUTOR","body":"@rdblue @openinx Please help review this change.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047433769/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047443114","html_url":"https://github.com/apache/iceberg/pull/4186#issuecomment-1047443114","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4186","id":1047443114,"node_id":"IC_kwDOCW7NX84-braq","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T05:38:11Z","updated_at":"2022-02-22T05:38:11Z","author_association":"CONTRIBUTOR","body":"This passes based on editor.swagger.io and openapi-schema-validator \r\n```bash\r\n$ openapi-spec-validator docs/rest/rest-catalog-open-api.yaml\r\nOK\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047443114/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047447027","html_url":"https://github.com/apache/iceberg/issues/2575#issuecomment-1047447027","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2575","id":1047447027,"node_id":"IC_kwDOCW7NX84-bsXz","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T05:46:05Z","updated_at":"2022-02-22T05:46:05Z","author_association":"CONTRIBUTOR","body":"\r\n> 2. Committing with one file in each snapshot, but failed on the final assert.\r\n\r\nThis can be fixed by the following change:\r\n\r\n```\r\n--- a/flink/v1.14/flink/src/test/java/org/apache/iceberg/flink/SimpleDataUtil.java\r\n+++ b/flink/v1.14/flink/src/test/java/org/apache/iceberg/flink/SimpleDataUtil.java\r\n@@ -275,10 +275,10 @@ public class SimpleDataUtil {\r\n       TableScan tableScan = table.newScan();\r\n       if (current.parentId() != null) {\r\n         // Collect the data files that was added only in current snapshot.\r\n-        tableScan.appendsBetween(current.parentId(), current.snapshotId());\r\n+        tableScan = tableScan.appendsBetween(current.parentId(), current.snapshotId());\r\n       } else {\r\n         // Collect the data files that was added in the oldest snapshot.\r\n-        tableScan.useSnapshot(current.snapshotId());\r\n+        tableScan = tableScan.useSnapshot(current.snapshotId());\r\n       }\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047447027/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047463823","html_url":"https://github.com/apache/iceberg/pull/3784#issuecomment-1047463823","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3784","id":1047463823,"node_id":"IC_kwDOCW7NX84-bweP","user":{"login":"hililiwei","id":59213263,"node_id":"MDQ6VXNlcjU5MjEzMjYz","avatar_url":"https://avatars.githubusercontent.com/u/59213263?v=4","gravatar_id":"","url":"https://api.github.com/users/hililiwei","html_url":"https://github.com/hililiwei","followers_url":"https://api.github.com/users/hililiwei/followers","following_url":"https://api.github.com/users/hililiwei/following{/other_user}","gists_url":"https://api.github.com/users/hililiwei/gists{/gist_id}","starred_url":"https://api.github.com/users/hililiwei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hililiwei/subscriptions","organizations_url":"https://api.github.com/users/hililiwei/orgs","repos_url":"https://api.github.com/users/hililiwei/repos","events_url":"https://api.github.com/users/hililiwei/events{/privacy}","received_events_url":"https://api.github.com/users/hililiwei/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T06:21:05Z","updated_at":"2022-02-22T06:21:05Z","author_association":"CONTRIBUTOR","body":"> @coolderli yes, parquet query performance is worse than orc when select by trino.\r\n> \r\n> @hililiwei and does this pr have any remaining unfinished work? I want merge this pr to my branch.\r\n\r\nFor now, there are no major changes. However, I'm still waiting for comments from @rdblue or anyone else, so may revise it again. ðŸ˜„ ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047463823/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047472013","html_url":"https://github.com/apache/iceberg/pull/4182#issuecomment-1047472013","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4182","id":1047472013,"node_id":"IC_kwDOCW7NX84-byeN","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T06:38:06Z","updated_at":"2022-02-22T06:38:06Z","author_association":"CONTRIBUTOR","body":"LGTM too.\r\n\r\n@szehon-ho, could you check whether we have similar tests for expiring snapshots via the `Table` API? It has a different mechanism compared to actions/procedures.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047472013/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047492144","html_url":"https://github.com/apache/iceberg/issues/2575#issuecomment-1047492144","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2575","id":1047492144,"node_id":"IC_kwDOCW7NX84-b3Yw","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T07:16:12Z","updated_at":"2022-02-22T07:16:12Z","author_association":"CONTRIBUTOR","body":"> 1. Committing with more than one files in one snapshot;\r\n\r\nFor part-1, i think the following log is more detailed by adding some flag log,\r\nIt's mostly like because `EndInput` comes before `notifyCheckpointComplete`. With the following timeline:\r\n_W is for IcebergStreamWriter, C is for IcebergFilesCommitter_\r\n* [W]file-1 created;\r\n* [W]checkpoint-1 prepared;\r\n* [W]result with file-1 emitted;\r\n* [W]file-2 created;\r\n* **[C]checkpoint-1 notified, snapshot-1 with file-1 committed;**\r\n* [W]checkpoint-2 prepared;\r\n* [W]result with file-2 emitted;\r\n* [W] file-3 created;\r\n* [W] endInput;\r\n* [W] result with file-3 emitted;\r\n* **[C] endInput, snapshot-2 with file-2, file-3 committed;**\r\n* [C] checkpoint-2 notified;\r\n\r\n```\r\n--- a/flink/v1.14/flink/src/main/java/org/apache/iceberg/flink/sink/IcebergFilesCommitter.java\r\n+++ b/flink/v1.14/flink/src/main/java/org/apache/iceberg/flink/sink/IcebergFilesCommitter.java\r\n  public void notifyCheckpointComplete(long checkpointId) throws Exception {\r\n+    LOG.info(\"Checkpoint notified, #{}\", checkpointId);\r\n     if (checkpointId > maxCommittedCheckpointId) {\r\n       commitUpToCheckpoint(dataFilesPerCheckpoint, flinkJobId, checkpointId);\r\n       this.maxCommittedCheckpointId = checkpointId;\r\n...\r\n   public void endInput() throws IOException {\r\n+    LOG.info(\"End input reached\");\r\n     // Flush the buffered data files into 'dataFilesPerCheckpoint' firstly.\r\n     long currentCheckpointId = Long.MAX_VALUE;\r\n     dataFilesPerCheckpoint.put(currentCheckpointId, writeToManifest(currentCheckpointId));\r\n--- a/flink/v1.14/flink/src/main/java/org/apache/iceberg/flink/sink/IcebergStreamWriter.java\r\n+++ b/flink/v1.14/flink/src/main/java/org/apache/iceberg/flink/sink/IcebergStreamWriter.java\r\n   @Override\r\n   public void prepareSnapshotPreBarrier(long checkpointId) throws Exception {\r\n+    LOG.info(\"Before checkpoint #{}\", checkpointId);\r\n     // close all open files and emit files to downstream committer operator\r\n     emit(writer.complete());\r\n...\r\n   @Override\r\n   public void endInput() throws IOException {\r\n+    LOG.info(\"End input reached\");\r\n     // For bounded stream, it may don't enable the checkpoint mechanism so we'd better to emit the remaining\r\n     // completed files to downstream before closing the writer so that we won't miss any of them.\r\n     emit(writer.complete());\r\n```\r\n\r\n```\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_table\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_table\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 create_table: Table(tableName:test_table, dbName:db, owner:tangyi, createTime:540425, lastAccessTime:540425, retention:2147483647, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:data, type:string, comment:null)], location:file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_table, inputFormat:org.apache.hadoop.mapred.FileInputFormat, outputFormat:org.apache.hadoop.mapred.FileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{EXTERNAL=TRUE, write.format.default=ORC, metadata_location=file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_table/metadata/00000-b94688ab-1fd9-465a-bed0-e4b1a93c98fb.metadata.json, uuid=ebd3ca64-66b1-40b1-8a6c-6b356dcd1e39, table_type=ICEBERG}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 create_table: Table(tableName:test_table, dbName:db, owner:tangyi, createTime:540425, lastAccessTime:540425, retention:2147483647, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:data, type:string, comment:null)], location:file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_table, inputFormat:org.apache.hadoop.mapred.FileInputFormat, outputFormat:org.apache.hadoop.mapred.FileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{EXTERNAL=TRUE, write.format.default=ORC, metadata_location=file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_table/metadata/00000-b94688ab-1fd9-465a-bed0-e4b1a93c98fb.metadata.json, uuid=ebd3ca64-66b1-40b1-8a6c-6b356dcd1e39, table_type=ICEBERG}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)\t\r\n[pool-11-thread-1] INFO hive.log - Updating table stats fast for test_table\r\n[pool-11-thread-1] INFO hive.log - Updated size of table test_table to 1245\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table testhive.db.test_table in 809 ms\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_table\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_table\t\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_table/metadata/00000-b94688ab-1fd9-465a-bed0-e4b1a93c98fb.metadata.json\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive.db.test_table\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_database: db\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_database: db\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 create_table: Table(tableName:test_hash_distribution_mode, dbName:db, owner:tangyi, createTime:540425, lastAccessTime:540425, retention:2147483647, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:data, type:string, comment:null)], location:file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode, inputFormat:org.apache.hadoop.mapred.FileInputFormat, outputFormat:org.apache.hadoop.mapred.FileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{EXTERNAL=TRUE, write.format.default=ORC, metadata_location=file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/00000-12b9361e-35a0-4862-94ec-9bae7deb0fe1.metadata.json, write.distribution-mode=hash, uuid=f2be590f-787b-4bf9-a4fa-4e8339d4e1a6, table_type=ICEBERG}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 create_table: Table(tableName:test_hash_distribution_mode, dbName:db, owner:tangyi, createTime:540425, lastAccessTime:540425, retention:2147483647, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:data, type:string, comment:null)], location:file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode, inputFormat:org.apache.hadoop.mapred.FileInputFormat, outputFormat:org.apache.hadoop.mapred.FileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{EXTERNAL=TRUE, write.format.default=ORC, metadata_location=file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/00000-12b9361e-35a0-4862-94ec-9bae7deb0fe1.metadata.json, write.distribution-mode=hash, uuid=f2be590f-787b-4bf9-a4fa-4e8339d4e1a6, table_type=ICEBERG}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)\t\r\n[pool-11-thread-1] INFO hive.log - Updating table stats fast for test_hash_distribution_mode\r\n[pool-11-thread-1] INFO hive.log - Updated size of table test_hash_distribution_mode to 1513\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table testhive.db.test_hash_distribution_mode in 93 ms\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_database: db\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_database: db\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=default_catalog\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=default_catalog\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_database: default_catalog\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_database: default_catalog\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_database: db\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_database: db\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_database: default_catalog\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_database: default_catalog\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/00000-12b9361e-35a0-4862-94ec-9bae7deb0fe1.metadata.json\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/00000-12b9361e-35a0-4862-94ec-9bae7deb0fe1.metadata.json\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: testhive.db.test_hash_distribution_mode\r\n[Test worker] INFO org.apache.flink.api.java.typeutils.TypeExtractor - class org.apache.iceberg.io.WriteResult does not contain a setter for field dataFiles\r\n[Test worker] INFO org.apache.flink.api.java.typeutils.TypeExtractor - Class class org.apache.iceberg.io.WriteResult cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on \"Data Types & Serialization\" for details of the effect on performance.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission 'insert-into_testhive.db.test_hash_distribution_mode' (0462ddc2e6a8276f79b3914f9b4fcd19).\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job 'insert-into_testhive.db.test_hash_distribution_mode' (0462ddc2e6a8276f79b3914f9b4fcd19).\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobMasterServiceLeadershipRunner\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_6 .\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.jobmaster.JobMaster - Initializing job 'insert-into_testhive.db.test_hash_distribution_mode' (0462ddc2e6a8276f79b3914f9b4fcd19).\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy FixedDelayRestartBackoffTimeStrategy(maxNumberRestartAttempts=2147483647, backoffTimeMS=1000) for insert-into_testhive.db.test_hash_distribution_mode (0462ddc2e6a8276f79b3914f9b4fcd19).\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job insert-into_testhive.db.test_hash_distribution_mode (0462ddc2e6a8276f79b3914f9b4fcd19).\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology - Built 1 pipelined regions in 0 ms\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2df480e8\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.state.StateBackendLoader - State backend loader loads the state backend as HashMapStateBackend\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.jobmaster.JobMaster - Checkpoint storage is set to 'jobmanager'\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@6a8e2389 for insert-into_testhive.db.test_hash_distribution_mode (0462ddc2e6a8276f79b3914f9b4fcd19).\r\n[jobmanager-io-thread-1] INFO org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_6 , session=2cc8799f-155e-4f8f-a8b4-1b9177294dfe\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job 'insert-into_testhive.db.test_hash_distribution_mode' (0462ddc2e6a8276f79b3914f9b4fcd19) under job master id a8b41b9177294dfe2cc8799f155e4f8f.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job insert-into_testhive.db.test_hash_distribution_mode (0462ddc2e6a8276f79b3914f9b4fcd19) switched from state CREATED to RUNNING.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1) (876164887f156d6a29a5e26a541b1d8b) switched from CREATED to SCHEDULED.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergStreamWriter (1/1) (c5292a7cfc1d527e13a5eeb9926a4a95) switched from CREATED to SCHEDULED.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1) (ca05ac4af8adb64ada4a789b93be3848) switched from CREATED to SCHEDULED.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_4(a3ea462904f2b99a88ed07a16e394a8b)\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration\r\n[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Registering job manager a8b41b9177294dfe2cc8799f155e4f8f@akka://flink/user/rpc/jobmanager_6 for job 0462ddc2e6a8276f79b3914f9b4fcd19.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Registered job manager a8b41b9177294dfe2cc8799f155e4f8f@akka://flink/user/rpc/jobmanager_6 for job 0462ddc2e6a8276f79b3914f9b4fcd19.\r\n[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: a3ea462904f2b99a88ed07a16e394a8b.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager - Received resource requirements from job 0462ddc2e6a8276f79b3914f9b4fcd19: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]\r\n[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 55cac133873b326447786e98d4a8bf2b for job 0462ddc2e6a8276f79b3914f9b4fcd19 from resource manager with leader id a3ea462904f2b99a88ed07a16e394a8b.\r\n[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 55cac133873b326447786e98d4a8bf2b.\r\n[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job 0462ddc2e6a8276f79b3914f9b4fcd19 for job leader monitoring.\r\n[mini-cluster-io-thread-2] INFO org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_6 with leader id 2cc8799f-155e-4f8f-a8b4-1b9177294dfe.\r\n[flink-akka.actor.default-dispatcher-9] INFO org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_6 for job 0462ddc2e6a8276f79b3914f9b4fcd19.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job 0462ddc2e6a8276f79b3914f9b4fcd19.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job 0462ddc2e6a8276f79b3914f9b4fcd19.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1) (876164887f156d6a29a5e26a541b1d8b) switched from SCHEDULED to DEPLOYING.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1) (attempt #0) with attempt id 876164887f156d6a29a5e26a541b1d8b to 1948ad9a-cb40-4a3d-9770-db7de5a7bae5 @ localhost (dataPort=-1) with allocation id 55cac133873b326447786e98d4a8bf2b\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergStreamWriter (1/1) (c5292a7cfc1d527e13a5eeb9926a4a95) switched from SCHEDULED to DEPLOYING.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying IcebergStreamWriter (1/1) (attempt #0) with attempt id c5292a7cfc1d527e13a5eeb9926a4a95 to 1948ad9a-cb40-4a3d-9770-db7de5a7bae5 @ localhost (dataPort=-1) with allocation id 55cac133873b326447786e98d4a8bf2b\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 55cac133873b326447786e98d4a8bf2b.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1) (ca05ac4af8adb64ada4a789b93be3848) switched from SCHEDULED to DEPLOYING.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1) (attempt #0) with attempt id ca05ac4af8adb64ada4a789b93be3848 to 1948ad9a-cb40-4a3d-9770-db7de5a7bae5 @ localhost (dataPort=-1) with allocation id 55cac133873b326447786e98d4a8bf2b\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader - StateChangelogStorageLoader initialized with shortcut names {memory}.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader - Creating a changelog storage with name 'memory'.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0 (876164887f156d6a29a5e26a541b1d8b), deploy into slot with allocation id 55cac133873b326447786e98d4a8bf2b.\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0 (876164887f156d6a29a5e26a541b1d8b) switched from CREATED to DEPLOYING.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 55cac133873b326447786e98d4a8bf2b.\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0 (876164887f156d6a29a5e26a541b1d8b) [DEPLOYING].\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task IcebergStreamWriter (1/1)#0 (c5292a7cfc1d527e13a5eeb9926a4a95), deploy into slot with allocation id 55cac133873b326447786e98d4a8bf2b.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergStreamWriter (1/1)#0 (c5292a7cfc1d527e13a5eeb9926a4a95) switched from CREATED to DEPLOYING.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task IcebergStreamWriter (1/1)#0 (c5292a7cfc1d527e13a5eeb9926a4a95) [DEPLOYING].\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 55cac133873b326447786e98d4a8bf2b.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 (ca05ac4af8adb64ada4a789b93be3848), deploy into slot with allocation id 55cac133873b326447786e98d4a8bf2b.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 (ca05ac4af8adb64ada4a789b93be3848) switched from CREATED to DEPLOYING.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 (ca05ac4af8adb64ada4a789b93be3848) [DEPLOYING].\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 55cac133873b326447786e98d4a8bf2b.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@eb5eb98\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.runtime.state.StateBackendLoader - State backend loader loads the state backend as HashMapStateBackend\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6873aa5c\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.state.StateBackendLoader - State backend loader loads the state backend as HashMapStateBackend\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] INFO org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6e0bd0bd\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] INFO org.apache.flink.runtime.state.StateBackendLoader - State backend loader loads the state backend as HashMapStateBackend\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] INFO org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 0462ddc2e6a8276f79b3914f9b4fcd19 because Checkpoint triggering task Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1) of job 0462ddc2e6a8276f79b3914f9b4fcd19 is not being executed at the moment. Aborting checkpoint. Failure reason: Not all required tasks are currently running.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 (ca05ac4af8adb64ada4a789b93be3848) switched from DEPLOYING to INITIALIZING.\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0 (876164887f156d6a29a5e26a541b1d8b) switched from DEPLOYING to INITIALIZING.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergStreamWriter (1/1)#0 (c5292a7cfc1d527e13a5eeb9926a4a95) switched from DEPLOYING to INITIALIZING.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1) (ca05ac4af8adb64ada4a789b93be3848) switched from DEPLOYING to INITIALIZING.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1) (876164887f156d6a29a5e26a541b1d8b) switched from DEPLOYING to INITIALIZING.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergStreamWriter (1/1) (c5292a7cfc1d527e13a5eeb9926a4a95) switched from DEPLOYING to INITIALIZING.\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] WARN org.apache.flink.metrics.MetricGroup - The operator name Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) exceeded the 80 characters length limit and was truncated.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder - Finished to build heap keyed state-backend.\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.state.heap.HeapKeyedStateBackend - Initializing heap keyed state backend with stream factory.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/00000-12b9361e-35a0-4862-94ec-9bae7deb0fe1.metadata.json\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: testhive.db.test_hash_distribution_mode\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergStreamWriter (1/1)#0 (c5292a7cfc1d527e13a5eeb9926a4a95) switched from INITIALIZING to RUNNING.\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0 (876164887f156d6a29a5e26a541b1d8b) switched from INITIALIZING to RUNNING.\r\n[flink-akka.actor.default-dispatcher-9] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergStreamWriter (1/1) (c5292a7cfc1d527e13a5eeb9926a4a95) switched from INITIALIZING to RUNNING.\r\n[flink-akka.actor.default-dispatcher-9] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1) (876164887f156d6a29a5e26a541b1d8b) switched from INITIALIZING to RUNNING.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 (ca05ac4af8adb64ada4a789b93be3848) switched from INITIALIZING to RUNNING.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1) (ca05ac4af8adb64ada4a789b93be3848) switched from INITIALIZING to RUNNING.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.HadoopShimsPre2_7 - Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-99c5c573-3f2b-46df-8a23-e359b36d2c6e-00001.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Triggering checkpoint 1 (type=CHECKPOINT) @ 1645512904342 for job 0462ddc2e6a8276f79b3914f9b4fcd19.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.WriterImpl - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-99c5c573-3f2b-46df-8a23-e359b36d2c6e-00001.orc with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergStreamWriter - Before checkpoint #1\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-99c5c573-3f2b-46df-8a23-e359b36d2c6e-00002.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.WriterImpl - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-99c5c573-3f2b-46df-8a23-e359b36d2c6e-00002.orc with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Start to flush snapshot state to state backend, table: testhive.db.test_hash_distribution_mode, checkpointId: 1\r\n[jobmanager-io-thread-5] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Completed checkpoint 1 for job 0462ddc2e6a8276f79b3914f9b4fcd19 (724151 bytes, checkpointDuration=1418 ms, finalizationTime=6 ms).\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Triggering checkpoint 2 (type=CHECKPOINT) @ 1645512905767 for job 0462ddc2e6a8276f79b3914f9b4fcd19.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Checkpoint notified, #1\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] INFO org.apache.flink.streaming.api.functions.source.datagen.DataGeneratorSource - generated 100000 rows\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0 (876164887f156d6a29a5e26a541b1d8b) switched from RUNNING to FINISHED.\r\n[Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0 (876164887f156d6a29a5e26a541b1d8b).\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1)#0 876164887f156d6a29a5e26a541b1d8b.\r\n[flink-akka.actor.default-dispatcher-9] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: TableSourceScan(table=[[default_catalog, default_database, src]], fields=[id]) -> Calc(select=[id, _UTF-16LE'aaa' AS data]) (1/1) (876164887f156d6a29a5e26a541b1d8b) switched from RUNNING to FINISHED.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergStreamWriter - Before checkpoint #2\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.PhysicalFsWriter - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-99c5c573-3f2b-46df-8a23-e359b36d2c6e-00003.orc with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.orc.impl.WriterImpl - ORC writer created for path: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/data/data=aaa/00000-0-99c5c573-3f2b-46df-8a23-e359b36d2c6e-00003.orc with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergStreamWriter - End input reached\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergStreamWriter (1/1)#0 (c5292a7cfc1d527e13a5eeb9926a4a95) switched from RUNNING to FINISHED.\r\n[IcebergStreamWriter (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for IcebergStreamWriter (1/1)#0 (c5292a7cfc1d527e13a5eeb9926a4a95).\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task IcebergStreamWriter (1/1)#0 c5292a7cfc1d527e13a5eeb9926a4a95.\r\n[flink-akka.actor.default-dispatcher-9] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergStreamWriter (1/1) (c5292a7cfc1d527e13a5eeb9926a4a95) switched from RUNNING to FINISHED.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Committing append with 1 data files and 0 delete files to table testhive.db.test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 alter_table: db=db tbl=test_hash_distribution_mode newtbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 alter_table: db=db tbl=test_hash_distribution_mode newtbl=test_hash_distribution_mode\t\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table testhive.db.test_hash_distribution_mode in 193 ms\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.SnapshotProducer - Committed snapshot 5883620300433327646 (MergeAppend)\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/00001-c3fbec69-b9e9-4734-ada1-46b3cf34af00.metadata.json\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Committed in 378 ms\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Start to flush snapshot state to state backend, table: testhive.db.test_hash_distribution_mode, checkpointId: 2\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - End input reached\r\n[jobmanager-io-thread-10] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Completed checkpoint 2 for job 0462ddc2e6a8276f79b3914f9b4fcd19 (15055 bytes, checkpointDuration=586 ms, finalizationTime=3 ms).\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 0462ddc2e6a8276f79b3914f9b4fcd19 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 0462ddc2e6a8276f79b3914f9b4fcd19 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 0462ddc2e6a8276f79b3914f9b4fcd19 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[Checkpoint Timer] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Failed to trigger checkpoint for job 0462ddc2e6a8276f79b3914f9b4fcd19 because Some tasks of the job have already finished and checkpointing with finished tasks is not enabled. Failure reason: Not all required tasks are currently running.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Committing append with 2 data files and 0 delete files to table testhive.db.test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 alter_table: db=db tbl=test_hash_distribution_mode newtbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 alter_table: db=db tbl=test_hash_distribution_mode newtbl=test_hash_distribution_mode\t\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table testhive.db.test_hash_distribution_mode in 104 ms\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.SnapshotProducer - Committed snapshot 8717152434606897052 (MergeAppend)\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/00002-3bfc06f1-94da-4443-8dc4-c14e35da3fc0.metadata.json\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Committed in 258 ms\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.iceberg.flink.sink.IcebergFilesCommitter - Checkpoint notified, #2\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 (ca05ac4af8adb64ada4a789b93be3848) switched from RUNNING to FINISHED.\r\n[IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 (ca05ac4af8adb64ada4a789b93be3848).\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FINISHED to JobManager for task IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1)#0 ca05ac4af8adb64ada4a789b93be3848.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - IcebergFilesCommitter -> Sink: IcebergSink testhive.db.test_hash_distribution_mode (1/1) (ca05ac4af8adb64ada4a789b93be3848) switched from RUNNING to FINISHED.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job insert-into_testhive.db.test_hash_distribution_mode (0462ddc2e6a8276f79b3914f9b4fcd19) switched from state RUNNING to FINISHED.\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Stopping checkpoint coordinator for job 0462ddc2e6a8276f79b3914f9b4fcd19.\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager - Clearing resource requirements of job 0462ddc2e6a8276f79b3914f9b4fcd19\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Job 0462ddc2e6a8276f79b3914f9b4fcd19 reached terminal state FINISHED.\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.jobmaster.JobMaster - Stopping the JobMaster for job 'insert-into_testhive.db.test_hash_distribution_mode' (0462ddc2e6a8276f79b3914f9b4fcd19).\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore - Shutting down\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool - Releasing slot [55cac133873b326447786e98d4a8bf2b].\r\n[flink-akka.actor.default-dispatcher-8] INFO org.apache.flink.runtime.jobmaster.JobMaster - Close ResourceManager connection c1d6e8672929f08ffdd6d908c456d65a: Stopping JobMaster for job 'insert-into_testhive.db.test_hash_distribution_mode' (0462ddc2e6a8276f79b3914f9b4fcd19).\r\n[flink-akka.actor.default-dispatcher-9] INFO org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{taskHeapMemory=256.000gb (274877906944 bytes), taskOffHeapMemory=256.000gb (274877906944 bytes), managedMemory=20.000mb (20971520 bytes), networkMemory=16.000mb (16777216 bytes)}, allocationId: 55cac133873b326447786e98d4a8bf2b, jobId: 0462ddc2e6a8276f79b3914f9b4fcd19).\r\n[flink-akka.actor.default-dispatcher-7] INFO org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Disconnect job manager a8b41b9177294dfe2cc8799f155e4f8f@akka://flink/user/rpc/jobmanager_6 for job 0462ddc2e6a8276f79b3914f9b4fcd19 from the resource manager.\r\n[flink-akka.actor.default-dispatcher-9] INFO org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Remove job 0462ddc2e6a8276f79b3914f9b4fcd19 from job leader monitoring.\r\n[flink-akka.actor.default-dispatcher-9] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Close JobManager connection for job 0462ddc2e6a8276f79b3914f9b4fcd19.\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/00002-3bfc06f1-94da-4443-8dc4-c14e35da3fc0.metadata.json\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive.db.test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[Test worker] INFO org.apache.iceberg.BaseTableScan - Scanning table hive.db.test_hash_distribution_mode snapshot 5883620300433327646 created at 2022-02-22 06:55:06.089 with filter true\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/00002-3bfc06f1-94da-4443-8dc4-c14e35da3fc0.metadata.json\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/00002-3bfc06f1-94da-4443-8dc4-c14e35da3fc0.metadata.json\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_hash_distribution_mode\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 drop_table : db=db tbl=test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 drop_table : db=db tbl=test_hash_distribution_mode\t\r\n[Test worker] INFO org.apache.iceberg.CatalogUtil - Manifests to delete: GenericManifestFile{path=file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/46ff29de-4b47-4980-b7c5-9f017f6e1722-m0.avro, length=6101, partition_spec_id=0, added_snapshot_id=8717152434606897052, added_data_files_count=2, added_rows_count=90069, existing_data_files_count=0, existing_rows_count=0, deleted_data_files_count=0, deleted_rows_count=0, partitions=[GenericPartitionFieldSummary{contains_null=false, contains_nan=false, lower_bound=[97, 97, 97], upper_bound=[97, 97, 97]}], key_metadata=null}, GenericManifestFile{path=file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_hash_distribution_mode/metadata/eb44b7e6-0d4f-4cd3-b8d9-709e4618e1e3-m0.avro, length=6055, partition_spec_id=0, added_snapshot_id=5883620300433327646, added_data_files_count=1, added_rows_count=9931, existing_data_files_count=0, existing_rows_count=0, deleted_data_files_count=0, deleted_rows_count=0, partitions=[GenericPartitionFieldSummary{contains_null=false, contains_nan=false, lower_bound=[97, 97, 97], upper_bound=[97, 97, 97]}], key_metadata=null}\r\n[Test worker] INFO org.apache.iceberg.hive.HiveCatalog - Dropped table: db.test_hash_distribution_mode\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_table\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_table\t\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_table/metadata/00000-b94688ab-1fd9-465a-bed0-e4b1a93c98fb.metadata.json\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_table\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_table\t\r\n[Test worker] INFO org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: file:/var/folders/t6/8l83wbcd52g29cp78v66n7rc0000gn/T/junit13141381595252095998/db.db/test_table/metadata/00000-b94688ab-1fd9-465a-bed0-e4b1a93c98fb.metadata.json\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_table : db=db tbl=test_table\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_table : db=db tbl=test_table\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 drop_table : db=db tbl=test_table\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 drop_table : db=db tbl=test_table\t\r\n[Test worker] INFO org.apache.iceberg.CatalogUtil - Manifests to delete: \r\n[Test worker] INFO org.apache.iceberg.hive.HiveCatalog - Dropped table: db.test_table\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_database: db\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_database: db\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 drop_database: db\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 drop_database: db\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_all_tables: db=db\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_all_tables: db=db\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:127.0.0.1 get_functions: db=db pat=*\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=tangyi\tip=127.0.0.1\tcmd=source:127.0.0.1 get_functions: db=db pat=*\t\r\n[pool-11-thread-1] INFO org.apache.hadoop.hive.metastore.ObjectStore - Dropping database db along with all tables\r\n[Test worker] INFO org.apache.iceberg.hive.HiveCatalog - Dropped namespace: db\r\n[Test worker] ERROR org.apache.iceberg.flink.TestFlinkTableSink - \r\n--------------------------------------------------------------------------------\r\nTest testHashDistributeMode[catalogName=testhive, baseNamespace=, format=ORC, isStreaming=true](org.apache.iceberg.flink.TestFlinkTableSink) failed with:\r\njava.lang.AssertionError: There should be 1 data file in partition 'aaa' expected:<1> but was:<2>\r\n\tat org.junit.Assert.fail(Assert.java:89)\r\n\tat org.junit.Assert.failNotEquals(Assert.java:835)\r\n\tat org.junit.Assert.assertEquals(Assert.java:647)\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047492144/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047509123","html_url":"https://github.com/apache/iceberg/pull/4189#issuecomment-1047509123","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4189","id":1047509123,"node_id":"IC_kwDOCW7NX84-b7iD","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T07:43:14Z","updated_at":"2022-02-22T07:43:14Z","author_association":"MEMBER","body":"Run this 20 times in my host, everything seems OK: \r\n\r\n```\r\nfor i in `seq 1 20`; do\r\n    ./gradlew :iceberg-flink:iceberg-flink-1.14_2.12:test --tests \"org.apache.iceberg.flink.TestFlinkTableSink\"\r\n    if [ ! $? -eq 0 ] ; then\r\n        exit 1\r\n    fi\r\ndone\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047509123/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047515094","html_url":"https://github.com/apache/iceberg/pull/4187#issuecomment-1047515094","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4187","id":1047515094,"node_id":"IC_kwDOCW7NX84-b8_W","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T07:52:51Z","updated_at":"2022-02-22T07:52:51Z","author_association":"CONTRIBUTOR","body":"@openinx updated, please check.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047515094/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047520875","html_url":"https://github.com/apache/iceberg/issues/2575#issuecomment-1047520875","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2575","id":1047520875,"node_id":"IC_kwDOCW7NX84-b-Zr","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T08:01:23Z","updated_at":"2022-02-22T08:01:23Z","author_association":"MEMBER","body":"@yittg  I think the #4189 & #4187 can still fix the all case you described.  Would you mind to check & verify this again after apply those two PR ? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047520875/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047543032","html_url":"https://github.com/apache/iceberg/issues/2575#issuecomment-1047543032","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2575","id":1047543032,"node_id":"IC_kwDOCW7NX84-cDz4","user":{"login":"yittg","id":4429171,"node_id":"MDQ6VXNlcjQ0MjkxNzE=","avatar_url":"https://avatars.githubusercontent.com/u/4429171?v=4","gravatar_id":"","url":"https://api.github.com/users/yittg","html_url":"https://github.com/yittg","followers_url":"https://api.github.com/users/yittg/followers","following_url":"https://api.github.com/users/yittg/following{/other_user}","gists_url":"https://api.github.com/users/yittg/gists{/gist_id}","starred_url":"https://api.github.com/users/yittg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yittg/subscriptions","organizations_url":"https://api.github.com/users/yittg/orgs","repos_url":"https://api.github.com/users/yittg/repos","events_url":"https://api.github.com/users/yittg/events{/privacy}","received_events_url":"https://api.github.com/users/yittg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T08:30:39Z","updated_at":"2022-02-22T08:30:39Z","author_association":"CONTRIBUTOR","body":"@openinx sure, i'll check it later","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047543032/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047618561","html_url":"https://github.com/apache/iceberg/issues/4191#issuecomment-1047618561","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4191","id":1047618561,"node_id":"IC_kwDOCW7NX84-cWQB","user":{"login":"KarlManong","id":2627662,"node_id":"MDQ6VXNlcjI2Mjc2NjI=","avatar_url":"https://avatars.githubusercontent.com/u/2627662?v=4","gravatar_id":"","url":"https://api.github.com/users/KarlManong","html_url":"https://github.com/KarlManong","followers_url":"https://api.github.com/users/KarlManong/followers","following_url":"https://api.github.com/users/KarlManong/following{/other_user}","gists_url":"https://api.github.com/users/KarlManong/gists{/gist_id}","starred_url":"https://api.github.com/users/KarlManong/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KarlManong/subscriptions","organizations_url":"https://api.github.com/users/KarlManong/orgs","repos_url":"https://api.github.com/users/KarlManong/repos","events_url":"https://api.github.com/users/KarlManong/events{/privacy}","received_events_url":"https://api.github.com/users/KarlManong/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T09:56:38Z","updated_at":"2022-02-22T09:56:38Z","author_association":"CONTRIBUTOR","body":"Also see https://issues.apache.org/jira/browse/SPARK-29260","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047618561/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047657437","html_url":"https://github.com/apache/iceberg/pull/4152#issuecomment-1047657437","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4152","id":1047657437,"node_id":"IC_kwDOCW7NX84-cfvd","user":{"login":"0xffmeta","id":98149057,"node_id":"U_kgDOBdmiwQ","avatar_url":"https://avatars.githubusercontent.com/u/98149057?v=4","gravatar_id":"","url":"https://api.github.com/users/0xffmeta","html_url":"https://github.com/0xffmeta","followers_url":"https://api.github.com/users/0xffmeta/followers","following_url":"https://api.github.com/users/0xffmeta/following{/other_user}","gists_url":"https://api.github.com/users/0xffmeta/gists{/gist_id}","starred_url":"https://api.github.com/users/0xffmeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/0xffmeta/subscriptions","organizations_url":"https://api.github.com/users/0xffmeta/orgs","repos_url":"https://api.github.com/users/0xffmeta/repos","events_url":"https://api.github.com/users/0xffmeta/events{/privacy}","received_events_url":"https://api.github.com/users/0xffmeta/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T10:37:53Z","updated_at":"2022-02-22T10:37:53Z","author_association":"CONTRIBUTOR","body":"@RussellSpitzer Could you help to merge this PR so that I don't need to rebase the commit for potential conflict? ðŸ¥² ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047657437/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047769838","html_url":"https://github.com/apache/iceberg/issues/4192#issuecomment-1047769838","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4192","id":1047769838,"node_id":"IC_kwDOCW7NX84-c7Lu","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T12:56:53Z","updated_at":"2022-02-22T12:58:03Z","author_association":"MEMBER","body":"The issue is probably that the table object you are using is not from the configured Spark Catalog.  Try loading the table instance without Spark3Util.loadIcebergTable. \n\nThe error is because Spark needs the catalog name to match the one in the Spark conf. Otherwise it does not know where to find the table. When instantiating a new table using the Java api it will have the default catalog name which is most likely not the same.\n\nA metadata table is just a special view of a table which returns information like what partitions are in the table or what files are in the table. All iceberg tables have them available, see the docs for more info.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047769838/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047774739","html_url":"https://github.com/apache/iceberg/pull/3910#issuecomment-1047774739","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3910","id":1047774739,"node_id":"IC_kwDOCW7NX84-c8YT","user":{"login":"zhongyujiang","id":42907416,"node_id":"MDQ6VXNlcjQyOTA3NDE2","avatar_url":"https://avatars.githubusercontent.com/u/42907416?v=4","gravatar_id":"","url":"https://api.github.com/users/zhongyujiang","html_url":"https://github.com/zhongyujiang","followers_url":"https://api.github.com/users/zhongyujiang/followers","following_url":"https://api.github.com/users/zhongyujiang/following{/other_user}","gists_url":"https://api.github.com/users/zhongyujiang/gists{/gist_id}","starred_url":"https://api.github.com/users/zhongyujiang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhongyujiang/subscriptions","organizations_url":"https://api.github.com/users/zhongyujiang/orgs","repos_url":"https://api.github.com/users/zhongyujiang/repos","events_url":"https://api.github.com/users/zhongyujiang/events{/privacy}","received_events_url":"https://api.github.com/users/zhongyujiang/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T13:02:53Z","updated_at":"2022-02-22T13:02:53Z","author_association":"CONTRIBUTOR","body":"I have rebased and backported this fix, and changed level from `Level.Invocation` to `Level.Iteration` to be consistent with #4149, both have the same effect here. Please check again. @nastra @rdblue ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047774739/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047820650","html_url":"https://github.com/apache/iceberg/pull/3910#issuecomment-1047820650","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3910","id":1047820650,"node_id":"IC_kwDOCW7NX84-dHlq","user":{"login":"zhongyujiang","id":42907416,"node_id":"MDQ6VXNlcjQyOTA3NDE2","avatar_url":"https://avatars.githubusercontent.com/u/42907416?v=4","gravatar_id":"","url":"https://api.github.com/users/zhongyujiang","html_url":"https://github.com/zhongyujiang","followers_url":"https://api.github.com/users/zhongyujiang/followers","following_url":"https://api.github.com/users/zhongyujiang/following{/other_user}","gists_url":"https://api.github.com/users/zhongyujiang/gists{/gist_id}","starred_url":"https://api.github.com/users/zhongyujiang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhongyujiang/subscriptions","organizations_url":"https://api.github.com/users/zhongyujiang/orgs","repos_url":"https://api.github.com/users/zhongyujiang/repos","events_url":"https://api.github.com/users/zhongyujiang/events{/privacy}","received_events_url":"https://api.github.com/users/zhongyujiang/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T13:54:53Z","updated_at":"2022-02-22T13:54:53Z","author_association":"CONTRIBUTOR","body":"Thanks for reminding, updated.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047820650/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047822733","html_url":"https://github.com/apache/iceberg/issues/4191#issuecomment-1047822733","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4191","id":1047822733,"node_id":"IC_kwDOCW7NX84-dIGN","user":{"login":"KarlManong","id":2627662,"node_id":"MDQ6VXNlcjI2Mjc2NjI=","avatar_url":"https://avatars.githubusercontent.com/u/2627662?v=4","gravatar_id":"","url":"https://api.github.com/users/KarlManong","html_url":"https://github.com/KarlManong","followers_url":"https://api.github.com/users/KarlManong/followers","following_url":"https://api.github.com/users/KarlManong/following{/other_user}","gists_url":"https://api.github.com/users/KarlManong/gists{/gist_id}","starred_url":"https://api.github.com/users/KarlManong/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KarlManong/subscriptions","organizations_url":"https://api.github.com/users/KarlManong/orgs","repos_url":"https://api.github.com/users/KarlManong/repos","events_url":"https://api.github.com/users/KarlManong/events{/privacy}","received_events_url":"https://api.github.com/users/KarlManong/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T13:57:14Z","updated_at":"2022-02-22T13:57:14Z","author_association":"CONTRIBUTOR","body":"ALTER DATABASE SET LOCATION statement changes the default parent-directory where new tables will be added for a database. Please note that it does not move the contents of the databaseâ€™s current directory to the newly specified location or change the locations associated with any tables/partitions under the specified database (available since Spark 3.0.0 with the Hive metastore version 3.0.0 and later).","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047822733/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047909043","html_url":"https://github.com/apache/iceberg/pull/4152#issuecomment-1047909043","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4152","id":1047909043,"node_id":"IC_kwDOCW7NX84-ddKz","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T15:24:38Z","updated_at":"2022-02-22T15:24:38Z","author_association":"MEMBER","body":"I did another pass there are unfortunately a few things we need to clean up again, but ping me when it is ready and i will look again.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047909043/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047976819","html_url":"https://github.com/apache/iceberg/pull/3059#issuecomment-1047976819","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3059","id":1047976819,"node_id":"IC_kwDOCW7NX84-dttz","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T16:27:12Z","updated_at":"2022-02-22T16:27:12Z","author_association":"MEMBER","body":"Sorry it took me so long to get to this, I think this is good to go once the PR has been rebased","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047976819/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047994681","html_url":"https://github.com/apache/iceberg/pull/3470#issuecomment-1047994681","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3470","id":1047994681,"node_id":"IC_kwDOCW7NX84-dyE5","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T16:43:38Z","updated_at":"2022-02-22T16:43:38Z","author_association":"MEMBER","body":"@jackye1995 Are you +1 on this? I think we have consensus to start getting these PR's in\r\n\r\n@ggershinsky looks like the tests are currently failing, could you rebase so we can be good to go?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1047994681/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1048007629","html_url":"https://github.com/apache/iceberg/pull/2638#issuecomment-1048007629","issue_url":"https://api.github.com/repos/apache/iceberg/issues/2638","id":1048007629,"node_id":"IC_kwDOCW7NX84-d1PN","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T16:56:39Z","updated_at":"2022-02-22T16:56:39Z","author_association":"MEMBER","body":"@ggershinsky Can you please fix the conflicts?\r\n\r\n@jackye1995 could you take another pass on this? I've looked it over internally and I think we should be good to go here. I'd like to start making progress merging some of these in.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1048007629/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1048021048","html_url":"https://github.com/apache/iceberg/pull/4182#issuecomment-1048021048","issue_url":"https://api.github.com/repos/apache/iceberg/issues/4182","id":1048021048,"node_id":"IC_kwDOCW7NX84-d4g4","user":{"login":"szehon-ho","id":20555759,"node_id":"MDQ6VXNlcjIwNTU1NzU5","avatar_url":"https://avatars.githubusercontent.com/u/20555759?v=4","gravatar_id":"","url":"https://api.github.com/users/szehon-ho","html_url":"https://github.com/szehon-ho","followers_url":"https://api.github.com/users/szehon-ho/followers","following_url":"https://api.github.com/users/szehon-ho/following{/other_user}","gists_url":"https://api.github.com/users/szehon-ho/gists{/gist_id}","starred_url":"https://api.github.com/users/szehon-ho/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szehon-ho/subscriptions","organizations_url":"https://api.github.com/users/szehon-ho/orgs","repos_url":"https://api.github.com/users/szehon-ho/repos","events_url":"https://api.github.com/users/szehon-ho/events{/privacy}","received_events_url":"https://api.github.com/users/szehon-ho/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T17:10:43Z","updated_at":"2022-02-22T17:10:43Z","author_association":"COLLABORATOR","body":"sure, will take a look","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1048021048/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1048042278","html_url":"https://github.com/apache/iceberg/pull/3910#issuecomment-1048042278","issue_url":"https://api.github.com/repos/apache/iceberg/issues/3910","id":1048042278,"node_id":"IC_kwDOCW7NX84-d9sm","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-02-22T17:33:05Z","updated_at":"2022-02-22T17:33:05Z","author_association":"CONTRIBUTOR","body":"Thanks, @zhongyujiang!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/1048042278/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]