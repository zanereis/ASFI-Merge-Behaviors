[{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707908716","html_url":"https://github.com/apache/iceberg/pull/1558#issuecomment-707908716","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1558","id":707908716,"node_id":"MDEyOklzc3VlQ29tbWVudDcwNzkwODcxNg==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T17:52:11Z","updated_at":"2020-10-13T17:52:11Z","author_association":"CONTRIBUTOR","body":" Okay, I understand why Flink won't load `hive-site.xml`: because Flink doesn't have direct Hive integration and that is the application's responsibility. Then, it also makes sense that the user might be creating a catalog using SQL, and would have no ability to set up the Hive config directly.\r\n\r\nWhat I don't understand is why Iceberg should do anything other than ensure that `hive-site.xml` is added as a default resource from the classpath.\r\n\r\nMost configuration for the `HiveCatalog` should come from catalog options, not from `hive-site.xml`. That config file would be primarily used for global defaults, so it makes more sense to me for it to be a default resource that is shared across all catalogs. If it is shared, then there is no need to load a path that is specific to each catalog. Would it be valuable to support multiple `hive-site.xml` configs, one per catalog?\r\n\r\nIf Hive only tuning defaults are controlled by `hive-site.xml`, then why not load it the normal way from the application classpath? That gives the user a way to add folders (by adding to the classpath) or to bundle the config file into their application Jar. When an application's Jars are being localized, the config file could be handled just like other classpath artifacts. That's the normal way of distributing config files.\r\n\r\nIn summary, unless we need catalog-specific Hive configs, I don't see why we wouldn't use the \"normal\" ways to distribute and add a `hive-site.xml` file. It doesn't seem like something we need Iceberg to handle, beyond ensuring that the `hive-site.xml` from the classpath is added as a default resource. Is there a use case that I'm misunderstanding?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707908716/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707909458","html_url":"https://github.com/apache/iceberg/pull/1559#issuecomment-707909458","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1559","id":707909458,"node_id":"MDEyOklzc3VlQ29tbWVudDcwNzkwOTQ1OA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T17:53:29Z","updated_at":"2020-10-13T17:53:29Z","author_association":"CONTRIBUTOR","body":"Does the file system API provide a rename with overwrite option? If so, we should use that regardless of whether it is atomic. If not, then we should move forward with delete and then rename.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707909458/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707912840","html_url":"https://github.com/apache/iceberg/pull/1522#issuecomment-707912840","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1522","id":707912840,"node_id":"MDEyOklzc3VlQ29tbWVudDcwNzkxMjg0MA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T17:59:51Z","updated_at":"2020-10-13T17:59:51Z","author_association":"CONTRIBUTOR","body":"> Yes, we return an iterator with the reused containers. I believe that this is okay because Spark generally converts to unsafe immediately. What code paths can't handle reused containers?\r\n\r\nFollowing up on this, it is safe for Spark in the v2 path because Spark ensures that there is a projection that converts to unsafe rows. That's because some Spark exec nodes expect unsafe.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707912840/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707912973","html_url":"https://github.com/apache/iceberg/issues/1549#issuecomment-707912973","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1549","id":707912973,"node_id":"MDEyOklzc3VlQ29tbWVudDcwNzkxMjk3Mw==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T18:00:09Z","updated_at":"2020-10-13T18:00:09Z","author_association":"CONTRIBUTOR","body":"@holdenk, would you have time to look into this? Not urgent.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707912973/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707913044","html_url":"https://github.com/apache/iceberg/issues/1548#issuecomment-707913044","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1548","id":707913044,"node_id":"MDEyOklzc3VlQ29tbWVudDcwNzkxMzA0NA==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T18:00:19Z","updated_at":"2020-10-13T18:00:19Z","author_association":"CONTRIBUTOR","body":"@holdenk, would you have time to look into this? Not urgent.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707913044/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707934852","html_url":"https://github.com/apache/iceberg/issues/1468#issuecomment-707934852","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1468","id":707934852,"node_id":"MDEyOklzc3VlQ29tbWVudDcwNzkzNDg1Mg==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T18:41:00Z","updated_at":"2020-10-13T18:41:00Z","author_association":"CONTRIBUTOR","body":"I just sent out a PR for AWS Glue support. With this update you can use `HiveCatalog` without the need to set up any Hive infrastructure and build your data lake on top of S3. #1608 ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707934852/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707971167","html_url":"https://github.com/apache/iceberg/issues/1560#issuecomment-707971167","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1560","id":707971167,"node_id":"MDEyOklzc3VlQ29tbWVudDcwNzk3MTE2Nw==","user":{"login":"NJordan72","id":5156166,"node_id":"MDQ6VXNlcjUxNTYxNjY=","avatar_url":"https://avatars.githubusercontent.com/u/5156166?v=4","gravatar_id":"","url":"https://api.github.com/users/NJordan72","html_url":"https://github.com/NJordan72","followers_url":"https://api.github.com/users/NJordan72/followers","following_url":"https://api.github.com/users/NJordan72/following{/other_user}","gists_url":"https://api.github.com/users/NJordan72/gists{/gist_id}","starred_url":"https://api.github.com/users/NJordan72/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/NJordan72/subscriptions","organizations_url":"https://api.github.com/users/NJordan72/orgs","repos_url":"https://api.github.com/users/NJordan72/repos","events_url":"https://api.github.com/users/NJordan72/events{/privacy}","received_events_url":"https://api.github.com/users/NJordan72/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T19:52:06Z","updated_at":"2020-10-13T19:52:06Z","author_association":"NONE","body":"I'm also seeing this on Spark 3.0 w/Iceberg 0.9.1.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707971167/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707984007","html_url":"https://github.com/apache/iceberg/pull/1609#issuecomment-707984007","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1609","id":707984007,"node_id":"MDEyOklzc3VlQ29tbWVudDcwNzk4NDAwNw==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T20:17:54Z","updated_at":"2020-10-13T20:17:54Z","author_association":"MEMBER","body":"@aokolnychyi To take some of the changes out of #1525 \r\n\r\nCC: @rdblue this one should be pretty uncontroversial :) ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/707984007/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708035039","html_url":"https://github.com/apache/iceberg/issues/1560#issuecomment-708035039","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1560","id":708035039,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODAzNTAzOQ==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T22:05:38Z","updated_at":"2020-10-13T22:05:38Z","author_association":"CONTRIBUTOR","body":"I figured out as Spark bug which may exist only on Spark 3. Filed https://issues.apache.org/jira/browse/SPARK-33136 and will submit a PR on Spark repo.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708035039/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708040409","html_url":"https://github.com/apache/iceberg/pull/1564#issuecomment-708040409","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1564","id":708040409,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODA0MDQwOQ==","user":{"login":"HotSushi","id":6441597,"node_id":"MDQ6VXNlcjY0NDE1OTc=","avatar_url":"https://avatars.githubusercontent.com/u/6441597?v=4","gravatar_id":"","url":"https://api.github.com/users/HotSushi","html_url":"https://github.com/HotSushi","followers_url":"https://api.github.com/users/HotSushi/followers","following_url":"https://api.github.com/users/HotSushi/following{/other_user}","gists_url":"https://api.github.com/users/HotSushi/gists{/gist_id}","starred_url":"https://api.github.com/users/HotSushi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HotSushi/subscriptions","organizations_url":"https://api.github.com/users/HotSushi/orgs","repos_url":"https://api.github.com/users/HotSushi/repos","events_url":"https://api.github.com/users/HotSushi/events{/privacy}","received_events_url":"https://api.github.com/users/HotSushi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T22:19:30Z","updated_at":"2020-10-13T22:19:30Z","author_association":"CONTRIBUTOR","body":"H @pvary, properties set in HiveIcebergStorageHandler.configureInputJobProperties() should propagate to the configuration object. Hive does copying of properties [here](https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java#L408)  \r\nAnother way to set would be through HiveIcebergStorageHandler.configureJobConf() . Were the properties still not transferred after this?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708040409/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708047098","html_url":"https://github.com/apache/iceberg/pull/1525#issuecomment-708047098","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1525","id":708047098,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODA0NzA5OA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-13T22:37:58Z","updated_at":"2020-10-13T22:37:58Z","author_association":"MEMBER","body":"One thing that is particularly annoying about this test suite is the retry behavior of the HiveOps which takes a considerable amount of time when checking whether things exist or not. I may work on that next in another ticket. As was discussed on slack, a \"DROP IF EXISTS\" operation or a check for table existence on a table which doesn't exist triggers a max amount of metadata look up attempts which ends up taking about 1.5 minutes.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708047098/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708100835","html_url":"https://github.com/apache/iceberg/issues/1605#issuecomment-708100835","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1605","id":708100835,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODEwMDgzNQ==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T01:37:08Z","updated_at":"2020-10-14T01:37:08Z","author_association":"CONTRIBUTOR","body":"This is a known issue and I am working on it，You can follow https://github.com/apache/iceberg/pull/1558","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708100835/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708110875","html_url":"https://github.com/apache/iceberg/issues/1605#issuecomment-708110875","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1605","id":708110875,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODExMDg3NQ==","user":{"login":"wg1026688210","id":14267759,"node_id":"MDQ6VXNlcjE0MjY3NzU5","avatar_url":"https://avatars.githubusercontent.com/u/14267759?v=4","gravatar_id":"","url":"https://api.github.com/users/wg1026688210","html_url":"https://github.com/wg1026688210","followers_url":"https://api.github.com/users/wg1026688210/followers","following_url":"https://api.github.com/users/wg1026688210/following{/other_user}","gists_url":"https://api.github.com/users/wg1026688210/gists{/gist_id}","starred_url":"https://api.github.com/users/wg1026688210/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wg1026688210/subscriptions","organizations_url":"https://api.github.com/users/wg1026688210/orgs","repos_url":"https://api.github.com/users/wg1026688210/repos","events_url":"https://api.github.com/users/wg1026688210/events{/privacy}","received_events_url":"https://api.github.com/users/wg1026688210/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T02:12:41Z","updated_at":"2020-10-14T02:12:41Z","author_association":"CONTRIBUTOR","body":"lgtm","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708110875/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708114465","html_url":"https://github.com/apache/iceberg/issues/1597#issuecomment-708114465","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1597","id":708114465,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODExNDQ2NQ==","user":{"login":"liukun4515","id":7450163,"node_id":"MDQ6VXNlcjc0NTAxNjM=","avatar_url":"https://avatars.githubusercontent.com/u/7450163?v=4","gravatar_id":"","url":"https://api.github.com/users/liukun4515","html_url":"https://github.com/liukun4515","followers_url":"https://api.github.com/users/liukun4515/followers","following_url":"https://api.github.com/users/liukun4515/following{/other_user}","gists_url":"https://api.github.com/users/liukun4515/gists{/gist_id}","starred_url":"https://api.github.com/users/liukun4515/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liukun4515/subscriptions","organizations_url":"https://api.github.com/users/liukun4515/orgs","repos_url":"https://api.github.com/users/liukun4515/repos","events_url":"https://api.github.com/users/liukun4515/events{/privacy}","received_events_url":"https://api.github.com/users/liukun4515/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T02:24:24Z","updated_at":"2020-10-15T07:11:20Z","author_association":"NONE","body":"> Can we just use `System.currentTimeMillis`? Spark returns us `java.sql.Timestamp` that is time zone agnostic, I guess.\r\n\r\nThe `system.currenttimestamp` is the absolute time which does‘t need to consider the time zone.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708114465/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708120181","html_url":"https://github.com/apache/iceberg/pull/1517#issuecomment-708120181","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1517","id":708120181,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODEyMDE4MQ==","user":{"login":"chenjunjiedada","id":3960228,"node_id":"MDQ6VXNlcjM5NjAyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3960228?v=4","gravatar_id":"","url":"https://api.github.com/users/chenjunjiedada","html_url":"https://github.com/chenjunjiedada","followers_url":"https://api.github.com/users/chenjunjiedada/followers","following_url":"https://api.github.com/users/chenjunjiedada/following{/other_user}","gists_url":"https://api.github.com/users/chenjunjiedada/gists{/gist_id}","starred_url":"https://api.github.com/users/chenjunjiedada/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chenjunjiedada/subscriptions","organizations_url":"https://api.github.com/users/chenjunjiedada/orgs","repos_url":"https://api.github.com/users/chenjunjiedada/repos","events_url":"https://api.github.com/users/chenjunjiedada/events{/privacy}","received_events_url":"https://api.github.com/users/chenjunjiedada/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T02:44:11Z","updated_at":"2020-10-14T02:44:11Z","author_association":"COLLABORATOR","body":"Thanks for reminding! It works before but I changed to use getter way to avoid null checking while not realize that serializer cannot copy the null value.  Too late didn't wait for the build result...","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708120181/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708130240","html_url":"https://github.com/apache/iceberg/issues/1610#issuecomment-708130240","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1610","id":708130240,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODEzMDI0MA==","user":{"login":"simonsssu","id":12323514,"node_id":"MDQ6VXNlcjEyMzIzNTE0","avatar_url":"https://avatars.githubusercontent.com/u/12323514?v=4","gravatar_id":"","url":"https://api.github.com/users/simonsssu","html_url":"https://github.com/simonsssu","followers_url":"https://api.github.com/users/simonsssu/followers","following_url":"https://api.github.com/users/simonsssu/following{/other_user}","gists_url":"https://api.github.com/users/simonsssu/gists{/gist_id}","starred_url":"https://api.github.com/users/simonsssu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/simonsssu/subscriptions","organizations_url":"https://api.github.com/users/simonsssu/orgs","repos_url":"https://api.github.com/users/simonsssu/repos","events_url":"https://api.github.com/users/simonsssu/events{/privacy}","received_events_url":"https://api.github.com/users/simonsssu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T03:17:49Z","updated_at":"2020-10-14T03:31:51Z","author_association":"CONTRIBUTOR","body":"That's a good use cases. For Flink Users who wants to do a DataFile compaction, they don't need to use a spark. Currently I have implemented the RewriteDataFile operator append to IcebergCommitter in our internal scenario.  It makes sense to extract the common logical if we want to implement a Batch Flink Job to do this. I think we can refactor the spark rewrite action first and then add Flink Batch Job. I'm interested to take this issue.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708130240/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708135039","html_url":"https://github.com/apache/iceberg/pull/1558#issuecomment-708135039","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1558","id":708135039,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODEzNTAzOQ==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T03:34:31Z","updated_at":"2020-10-14T03:34:31Z","author_association":"CONTRIBUTOR","body":"Let me talk about my thoughts. in flink,  the use of hive is only the behavior of the application, so hive-site.xml and hive jars are not loaded at flink startup, and are loaded by the flink application. \r\nIf the user's flink program is a jar, we can include hive-site.xml into the jar , but for users who use flink sql client, this may not be easy to implement. If we want to load hive-site.xml into the classpath and as a global configuration, this can only be loaded by flink at startup, but this is contrary to the design of flink.\r\nIn addition, if a user's application loads hive-site.xml to the classpath, and then uses it as a shared global configuration for other applications, I think this may not be easy to implement.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708135039/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708136475","html_url":"https://github.com/apache/iceberg/issues/1599#issuecomment-708136475","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1599","id":708136475,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODEzNjQ3NQ==","user":{"login":"liukun4515","id":7450163,"node_id":"MDQ6VXNlcjc0NTAxNjM=","avatar_url":"https://avatars.githubusercontent.com/u/7450163?v=4","gravatar_id":"","url":"https://api.github.com/users/liukun4515","html_url":"https://github.com/liukun4515","followers_url":"https://api.github.com/users/liukun4515/followers","following_url":"https://api.github.com/users/liukun4515/following{/other_user}","gists_url":"https://api.github.com/users/liukun4515/gists{/gist_id}","starred_url":"https://api.github.com/users/liukun4515/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liukun4515/subscriptions","organizations_url":"https://api.github.com/users/liukun4515/orgs","repos_url":"https://api.github.com/users/liukun4515/repos","events_url":"https://api.github.com/users/liukun4515/events{/privacy}","received_events_url":"https://api.github.com/users/liukun4515/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T03:40:05Z","updated_at":"2020-10-14T03:40:05Z","author_association":"NONE","body":"I am working on this issue.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708136475/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708140427","html_url":"https://github.com/apache/iceberg/issues/1589#issuecomment-708140427","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1589","id":708140427,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODE0MDQyNw==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T03:55:51Z","updated_at":"2020-10-14T03:55:51Z","author_association":"CONTRIBUTOR","body":"hi,@aokolnychyi \r\nI don't know whether flink supports stored procedures, but I see that the source code of flink has a related sqlnode extension interface. I think we should be able to do sql extension by implementing this interface.\r\n\r\nhttps://github.com/apache/flink/blob/master/flink-table/flink-sql-parser/src/main/java/org/apache/flink/sql/parser/ExtendedSqlNode.java\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708140427/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708144489","html_url":"https://github.com/apache/iceberg/issues/1599#issuecomment-708144489","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1599","id":708144489,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODE0NDQ4OQ==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T04:12:04Z","updated_at":"2020-10-14T04:12:04Z","author_association":"CONTRIBUTOR","body":"We can probably skip `ignore_scheme` and `ignore_authority` for now since we haven't agreed on this yet.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708144489/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708167706","html_url":"https://github.com/apache/iceberg/pull/1564#issuecomment-708167706","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1564","id":708167706,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODE2NzcwNg==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T05:34:36Z","updated_at":"2020-10-14T05:34:36Z","author_association":"CONTRIBUTOR","body":"> H @pvary, properties set in HiveIcebergStorageHandler.configureInputJobProperties() should propagate to the configuration object. Hive does copying of properties [here](https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java#L408)\r\n> Another way to set would be through HiveIcebergStorageHandler.configureJobConf() . Were the properties still not transferred after this?\r\n\r\n@HotSushi: Thanks for the quick answer! In my last patch I try to load the schema from the `conf` and if not successful then from the `serDeProperties`. This means then one of the checks is unnecessary and I can remove it. I was just afraid that this is again some Hive 1.1 difference which we have to handle.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708167706/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708196162","html_url":"https://github.com/apache/iceberg/pull/1515#issuecomment-708196162","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1515","id":708196162,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODE5NjE2Mg==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T06:44:39Z","updated_at":"2020-10-14T06:44:39Z","author_association":"MEMBER","body":"We have few discussion in our team, for the first question how do we distinguish the batch job and streaming job without checkpoint states.  In current flink 1.11,  there's no way to indicate it's batch job,  so we could only extend the `BoundedOneInput` interface to do the iceberg transaction commit.  In theory, we shouldn't break the big transaction into several small transactions when in batch mode because users would expected the job to be committed successfully or rollback in atomically.   Currently,  we may could set a property in iceberg flink sink, to indicate whether it's batch or streaming job  explicitly.  In future flink release,  there will be methods to accomplish. \r\n\r\nFor the second question,  at-least-once or at-most-once ?  If the kafka source have enough data that we flink job could start from,  then we don't loss any data from the source operator then we have the at-least-once guarantee.  For less duplication when recovering,  there's no flink interface to keep the latest successful consumed offset in iceberg sink I think, if someone really want to do that, then could use the system timestamp or user-defined field which could persist in iceberg table properties. \r\n\r\nFor now,  I totally agree with @rdblue that have a check to throw the exception that iceberg don't support streaming job with checkpoint disabled. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708196162/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708200923","html_url":"https://github.com/apache/iceberg/pull/1515#issuecomment-708200923","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1515","id":708200923,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODIwMDkyMw==","user":{"login":"simonsssu","id":12323514,"node_id":"MDQ6VXNlcjEyMzIzNTE0","avatar_url":"https://avatars.githubusercontent.com/u/12323514?v=4","gravatar_id":"","url":"https://api.github.com/users/simonsssu","html_url":"https://github.com/simonsssu","followers_url":"https://api.github.com/users/simonsssu/followers","following_url":"https://api.github.com/users/simonsssu/following{/other_user}","gists_url":"https://api.github.com/users/simonsssu/gists{/gist_id}","starred_url":"https://api.github.com/users/simonsssu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/simonsssu/subscriptions","organizations_url":"https://api.github.com/users/simonsssu/orgs","repos_url":"https://api.github.com/users/simonsssu/repos","events_url":"https://api.github.com/users/simonsssu/events{/privacy}","received_events_url":"https://api.github.com/users/simonsssu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T06:54:42Z","updated_at":"2020-10-14T07:00:38Z","author_association":"CONTRIBUTOR","body":"@openinx You are right, for batch job, it will break transaction into several small commit because of ProcessingTimer. I also agree to throw exception. when using java api, we can pass stream or batch mode when building FlinkSink, when using in SQL, we may need an API (maybe add in Context ? ) to tell a stream or batch mode.  I think it's better to add an API in TableEnvironment so that we can use it when building FlinkSink. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708200923/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708217472","html_url":"https://github.com/apache/iceberg/pull/1495#issuecomment-708217472","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1495","id":708217472,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODIxNzQ3Mg==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T07:30:18Z","updated_at":"2020-10-14T07:30:18Z","author_association":"CONTRIBUTOR","body":"> Merged! Thanks @pvary for all your work on this one!\r\n\r\nThanks for the reviews and the merge @rdblue!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708217472/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708318260","html_url":"https://github.com/apache/iceberg/pull/1559#issuecomment-708318260","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1559","id":708318260,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODMxODI2MA==","user":{"login":"lcspinter","id":47777102,"node_id":"MDQ6VXNlcjQ3Nzc3MTAy","avatar_url":"https://avatars.githubusercontent.com/u/47777102?v=4","gravatar_id":"","url":"https://api.github.com/users/lcspinter","html_url":"https://github.com/lcspinter","followers_url":"https://api.github.com/users/lcspinter/followers","following_url":"https://api.github.com/users/lcspinter/following{/other_user}","gists_url":"https://api.github.com/users/lcspinter/gists{/gist_id}","starred_url":"https://api.github.com/users/lcspinter/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lcspinter/subscriptions","organizations_url":"https://api.github.com/users/lcspinter/orgs","repos_url":"https://api.github.com/users/lcspinter/repos","events_url":"https://api.github.com/users/lcspinter/events{/privacy}","received_events_url":"https://api.github.com/users/lcspinter/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T10:39:19Z","updated_at":"2020-10-14T10:39:19Z","author_association":"CONTRIBUTOR","body":"@rdblue I agree, rename with overwrite would be the best solution but on HDFS the rename fails without raising any exception if destination exists.  ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708318260/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708324183","html_url":"https://github.com/apache/iceberg/pull/1559#issuecomment-708324183","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1559","id":708324183,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODMyNDE4Mw==","user":{"login":"lcspinter","id":47777102,"node_id":"MDQ6VXNlcjQ3Nzc3MTAy","avatar_url":"https://avatars.githubusercontent.com/u/47777102?v=4","gravatar_id":"","url":"https://api.github.com/users/lcspinter","html_url":"https://github.com/lcspinter","followers_url":"https://api.github.com/users/lcspinter/followers","following_url":"https://api.github.com/users/lcspinter/following{/other_user}","gists_url":"https://api.github.com/users/lcspinter/gists{/gist_id}","starred_url":"https://api.github.com/users/lcspinter/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lcspinter/subscriptions","organizations_url":"https://api.github.com/users/lcspinter/orgs","repos_url":"https://api.github.com/users/lcspinter/repos","events_url":"https://api.github.com/users/lcspinter/events{/privacy}","received_events_url":"https://api.github.com/users/lcspinter/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T10:51:25Z","updated_at":"2020-10-14T10:51:25Z","author_association":"CONTRIBUTOR","body":"@rdblue According to the Filesystem rename API doc\r\nLocal FileSystem : the rename succeeds; the destination file is replaced by the source file.\r\nHDFS : The rename fails, no exception is raised. Instead the method call simply returns false.\r\n\r\nWhat if I try the rename with overwrite, and if it returns false I fallback to delete and rename? What do you think?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708324183/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708376836","html_url":"https://github.com/apache/iceberg/pull/1559#issuecomment-708376836","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1559","id":708376836,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODM3NjgzNg==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T12:44:06Z","updated_at":"2020-10-14T12:44:06Z","author_association":"CONTRIBUTOR","body":"To clarify, the API I mentioned was `FileContext.rename(src, dst, options)`, not `FileSystem.rename(src, dst)`, which the filesystem doc documents.\r\n\r\nI don't have HDFS cluster now, but the result of the rename operation against local filesystem via FileContext is quite different from the document says.\r\n\r\nBelow is the code you can run with spark-shell against Hadoop 2.7 & Hadoop 3.2.\r\n\r\n```\r\n\r\nimport org.apache.hadoop.fs.{FileContext, Path}\r\nimport org.apache.hadoop.fs.Options.Rename\r\nimport org.apache.hadoop.fs.permission.FsPermission\r\n\r\nval context = FileContext.getFileContext()\r\n\r\n// assuming you have files `unit-tests.log` and `unit-tests-succeed.log` (different file size) in /tmp\r\n\r\nval setupPath = new Path(\"/tmp/unit-tests-succeed.log\")\r\nval anotherFilePath = new Path(\"/tmp/unit-tests.log\")\r\nval sourceDirPath = new Path(\"/tmp/rename-experiment-src\")\r\nval destDirPath = new Path(\"/tmp/rename-experiment-dst\")\r\nval anotherFileSourcePath = new Path(\"/tmp/rename-experiment-src/unit-tests.log\")\r\nval sourcePath = new Path(\"/tmp/rename-experiment-src/unit-tests-succeed.log\")\r\nval destPath = new Path(\"/tmp/rename-experiment-dst/unit-tests-succeed.log\")\r\n\r\n// remove directories\r\ncontext.delete(sourceDirPath, true)\r\ncontext.delete(destDirPath, true)\r\ncontext.mkdir(sourceDirPath, FsPermission.getDirDefault(), true)\r\ncontext.mkdir(destDirPath, FsPermission.getDirDefault(), true)\r\n\r\n// setup file\r\ncontext.util.copy(setupPath, sourcePath)\r\n\r\n// the file got moved\r\ncontext.rename(sourcePath, destPath)\r\n\r\n// check whether the file is moved\r\nprintln(s\"src path: ${context.util.exists(sourcePath)}\")\r\nprintln(s\"dest path: ${context.util.exists(destPath)}\")\r\nprintln(s\"content summary on dest path: ${context.util.getContentSummary(destPath)}\")\r\n\r\n// re-setup file\r\ncontext.util.copy(setupPath, sourcePath)\r\n\r\n// re-rename -> this will throw exception as file already exists\r\ncontext.rename(sourcePath, destPath)\r\n\r\n// setup another file\r\ncontext.util.copy(anotherFilePath, anotherFileSourcePath)\r\n\r\n// re-rename with overwrite option -> this will not throw exception\r\ncontext.rename(anotherFileSourcePath, destPath, Rename.OVERWRITE)\r\n\r\n// check whether the file is moved\r\nprintln(s\"src path: ${context.util.exists(anotherFileSourcePath)}\")\r\nprintln(s\"dest path: ${context.util.exists(destPath)}\")\r\nprintln(s\"content summary on dest path: ${context.util.getContentSummary(destPath)}\")\r\n```\r\n\r\nIt correctly fails on existing file in destination, and correctly overwrites the new file if the overwrite option is provided.\r\n\r\nI also looked through the code path on how namenode handles rename, and it redirects me to `DistributedFileSystem.rename` which javadoc says it guarantees atomicity.\r\n\r\n> rel/release-2.7.4\r\n\r\nhttps://github.com/apache/hadoop/blob/cd915e1e8d9d0131462a0b7301586c175728a282/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java#L647-L653\r\n\r\n> rel/release-3.2.0\r\n\r\nhttps://github.com/apache/hadoop/blob/e97acb3bd8f3befd27418996fa5d4b50bf2e17bf/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java#L892-L898\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708376836/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708386122","html_url":"https://github.com/apache/iceberg/pull/1559#issuecomment-708386122","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1559","id":708386122,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODM4NjEyMg==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T13:01:06Z","updated_at":"2020-10-14T13:01:06Z","author_association":"CONTRIBUTOR","body":"(It probably depends on the preference of using FileContext though.)","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708386122/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708407787","html_url":"https://github.com/apache/iceberg/issues/1560#issuecomment-708407787","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1560","id":708407787,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODQwNzc4Nw==","user":{"login":"cccs-dm","id":62555897,"node_id":"MDQ6VXNlcjYyNTU1ODk3","avatar_url":"https://avatars.githubusercontent.com/u/62555897?v=4","gravatar_id":"","url":"https://api.github.com/users/cccs-dm","html_url":"https://github.com/cccs-dm","followers_url":"https://api.github.com/users/cccs-dm/followers","following_url":"https://api.github.com/users/cccs-dm/following{/other_user}","gists_url":"https://api.github.com/users/cccs-dm/gists{/gist_id}","starred_url":"https://api.github.com/users/cccs-dm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cccs-dm/subscriptions","organizations_url":"https://api.github.com/users/cccs-dm/orgs","repos_url":"https://api.github.com/users/cccs-dm/repos","events_url":"https://api.github.com/users/cccs-dm/events{/privacy}","received_events_url":"https://api.github.com/users/cccs-dm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T13:38:43Z","updated_at":"2020-10-14T13:38:43Z","author_association":"NONE","body":"Thanks @HeartSaVioR !","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708407787/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708457571","html_url":"https://github.com/apache/iceberg/pull/1525#issuecomment-708457571","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1525","id":708457571,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODQ1NzU3MQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T14:54:57Z","updated_at":"2020-10-14T15:40:46Z","author_association":"MEMBER","body":"@aokolnychyi + @holdenk + @rdblue I think this is ready for another look, but to make things easier I'm going to pull the Actions move into another PR (https://github.com/apache/iceberg/pull/1613) so hopefully we can get that piece in first, minimize the changes in this pr.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708457571/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708486374","html_url":"https://github.com/apache/iceberg/pull/1525#issuecomment-708486374","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1525","id":708486374,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODQ4NjM3NA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T15:39:46Z","updated_at":"2020-10-14T15:39:46Z","author_association":"MEMBER","body":"https://github.com/apache/iceberg/pull/1613","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708486374/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708487798","html_url":"https://github.com/apache/iceberg/pull/1613#issuecomment-708487798","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1613","id":708487798,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODQ4Nzc5OA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T15:42:01Z","updated_at":"2020-10-14T15:42:01Z","author_association":"MEMBER","body":"@aokolnychyi + @holdenk  + @rdblue + @kbendick - The Actions Split independent of the create table PR, this piece is self contained and won't add any new changes users have to deal with.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708487798/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708500362","html_url":"https://github.com/apache/iceberg/pull/1573#issuecomment-708500362","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1573","id":708500362,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODUwMDM2Mg==","user":{"login":"danielcweeks","id":4925077,"node_id":"MDQ6VXNlcjQ5MjUwNzc=","avatar_url":"https://avatars.githubusercontent.com/u/4925077?v=4","gravatar_id":"","url":"https://api.github.com/users/danielcweeks","html_url":"https://github.com/danielcweeks","followers_url":"https://api.github.com/users/danielcweeks/followers","following_url":"https://api.github.com/users/danielcweeks/following{/other_user}","gists_url":"https://api.github.com/users/danielcweeks/gists{/gist_id}","starred_url":"https://api.github.com/users/danielcweeks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielcweeks/subscriptions","organizations_url":"https://api.github.com/users/danielcweeks/orgs","repos_url":"https://api.github.com/users/danielcweeks/repos","events_url":"https://api.github.com/users/danielcweeks/events{/privacy}","received_events_url":"https://api.github.com/users/danielcweeks/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T16:02:00Z","updated_at":"2020-10-14T16:02:00Z","author_association":"CONTRIBUTOR","body":"> Has there been any consideration to using the AWS Java SDK v2? I know that @jacques-n mentioned they found the java v2 Async s3 SDK buggy, but the linked code from their project is using the AWS Java SDK v2 (all of the imports start with `software.amazon`).\r\n> \r\n> To me it seems like it would be smarter to start on the newer client version than have to do an upgrade later. My understanding is that the Java SDK V2 is much more performant for most things as its the one seeing most of the work. And though I don't doubt @jacques-n's performance / bug issues with the java sdk v2 async s3 client, but I would ask when that was? I've personally noticed that when new clients and new services are brought out by amazon, they're not always production ready from the start. But many times I've found that things we performance tested 6 months prior were much more performant / resilient later on.\r\n\r\nI would say that I've also had issues when exploring the v2 sdk, but more in terms of completeness of the implementation.  For example they don't have transfer manager (not that we're using here), but if we decide to go that route, we would need to go back to v1.  Also, at this point most other systems (Spark, S3A, Presto, etc.) are still on v1 as well.  If there are documented performance or other features in v2, I'd be happy to upgrade, but it seems like the community hasn't really moved that direction yet.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708500362/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708513468","html_url":"https://github.com/apache/iceberg/pull/1573#issuecomment-708513468","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1573","id":708513468,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODUxMzQ2OA==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T16:24:13Z","updated_at":"2020-10-14T16:24:13Z","author_association":"CONTRIBUTOR","body":"> > Has there been any consideration to using the AWS Java SDK v2? I know that @jacques-n mentioned they found the java v2 Async s3 SDK buggy, but the linked code from their project is using the AWS Java SDK v2 (all of the imports start with `software.amazon`).\r\n> > To me it seems like it would be smarter to start on the newer client version than have to do an upgrade later. My understanding is that the Java SDK V2 is much more performant for most things as its the one seeing most of the work. And though I don't doubt @jacques-n's performance / bug issues with the java sdk v2 async s3 client, but I would ask when that was? I've personally noticed that when new clients and new services are brought out by amazon, they're not always production ready from the start. But many times I've found that things we performance tested 6 months prior were much more performant / resilient later on.\r\n> \r\n> I would say that I've also had issues when exploring the v2 sdk, but more in terms of completeness of the implementation. For example they don't have transfer manager (not that we're using here), but if we decide to go that route, we would need to go back to v1. Also, at this point most other systems (Spark, S3A, Presto, etc.) are still on v1 as well. If there are documented performance or other features in v2, I'd be happy to upgrade, but it seems like the community hasn't really moved that direction yet.\r\n\r\nThe SDK v2 is intended to live together with v1 because some old packages such as S3AFileSystem might never upgrade. That is why they have completely different class path and you do not need to resolve any dependency conflicts.\r\n\r\nAll the new features related to the client itself will only be developed in v2, so it is always recommended to use the v2 client when possible for new projects. There is a [blog](https://aws.amazon.com/blogs/developer/tag/aws-sdk-java-v2/) that is dedicated to new features added to v2.\r\n\r\nFor performance, there are optimizations made for users in AWS Lambda environment based on [this doc](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/client-configuration-starttime.html). There is no performance benchmark done for HTTP calls, but since v2 supports HTTP2, it is supposed to be faster when the service enables HTTP2 traffic.\r\n\r\nFrom feature perspective, yes the transfer manager is not there, but for Iceberg the most important feature should be the multipart upload which is there, so I see much more benefits to use v2 instead of v1.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708513468/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708563244","html_url":"https://github.com/apache/iceberg/pull/1477#issuecomment-708563244","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1477","id":708563244,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODU2MzI0NA==","user":{"login":"stevenzwu","id":1545663,"node_id":"MDQ6VXNlcjE1NDU2NjM=","avatar_url":"https://avatars.githubusercontent.com/u/1545663?v=4","gravatar_id":"","url":"https://api.github.com/users/stevenzwu","html_url":"https://github.com/stevenzwu","followers_url":"https://api.github.com/users/stevenzwu/followers","following_url":"https://api.github.com/users/stevenzwu/following{/other_user}","gists_url":"https://api.github.com/users/stevenzwu/gists{/gist_id}","starred_url":"https://api.github.com/users/stevenzwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stevenzwu/subscriptions","organizations_url":"https://api.github.com/users/stevenzwu/orgs","repos_url":"https://api.github.com/users/stevenzwu/repos","events_url":"https://api.github.com/users/stevenzwu/events{/privacy}","received_events_url":"https://api.github.com/users/stevenzwu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T17:54:06Z","updated_at":"2020-10-14T17:54:06Z","author_association":"CONTRIBUTOR","body":"This looks good to me.\r\n\r\nI am wondering if we should define `FlinkManifestFile` impl and provide a state serializer for it. right now, we pass in byte[] type to Flink state. We probably need to change this once we move to the new FLIP-143 sink interface, which will require a GlobalCommT and a serializer for it. So I am saying we can postpone the work until then.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708563244/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708564768","html_url":"https://github.com/apache/iceberg/pull/1613#issuecomment-708564768","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1613","id":708564768,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODU2NDc2OA==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T17:56:52Z","updated_at":"2020-10-14T17:56:52Z","author_association":"CONTRIBUTOR","body":"Overall, looks good to me, just two questions.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708564768/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708580621","html_url":"https://github.com/apache/iceberg/pull/1573#issuecomment-708580621","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1573","id":708580621,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODU4MDYyMQ==","user":{"login":"danielcweeks","id":4925077,"node_id":"MDQ6VXNlcjQ5MjUwNzc=","avatar_url":"https://avatars.githubusercontent.com/u/4925077?v=4","gravatar_id":"","url":"https://api.github.com/users/danielcweeks","html_url":"https://github.com/danielcweeks","followers_url":"https://api.github.com/users/danielcweeks/followers","following_url":"https://api.github.com/users/danielcweeks/following{/other_user}","gists_url":"https://api.github.com/users/danielcweeks/gists{/gist_id}","starred_url":"https://api.github.com/users/danielcweeks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielcweeks/subscriptions","organizations_url":"https://api.github.com/users/danielcweeks/orgs","repos_url":"https://api.github.com/users/danielcweeks/repos","events_url":"https://api.github.com/users/danielcweeks/events{/privacy}","received_events_url":"https://api.github.com/users/danielcweeks/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T18:25:39Z","updated_at":"2020-10-14T18:25:39Z","author_association":"CONTRIBUTOR","body":"@jackye1995 and @kbendick I think you both make a good case for going forward with v2.  After looking into the docs a little, the main point for me was that it provides more control over the underlying http transport, which we may want to take advantage of.\r\n\r\nThe usage in the initial version is pretty basic and should be trivial to switch over to v2 (I have no objection to doing that).  \r\n\r\nThe main issue is testing support for the s3mock library with junit4 doesn't appear to support v2 so we would need to switch to junit5. (Is there better testing harnesses in/for v2?).  @rdblue do you have any objection to using junit5 for this module?\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708580621/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708586861","html_url":"https://github.com/apache/iceberg/pull/1573#issuecomment-708586861","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1573","id":708586861,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODU4Njg2MQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T18:37:40Z","updated_at":"2020-10-14T18:37:40Z","author_association":"CONTRIBUTOR","body":"I think it would be fine to use JUnit5. We've been considering it for Hive testing as well so we can improve how we parameterize the HiveRunner tests.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708586861/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708650031","html_url":"https://github.com/apache/iceberg/issues/1496#issuecomment-708650031","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1496","id":708650031,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODY1MDAzMQ==","user":{"login":"fbocse","id":559272,"node_id":"MDQ6VXNlcjU1OTI3Mg==","avatar_url":"https://avatars.githubusercontent.com/u/559272?v=4","gravatar_id":"","url":"https://api.github.com/users/fbocse","html_url":"https://github.com/fbocse","followers_url":"https://api.github.com/users/fbocse/followers","following_url":"https://api.github.com/users/fbocse/following{/other_user}","gists_url":"https://api.github.com/users/fbocse/gists{/gist_id}","starred_url":"https://api.github.com/users/fbocse/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fbocse/subscriptions","organizations_url":"https://api.github.com/users/fbocse/orgs","repos_url":"https://api.github.com/users/fbocse/repos","events_url":"https://api.github.com/users/fbocse/events{/privacy}","received_events_url":"https://api.github.com/users/fbocse/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T20:44:45Z","updated_at":"2020-10-14T20:45:55Z","author_association":"CONTRIBUTOR","body":"@pvary thank you for following up on this - I think that the solution you are considering reproduces the behaviour we are seeing for the server-side implementation of `create(overwrite=true)` used by Iceberg to override the `version-hint.txt` file. I don't think that in our particular case this is necessarily going to be a benefit at the \"expense\" of a couple of more hdfs requests.\r\n\r\nHowever your thoughts got me thinking too, especially with the new fallback behaviour in place. I wouldn't necessarily advertise using more APIs than necessary to implement optimistic locking because we're also exposing more edge-cases, I was thinking about this one in particular, accounting for your proposal:\r\n\r\n-1. writer reads version-hint.txt (with content 17)\r\n0. writer create(overwrite=false) v18.metadata.json\r\n\r\n1. writer create(overwrite=false) file version-hint-18.txt (with content 18)\r\n2. writer deletes version-hint.txt (with content 17)\r\n3. writer moves version-hint-18.txt to version-hint.txt  (with content 18)\r\n\r\nIf between 2 and 3 a NEW writer attempts to commit it will fail to load `version-hint.txt` and it will fallback to directory listing instead - then it finds v18.metadata.json as the greatest version and continues to write v19.metadata.json and to commit its new version to the version-hint.txt file.\r\nIf it so happens that the NEW writer also manages to commit its own 2 and 3 steps (unlikely but not impossible, think GC pause?) before the initial writer does we might end up with version 19 being overridden by version 18. This is a classic dead-lock.\r\nThis basically \"locks\" the table for any subsequent writers - cause new writers will find version-hint.txt and load value 18, increment that value to resolve the version they should write a new metadata file for but fail to do so since there already is a v19.metadata.json file.\r\n\r\nI think that this behaviour is present today should the client exit unexpectedly right before replacing version-hint.txt. \r\nBut to that edge-case this implementation adds an edge case of a different category, it relates to the distributed nature of writers attempting to replace the same resource.\r\n\r\nAlso looking at your suggestion I think that if any writer exits unexpectedly before step 3 I assume version-hint.txt file is never going to be materialized and all subsequent writers will fallback to directory listing for version resolution, right? I assume that resolving the version-hint.txt file doesn't involve also to write the version to the file as well.\r\n\r\nMy suggestion is we'd also extract the current implementation of `HadoopTableOperations:writeVersionHint` and `HadoopTableOperations:readVersionHint` to something we can override by using the APIs that provide the right atomic and consistency guarantees - say dir listing provides read-after-write guarantees and we also get atomic create(overwrite=false) guarantees we can implement version resolution on top of those - each new version is a new version file, every writer attempts to delete older versions than say the last 10 so we keep dir listing in constant time","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708650031/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708658252","html_url":"https://github.com/apache/iceberg/pull/1573#issuecomment-708658252","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1573","id":708658252,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODY1ODI1Mg==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T21:02:29Z","updated_at":"2020-10-14T21:02:29Z","author_association":"CONTRIBUTOR","body":"> @jackye1995 and @kbendick I think you both make a good case for going forward with v2. After looking into the docs a little, the main point for me was that it provides more control over the underlying http transport, which we may want to take advantage of.\r\n> \r\n> The usage in the initial version is pretty basic and should be trivial to switch over to v2 (I have no objection to doing that).\r\n> \r\n> The main issue is testing support for the s3mock library with junit4 doesn't appear to support v2 so we would need to switch to junit5. (Is there better testing harnesses in/for v2?). @rdblue do you have any objection to using junit5 for this module?\r\n\r\nWhat do you mean by S3Mock library not supporting v2? S3Mock runs as a server, and a client can simply override the endpoint to localhost to communicate with the server. The version of the client should not matter.\r\n\r\nserver:\r\n```java\r\nS3MockApplication.start(\"--server.port=8001\");\r\n```\r\n\r\nclient:\r\n```java\r\ns3 = S3Client.builder()\r\n            .endpointOverride(URI.create(\"http://localhost:8001\"))\r\n            .region(Region.US_EAST_1) // dummy region\r\n            .credentialsProvider(StaticCredentialsProvider.create(\r\n                    AwsBasicCredentials.create(\"key\", \"secret\"))) // dummy credential\r\n            .build();\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708658252/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708708370","html_url":"https://github.com/apache/iceberg/pull/1517#issuecomment-708708370","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1517","id":708708370,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODcwODM3MA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T23:12:01Z","updated_at":"2020-10-14T23:12:01Z","author_association":"CONTRIBUTOR","body":"Thanks, @chenjunjiedada! Good to have all of the read paths updated for row-level deletes!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708708370/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708715504","html_url":"https://github.com/apache/iceberg/pull/1572#issuecomment-708715504","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1572","id":708715504,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODcxNTUwNA==","user":{"login":"holdenk","id":59893,"node_id":"MDQ6VXNlcjU5ODkz","avatar_url":"https://avatars.githubusercontent.com/u/59893?v=4","gravatar_id":"","url":"https://api.github.com/users/holdenk","html_url":"https://github.com/holdenk","followers_url":"https://api.github.com/users/holdenk/followers","following_url":"https://api.github.com/users/holdenk/following{/other_user}","gists_url":"https://api.github.com/users/holdenk/gists{/gist_id}","starred_url":"https://api.github.com/users/holdenk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/holdenk/subscriptions","organizations_url":"https://api.github.com/users/holdenk/orgs","repos_url":"https://api.github.com/users/holdenk/repos","events_url":"https://api.github.com/users/holdenk/events{/privacy}","received_events_url":"https://api.github.com/users/holdenk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-14T23:35:59Z","updated_at":"2020-10-14T23:35:59Z","author_association":"CONTRIBUTOR","body":"Thanks y'all for the reviews. Sorry I'm a little slow responding to this, I'm currently dealing with a race condition inside of some new Spark code but I'm hoping to circle back to this PR before the end of the week.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708715504/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708848381","html_url":"https://github.com/apache/iceberg/issues/1610#issuecomment-708848381","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1610","id":708848381,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODg0ODM4MQ==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T02:08:22Z","updated_at":"2020-10-15T02:08:22Z","author_association":"MEMBER","body":"@simonsssu  we have discussion about the flink compaction policy, and I know you are doing the PoC for it,  maybe you could open a WIP PR for this to show your work if you don't mind. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708848381/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708857326","html_url":"https://github.com/apache/iceberg/issues/1610#issuecomment-708857326","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1610","id":708857326,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODg1NzMyNg==","user":{"login":"simonsssu","id":12323514,"node_id":"MDQ6VXNlcjEyMzIzNTE0","avatar_url":"https://avatars.githubusercontent.com/u/12323514?v=4","gravatar_id":"","url":"https://api.github.com/users/simonsssu","html_url":"https://github.com/simonsssu","followers_url":"https://api.github.com/users/simonsssu/followers","following_url":"https://api.github.com/users/simonsssu/following{/other_user}","gists_url":"https://api.github.com/users/simonsssu/gists{/gist_id}","starred_url":"https://api.github.com/users/simonsssu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/simonsssu/subscriptions","organizations_url":"https://api.github.com/users/simonsssu/orgs","repos_url":"https://api.github.com/users/simonsssu/repos","events_url":"https://api.github.com/users/simonsssu/events{/privacy}","received_events_url":"https://api.github.com/users/simonsssu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T02:36:11Z","updated_at":"2020-10-15T02:36:11Z","author_association":"CONTRIBUTOR","body":"@openinx Thanks, I will open a WIP PR later. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708857326/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708906044","html_url":"https://github.com/apache/iceberg/pull/1608#issuecomment-708906044","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1608","id":708906044,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODkwNjA0NA==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T05:26:08Z","updated_at":"2020-10-15T05:26:08Z","author_association":"CONTRIBUTOR","body":"Hi @jackye1995. Thanks for taking this on. Have you seen this PR for integrating Nessie with Iceberg? I believe that the idea there is _partially_ that Nessie would also allow for AWS Glue to be used. https://github.com/apache/iceberg/pull/1587\r\n\r\nHowever, by no means do I intend to say that this PR should not be moved forward. I think this is a valuable contribution as many people likely use AWS Glue.\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708906044/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708912736","html_url":"https://github.com/apache/iceberg/pull/1515#issuecomment-708912736","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1515","id":708912736,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODkxMjczNg==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T05:47:15Z","updated_at":"2020-10-15T05:47:15Z","author_association":"CONTRIBUTOR","body":"> I think it would make sense to get a configuration check into 0.10.0 to ensure that users don't configure the sink without checkpointing. That could cause users to lose data.\r\n\r\nI have personally seen several pipelines configured accidentally without checkpointing, as it's not enabled by default. So from my personal experience I think this is a very valid concern @rdblue.\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708912736/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708921377","html_url":"https://github.com/apache/iceberg/issues/1610#issuecomment-708921377","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1610","id":708921377,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODkyMTM3Nw==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T06:09:19Z","updated_at":"2020-10-15T06:09:19Z","author_association":"CONTRIBUTOR","body":"I implemented a RewriteDataFilesAction for flink myself. My idea is that we can also extract some common functions and put them in iceberg-core when implementing RewriteDataFilesAction of flink, and then use the commcon functions to refactor spark RewriteDataFilesAction.\r\n\r\nWe can also do some iceberg management functions in the future（iceberg admin client or sql  extension）, which can trigger compression manually.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708921377/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708924017","html_url":"https://github.com/apache/iceberg/pull/1515#issuecomment-708924017","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1515","id":708924017,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODkyNDAxNw==","user":{"login":"simonsssu","id":12323514,"node_id":"MDQ6VXNlcjEyMzIzNTE0","avatar_url":"https://avatars.githubusercontent.com/u/12323514?v=4","gravatar_id":"","url":"https://api.github.com/users/simonsssu","html_url":"https://github.com/simonsssu","followers_url":"https://api.github.com/users/simonsssu/followers","following_url":"https://api.github.com/users/simonsssu/following{/other_user}","gists_url":"https://api.github.com/users/simonsssu/gists{/gist_id}","starred_url":"https://api.github.com/users/simonsssu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/simonsssu/subscriptions","organizations_url":"https://api.github.com/users/simonsssu/orgs","repos_url":"https://api.github.com/users/simonsssu/repos","events_url":"https://api.github.com/users/simonsssu/events{/privacy}","received_events_url":"https://api.github.com/users/simonsssu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T06:15:59Z","updated_at":"2020-10-15T06:15:59Z","author_association":"CONTRIBUTOR","body":"@kbendick I think the problem now is Flink don't have the API to tell a batch or stream mode, so in current implementation, it's hard to determine a job without checkpoint is valid or not. (Although you can set a config with JAVA API, but it's hard to do this when running IcebergTableSink by SQL.  Although we can use a processing time to trigger a commit when disable checkpoint, it will also make a batch job split into several small transaction commit. I think the solution would be:\r\n1. For stream job, we can register a timer for jobs which disable checkpoint.\r\n2. For batch job, we do nothing. \r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708924017/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708926572","html_url":"https://github.com/apache/iceberg/issues/1610#issuecomment-708926572","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1610","id":708926572,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODkyNjU3Mg==","user":{"login":"simonsssu","id":12323514,"node_id":"MDQ6VXNlcjEyMzIzNTE0","avatar_url":"https://avatars.githubusercontent.com/u/12323514?v=4","gravatar_id":"","url":"https://api.github.com/users/simonsssu","html_url":"https://github.com/simonsssu","followers_url":"https://api.github.com/users/simonsssu/followers","following_url":"https://api.github.com/users/simonsssu/following{/other_user}","gists_url":"https://api.github.com/users/simonsssu/gists{/gist_id}","starred_url":"https://api.github.com/users/simonsssu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/simonsssu/subscriptions","organizations_url":"https://api.github.com/users/simonsssu/orgs","repos_url":"https://api.github.com/users/simonsssu/repos","events_url":"https://api.github.com/users/simonsssu/events{/privacy}","received_events_url":"https://api.github.com/users/simonsssu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T06:22:15Z","updated_at":"2020-10-15T06:22:15Z","author_association":"CONTRIBUTOR","body":"@zhangjun0x01 Thanks ZhangJun,  I totally agree with you to refactor the current Rewrite Part. If you have implemented this, maybe you can open a PR. That's quite useful for Flink Users. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708926572/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708928006","html_url":"https://github.com/apache/iceberg/issues/1610#issuecomment-708928006","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1610","id":708928006,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODkyODAwNg==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T06:25:39Z","updated_at":"2020-10-15T06:25:39Z","author_association":"CONTRIBUTOR","body":"@simonsssu\r\nI am doing test for it, after finishing I will open a PR","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708928006/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708930754","html_url":"https://github.com/apache/iceberg/pull/1608#issuecomment-708930754","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1608","id":708930754,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODkzMDc1NA==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T06:31:47Z","updated_at":"2020-10-15T06:31:47Z","author_association":"CONTRIBUTOR","body":"> Hi @jackye1995. Thanks for taking this on. Have you seen this PR for integrating Nessie with Iceberg? I believe that the idea there is _partially_ that Nessie would also allow for AWS Glue to be used. #1587\r\n> \r\n> However, by no means do I intend to say that this PR should not be moved forward. I think this is a valuable contribution as many people likely use AWS Glue.\r\n\r\nYeah I read about that project a few days ago. I think they can coexist, and I am focusing on the use case for people who only need Glue + Iceberg. The patch here will be largely simplified based on community feedback, so I don't see any conflicts for continuing with both approaches at the same time.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708930754/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708938985","html_url":"https://github.com/apache/iceberg/issues/1548#issuecomment-708938985","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1548","id":708938985,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODkzODk4NQ==","user":{"login":"SteNicholas","id":10048174,"node_id":"MDQ6VXNlcjEwMDQ4MTc0","avatar_url":"https://avatars.githubusercontent.com/u/10048174?v=4","gravatar_id":"","url":"https://api.github.com/users/SteNicholas","html_url":"https://github.com/SteNicholas","followers_url":"https://api.github.com/users/SteNicholas/followers","following_url":"https://api.github.com/users/SteNicholas/following{/other_user}","gists_url":"https://api.github.com/users/SteNicholas/gists{/gist_id}","starred_url":"https://api.github.com/users/SteNicholas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SteNicholas/subscriptions","organizations_url":"https://api.github.com/users/SteNicholas/orgs","repos_url":"https://api.github.com/users/SteNicholas/repos","events_url":"https://api.github.com/users/SteNicholas/events{/privacy}","received_events_url":"https://api.github.com/users/SteNicholas/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T06:49:04Z","updated_at":"2020-10-15T06:49:04Z","author_association":"MEMBER","body":"@aokolnychyi IMO, `MetricsConfig` could add `validateProperties` method to check metrics config references columns in schema, and the method should be called in `createTable()`.   Is this similar with your point?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708938985/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708943564","html_url":"https://github.com/apache/iceberg/issues/1560#issuecomment-708943564","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1560","id":708943564,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODk0MzU2NA==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T06:58:35Z","updated_at":"2020-10-15T06:58:35Z","author_association":"CONTRIBUTOR","body":"The PR for SPARK-33136 is merged and will be shipped to Spark 3.0.2 / 3.1.0. Shall we close this, or would someone like to build the Spark on branch-3.0 and verify on their end?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708943564/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708961155","html_url":"https://github.com/apache/iceberg/issues/1556#issuecomment-708961155","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1556","id":708961155,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODk2MTE1NQ==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T07:35:06Z","updated_at":"2020-10-15T07:35:06Z","author_association":"MEMBER","body":"@elkhand  we're responsible for maintaining the apache flink iceberg sink connector.   Just curious : did you have any log message such as the following ? \r\n\r\n```\r\n LOG.info(\"Dropped table: {}\", identifier);\r\n```\r\n\r\nor \r\n\r\n```\r\nLOG.info(\"Skipping drop, table does not exist: {}\", identifier, e);\r\n```\r\n\r\nIs it possible that we've provided a non-existing table identifier ? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708961155/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708964031","html_url":"https://github.com/apache/iceberg/pull/1477#issuecomment-708964031","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1477","id":708964031,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODk2NDAzMQ==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T07:40:47Z","updated_at":"2020-10-15T07:40:47Z","author_association":"MEMBER","body":"> So I am saying we can postpone the work until then.\r\n\r\nI read the long conversation from the [flink mail list](https://lists.apache.org/thread.html/rf09dfeeaf35da5ee98afe559b5a6e955c9f03ade0262727f6b5c4c1e%40%3Cdev.flink.apache.org%3E),  and skimmed the pull requests under the [FLINK-19510](https://issues.apache.org/jira/browse/FLINK-19510).   Sounds the whole api will be available in the next flink release 1.12.0,  I think it would be better to adjust the iceberg sink connector until it provides the final sink API.  ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708964031/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708983340","html_url":"https://github.com/apache/iceberg/pull/1608#issuecomment-708983340","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1608","id":708983340,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODk4MzM0MA==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T08:17:00Z","updated_at":"2020-10-15T08:17:00Z","author_association":"MEMBER","body":"Looks like a big patch,   would be better to understand if we have a short doc to describe the core things.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708983340/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708992950","html_url":"https://github.com/apache/iceberg/pull/1586#issuecomment-708992950","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1586","id":708992950,"node_id":"MDEyOklzc3VlQ29tbWVudDcwODk5Mjk1MA==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T08:34:51Z","updated_at":"2020-10-15T08:34:51Z","author_association":"MEMBER","body":"The broken unit test is : \r\n\r\n```\r\norg.apache.iceberg.flink.TestFlinkCatalogDatabase > testListNamespace[catalogName = testhadoop baseNamespace = [Ljava.lang.String;@155b8b06] FAILED\r\n    java.lang.AssertionError: Should have 2 database expected:<2> but was:<3>\r\n        at org.junit.Assert.fail(Assert.java:88)\r\n        at org.junit.Assert.failNotEquals(Assert.java:834)\r\n        at org.junit.Assert.assertEquals(Assert.java:645)\r\n        at org.apache.iceberg.flink.TestFlinkCatalogDatabase.testListNamespace(TestFlinkCatalogDatabase.java:150)\r\n```\r\n\r\nLet we find out why. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/708992950/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709014580","html_url":"https://github.com/apache/iceberg/pull/1558#issuecomment-709014580","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1558","id":709014580,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTAxNDU4MA==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T09:00:19Z","updated_at":"2020-10-15T09:00:19Z","author_association":"MEMBER","body":"> What I don't understand is why Iceberg should do anything other than ensure that hive-site.xml is added as a default resource from the classpath.\r\n\r\nFor flink SQL,  we usually create only one `iceberg-flink-runtime.jar` and make it in the flink classpath.  Different users would use the same flink distribution to run their flink sql jobs, if the `iceberg-flink-runtime.jar` is bounded with the specific `hive-site.xml` in its resources, then how could different users  use the same distribution to access different hive metastore ?  That would require different users to build different distribution ?  \r\n\r\nFor hadoop configurations,  we provide `HADOOP_HOME` environment , or `fs.hdfs.hadoopconf` config keys in flink configuration file , or `HADOOP_CONF_DIR` environment to load hadoop(hdfs-site.xml, core-site.xml) configurations,  then it won't have the hive config issues.  I created a patch to provide the similar behavior  here : https://github.com/apache/iceberg/pull/1586/files#diff-dfee8e9c94fb35806da6eea03a18614d2c5ad778563749493452829bcaec7cc1R95.\r\n\r\n\r\n@zhangjun0x01 , for uploading the configurations files to hdfs and downloading & loading it for flink stream job in `application` mode,  I'm thinking that it's over designed now. Besides the hive-site.xml,  hadoop configurations are loaded either from environment or classpath or path configured in flink conf file, would the flink module in iceberg also need to download those and loading them ?  That does not make sense.  A better way is following the current flink design , bundled the hive-site.xml and other related config files into your flink datastream jar, and upload it to flink cluster.   Flink DataStream job submission is more flexible  that Flink SQL,  it make sense to build a separate bundled jar per job. \r\n\r\nI provided a more reasonable patch (https://github.com/apache/iceberg/pull/1586) to handle hive-site.xml (As the flink 0.10.0 release is coming, and we hope to resolve this thing as soon as possible, so I pull requested the patch for the same issue, your discussion is valuable @zhangjun0x01 , hope you don't mind, Thanks).\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709014580/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709027336","html_url":"https://github.com/apache/iceberg/pull/1558#issuecomment-709027336","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1558","id":709027336,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTAyNzMzNg==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T09:15:08Z","updated_at":"2020-10-15T09:15:08Z","author_association":"CONTRIBUTOR","body":"@openinx  it don't matter","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709027336/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709040812","html_url":"https://github.com/apache/iceberg/pull/1477#issuecomment-709040812","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1477","id":709040812,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTA0MDgxMg==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T09:33:32Z","updated_at":"2020-10-15T09:33:32Z","author_association":"MEMBER","body":"Ping @rdblue @stevenzwu , any other concern ? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709040812/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709219092","html_url":"https://github.com/apache/iceberg/issues/1560#issuecomment-709219092","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1560","id":709219092,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTIxOTA5Mg==","user":{"login":"NJordan72","id":5156166,"node_id":"MDQ6VXNlcjUxNTYxNjY=","avatar_url":"https://avatars.githubusercontent.com/u/5156166?v=4","gravatar_id":"","url":"https://api.github.com/users/NJordan72","html_url":"https://github.com/NJordan72","followers_url":"https://api.github.com/users/NJordan72/followers","following_url":"https://api.github.com/users/NJordan72/following{/other_user}","gists_url":"https://api.github.com/users/NJordan72/gists{/gist_id}","starred_url":"https://api.github.com/users/NJordan72/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/NJordan72/subscriptions","organizations_url":"https://api.github.com/users/NJordan72/orgs","repos_url":"https://api.github.com/users/NJordan72/repos","events_url":"https://api.github.com/users/NJordan72/events{/privacy}","received_events_url":"https://api.github.com/users/NJordan72/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T11:26:32Z","updated_at":"2020-10-15T11:26:32Z","author_association":"NONE","body":"I think it is safe to close.  I haven't been able to confirm with the patch, but using some casts I was able to match the nullability and I can confirm that fixed the problem. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709219092/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709426101","html_url":"https://github.com/apache/iceberg/pull/1421#issuecomment-709426101","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1421","id":709426101,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTQyNjEwMQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T16:02:35Z","updated_at":"2020-10-15T16:02:35Z","author_association":"MEMBER","body":"@holdenk This is the last of the bigger PR's I currently have in flight if you wanted to take a peak. I would be grateful for the review :)","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709426101/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709445722","html_url":"https://github.com/apache/iceberg/pull/1615#issuecomment-709445722","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1615","id":709445722,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTQ0NTcyMg==","user":{"login":"shardulm94","id":6961317,"node_id":"MDQ6VXNlcjY5NjEzMTc=","avatar_url":"https://avatars.githubusercontent.com/u/6961317?v=4","gravatar_id":"","url":"https://api.github.com/users/shardulm94","html_url":"https://github.com/shardulm94","followers_url":"https://api.github.com/users/shardulm94/followers","following_url":"https://api.github.com/users/shardulm94/following{/other_user}","gists_url":"https://api.github.com/users/shardulm94/gists{/gist_id}","starred_url":"https://api.github.com/users/shardulm94/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shardulm94/subscriptions","organizations_url":"https://api.github.com/users/shardulm94/orgs","repos_url":"https://api.github.com/users/shardulm94/repos","events_url":"https://api.github.com/users/shardulm94/events{/privacy}","received_events_url":"https://api.github.com/users/shardulm94/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T16:34:45Z","updated_at":"2020-10-15T16:34:45Z","author_association":"CONTRIBUTOR","body":"@RussellSpitzer I saw some other places in the doc using it, so I updated the PR to use it too. Thanks for the suggestion!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709445722/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709451096","html_url":"https://github.com/apache/iceberg/pull/1573#issuecomment-709451096","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1573","id":709451096,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTQ1MTA5Ng==","user":{"login":"danielcweeks","id":4925077,"node_id":"MDQ6VXNlcjQ5MjUwNzc=","avatar_url":"https://avatars.githubusercontent.com/u/4925077?v=4","gravatar_id":"","url":"https://api.github.com/users/danielcweeks","html_url":"https://github.com/danielcweeks","followers_url":"https://api.github.com/users/danielcweeks/followers","following_url":"https://api.github.com/users/danielcweeks/following{/other_user}","gists_url":"https://api.github.com/users/danielcweeks/gists{/gist_id}","starred_url":"https://api.github.com/users/danielcweeks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielcweeks/subscriptions","organizations_url":"https://api.github.com/users/danielcweeks/orgs","repos_url":"https://api.github.com/users/danielcweeks/repos","events_url":"https://api.github.com/users/danielcweeks/events{/privacy}","received_events_url":"https://api.github.com/users/danielcweeks/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T16:43:47Z","updated_at":"2020-10-15T16:43:47Z","author_association":"CONTRIBUTOR","body":"@jackye1995 Sorry, my comment about S3Mock wasn't that it was not supported with v2, but rather the [docs for S3Mock say](https://github.com/adobe/S3Mock#using-the-junit5-extension) integration exists with JUnit4 with v1 and JUnit5 with v1 and v2.  I didn't mean to imply that it didn't work, more that the current unit tests need to be updated to either use S3Mock like your example or switch to JUnit5 and use the extensions.\r\n\r\nI might be able to use a combination of the JUnit4 Rule with a custom client configured as well.  It's not a big change overall, but I was also interested as to whether there was something provided by the sdkv2 that provides something similar to s3mock for testing.  \r\n\r\nThanks for the example, I'll give that a shot and see if I can keep the existing JUnit4 tests.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709451096/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709499875","html_url":"https://github.com/apache/iceberg/pull/1477#issuecomment-709499875","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1477","id":709499875,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTQ5OTg3NQ==","user":{"login":"stevenzwu","id":1545663,"node_id":"MDQ6VXNlcjE1NDU2NjM=","avatar_url":"https://avatars.githubusercontent.com/u/1545663?v=4","gravatar_id":"","url":"https://api.github.com/users/stevenzwu","html_url":"https://github.com/stevenzwu","followers_url":"https://api.github.com/users/stevenzwu/followers","following_url":"https://api.github.com/users/stevenzwu/following{/other_user}","gists_url":"https://api.github.com/users/stevenzwu/gists{/gist_id}","starred_url":"https://api.github.com/users/stevenzwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stevenzwu/subscriptions","organizations_url":"https://api.github.com/users/stevenzwu/orgs","repos_url":"https://api.github.com/users/stevenzwu/repos","events_url":"https://api.github.com/users/stevenzwu/events{/privacy}","received_events_url":"https://api.github.com/users/stevenzwu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T18:08:58Z","updated_at":"2020-10-15T18:08:58Z","author_association":"CONTRIBUTOR","body":"nope. looks good to me","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709499875/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709542787","html_url":"https://github.com/apache/iceberg/pull/1615#issuecomment-709542787","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1615","id":709542787,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTU0Mjc4Nw==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T19:26:52Z","updated_at":"2020-10-15T19:26:52Z","author_association":"MEMBER","body":"I don't have a strong opinion :) either way is fine with me. I just end up\nsinging the Vampire Weekend song of the same name every time I see one\nmissing\n\nOn Thu, Oct 15, 2020, 11:35 AM Shardul Mahadik <notifications@github.com>\nwrote:\n\n> @RussellSpitzer <https://github.com/RussellSpitzer> I saw some other\n> places in the doc using it, so I updated the PR to use it too. Thanks for\n> the suggestion!\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/iceberg/pull/1615#issuecomment-709445722>, or\n> unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AADE2YPY35HXSJZILU3ZCLTSK4QDNANCNFSM4SSGREYA>\n> .\n>\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709542787/reactions","total_count":1,"+1":0,"-1":0,"laugh":1,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709560757","html_url":"https://github.com/apache/iceberg/pull/1421#issuecomment-709560757","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1421","id":709560757,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTU2MDc1Nw==","user":{"login":"holdenk","id":59893,"node_id":"MDQ6VXNlcjU5ODkz","avatar_url":"https://avatars.githubusercontent.com/u/59893?v=4","gravatar_id":"","url":"https://api.github.com/users/holdenk","html_url":"https://github.com/holdenk","followers_url":"https://api.github.com/users/holdenk/followers","following_url":"https://api.github.com/users/holdenk/following{/other_user}","gists_url":"https://api.github.com/users/holdenk/gists{/gist_id}","starred_url":"https://api.github.com/users/holdenk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/holdenk/subscriptions","organizations_url":"https://api.github.com/users/holdenk/orgs","repos_url":"https://api.github.com/users/holdenk/repos","events_url":"https://api.github.com/users/holdenk/events{/privacy}","received_events_url":"https://api.github.com/users/holdenk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T20:03:44Z","updated_at":"2020-10-15T20:03:44Z","author_association":"CONTRIBUTOR","body":"Oh yeah this is a big one :) I'll try and look at it tomorrow afternoon. Is there a part of it where you would like me to focus?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709560757/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709563046","html_url":"https://github.com/apache/iceberg/pull/1421#issuecomment-709563046","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1421","id":709563046,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTU2MzA0Ng==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T20:08:27Z","updated_at":"2020-10-15T20:08:27Z","author_association":"MEMBER","body":"There are a few \r\n\r\n> Oh yeah this is a big one :) I'll try and look at it tomorrow afternoon. Is there a part of it where you would like me to focus?\r\n\r\nI think we are mainly looking for any ways to reduce the amount of internals that are being opened up, and also thinking about any places where there are potential simplifications. If you could think of a cleaner way to get that \"specID\" property into our DataFiles table that would be awesome too, it's definitely the most hacky part of this imho.\r\n\r\nWe were punting on adaptive implementation of distributed planning till a later ticket as well as pushing down filters directly into our Metadata tables. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709563046/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709582724","html_url":"https://github.com/apache/iceberg/issues/1549#issuecomment-709582724","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1549","id":709582724,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTU4MjcyNA==","user":{"login":"holdenk","id":59893,"node_id":"MDQ6VXNlcjU5ODkz","avatar_url":"https://avatars.githubusercontent.com/u/59893?v=4","gravatar_id":"","url":"https://api.github.com/users/holdenk","html_url":"https://github.com/holdenk","followers_url":"https://api.github.com/users/holdenk/followers","following_url":"https://api.github.com/users/holdenk/following{/other_user}","gists_url":"https://api.github.com/users/holdenk/gists{/gist_id}","starred_url":"https://api.github.com/users/holdenk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/holdenk/subscriptions","organizations_url":"https://api.github.com/users/holdenk/orgs","repos_url":"https://api.github.com/users/holdenk/repos","events_url":"https://api.github.com/users/holdenk/events{/privacy}","received_events_url":"https://api.github.com/users/holdenk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T20:49:56Z","updated_at":"2020-10-15T20:49:56Z","author_association":"CONTRIBUTOR","body":"Sure I can try :)","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709582724/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709599748","html_url":"https://github.com/apache/iceberg/pull/1566#issuecomment-709599748","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1566","id":709599748,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTU5OTc0OA==","user":{"login":"shardulm94","id":6961317,"node_id":"MDQ6VXNlcjY5NjEzMTc=","avatar_url":"https://avatars.githubusercontent.com/u/6961317?v=4","gravatar_id":"","url":"https://api.github.com/users/shardulm94","html_url":"https://github.com/shardulm94","followers_url":"https://api.github.com/users/shardulm94/followers","following_url":"https://api.github.com/users/shardulm94/following{/other_user}","gists_url":"https://api.github.com/users/shardulm94/gists{/gist_id}","starred_url":"https://api.github.com/users/shardulm94/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shardulm94/subscriptions","organizations_url":"https://api.github.com/users/shardulm94/orgs","repos_url":"https://api.github.com/users/shardulm94/repos","events_url":"https://api.github.com/users/shardulm94/events{/privacy}","received_events_url":"https://api.github.com/users/shardulm94/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T21:26:39Z","updated_at":"2020-10-15T21:26:39Z","author_association":"CONTRIBUTOR","body":"I guess https://github.com/apache/iceberg/blob/cd70cac279d3f14ba61f0143f9988d4cc9413651/parquet/src/main/java/org/apache/iceberg/parquet/ParquetReader.java#L120 also needs to be changed to use `valuesRead + skippedValues` just like `hasNext()`","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709599748/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709606269","html_url":"https://github.com/apache/iceberg/pull/1573#issuecomment-709606269","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1573","id":709606269,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTYwNjI2OQ==","user":{"login":"danielcweeks","id":4925077,"node_id":"MDQ6VXNlcjQ5MjUwNzc=","avatar_url":"https://avatars.githubusercontent.com/u/4925077?v=4","gravatar_id":"","url":"https://api.github.com/users/danielcweeks","html_url":"https://github.com/danielcweeks","followers_url":"https://api.github.com/users/danielcweeks/followers","following_url":"https://api.github.com/users/danielcweeks/following{/other_user}","gists_url":"https://api.github.com/users/danielcweeks/gists{/gist_id}","starred_url":"https://api.github.com/users/danielcweeks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danielcweeks/subscriptions","organizations_url":"https://api.github.com/users/danielcweeks/orgs","repos_url":"https://api.github.com/users/danielcweeks/repos","events_url":"https://api.github.com/users/danielcweeks/events{/privacy}","received_events_url":"https://api.github.com/users/danielcweeks/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T21:42:31Z","updated_at":"2020-10-15T21:42:59Z","author_association":"CONTRIBUTOR","body":"@jackye1995 and @kbendick I updated to aws java sdk v2 for almost everything.  I do feel the new api has a few rough edges compared to sdk v1 (e.g. range() specification is less intuitive, missing [URI parsing functionality like AmazonS3URI](https://github.com/aws/aws-sdk-java-v2/issues/272)), but overall it wasn't much effort.  I'm still using v1 for URI parsing (if you're aware of something better in v2, please let me know).  Turns out the tests were easier than I thought because S3Mock had a v2 client that just wasn't called out in the docs.\r\n\r\nAny feedback is appreciated.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709606269/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709608971","html_url":"https://github.com/apache/iceberg/pull/1615#issuecomment-709608971","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1615","id":709608971,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTYwODk3MQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T21:49:45Z","updated_at":"2020-10-15T21:49:45Z","author_association":"CONTRIBUTOR","body":"I appreciate the Oxford commas.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709608971/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709616189","html_url":"https://github.com/apache/iceberg/pull/1608#issuecomment-709616189","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1608","id":709616189,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTYxNjE4OQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-15T22:08:56Z","updated_at":"2020-10-15T22:08:56Z","author_association":"CONTRIBUTOR","body":"I've been talking with @jackye1995 in the Iceberg channel. Just to update anyone following here, my main concern is that this is a huge patch because it contains the implementation of Hive's thrift API for Glue. Jack is going to pare down the classes required so that we can see what is actually necessary for that approach and we can decide whether to build off of `BaseMetastoreClientOperations` or use Hive after that.\r\n\r\nAlso, this is a draft so we can look at the whole thing, but we will probably want to split it into multiple PRs. For example, the changes to allow injecting a different Hive client could be a stand-alone PR.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709616189/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709671206","html_url":"https://github.com/apache/iceberg/pull/1616#issuecomment-709671206","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1616","id":709671206,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTY3MTIwNg==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T01:12:41Z","updated_at":"2020-10-16T01:12:41Z","author_association":"CONTRIBUTOR","body":"I think I prefer this way because it's so much smaller. I don't see much benefit to avoiding reflection, and this ensures that the class that users interact with is common between the two implementations. If we go with the other approach, then a user can compile against the Spark 3 `Actions` methods and have missing methods at runtime, which would be more confusing than failing with `UnsupportedOperationException` thrown by the superclass.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709671206/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709683962","html_url":"https://github.com/apache/iceberg/pull/348#issuecomment-709683962","issue_url":"https://api.github.com/repos/apache/iceberg/issues/348","id":709683962,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTY4Mzk2Mg==","user":{"login":"yyanyy","id":71906210,"node_id":"MDQ6VXNlcjcxOTA2MjEw","avatar_url":"https://avatars.githubusercontent.com/u/71906210?v=4","gravatar_id":"","url":"https://api.github.com/users/yyanyy","html_url":"https://github.com/yyanyy","followers_url":"https://api.github.com/users/yyanyy/followers","following_url":"https://api.github.com/users/yyanyy/following{/other_user}","gists_url":"https://api.github.com/users/yyanyy/gists{/gist_id}","starred_url":"https://api.github.com/users/yyanyy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yyanyy/subscriptions","organizations_url":"https://api.github.com/users/yyanyy/orgs","repos_url":"https://api.github.com/users/yyanyy/repos","events_url":"https://api.github.com/users/yyanyy/events{/privacy}","received_events_url":"https://api.github.com/users/yyanyy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T01:58:42Z","updated_at":"2020-10-16T01:58:42Z","author_association":"CONTRIBUTOR","body":"Is anyone working on this at the moment? I'm currently looking into implementing java code for this spec change. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709683962/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709688422","html_url":"https://github.com/apache/iceberg/pull/1616#issuecomment-709688422","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1616","id":709688422,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTY4ODQyMg==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T02:15:20Z","updated_at":"2020-10-16T02:15:48Z","author_association":"MEMBER","body":"I'm not sure it's likely that a user can compile against the Spark 3 Module and not have many many other things go wrong at runtime if they are actually on Spark 2 :)","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709688422/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709690136","html_url":"https://github.com/apache/iceberg/pull/1608#issuecomment-709690136","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1608","id":709690136,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTY5MDEzNg==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T02:21:05Z","updated_at":"2020-10-16T02:21:05Z","author_association":"CONTRIBUTOR","body":"> I've been talking with @jackye1995 in the Iceberg channel. Just to update anyone following here, my main concern is that this is a huge patch because it contains the implementation of Hive's thrift API for Glue. Jack is going to pare down the classes required so that we can see what is actually necessary for that approach and we can decide whether to build off of `BaseMetastoreClientOperations` or use Hive after that.\r\n> \r\n> Also, this is a draft so we can look at the whole thing, but we will probably want to split it into multiple PRs. For example, the changes to allow injecting a different Hive client could be a stand-alone PR.\r\n\r\nI talked with a few folks today regarding the best way to go for the changes, and what I will do is the following PRs:\r\n1. `GlueCatalog` that directly implements the `Catalog` interface, and all the table operations\r\n2. add Dynamo lock table for catalog commit\r\n3. a dynamic loader of Hive client in `HiveClientPool` so that EMR users can switch the Hive client implementation if they want, no class of the client impl will be added in Iceberg.\r\n4. Spark and Flink integration points\r\n5. documentations\r\n\r\nPlease let me know if there are any further concerns, otherwise I will close this PR later.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709690136/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709692251","html_url":"https://github.com/apache/iceberg/pull/1608#issuecomment-709692251","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1608","id":709692251,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTY5MjI1MQ==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T02:28:23Z","updated_at":"2020-10-16T02:28:23Z","author_association":"CONTRIBUTOR","body":"> Looks like a big patch, would be better to understand if we have a short doc to describe the core things.\r\n\r\nSure I can add a short doc, and as I replied with Ryan, I will separate things to small patches for actual contribution. Let me close this PR, and I will attach a doc after I resubmit a smaller PR, thank you.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709692251/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709692340","html_url":"https://github.com/apache/iceberg/pull/1608#issuecomment-709692340","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1608","id":709692340,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTY5MjM0MA==","user":{"login":"jackye1995","id":29823233,"node_id":"MDQ6VXNlcjI5ODIzMjMz","avatar_url":"https://avatars.githubusercontent.com/u/29823233?v=4","gravatar_id":"","url":"https://api.github.com/users/jackye1995","html_url":"https://github.com/jackye1995","followers_url":"https://api.github.com/users/jackye1995/followers","following_url":"https://api.github.com/users/jackye1995/following{/other_user}","gists_url":"https://api.github.com/users/jackye1995/gists{/gist_id}","starred_url":"https://api.github.com/users/jackye1995/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackye1995/subscriptions","organizations_url":"https://api.github.com/users/jackye1995/orgs","repos_url":"https://api.github.com/users/jackye1995/repos","events_url":"https://api.github.com/users/jackye1995/events{/privacy}","received_events_url":"https://api.github.com/users/jackye1995/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T02:28:43Z","updated_at":"2020-10-16T02:28:43Z","author_association":"CONTRIBUTOR","body":"Will contribute in smaller PRs.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709692340/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709696134","html_url":"https://github.com/apache/iceberg/issues/1560#issuecomment-709696134","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1560","id":709696134,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTY5NjEzNA==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T02:41:48Z","updated_at":"2020-10-16T02:41:48Z","author_association":"CONTRIBUTOR","body":"Thanks @NJordan72 for confirming! Could you please close this issue, @cccs-dm ?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709696134/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709706132","html_url":"https://github.com/apache/iceberg/issues/567#issuecomment-709706132","issue_url":"https://api.github.com/repos/apache/iceberg/issues/567","id":709706132,"node_id":"MDEyOklzc3VlQ29tbWVudDcwOTcwNjEzMg==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T03:16:36Z","updated_at":"2020-10-16T03:16:36Z","author_association":"MEMBER","body":"Since we've merged the flink sink connector, it's time to close this issue now.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/709706132/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/710165280","html_url":"https://github.com/apache/iceberg/issues/1560#issuecomment-710165280","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1560","id":710165280,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMDE2NTI4MA==","user":{"login":"cccs-dm","id":62555897,"node_id":"MDQ6VXNlcjYyNTU1ODk3","avatar_url":"https://avatars.githubusercontent.com/u/62555897?v=4","gravatar_id":"","url":"https://api.github.com/users/cccs-dm","html_url":"https://github.com/cccs-dm","followers_url":"https://api.github.com/users/cccs-dm/followers","following_url":"https://api.github.com/users/cccs-dm/following{/other_user}","gists_url":"https://api.github.com/users/cccs-dm/gists{/gist_id}","starred_url":"https://api.github.com/users/cccs-dm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cccs-dm/subscriptions","organizations_url":"https://api.github.com/users/cccs-dm/orgs","repos_url":"https://api.github.com/users/cccs-dm/repos","events_url":"https://api.github.com/users/cccs-dm/events{/privacy}","received_events_url":"https://api.github.com/users/cccs-dm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T16:18:55Z","updated_at":"2020-10-16T16:18:55Z","author_association":"NONE","body":"Sure thing! Thanks for fixing it so quickly.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/710165280/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/710221106","html_url":"https://github.com/apache/iceberg/pull/1608#issuecomment-710221106","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1608","id":710221106,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMDIyMTEwNg==","user":{"login":"rymurr","id":2022305,"node_id":"MDQ6VXNlcjIwMjIzMDU=","avatar_url":"https://avatars.githubusercontent.com/u/2022305?v=4","gravatar_id":"","url":"https://api.github.com/users/rymurr","html_url":"https://github.com/rymurr","followers_url":"https://api.github.com/users/rymurr/followers","following_url":"https://api.github.com/users/rymurr/following{/other_user}","gists_url":"https://api.github.com/users/rymurr/gists{/gist_id}","starred_url":"https://api.github.com/users/rymurr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymurr/subscriptions","organizations_url":"https://api.github.com/users/rymurr/orgs","repos_url":"https://api.github.com/users/rymurr/repos","events_url":"https://api.github.com/users/rymurr/events{/privacy}","received_events_url":"https://api.github.com/users/rymurr/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T16:57:11Z","updated_at":"2020-10-16T16:57:11Z","author_association":"CONTRIBUTOR","body":"Hey @jackye1995 this is pretty exciting. Please cc me when the other PRs are submitted. Especially interested in the dynamo stuff and if there are any synergies w/ Nessie","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/710221106/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/710225570","html_url":"https://github.com/apache/iceberg/pull/1620#issuecomment-710225570","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1620","id":710225570,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMDIyNTU3MA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T17:00:12Z","updated_at":"2020-10-16T17:00:12Z","author_association":"CONTRIBUTOR","body":"Thanks for looking into the problem, @pvary! I know these are hard to track down so I really appreciate you taking the time.\r\n\r\nWhile I'd like to avoid increasing the number of threads for tests that we control, I'm going to merge this to fix the tests. We can follow up to decrease the number of threads for the HMS tests.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/710225570/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/710292514","html_url":"https://github.com/apache/iceberg/pull/1616#issuecomment-710292514","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1616","id":710292514,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMDI5MjUxNA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T17:40:23Z","updated_at":"2020-10-16T17:40:23Z","author_association":"MEMBER","body":"@rdblue All cleaned up with the Dyn utility class. If this is the route you want to go let's merge it and I'll rebase the Create PR","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/710292514/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/710557961","html_url":"https://github.com/apache/iceberg/pull/1616#issuecomment-710557961","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1616","id":710557961,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMDU1Nzk2MQ==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-16T20:20:29Z","updated_at":"2020-10-16T20:20:29Z","author_association":"CONTRIBUTOR","body":"I am not a big fun of reflection but this does make the change smaller so seems reasonable.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/710557961/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711412980","html_url":"https://github.com/apache/iceberg/pull/1625#issuecomment-711412980","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1625","id":711412980,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMTQxMjk4MA==","user":{"login":"stevenzwu","id":1545663,"node_id":"MDQ6VXNlcjE1NDU2NjM=","avatar_url":"https://avatars.githubusercontent.com/u/1545663?v=4","gravatar_id":"","url":"https://api.github.com/users/stevenzwu","html_url":"https://github.com/stevenzwu","followers_url":"https://api.github.com/users/stevenzwu/followers","following_url":"https://api.github.com/users/stevenzwu/following{/other_user}","gists_url":"https://api.github.com/users/stevenzwu/gists{/gist_id}","starred_url":"https://api.github.com/users/stevenzwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stevenzwu/subscriptions","organizations_url":"https://api.github.com/users/stevenzwu/orgs","repos_url":"https://api.github.com/users/stevenzwu/repos","events_url":"https://api.github.com/users/stevenzwu/events{/privacy}","received_events_url":"https://api.github.com/users/stevenzwu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-18T19:51:55Z","updated_at":"2020-10-18T19:51:55Z","author_association":"CONTRIBUTOR","body":"@JingsongLi @openinx can you help take a look at this small refactoring?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711412980/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711472831","html_url":"https://github.com/apache/iceberg/pull/1625#issuecomment-711472831","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1625","id":711472831,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMTQ3MjgzMQ==","user":{"login":"JingsongLi","id":9601882,"node_id":"MDQ6VXNlcjk2MDE4ODI=","avatar_url":"https://avatars.githubusercontent.com/u/9601882?v=4","gravatar_id":"","url":"https://api.github.com/users/JingsongLi","html_url":"https://github.com/JingsongLi","followers_url":"https://api.github.com/users/JingsongLi/followers","following_url":"https://api.github.com/users/JingsongLi/following{/other_user}","gists_url":"https://api.github.com/users/JingsongLi/gists{/gist_id}","starred_url":"https://api.github.com/users/JingsongLi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JingsongLi/subscriptions","organizations_url":"https://api.github.com/users/JingsongLi/orgs","repos_url":"https://api.github.com/users/JingsongLi/repos","events_url":"https://api.github.com/users/JingsongLi/events{/privacy}","received_events_url":"https://api.github.com/users/JingsongLi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T02:20:35Z","updated_at":"2020-10-19T02:20:35Z","author_association":"CONTRIBUTOR","body":"Why move to `RowDataIter`? If we have `BatchDataIterator`, it may need to rely on this `convertConstant`.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711472831/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711490862","html_url":"https://github.com/apache/iceberg/pull/1625#issuecomment-711490862","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1625","id":711490862,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMTQ5MDg2Mg==","user":{"login":"stevenzwu","id":1545663,"node_id":"MDQ6VXNlcjE1NDU2NjM=","avatar_url":"https://avatars.githubusercontent.com/u/1545663?v=4","gravatar_id":"","url":"https://api.github.com/users/stevenzwu","html_url":"https://github.com/stevenzwu","followers_url":"https://api.github.com/users/stevenzwu/followers","following_url":"https://api.github.com/users/stevenzwu/following{/other_user}","gists_url":"https://api.github.com/users/stevenzwu/gists{/gist_id}","starred_url":"https://api.github.com/users/stevenzwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stevenzwu/subscriptions","organizations_url":"https://api.github.com/users/stevenzwu/orgs","repos_url":"https://api.github.com/users/stevenzwu/repos","events_url":"https://api.github.com/users/stevenzwu/events{/privacy}","received_events_url":"https://api.github.com/users/stevenzwu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T03:29:08Z","updated_at":"2020-10-19T03:29:56Z","author_association":"CONTRIBUTOR","body":"@JingsongLi `DataIterator<T>` is for generic type T, which could be an Avro GenericRecord or sth else. Currently, `convertConstant` method deals with Flink data types used by `RowData`  (like DecimalData, StringData, TimestampData etc.).  Hence, I was thinking `RowDataIterator` is the right home for it. If there is a new `BatchDataIterator` impl for a different type `T`, I would imagine that we may need a diff impl of `convertConstant `.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711490862/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711494157","html_url":"https://github.com/apache/iceberg/pull/1623#issuecomment-711494157","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1623","id":711494157,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMTQ5NDE1Nw==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T03:42:01Z","updated_at":"2020-10-19T03:42:01Z","author_association":"MEMBER","body":"Thanks @zhangjun0x01 and @simonsssu  for the work ,  I will take a look today. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711494157/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711494281","html_url":"https://github.com/apache/iceberg/pull/1625#issuecomment-711494281","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1625","id":711494281,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMTQ5NDI4MQ==","user":{"login":"JingsongLi","id":9601882,"node_id":"MDQ6VXNlcjk2MDE4ODI=","avatar_url":"https://avatars.githubusercontent.com/u/9601882?v=4","gravatar_id":"","url":"https://api.github.com/users/JingsongLi","html_url":"https://github.com/JingsongLi","followers_url":"https://api.github.com/users/JingsongLi/followers","following_url":"https://api.github.com/users/JingsongLi/following{/other_user}","gists_url":"https://api.github.com/users/JingsongLi/gists{/gist_id}","starred_url":"https://api.github.com/users/JingsongLi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JingsongLi/subscriptions","organizations_url":"https://api.github.com/users/JingsongLi/orgs","repos_url":"https://api.github.com/users/JingsongLi/repos","events_url":"https://api.github.com/users/JingsongLi/events{/privacy}","received_events_url":"https://api.github.com/users/JingsongLi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T03:42:29Z","updated_at":"2020-10-19T03:42:29Z","author_association":"CONTRIBUTOR","body":"I see, My previous idea is that it is within the scope of `RowData`. For example, for Spark, `ColumnarBatch` also follows the interface of `InternalRow`. But I am OK to make it more generic.\r\n\r\nCan you move this `convertConstant` to a new util class, like `org.apache.iceberg.flink.data.RowDataUtils`?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711494281/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711506424","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-711506424","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":711506424,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMTUwNjQyNA==","user":{"login":"edwinchoi","id":773193,"node_id":"MDQ6VXNlcjc3MzE5Mw==","avatar_url":"https://avatars.githubusercontent.com/u/773193?v=4","gravatar_id":"","url":"https://api.github.com/users/edwinchoi","html_url":"https://github.com/edwinchoi","followers_url":"https://api.github.com/users/edwinchoi/followers","following_url":"https://api.github.com/users/edwinchoi/following{/other_user}","gists_url":"https://api.github.com/users/edwinchoi/gists{/gist_id}","starred_url":"https://api.github.com/users/edwinchoi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/edwinchoi/subscriptions","organizations_url":"https://api.github.com/users/edwinchoi/orgs","repos_url":"https://api.github.com/users/edwinchoi/repos","events_url":"https://api.github.com/users/edwinchoi/events{/privacy}","received_events_url":"https://api.github.com/users/edwinchoi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T04:04:53Z","updated_at":"2020-10-19T04:05:37Z","author_association":"NONE","body":"> Also, from what I see, the metadata timestamp is always the same as the snapshot timestamp when the metadata is written for a new snapshot.\r\n\r\nIf you use Spark 3's catalog API, you'll see that the snapshot timestamp and the metadata are _not guaranteed_ to have the same time . You can trace the call from `SparkCatalog.stageCreateOrReplace`. RTAS applies the changes in a transaction, which uses independent calls to `System.currentTimeMillis()` for the two timestamps.\r\n\r\nTry adding tests to `TestCreateTableAsSelect` that do CTAS/RTAS, and you'll see that the timestamps are not the same.\r\n\r\nAlso, after giving this some more thought, you can't rely on a partial ordering between the snapshot and metadata update timestamps. `System.currentTimeMillis()` is not monotonic - clock adjustments via NTP can cause two consecutive readings to go back in time. The only safe option then is to scan the metadata files to find the file where the current-snapshot-id matches the target snapshot-id.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711506424/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711652322","html_url":"https://github.com/apache/iceberg/pull/1625#issuecomment-711652322","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1625","id":711652322,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMTY1MjMyMg==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T06:30:40Z","updated_at":"2020-10-19T06:30:40Z","author_association":"MEMBER","body":"> @JingsongLi DataIterator<T> is for generic type T, which could be an Avro GenericRecord or sth else. \r\n\r\nI guess you are implementing the native avro reader for flink ?  It's right that moving this RowData specific convertion out of `DataIteraotr<T>`.    For me, moving to `RowDataUtils` or `RowDataIterator` , both work for me.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711652322/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711696891","html_url":"https://github.com/apache/iceberg/issues/1626#issuecomment-711696891","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1626","id":711696891,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMTY5Njg5MQ==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T06:53:53Z","updated_at":"2020-10-19T06:53:53Z","author_association":"MEMBER","body":"Looking forward to the draft PR or Poc patch, Thanks for the work @stevenzwu .","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711696891/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711757170","html_url":"https://github.com/apache/iceberg/pull/1620#issuecomment-711757170","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1620","id":711757170,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMTc1NzE3MA==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T07:30:15Z","updated_at":"2020-10-19T07:30:15Z","author_association":"CONTRIBUTOR","body":"Thanks for the merge. Create the new PR: #1629","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711757170/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711972887","html_url":"https://github.com/apache/iceberg/pull/1629#issuecomment-711972887","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1629","id":711972887,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMTk3Mjg4Nw==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T10:05:59Z","updated_at":"2020-10-19T10:05:59Z","author_association":"MEMBER","body":"I encountered the similar issue when preparing the patch [here](https://github.com/apache/iceberg/pull/1586/files#diff-5dba09acdd092bc5ab211cd7835fdf47e6b7b6ccc9918a56adb0fb648a37188bR170),  PR looks good to me, thanks for the great work.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/711972887/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/712076629","html_url":"https://github.com/apache/iceberg/pull/1623#issuecomment-712076629","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1623","id":712076629,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMjA3NjYyOQ==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T11:14:56Z","updated_at":"2020-10-19T11:14:56Z","author_association":"CONTRIBUTOR","body":"Thank you very much for the review @openinx @simonsssu , I have solved all comments","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/712076629/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/712094837","html_url":"https://github.com/apache/iceberg/issues/1630#issuecomment-712094837","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1630","id":712094837,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMjA5NDgzNw==","user":{"login":"massdosage","id":29457,"node_id":"MDQ6VXNlcjI5NDU3","avatar_url":"https://avatars.githubusercontent.com/u/29457?v=4","gravatar_id":"","url":"https://api.github.com/users/massdosage","html_url":"https://github.com/massdosage","followers_url":"https://api.github.com/users/massdosage/followers","following_url":"https://api.github.com/users/massdosage/following{/other_user}","gists_url":"https://api.github.com/users/massdosage/gists{/gist_id}","starred_url":"https://api.github.com/users/massdosage/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/massdosage/subscriptions","organizations_url":"https://api.github.com/users/massdosage/orgs","repos_url":"https://api.github.com/users/massdosage/repos","events_url":"https://api.github.com/users/massdosage/events{/privacy}","received_events_url":"https://api.github.com/users/massdosage/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T11:31:09Z","updated_at":"2020-10-19T11:31:09Z","author_association":"CONTRIBUTOR","body":"@marton-bod could you look at the above? I haven't had time to try come up with a solution but my first guess would be that we're going to need a `hive2-runtime` jar and a `hive3-runtime` jar.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/712094837/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/712099411","html_url":"https://github.com/apache/iceberg/issues/1630#issuecomment-712099411","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1630","id":712099411,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMjA5OTQxMQ==","user":{"login":"marton-bod","id":19599214,"node_id":"MDQ6VXNlcjE5NTk5MjE0","avatar_url":"https://avatars.githubusercontent.com/u/19599214?v=4","gravatar_id":"","url":"https://api.github.com/users/marton-bod","html_url":"https://github.com/marton-bod","followers_url":"https://api.github.com/users/marton-bod/followers","following_url":"https://api.github.com/users/marton-bod/following{/other_user}","gists_url":"https://api.github.com/users/marton-bod/gists{/gist_id}","starred_url":"https://api.github.com/users/marton-bod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marton-bod/subscriptions","organizations_url":"https://api.github.com/users/marton-bod/orgs","repos_url":"https://api.github.com/users/marton-bod/repos","events_url":"https://api.github.com/users/marton-bod/events{/privacy}","received_events_url":"https://api.github.com/users/marton-bod/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T11:41:21Z","updated_at":"2020-10-19T11:41:21Z","author_association":"COLLABORATOR","body":"Thanks @massdosage. I think we can avoid having to create a different runtime jar for Hive2, we'll just have to use `MetastoreUtil.hive3PresentOnClasspath()` to select the correct object inspector at runtime. I'll post a fix as soon as I can.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/712099411/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/712099812","html_url":"https://github.com/apache/iceberg/issues/1496#issuecomment-712099812","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1496","id":712099812,"node_id":"MDEyOklzc3VlQ29tbWVudDcxMjA5OTgxMg==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-10-19T11:42:11Z","updated_at":"2020-10-19T11:42:11Z","author_association":"CONTRIBUTOR","body":"Thanks @fbocse for the review!\r\n\r\n> @pvary thank you for following up on this\r\n\r\nActually @lcspinter is the one who is working on this 😄\r\n\r\n> This basically \"locks\" the table for any subsequent writers - cause new writers will find version-hint.txt and load value 18, increment that value to resolve the version they should write a new metadata file for but fail to do so since there already is a v19.metadata.json file.\r\n\r\nI think this should not be a problem as we use version-hint.txt only as a hint and in [HadoopTableOperations.refresh()](https://github.com/apache/iceberg/blob/96959ece9faeb795757388908274cfd0ff1856ca/core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java#L108-L113) we iterate through on the possible metadata locations and stop only if there is not new snapshot is available:\r\n```java\r\n      Path nextMetadataFile = getMetadataFile(ver + 1);\r\n      while (nextMetadataFile != null) {\r\n        ver += 1;\r\n        metadataFile = nextMetadataFile;\r\n        nextMetadataFile = getMetadataFile(ver + 1);\r\n      }\r\n```\r\n\r\nI hope this loop solves the dead-lock problem you mentioned above.\r\nWhat do you think?\r\n\r\nThanks,\r\nPeter\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/712099812/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]