[{"url":"https://api.github.com/repos/apache/drill/issues/comments/2220259220","html_url":"https://github.com/apache/drill/issues/2924#issuecomment-2220259220","issue_url":"https://api.github.com/repos/apache/drill/issues/2924","id":2220259220,"node_id":"IC_kwDOAFa5xc6EVneU","user":{"login":"Jeducious","id":34228929,"node_id":"MDQ6VXNlcjM0MjI4OTI5","avatar_url":"https://avatars.githubusercontent.com/u/34228929?v=4","gravatar_id":"","url":"https://api.github.com/users/Jeducious","html_url":"https://github.com/Jeducious","followers_url":"https://api.github.com/users/Jeducious/followers","following_url":"https://api.github.com/users/Jeducious/following{/other_user}","gists_url":"https://api.github.com/users/Jeducious/gists{/gist_id}","starred_url":"https://api.github.com/users/Jeducious/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Jeducious/subscriptions","organizations_url":"https://api.github.com/users/Jeducious/orgs","repos_url":"https://api.github.com/users/Jeducious/repos","events_url":"https://api.github.com/users/Jeducious/events{/privacy}","received_events_url":"https://api.github.com/users/Jeducious/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-10T11:22:54Z","updated_at":"2024-07-10T11:22:54Z","author_association":"NONE","body":"Confirmed this is fixed for me now, website now displaying properly.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2220259220/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2226369906","html_url":"https://github.com/apache/drill/pull/2925#issuecomment-2226369906","issue_url":"https://api.github.com/repos/apache/drill/issues/2925","id":2226369906,"node_id":"IC_kwDOAFa5xc6Es7Vy","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-12T21:20:48Z","updated_at":"2024-07-12T21:20:48Z","author_association":"CONTRIBUTOR","body":"Looks like Drill uses a different version of commons-io than POI needs. I'll look into it. There are NoSuchMethodErrors happening.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2226369906/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2227415938","html_url":"https://github.com/apache/drill/pull/2907#issuecomment-2227415938","issue_url":"https://api.github.com/repos/apache/drill/issues/2907","id":2227415938,"node_id":"IC_kwDOAFa5xc6Ew6uC","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-14T17:07:18Z","updated_at":"2024-07-14T17:07:18Z","author_association":"CONTRIBUTOR","body":"@jnturton Can we merge this?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2227415938/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2227577005","html_url":"https://github.com/apache/drill/pull/2657#issuecomment-2227577005","issue_url":"https://api.github.com/repos/apache/drill/issues/2657","id":2227577005,"node_id":"IC_kwDOAFa5xc6ExiCt","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-15T01:38:12Z","updated_at":"2024-07-15T01:38:12Z","author_association":"CONTRIBUTOR","body":"@jnturton \r\nCould you do a review of this.  I realized that this has been languishing and we might as well merge it if it can be.   \r\nThe one area which I'm a little hesitant about is the ScanBatchCreator.  Basically, since I didn't write this storage plugin and it was a bit more complicated than some of the ones I've written, I'd like another set of eyes on it. ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2227577005/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2227884836","html_url":"https://github.com/apache/drill/issues/2920#issuecomment-2227884836","issue_url":"https://api.github.com/repos/apache/drill/issues/2920","id":2227884836,"node_id":"IC_kwDOAFa5xc6EytMk","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-15T07:46:26Z","updated_at":"2024-07-15T07:46:26Z","author_association":"CONTRIBUTOR","body":"The [Hadoop S3A connector](https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html) is what Drill uses to access S3 so whatever is supported there is either already usable from Drill or probably not much work to incorporate.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2227884836/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2229913101","html_url":"https://github.com/apache/drill/pull/2923#issuecomment-2229913101","issue_url":"https://api.github.com/repos/apache/drill/issues/2923","id":2229913101,"node_id":"IC_kwDOAFa5xc6E6cYN","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-16T03:04:48Z","updated_at":"2024-07-16T03:04:48Z","author_association":"CONTRIBUTOR","body":"@jnturton Do you want to weigh in on this one?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2229913101/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2233125390","html_url":"https://github.com/apache/drill/issues/2914#issuecomment-2233125390","issue_url":"https://api.github.com/repos/apache/drill/issues/2914","id":2233125390,"node_id":"IC_kwDOAFa5xc6FGsoO","user":{"login":"Zakyrel","id":142769136,"node_id":"U_kgDOCIJ78A","avatar_url":"https://avatars.githubusercontent.com/u/142769136?v=4","gravatar_id":"","url":"https://api.github.com/users/Zakyrel","html_url":"https://github.com/Zakyrel","followers_url":"https://api.github.com/users/Zakyrel/followers","following_url":"https://api.github.com/users/Zakyrel/following{/other_user}","gists_url":"https://api.github.com/users/Zakyrel/gists{/gist_id}","starred_url":"https://api.github.com/users/Zakyrel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Zakyrel/subscriptions","organizations_url":"https://api.github.com/users/Zakyrel/orgs","repos_url":"https://api.github.com/users/Zakyrel/repos","events_url":"https://api.github.com/users/Zakyrel/events{/privacy}","received_events_url":"https://api.github.com/users/Zakyrel/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-17T11:49:19Z","updated_at":"2024-07-17T11:49:19Z","author_association":"NONE","body":"Hello,\r\n\r\nKind reminder about this issue.\r\n\r\nRegards,","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2233125390/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2235261612","html_url":"https://github.com/apache/drill/pull/2923#issuecomment-2235261612","issue_url":"https://api.github.com/repos/apache/drill/issues/2923","id":2235261612,"node_id":"IC_kwDOAFa5xc6FO2Ks","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-18T03:46:10Z","updated_at":"2024-07-18T03:46:10Z","author_association":"CONTRIBUTOR","body":"@rymarm Would you mind please creating a JIRA issue for this?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2235261612/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2236471316","html_url":"https://github.com/apache/drill/pull/2923#issuecomment-2236471316","issue_url":"https://api.github.com/repos/apache/drill/issues/2923","id":2236471316,"node_id":"IC_kwDOAFa5xc6FTdgU","user":{"login":"rymarm","id":62295633,"node_id":"MDQ6VXNlcjYyMjk1NjMz","avatar_url":"https://avatars.githubusercontent.com/u/62295633?v=4","gravatar_id":"","url":"https://api.github.com/users/rymarm","html_url":"https://github.com/rymarm","followers_url":"https://api.github.com/users/rymarm/followers","following_url":"https://api.github.com/users/rymarm/following{/other_user}","gists_url":"https://api.github.com/users/rymarm/gists{/gist_id}","starred_url":"https://api.github.com/users/rymarm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymarm/subscriptions","organizations_url":"https://api.github.com/users/rymarm/orgs","repos_url":"https://api.github.com/users/rymarm/repos","events_url":"https://api.github.com/users/rymarm/events{/privacy}","received_events_url":"https://api.github.com/users/rymarm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-18T13:14:04Z","updated_at":"2024-07-18T13:14:04Z","author_association":"MEMBER","body":"@cgivre yes, sure. I've updated the PR with Jira ticket information. ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2236471316/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2239541054","html_url":"https://github.com/apache/drill/pull/2926#issuecomment-2239541054","issue_url":"https://api.github.com/repos/apache/drill/issues/2926","id":2239541054,"node_id":"IC_kwDOAFa5xc6FfK8-","user":{"login":"bdemers","id":99954,"node_id":"MDQ6VXNlcjk5OTU0","avatar_url":"https://avatars.githubusercontent.com/u/99954?v=4","gravatar_id":"","url":"https://api.github.com/users/bdemers","html_url":"https://github.com/bdemers","followers_url":"https://api.github.com/users/bdemers/followers","following_url":"https://api.github.com/users/bdemers/following{/other_user}","gists_url":"https://api.github.com/users/bdemers/gists{/gist_id}","starred_url":"https://api.github.com/users/bdemers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bdemers/subscriptions","organizations_url":"https://api.github.com/users/bdemers/orgs","repos_url":"https://api.github.com/users/bdemers/repos","events_url":"https://api.github.com/users/bdemers/events{/privacy}","received_events_url":"https://api.github.com/users/bdemers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-19T16:19:14Z","updated_at":"2024-07-19T16:19:14Z","author_association":"MEMBER","body":"I wasn't able to run the tests locally, (they just hung before getting to the fmpp module)\r\nAssuming CI passes, and this is a valid change, I can create an issue","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2239541054/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2247779267","html_url":"https://github.com/apache/drill/pull/2926#issuecomment-2247779267","issue_url":"https://api.github.com/repos/apache/drill/issues/2926","id":2247779267,"node_id":"IC_kwDOAFa5xc6F-mPD","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-24T12:23:55Z","updated_at":"2024-07-24T12:23:55Z","author_association":"CONTRIBUTOR","body":"@bdemers It looks like CI has passed.  Could you please create an issue and we will merge this.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2247779267/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":1,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2248034243","html_url":"https://github.com/apache/drill/pull/2926#issuecomment-2248034243","issue_url":"https://api.github.com/repos/apache/drill/issues/2926","id":2248034243,"node_id":"IC_kwDOAFa5xc6F_kfD","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-24T13:57:26Z","updated_at":"2024-07-24T13:57:26Z","author_association":"CONTRIBUTOR","body":"> @bdemers It looks like CI has passed. Could you please create an issue and we will merge this.\r\n\r\nSorry... I should have been more clear.   I meant a JIRA issue, but don't bother.. This is a minor update. ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2248034243/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2248307027","html_url":"https://github.com/apache/drill/pull/2923#issuecomment-2248307027","issue_url":"https://api.github.com/repos/apache/drill/issues/2923","id":2248307027,"node_id":"IC_kwDOAFa5xc6GAnFT","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-24T15:28:40Z","updated_at":"2024-07-24T15:28:40Z","author_association":"CONTRIBUTOR","body":"Sorry I missed this at the time. Thanks for the cleanup.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2248307027/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2257393168","html_url":"https://github.com/apache/drill/issues/2919#issuecomment-2257393168","issue_url":"https://api.github.com/repos/apache/drill/issues/2919","id":2257393168,"node_id":"IC_kwDOAFa5xc6GjRYQ","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-07-30T03:36:57Z","updated_at":"2024-07-30T03:36:57Z","author_association":"NONE","body":"‚è≥ ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2257393168/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2264807502","html_url":"https://github.com/apache/drill/issues/2919#issuecomment-2264807502","issue_url":"https://api.github.com/repos/apache/drill/issues/2919","id":2264807502,"node_id":"IC_kwDOAFa5xc6G_jhO","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-02T08:03:06Z","updated_at":"2024-08-02T08:03:06Z","author_association":"CONTRIBUTOR","body":"Container images updated.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2264807502/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2288593491","html_url":"https://github.com/apache/drill/issues/2914#issuecomment-2288593491","issue_url":"https://api.github.com/repos/apache/drill/issues/2914","id":2288593491,"node_id":"IC_kwDOAFa5xc6IaSpT","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-14T12:19:35Z","updated_at":"2024-08-14T12:19:35Z","author_association":"CONTRIBUTOR","body":"Can you share the SQL that Drill tries to execute? It should be written to the Drill logs...","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2288593491/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2308941784","html_url":"https://github.com/apache/drill/pull/2935#issuecomment-2308941784","issue_url":"https://api.github.com/repos/apache/drill/issues/2935","id":2308941784,"node_id":"IC_kwDOAFa5xc6Jn6fY","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-25T17:58:22Z","updated_at":"2024-08-25T17:58:22Z","author_association":"CONTRIBUTOR","body":"Unless anyone has any objections, I'm going to merge this.  It seems that whatever was going wrong with the CI has magically fixed itself.  Although some unrelated Hive tests are failing due to connections being dropped, but only for Hadoop 2.... \r\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2308941784/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2308957085","html_url":"https://github.com/apache/drill/pull/2929#issuecomment-2308957085","issue_url":"https://api.github.com/repos/apache/drill/issues/2929","id":2308957085,"node_id":"IC_kwDOAFa5xc6Jn-Od","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-25T18:54:02Z","updated_at":"2024-08-25T18:54:02Z","author_association":"CONTRIBUTOR","body":"@jnturton It looks like the GitHub CI is failing on the Hadoop 2 tests with Hive. ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2308957085/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2312583394","html_url":"https://github.com/apache/drill/issues/2936#issuecomment-2312583394","issue_url":"https://api.github.com/repos/apache/drill/issues/2936","id":2312583394,"node_id":"IC_kwDOAFa5xc6J1zji","user":{"login":"egasimov","id":58927497,"node_id":"MDQ6VXNlcjU4OTI3NDk3","avatar_url":"https://avatars.githubusercontent.com/u/58927497?v=4","gravatar_id":"","url":"https://api.github.com/users/egasimov","html_url":"https://github.com/egasimov","followers_url":"https://api.github.com/users/egasimov/followers","following_url":"https://api.github.com/users/egasimov/following{/other_user}","gists_url":"https://api.github.com/users/egasimov/gists{/gist_id}","starred_url":"https://api.github.com/users/egasimov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/egasimov/subscriptions","organizations_url":"https://api.github.com/users/egasimov/orgs","repos_url":"https://api.github.com/users/egasimov/repos","events_url":"https://api.github.com/users/egasimov/events{/privacy}","received_events_url":"https://api.github.com/users/egasimov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-27T13:35:00Z","updated_at":"2024-08-27T13:35:00Z","author_association":"NONE","body":"After analyzing the source code for the UNNEST operator, we have observed the following pattern need to be used with  the UNNEST operator.\r\n\r\n\r\n```\r\n{\r\n    \"queryType\": \"SQL\",\r\n    \"query\": \"SELECT d.customer_id, d.purchased_items  FROM dfs.root.`/datas3/customers/*` d WHERE EXISTS ( SELECT 1 FROM UNNEST(d.purchased_items) t2(ord) WHERE  t2.ord.item_id in (2000001))\"\r\n}\r\n\r\n``` ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2312583394/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2312595981","html_url":"https://github.com/apache/drill/issues/2936#issuecomment-2312595981","issue_url":"https://api.github.com/repos/apache/drill/issues/2936","id":2312595981,"node_id":"IC_kwDOAFa5xc6J12oN","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-27T13:40:01Z","updated_at":"2024-08-27T13:40:01Z","author_association":"CONTRIBUTOR","body":"@egasimov You beat me to it, but I don't think `UNNEST` is the operator you want.  `UNNEST` performs a LATERAL JOIN automatically, even when not specified.  I think `FLATTEN` is probably the operator you want to use.  \r\n\r\nAlso, I'd recommend NOT using dot notation to reference inner fields in maps.  IE:\r\n\r\nDon't use \r\n\r\n```\r\nSELECT s.id\r\n```\r\n\r\nInstead use \r\n\r\n```sql\r\nSELECT s['id']\r\n```\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2312595981/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2312770836","html_url":"https://github.com/apache/drill/issues/2936#issuecomment-2312770836","issue_url":"https://api.github.com/repos/apache/drill/issues/2936","id":2312770836,"node_id":"IC_kwDOAFa5xc6J2hUU","user":{"login":"egasimov","id":58927497,"node_id":"MDQ6VXNlcjU4OTI3NDk3","avatar_url":"https://avatars.githubusercontent.com/u/58927497?v=4","gravatar_id":"","url":"https://api.github.com/users/egasimov","html_url":"https://github.com/egasimov","followers_url":"https://api.github.com/users/egasimov/followers","following_url":"https://api.github.com/users/egasimov/following{/other_user}","gists_url":"https://api.github.com/users/egasimov/gists{/gist_id}","starred_url":"https://api.github.com/users/egasimov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/egasimov/subscriptions","organizations_url":"https://api.github.com/users/egasimov/orgs","repos_url":"https://api.github.com/users/egasimov/repos","events_url":"https://api.github.com/users/egasimov/events{/privacy}","received_events_url":"https://api.github.com/users/egasimov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-27T14:45:07Z","updated_at":"2024-08-27T14:45:07Z","author_association":"NONE","body":"Hey @cgivre , Thank you for response. I have really appreciated it.\r\n\r\nRequirement for the SQL query is to check and filter the those rows whose nested array field(_purchased_items_) have at least one of the values provided in the IN clause and return the original rows(without duplicating the entries).\r\n\r\nWhen **FLATTEN** used in the query, after the filter operations, we will again need to **GROUP BY** or **DISTINCT** to remove duplicate rows form result.\r\n\r\nWdyt, Is there any other way to accomplish the same goal but in optimized way ? :thinking:","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2312770836/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2317456893","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2317456893","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2317456893,"node_id":"IC_kwDOAFa5xc6KIZX9","user":{"login":"rymarm","id":62295633,"node_id":"MDQ6VXNlcjYyMjk1NjMz","avatar_url":"https://avatars.githubusercontent.com/u/62295633?v=4","gravatar_id":"","url":"https://api.github.com/users/rymarm","html_url":"https://github.com/rymarm","followers_url":"https://api.github.com/users/rymarm/followers","following_url":"https://api.github.com/users/rymarm/following{/other_user}","gists_url":"https://api.github.com/users/rymarm/gists{/gist_id}","starred_url":"https://api.github.com/users/rymarm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymarm/subscriptions","organizations_url":"https://api.github.com/users/rymarm/orgs","repos_url":"https://api.github.com/users/rymarm/repos","events_url":"https://api.github.com/users/rymarm/events{/privacy}","received_events_url":"https://api.github.com/users/rymarm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-29T12:04:34Z","updated_at":"2024-08-29T12:04:34Z","author_association":"MEMBER","body":"@jnturton @paul-rogers could you please take a look? \r\n\r\nDrill has a hidden issue caused by the following change:\r\nhttps://github.com/apache/drill/pull/909/files#diff-437f42bceabae9bccd3ff19064898dc0d03df3dd40fcdbe5051c9fcced433c94R245-R247\r\n\r\nThis change caused a little-noticeable problem, that makes `ParquetSchema#createMissingColumn` to create a \"dummy\" column but with backticks in the name of the column:\r\n```\r\nError: UNSUPPORTED_OPERATION ERROR: Schema changes not supported in External Sort. Please enable Union type.\r\nPrevious schema: BatchSchema [fields=[[`age` (INT:OPTIONAL)]], selectionVector=NONE]\r\nIncoming schema: BatchSchema [fields=[[`age` (INT:OPTIONAL)], [``age`` (INT:OPTIONAL)]], selectionVector=NONE]\r\n```\r\n\r\nThis change was definitely made intentionally, but the purpose of the change is not clear to me. @ychernysh and I think this change needs to be reverted, but maybe we missed something.\r\n\r\nAt this moment some of deltalake test fails due to this change, but before we move on, we would like to know, whether it's a good idea to keep using `col.getAsUnescapedPath()` instead of `col.toExpr()`","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2317456893/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2318972159","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2318972159","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2318972159,"node_id":"IC_kwDOAFa5xc6KOLT_","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-29T20:54:34Z","updated_at":"2024-08-29T20:54:34Z","author_association":"CONTRIBUTOR","body":"@rymarm, thanks for this fix. I'm a bit rusty on Drill, but let's see what I can sort out. This stuff is complex, so I'm going to throw a wall of text at you so we get on the same page.\r\n\r\nFirst some background. If memory serves, the Parquet reader was written quickly by an intern early on: it is so complex that few have summoned the effort to understand or improve it. So, digging into it is a classic \"legacy code\" experience.\r\n\r\nIn the early days, every single format reader created its own way to write data to vectors. This lead to all manner of bugs (getting the code right once is hard, doing it a dozen times is impossible). It also resulted in inconsistent behavior. To solve these (and to avoid Drill's memory fragmentation issues of the time), we created EVF (extended vector framework) to unify how we write to vectors and how we solve schema consistency issues for readers. EVF replaced the older column writer mechanisms. By now, all Drill readers _except Parquet_ are based on EVF.\r\n\r\nHowever, the Parquet reader is special: it is the only one that still uses the original, fragile mechanisms. As the story goes, Parquet was written very quickly by an intern, and the result was so complex that few people have been brave enough to try to sort out the code. Since Parquet still uses the old mechanisms, it has its own way to solve schema issues, its own way to handle unprojected columns, and still suffers from the bugs in the original, fragile mechanisms. It looks like your PR tries to fix some of these. In particular, it may be that that you're trying to fix a bug in Parquet that EVF solves for other readers. It would be great if your fix is consistent with EVF. I'll try to check this when I review the code.\r\n\r\nWhat we really need is for someone to take on a \"weekend project\" to rewrite the Parquet reader to use EVF so we have one complete schema mechanism rather than two inconsistent versions. (I can dream.)\r\n\r\nNow let's look at the bug in question. You received a schema change error. This means that some operator in the DAG saw two different schemas for the same table. In particular, the SORT operator can't handle the case of, say, `(a: INT, b: VARCHAR, c: double)` and `(a: INT, b: VARCHAR)` or` (a: INT: b: INT)`, even if our query only has `...ORDER BY a`. There was discussion about using `UNION` columns, or dynamically reformatting data. But, all of that was far too complex (and slow) to actually build. \r\n\r\nMost DB and query tools impose a schema at read time. That is, if we have files that have undergone schema evolution, as above, we work out at plan time that the common schema is, say `(a: INT, b: VARCHAR, c: DOUBLE)`, with `c` being `OPTIONAL` (`NULLABLE` in standard DB parlance) since it appears in only some of the files. For example, Presto and Impala avoid the issue by reading into the correct common schema in the first place, rather than cleaning up the mess later in each downstream operator.\r\n\r\nOf course, Drill's claim to fame is that it is schema-free: it works out the schema on the fly. That's all cool, except that Drill also supports operators that only work for a single schema. (Joins have the same issue.) That is, we promote a really cool feature, but we can't actually make it work. This is great marketing, but causes frustration in reality.\r\n\r\nAnd, as befits any bit of  software that has a few miles on its tires, Drill has multiple ways to work around the schema issue. There is a \"provided schema\" feature that tells readers the common schema. The reader's job is then to map the actual file columns into that schema. The provided schema is supported in EVF, but not, alas, by the Parquet reader. Also, the planner never got around to supporting schemas, so provided schemas only work in rather special cases. There is also a Drill Metastore feature that emulates the Hive Metastore (HMS), but be in common use.\r\n\r\nThe original way to manage schemas, for Parquet only, is to scan all the files and build up a JSON file that contains the union of all the schemas. I can't recall if this mechanism was supposed to provide type consistency, but it certainly could: we just look at the `c` column in all schemas of all Parquet files in a directory tree and work out a common type. We do this at plan time and send that type along to Parquet in the physical plan. I didn't work in that area, so my knowledge here is a bit light. It's worth a check.\r\n\r\nNow, one might say, hold on, isn't there an easy answer? If we read file A and get one schema, then read file B and get another schema, can't we blend them on the fly? Indeed, in some cases this is possible, and EVF implements those cases. However as I'm fond of saying, \"Drill can't predict the future\", so there are cases where we get it wrong. For example, the query asks for columns `(a, b, c)`. The first file has `(a, b)` and creates a dummy column for `c` that will hold all `NULL`s. But, of what type? Drill traditionally chooses `INT`. Then, we read file 2 that has `(a, b, c: VARCHAR)`. Now we realize that `c` should have been `VARCHAR`, but we've sent a batch of rows downstream already with the \"wrong\" `INT` type. \r\n\r\nPlus, remember, Drill is distributed. Those two files might have been read by different fragments running on different machines. They can't communicate until the rows come together in the sort, after which it is too late to fix the problem.\r\n\r\nOne other tricky item to remember: Drill is fastest when columns are `REQUIRED` (i.e. non-nullable or `NOT NULL`). This avoids the `NULL` check on each column operation. **BUT**, Drill also allows schema to vary, and we fill in missing columns with `NULL` values. So, unless we have some guarantee that column `c` actually exists in all files read by a query, we are pretty much forced to make `c` be `OPTIONAL` (nullable), even when reading a file that contains `c` as a `NOT NULL` column. Again, Drill can't predict the future, so we can't know that some future file (in, perhaps, some other fragment on some other machine) will read a file that doesn't have `c`.\r\n\r\nThere is a reason that SQL DBs, for 50+ years, have required a schema. It isn't that all those folks were backward, it is that SQL doesn't work without a common schema. (Apache Druid has a similar problem, but it solves it by treating all values as, essentially, untyped: the values change type on the fly as needed.) When faced with bugs of the kind here, it is important to sort out which are just \"bad code\" bugs and which are the \"this design just can't work\" bugs.\r\n\r\nNow, with that background, we can try to sort out the problem you are trying to solve. Does your test case have Parquet files with differing column sets or types? If so, let's identify exactly how the schemas differ, then we can discuss possible solutions.\r\n\r\nLooking at the specific line you pointed out, I'll hazard a guess as to what it is doing: that case we discussed above. Suppose our SQL is `SELECT a, b FROM 'my-dir'`. Suppose `my-dir` is a directory that contains two files. `file1.parquet` contains column `(a: VARCHAR)` and `file2.parquet` contains `(a: VARCHAR, b: VARCHAR)`. Both are read by the same reader (the scan is not distributed in this case.) File read order is random. Suppose we read them in the order `(file2, file1)`. We can set up a schema of `(a: VARCHAR, b: VARCHAR)`. When we read `file1`, we notice that 'b' is missing, but that, when it appeared previously, it was `VARCHAR`, so we keep that type and fill with nulls. (This is what EVF does, I'll speculate that Parquet's reader does something similar.) Great. What if we read the other order? We see we want `(a, b)`, but we have only` (a: VARCHAR)`, so we create that vector. What about `b`? Well, we helpfully create `(b: OPTIONAL INT)`. That is exactly what the code that you pointed to does. When we read `file2`, we see that `b` has \"changed schema\" to `VARCHAR` so we throw away the `(a: VARCHAR, b: INT)` schema and start reading with `(a: VARCHAR, b: VARCHAR)`. This then blows up the SORT.\r\n\r\nGiven this, I don't think the problem is with the column name (which is what that referenced code change handles). The code change in question allowed handling a column name of the form `foo.a` where `foo` is not a MAP, with `a` as a member, but just a (poorly chosen) name of a column. That is, the problem is probably not that the test Parquet file columns are actually named `foo.a` and `foo.b` (with dots). You can try changing the code and rerunning the test, but I suspect that the problem won't go away unless you happen to run a test that reverses the file read order.\r\n\r\nInstead, the problem may be with the part of that code that did not change: Drill is trying to predict the future and predicting that when the missing column appears, it will be `INT`. It may be that Drill is predicting incorrectly. We need to use the \"crystal ball\" module to improve the prediction. Sadly, however, we never got around to writing that module. Hence the multiple attempts to manage schemas globally.\r\n\r\nWhere does this leave us? If you can pin things down to one very specific case, we can sort out if it is a \"bad code\" bug or a \"that just won't work given Drill's design\" bug. In particular, reading Parquet files with inconsistent schemas, projecting the inconsistent columns, and adding a SORT won't work unless the missing columns will be of type `INT` when they appear. You can get lucky with file read order and work distribution so that, sometimes, it does work. Relying on luck produces flaky tests, however.\r\n\r\nOn the other hand, you can have as much inconsistency as you want as long as the columns you project appear in all files and the type of those columns stays the same. Feel free to add as many other, inconsistent, columns as you like: just don't project them in queries with a SORT.\r\n\r\nI'd suggest that, since Drill doesn't handle Parquet schema changes well (though that is Drill's compelling feature), we maybe should not test stuff that can't actually work. Test with files with a consistent schema instead. Or, if files have an inconsistent schema, test with the Parquet schema feature enabled and after doing a scan of all the files. (I forget the command: `ANALYZE` maybe?) It _may_ be that the Parquet schema feature unifies column types, but then, given the haste with which it was written way back when, maybe it doesn't. Or, to be more modern, test with the Drill Metastore enabled.\r\n\r\nThis stuff is horribly complex, and I may have missed the mark on this particular bug. But, at least we're now on the same page.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2318972159/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2320908961","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2320908961","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2320908961,"node_id":"IC_kwDOAFa5xc6KVkKh","user":{"login":"ychernysh","id":101880553,"node_id":"U_kgDOBhKS6Q","avatar_url":"https://avatars.githubusercontent.com/u/101880553?v=4","gravatar_id":"","url":"https://api.github.com/users/ychernysh","html_url":"https://github.com/ychernysh","followers_url":"https://api.github.com/users/ychernysh/followers","following_url":"https://api.github.com/users/ychernysh/following{/other_user}","gists_url":"https://api.github.com/users/ychernysh/gists{/gist_id}","starred_url":"https://api.github.com/users/ychernysh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ychernysh/subscriptions","organizations_url":"https://api.github.com/users/ychernysh/orgs","repos_url":"https://api.github.com/users/ychernysh/repos","events_url":"https://api.github.com/users/ychernysh/events{/privacy}","received_events_url":"https://api.github.com/users/ychernysh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-30T11:21:48Z","updated_at":"2024-08-30T11:21:48Z","author_association":"NONE","body":"Hi @paul-rogers ,\r\nThanks for your comments! Let me clarify some points here:\r\n> Given this, I don't think the problem is with the column name (which is what that referenced code change handles).\r\n\r\nThe thing is that regardless of whether we did or did not succeed with \"guessing\" the major type for the missing column, the solution won't work until we solve the backticks problem, because essentially instead of creating _the missing column_ (unquoted), we currently create _a brand new column_ (quoted) which has nothing to do with the \"real\" missing one. Please see my `ORDER BY` example in [DRILL-8507](https://issues.apache.org/jira/browse/DRILL-8507) and the error from there:\r\n```\r\nError: UNSUPPORTED_OPERATION ERROR: Schema changes not supported in External Sort. Please enable Union type.\r\nPrevious schema: BatchSchema [fields=[[`age` (INT:OPTIONAL)]], selectionVector=NONE]\r\nIncoming schema: BatchSchema [fields=[[`age` (INT:OPTIONAL)], [``age`` (INT:OPTIONAL)]], selectionVector=NONE]\r\n```\r\nNote that all the major types here are guessed correctly (`INT:OPTIONAL`), but we fail because of different field counts. This happens because in the incoming schema we have 2 fields: quoted and unquoted, while it is supposed to have only one (unquoted, based on previous schema).\r\nThis is the reason I reported the issue as 2 separate jiras and divided the PR into separate commits.\r\nSo before proceeding to any type guessing logic, we have to get rid of the quoting problem first.\r\n> Also, note that this fix works ONLY in one direction (column appears, then disappears), and ONLY within a single thread: it can't solve the same problem if the two files are read in different threads and sent to the SORT to reconcile.\r\n\r\nThanks to [AbstractParquetRowGroupScan's schema](https://github.com/apache/drill/blob/5a3b1785c119a5e3986b6cb269a48ba76db94a3b/exec/java-exec/src/main/java/org/apache/drill/exec/store/parquet/AbstractParquetRowGroupScan.java#L46), which this (DRILL-8508) solution is based on, all readers in all fragments on all machines are aware about the overall (constructed from all parquet files to read) table schema. Foreman scans the footers of all the files and merges a single schema from them back in the planning phase and then sends it to each fragment. This is exactly what gives us the opportunity to \"see the future\" at reading phase, because all the metadata (even for future files) is already available and merged into a single schema. \r\nWith that, we are not just _propagating the old column type_, but we are propagating _the certainly correct_ column type. And we **are sure** the type is correct because it was resolved back in the planner.\r\nSo, in fact, the fix works in ALL directions and within ALL threads and machines.\r\n\r\n> Further, we are changing the mode to OPTIONAL as required so we can fill the vector with NULL values. However, change of mode (i.e. nullability) is a schema change and will cause the SORT to fail. We have to have known, on the previous file, that the column will be missing in this file, so that we can create the original column as OPTIONAL.\r\n\r\nExactly, and that is why I added this _enforcing OPTIONAL_ logic. That is, even if the particular parquet reader is going to read REQUIRED parquet column, we enforce it to put it in NULLABLE value vector to get consistent schema with missing column in some file. Note that we are able to so, because _we know at the reading phase that the column is partially missing_ thanks to the aforementioned schema propagated to all readers.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2320908961/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2321094956","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2321094956","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2321094956,"node_id":"IC_kwDOAFa5xc6KWRks","user":{"login":"ychernysh","id":101880553,"node_id":"U_kgDOBhKS6Q","avatar_url":"https://avatars.githubusercontent.com/u/101880553?v=4","gravatar_id":"","url":"https://api.github.com/users/ychernysh","html_url":"https://github.com/ychernysh","followers_url":"https://api.github.com/users/ychernysh/followers","following_url":"https://api.github.com/users/ychernysh/following{/other_user}","gists_url":"https://api.github.com/users/ychernysh/gists{/gist_id}","starred_url":"https://api.github.com/users/ychernysh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ychernysh/subscriptions","organizations_url":"https://api.github.com/users/ychernysh/orgs","repos_url":"https://api.github.com/users/ychernysh/repos","events_url":"https://api.github.com/users/ychernysh/events{/privacy}","received_events_url":"https://api.github.com/users/ychernysh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-30T12:31:57Z","updated_at":"2024-08-30T12:31:57Z","author_association":"NONE","body":"@paul-rogers \r\nI have tested the fix the following way. I have a Hadoop/Drill cluster with 2 nodes running DataNode/Drillbit. I have a `dfs.tmp.people` table consisting of 100 parquet files each having 10 or more row groups with such schemas:\r\n```\r\n# case 1:\r\n/tmp/people/{0..49}.parquet: id<INT(REQUIRED)> | name<VARCHAR(OPTIONAL)> | age<INT(OPTIONAL)>\r\n/tmp/people/{50..99}.parquet: id<INT(REQUIRED)>\r\n# case 2:\r\n/tmp/people/{50..99}.parquet: id<INT(REQUIRED)>\r\n/tmp/people/{100..149}.parquet: id<INT(REQUIRED)> | name<VARCHAR(OPTIONAL)> | age<INT(OPTIONAL)>\r\n```\r\nThe files are spread evenly across all DataNodes and when I run a query, I see (in each Drillbit's logs, and in query profile) that Drill reads in parallel in 2 Drillbits. I run such queries:\r\n```\r\nSELECT age FROM dfs.tmp.people ORDER BY age;\r\nSELECT name FROM dfs.tmp.people ORDER BY name;\r\nSELECT age FROM dfs.tmp.people UNION ALL (VALUES(1));\r\nSELECT age FROM dfs.tmp.people UNION (VALUES(1));\r\nSELECT name FROM dfs.tmp.people UNION (VALUES ('Bob'));\r\nSELECT name FROM dfs.tmp.people UNION ALL (VALUES ('Bob'));\r\n```\r\nThey all succeeded. Without the fix, Drill would fail. And note that we need all of the 3 solutions provided in this PR to make all of them pass:\r\n1. Solve the naming problem\r\n2. Set the correct minor type\r\n3. Set the correct data mode\r\n\r\nThe main idea of [DRILL-8508](https://issues.apache.org/jira/browse/DRILL-8508) solution is that since we scan footers of all the parquet files to read back at the planning phase in Foreman, we should already know what columns are (partially) missing and what are not. Knowing that `file1.parquet` contains `(a: VARCHAR:REQUIRED)` and `file2.parquet` has no `a` column at the planning phase, we can tell the reader 1 to forcefully put `a` column in a nullable vector (and not `REQUIRED`) and the reader 2 to create a missing column vector of type `VARCHAR` (and not default to `INT`). And since we've got this information even before any of the readers start to actually read, it doesn't matter what file would be read first. So this solution is order-agnostic \r\n\r\n**Note about tests**: Unit tests for the fix, however, require having specific file read order. This is due to some operators such `UNION ALL`, who build their own output schema based on [the first prefetched batches from left and right inputs](https://github.com/apache/drill/blob/11aaa3f89cb85f7ef63e6cc5416c6b2f90e8322c/exec/java-exec/src/main/java/org/apache/drill/exec/physical/impl/union/UnionAllRecordBatch.java#L89). Here it does matter what file would be read first since it defines the `UNION ALL` output schema. So the unit tests aim to do such an order that without the fix there would have been an error, while with the fix it succeeds.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2321094956/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2322288590","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2322288590","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2322288590,"node_id":"IC_kwDOAFa5xc6Ka0_O","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-30T20:27:08Z","updated_at":"2024-08-30T20:27:08Z","author_association":"CONTRIBUTOR","body":"@ychernysh, thanks for the clarification of the column name issue. I agree that the name stored in the vector should not contain backticks.\r\n\r\nI am unaware of any code in the Foreman that scans all the Parquet files. Is that something new? Doing that in the Foreman places extreme load on the Foreman, causes remote reads in Hadoop, and will be slow. Drill relies on statistical averages to balance load: each node does about the same amount of work. Doing a large prescan in the Foreman invalidates this assumption. The feature is fine for Drill run as a single process on a single machine for a single user. It will cause hotspots and resource issues on a busy, distributed cluster.\r\n\r\nThe old, original Parquet schema cache did, in fact, read all the files in a folder, but did so in a distributed fashion, and wrote the result to a JSON file. (But without locking, so that two updates at the same time led to corruption.) Are we talking about a new feature recently added in the last few years? Or, about the original Parquet schema cache?\r\n\r\nIf this feature does exist, then we now have six ways that Drill handles schema (Parquet cache, provides schema, Drill Metastore, HMS, on-the-fly, and this new prescan of Parquet files). If a schema is available, then I agree with your analysis. The planner should detect column type conflicts, and if a column is missing. If a column is missing in any file, then the schema sent to the readers should be OPTIONAL for that column. Further, if some Parquet files have REQUIRED, and some OPTIONAL, then the mode should be OPTIONAL. You know the drill (pardon the pun).\r\n\r\nNote, however, that deciding on a common schema is a **planner** task. With EVF, the planner would provide the schema (using the provided schema mechanism) to the reader and EVF would \"do the right thing\" to ensure that the reader's output schema matches that defined by the planner. There are many CSV file unit tests that show this in action.\r\n\r\nCalcite does a fine job working out the required types assuming that Drill provides column type information in its metadata. Does the new Parquet prescan feed into Calcite, or is it something done on the side? If on the side, then we'll run into issues where Calcite guesses one column type (based on operations) but the Parquet schema prescan works out some other type (based on the Parquet files.) For example, if I have a query `SELECT SQRT(foo)...`, Calcite will guess that the column has to be numeric. But, if the Parquet prescan sees that `foo` is `VARCHAR`, then there will be a runtime conflict rather than the planner sorting out the mess. Again, I'm ignorant of the prescan feature, so I don't know what might have been done there.\r\n\r\nThus, the task for Parquet should be to recreate what EVF does (since EVF already fought these battles), but using the older column writers. That is:\r\n\r\n* The Parquet reader has to properly handle the missing column to avoid a schema change. In Drill, \"schema change\" means \"rebind the vectors and regenerate any operator-specific code.\"\r\n* If the first file does not have the column, create a dummy column of the type specified by the planner.\r\n* If the first file does have a given column, create a vector _with the type specified by the planner_, not the type specified by Parquet.\r\n* If a subsequent file does not have the column, _reuse_ the prior vector, which should be of OPTIONAL mode.\r\n\r\nNote that Parquet must already have a way to reuse columns common to two files, else we'd get a schema change on each new file. (Sorry, my knowledge of the old column writers is rusty; it's been several years since I last looked at them.)\r\n\r\nIn fact, given that Parquet is trying to solve the same problems as EVF, one might want to review the EVF unit tests and recreate those many cases using Parquet. \"If one is ignorant of history one is doomed to repeat it.\"\r\n\r\nThanks again for the explanations. Now that I better understand the problem (and am aware of that new Parquet prescan feature), I can do a better code review.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2322288590/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2322342869","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2322342869","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2322342869,"node_id":"IC_kwDOAFa5xc6KbCPV","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-30T21:11:14Z","updated_at":"2024-08-30T21:11:14Z","author_association":"CONTRIBUTOR","body":"@paul-rogers @ychernysh I'm wondering if it wouldn't be worth it to refactor the Parquet reader to use EVF2 rather than debug all this.   I don't know what was involved, but I do know that refactoring all the other plugins to use EVF2 wasn't all that difficult, but I do know that Parquet is another ball game.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2322342869/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2322376645","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2322376645","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2322376645,"node_id":"IC_kwDOAFa5xc6KbKfF","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-30T21:43:06Z","updated_at":"2024-08-30T21:43:06Z","author_association":"CONTRIBUTOR","body":"> @paul-rogers @ychernysh I'm wondering if it wouldn't be worth it to refactor the Parquet reader to use EVF2 rather than debug all this. I don't know what was involved, but I do know that refactoring all the other plugins to use EVF2 wasn't all that difficult, but I do know that Parquet is another ball game.\r\n\r\nDoing so would be the ideal solution. The challenge has always been that the Parquet reader is horribly complex. I took a few cracks a refactoring it back in the day, but it is still pretty complex.\r\n\r\nThe most challenging issue is that Parquet is parallel: it reads each column in a separate thread. MapR did a large number of hacks to maximize parallelism, so that code grew quite complex with many nuances to saturate threads while not using too many resources overall: that is, to maximize parallelism within a single query, but also across the \"thousands of concurrent queries\" that were the rage back in the day.\r\n\r\nAll other readers are row-based since that is how most other data formats work. EVF is a row-based implementation. As a result, EVF would be difficult to reuse.\r\n\r\nThis raises the reason that EVF was created in the first place: limiting batch size to prevent memory fragmentation. Back in the day, all readers read 64K records per batch, even if that resulted in huge vectors. EVF imposes a batch size limit, and gracefully wraps up each batch, rolling over any \"excess\" data to the next one.\r\n\r\nIn Parquet, that logic does not exist. That is, if we have, say, 20 column writers all busy building their own vectors, there is nothing to say, \"hold, on, we're over our 16 MB batch size limit\". Instead, the readers just read _n_ rows, creating whatever size vectors are required. Read 1000 columns of 1 MB each and you need a 1GB value vector.\r\n\r\nThe memory fragmentation issue arises because Drill's Netty-based memory manager handles allocations up to 32 MB (IIRC) from its binary-buddy free list. Beyond that, every request comes from the OS. Netty does not release memory back to the OS if even a single byte is in use from a 32 MB block. Eventually, all memory resides in the Netty free list, and we reach the OS allocation limit. As a result, we can have 100% of the Netty pool free, but no OS capacity to allocate another 64MB vector and we get an OOM. The only recourse is to restart Drill to return memory to the OS.\r\n\r\nWhile we long ago fixed the fragmentation issues in the other readers (via EVF) and other operators (using the \"temporary\" \"batch sizer\" hack), it may be that Parquet still suffers from memory fragmentation issues because of its unique, parallel structure.\r\n\r\nStill, perhaps there is some way to have EVF handle the schema and vector management stuff, but to disable the row-oriented batch size checks and let the Parquet readers write as much data as they want to each vector (fragmenting memory if it chooses to do so). Or, maybe work out some way to give each column reader a \"lease\" to read up to x MB. EVF can handle the work needed to copy \"extra\" data over to a new vector for the next batch. I'd have to try to swap EVF knowledge back into the ole' brain to sort this out.\r\n\r\nAll this said, I can certainly see the argument for hacking the existing code just to get done. I guess I'd just suggest that the hacks at least reuse the rules we already worked out for EVF, even if they can't reuse the code.\r\n\r\nAll of this is premised on the notion that someone did, recently, add a \"Parquet prescan\" to the planner, and that someone added column type propagation to the Calcite planner. Was this actually done? Or, are we somehow assuming it was done? Are we confusing this with the old Parquet schema cache? Again, I've been out of the loop so I'm just verifying I'm understanding the situation.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2322376645/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2322480191","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2322480191","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2322480191,"node_id":"IC_kwDOAFa5xc6Kbjw_","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-30T22:22:01Z","updated_at":"2024-08-30T22:22:30Z","author_association":"CONTRIBUTOR","body":"> All of this is premised on the notion that someone did, recently, add a \"Parquet prescan\" to the planner, and that someone added column type propagation to the Calcite planner. Was this actually done? Or, are we somehow assuming it was done? Are we confusing this with the old Parquet schema cache? Again, I've been out of the loop so I'm just verifying I'm understanding the situation.\r\n\r\n@paul-rogers I'm not aware of any recent significant work on the Parquet reader.  I know @jnturton did some work regarding adding new compression capabilities and there have been a few bug fixes here and there, but nothing major as I recall.   So I don't think we've added any Parquet \"prescan\" that I am aware of. ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2322480191/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2322784235","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2322784235","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2322784235,"node_id":"IC_kwDOAFa5xc6Kct_r","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-08-31T05:45:04Z","updated_at":"2024-08-31T05:45:04Z","author_association":"CONTRIBUTOR","body":"> @paul-rogers I'm not aware of any recent significant work on the Parquet reader. I know @jnturton did some work regarding adding new compression capabilities and there have been a few bug fixes here and there, but nothing major as I recall. So I don't think we've added any Parquet \"prescan\" that I am aware of.\r\n\r\nAh. I'm misunderstanding something. I outlined a number of the common problems we encounter when we try to figure out schema dynamically. A response suggested that this pull request solves this because it has access to the full Parquet schema in the planner. The only way to get schema that is either to use the old Parquet metadata cache, or something that scans all the Parquet files in the planner. I thought I saw a statement that such a scan was being done.\r\n\r\nTo prevent further confusion, what is the source of the Parquet schema in this fix?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2322784235/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2325133637","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2325133637","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2325133637,"node_id":"IC_kwDOAFa5xc6KlrlF","user":{"login":"ychernysh","id":101880553,"node_id":"U_kgDOBhKS6Q","avatar_url":"https://avatars.githubusercontent.com/u/101880553?v=4","gravatar_id":"","url":"https://api.github.com/users/ychernysh","html_url":"https://github.com/ychernysh","followers_url":"https://api.github.com/users/ychernysh/followers","following_url":"https://api.github.com/users/ychernysh/following{/other_user}","gists_url":"https://api.github.com/users/ychernysh/gists{/gist_id}","starred_url":"https://api.github.com/users/ychernysh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ychernysh/subscriptions","organizations_url":"https://api.github.com/users/ychernysh/orgs","repos_url":"https://api.github.com/users/ychernysh/repos","events_url":"https://api.github.com/users/ychernysh/events{/privacy}","received_events_url":"https://api.github.com/users/ychernysh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-02T17:30:38Z","updated_at":"2024-09-02T18:11:01Z","author_association":"NONE","body":"@paul-rogers @cgivre \r\n\r\n> I am unaware of any code in the Foreman that scans all the Parquet files. Is that something new?\r\n\r\nDrill parallelizes scanning a parquet table at file, row group, column chunk and page levels. A single [ParquetRecordReader](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/store/parquet/columnreaders/ParquetRecordReader.java) object (which is the key part of the issue, since it creates null-filled vectors for missing columns) reads 1 row group, so this is the level we're interested in. Each Minor Fragment is assigned a list of row groups (that is, a list of ParquetRecordReader objects) to read.\r\nThe assignment happens in Foreman at parallelization phase ([Foreman#runPhysicalPlan:416](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/work/foreman/Foreman.java#L416), [AbstractParquetGroupScan#applyAssignments](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/store/parquet/AbstractParquetGroupScan.java#L170-L173)) and requires the files metadata to be known at that phase (we need to know what row groups are there in order to assign them to the minor fragments). \r\nSo the metadata is scanned back at the physical plan creation phase ([Foreman#runSQL:594](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/work/foreman/Foreman.java#L594)) using the [ParquetTableMetadataProvider](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/metastore/store/parquet/ParquetTableMetadataProvider.java) interface (see [this code block](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/store/parquet/ParquetGroupScan.java#L137-L157)), whose implementations can either read from Drill Metastore, or from the files in FS themselves.\r\nFurthermore, the schema from the metadata (that is used in this PR) is also needed at ScanBatch initialization phase (minor fragment initialization) for row group pruning (see [RowsMatch](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/expr/stat/RowsMatch.java#L20-L27) for the logic). See [this](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/store/parquet/AbstractParquetScanBatchCreator.java#L119) and [this](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/store/parquet/AbstractParquetScanBatchCreator.java#L206) lines, where `rowGroupScan.getSchema()` is also used.\r\nSo, the answer is: **no**, that's not something new. Rather, it's a thing required for some basic Drill functionality (assigning the row groups to minor fragments), but also for some specific functionality (row group pruning). \r\n\r\n> Doing that in the Foreman places extreme load on the Foreman, causes remote reads in Hadoop, and will be slow.\r\n\r\n As I said above, we cannot avoid it. But, for your information, the process of reading metadata from all the parquet files is [parallelized](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/store/parquet/metadata/Metadata.java#L432-L439) into 16 threads within a Foreman JVM. \r\n\r\n>The old, original Parquet schema cache did, in fact, read all the files in a folder, but did so in a distributed fashion, and wrote the result to a JSON file. (But without locking, so that two updates at the same time led to corruption.) Are we talking about a new feature recently added in the last few years? Or, about the original Parquet schema cache?\r\n\r\nBased on the above, and on that [ParquetTableMetadataProvider can use metadata cache files](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/metastore/store/parquet/ParquetTableMetadataProvider.java#L27-L32), I assume that we're talking about the original Parquet schema cache. But I'm not sure...\r\n\r\n> If this feature does exist, then we now have six ways that Drill handles schema (Parquet cache, provides schema, Drill Metastore, HMS, on-the-fly, and this new prescan of Parquet files).\r\n\r\nSo, I guess we still have 5 ways, and let me summarize my knowledge on each:\r\n- parquet cache: used in this PR\r\n- [provided schema](https://drill.apache.org/docs/create-or-replace-schema/): only supports text files, not parquet\r\n- Drill Metastore: I have just checked, all the errors described in the issue are still reproducible with this way. Seems like this schema is not passed down to ParquetRecordReader (so was the parquet cache schema before this PR). In theory, we could take this schema, but: 1) it requires users to use Drill metastore, while this PR does not; 2) this PR has already done the same, but with parquet cache schema\r\n- HMS: ???\r\n- on-the-fly: not applicable to this solution, since we want to take advantages of the \"neighbor\" parquet files, while this is the schema for a single file being read\r\n\r\n> - The Parquet reader has to properly handle the missing column to avoid a schema change. In Drill, \"schema change\" means \"rebind the vectors and regenerate any operator-specific code.\"\r\n> - If the first file does not have the column, create a dummy column of the type specified by the planner.\r\n> - If the first file does have a given column, create a vector with the type specified by the planner, not the type specified by Parquet.\r\n> - If a subsequent file does not have the column, reuse the prior vector, which should be of OPTIONAL mode.\r\n\r\nBasically all of the above is met by this PR, but with a bit different wording (not using terms _first/subsequent file_, since as said before, the fix is order-agnostic):\r\n1. If at least 1 parquet file contains a selected column, then the null-filled vectors should have its minor type\r\n2. If at least 1 parquet file does not have a selected column, or have it as OPTIONAL, then ALL of the readers are forced to return it as OPTIONAL\r\n\r\n---\r\n\r\nPlease sorry if I missed answering some of the questions. I am new to Drill and this is one of my first tasks on it, so I might not understand some things. Regarding refactoring to EVF: I've never seen it before and probably I'm not the best person to implement it. I will try to research it though to understand better @paul-rogers 's reviews. But I think we should at least agree on how would we treat the issue: refactoring everything to EVF (which, as far as I understand, would erase everything made in this PR), making current parquet reader simulate the EVF as much as possible or just solving the concrete problems described in the tickets. Note that this PR went the 3rd way. So before applying any edits for this PR it would be nice to understand if it would make any sense at all first :)\r\n@rymarm , maybe you could fill in the holes in my answer with your knowledge/experience? ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2325133637/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2325302884","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2325302884","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2325302884,"node_id":"IC_kwDOAFa5xc6KmU5k","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-02T21:09:05Z","updated_at":"2024-09-02T21:09:05Z","author_association":"CONTRIBUTOR","body":"@ychernysh, thank you for your detailed explanation. Let's focus in on one point.\r\n\r\n> The assignment happens in Foreman at parallelization phase ([Foreman#runPhysicalPlan:416](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/work/foreman/Foreman.java#L416), [AbstractParquetGroupScan#applyAssignments](https://github.com/apache/drill/blob/drill-1.21.2/exec/java-exec/src/main/java/org/apache/drill/exec/store/parquet/AbstractParquetGroupScan.java#L170-L173)) and requires the files metadata to be known at that phase (we need to know what row groups are there in order to assign them to the minor fragments).\r\n\r\nIt is surprising that none of the \"second generation\" Drill developers ever knew about, or mentioned that Drill scans Parquet files at plan time. Of course, it could be that I just never understood what someone was saying. We used to wrestle with inconsistent schemas all the time, so it is surprising if the solution was available the whole time. That's why, if this code exists, I suspect it must have been added ether very early (by a \"first generation\" developer who later left) or within the last few years.\r\n\r\nAnother reason it is surprising that we have such code is the big deal we make of being \"schema free.\" Of course, \"schema free\" has problems. Why would we not have mentioned that \"schema free\" means \"infer the schema at plan time\" if doing so would solve the schema inconsistency issues? Amazing...\r\n\r\nIf such code exists, then it should have been integrated not just into parallelization planning, but also Calcite type propagation, and the schema included in the physical plan sent to the Parquet readers. I suppose whoever added it could have just been focused on parallelization, and hoped Drill's \"magic\" would handle the schema. In fact, the \"missing\" type propagation code is very code that you're now adding, though, it seems, without using Calcite for the type propagation.\r\n\r\nThe discussion we are having depends _entirely_ on whether schema information is available at plan time. Before I comment further, you've given me so me homework: I'll look at that code to determine if it really does scan all the file headers at plan time.\r\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2325302884/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2325315052","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2325315052","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2325315052,"node_id":"IC_kwDOAFa5xc6KmX3s","user":{"login":"ychernysh","id":101880553,"node_id":"U_kgDOBhKS6Q","avatar_url":"https://avatars.githubusercontent.com/u/101880553?v=4","gravatar_id":"","url":"https://api.github.com/users/ychernysh","html_url":"https://github.com/ychernysh","followers_url":"https://api.github.com/users/ychernysh/followers","following_url":"https://api.github.com/users/ychernysh/following{/other_user}","gists_url":"https://api.github.com/users/ychernysh/gists{/gist_id}","starred_url":"https://api.github.com/users/ychernysh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ychernysh/subscriptions","organizations_url":"https://api.github.com/users/ychernysh/orgs","repos_url":"https://api.github.com/users/ychernysh/repos","events_url":"https://api.github.com/users/ychernysh/events{/privacy}","received_events_url":"https://api.github.com/users/ychernysh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-02T21:29:11Z","updated_at":"2024-09-02T21:29:11Z","author_association":"NONE","body":"@paul-rogers \r\n\r\n> though, it seems, without using Calcite for the type propagation\r\n\r\nSorry, I don't really understand the question regarding Calcite (I'm not familiar with it). I didn't consider Calcite in my work, so, probably, your statement is correct.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2325315052/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2326078335","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2326078335","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2326078335,"node_id":"IC_kwDOAFa5xc6KpSN_","user":{"login":"rymarm","id":62295633,"node_id":"MDQ6VXNlcjYyMjk1NjMz","avatar_url":"https://avatars.githubusercontent.com/u/62295633?v=4","gravatar_id":"","url":"https://api.github.com/users/rymarm","html_url":"https://github.com/rymarm","followers_url":"https://api.github.com/users/rymarm/followers","following_url":"https://api.github.com/users/rymarm/following{/other_user}","gists_url":"https://api.github.com/users/rymarm/gists{/gist_id}","starred_url":"https://api.github.com/users/rymarm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymarm/subscriptions","organizations_url":"https://api.github.com/users/rymarm/orgs","repos_url":"https://api.github.com/users/rymarm/repos","events_url":"https://api.github.com/users/rymarm/events{/privacy}","received_events_url":"https://api.github.com/users/rymarm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-03T09:45:19Z","updated_at":"2024-09-03T09:45:19Z","author_association":"MEMBER","body":"@paul-rogers, there is no new feature. This behavior of reading all parquet files metadata during the planning phase has been present for a long time. Moreover, we even have a feature called \"parquet metadata cache\" aimed to resolve the con of this logic \r\nwhen the planning phase takes significant time due to the reading of metadata of many distinct parquet files\r\n\r\n> Parquet metadata caching is a feature that enables Drill to read a single metadata cache file instead of retrieving metadata from multiple Parquet files during the query-planning phase\r\n> ...\r\n> Metadata caching is useful when planning time is a significant percentage of the total elapsed time of the query \r\n\r\n\r\nhttps://drill.apache.org/docs/optimizing-parquet-metadata-reading/","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2326078335/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2326107900","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2326107900","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2326107900,"node_id":"IC_kwDOAFa5xc6KpZb8","user":{"login":"rymarm","id":62295633,"node_id":"MDQ6VXNlcjYyMjk1NjMz","avatar_url":"https://avatars.githubusercontent.com/u/62295633?v=4","gravatar_id":"","url":"https://api.github.com/users/rymarm","html_url":"https://github.com/rymarm","followers_url":"https://api.github.com/users/rymarm/followers","following_url":"https://api.github.com/users/rymarm/following{/other_user}","gists_url":"https://api.github.com/users/rymarm/gists{/gist_id}","starred_url":"https://api.github.com/users/rymarm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymarm/subscriptions","organizations_url":"https://api.github.com/users/rymarm/orgs","repos_url":"https://api.github.com/users/rymarm/repos","events_url":"https://api.github.com/users/rymarm/events{/privacy}","received_events_url":"https://api.github.com/users/rymarm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-03T09:59:28Z","updated_at":"2024-09-03T09:59:28Z","author_association":"MEMBER","body":"@paul-rogers \r\n>Another reason it is surprising that we have such code is the big deal we make of being \"schema free.\" Of course, \"schema free\" has problems. Why would we not have mentioned that \"schema free\" means \"infer the schema at plan time\" if doing so would solve the schema inconsistency issues? Amazing...\r\n\r\nI was supposing that the Drill's key feature is that Drill takes care of the data structure and type, while the user is left only to query the data like it is a simple Porstgres or MySql table. Saying this I think it's fine to read all the available metadata of the data whenever at any query execution phase if it helps us to execute faster and with less fail chance the query and if there is no additional setup from the user required. ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2326107900/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2332920168","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2332920168","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2332920168,"node_id":"IC_kwDOAFa5xc6LDYlo","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-06T00:00:50Z","updated_at":"2024-09-06T00:00:50Z","author_association":"CONTRIBUTOR","body":"Thanks again for the many pointers and explanations. Much to my surprise, Drill does, indeed, seem to read the Parquet metadata at plan time. Your explanation makes sense: clearly we need the information for parallelization planning. The Parquet metadata cache simply bypasses the physical file reads if the cache is present.\r\n\r\nI traced the whole flow. It all looks good except at the last step, writing data to a vector. That will prevent any direct attempt to have the Parquet reader write to a vector other than the one that matches the Parquet type.\r\n\r\nThat may still be OK. As you can tell, my comments are based on the general schema change case: the problems we've encountered over the years. But, I suspect this PR can address one very specific case: missing columns when the type is consistent across files where it does appear.\r\n\r\n### Recap of the Parquet Planning Process\r\n\r\nThe code is hard to follow statically. Instead, I ran the unit tests in the PR to get the dynamic view. As described above, the `ParquetGroupScan` does read the files by way of a number of builders, providers and associated classes. The actual reading is about here: `ParquetFileAndRowCountMetadata.getParquetFileMetadata_v4`.\r\n\r\nHere I will insert a grumble that if Drill scans the Parquet files per query to get schema, then it could certainly do so for all other file types and avoid a large number of problems. Files have a path and a timestamp: we could easily build up a per-Drillbit cache of metadata so we read it only once per session, and only if the file changes. Trying to distribute that data is the hard part. (Everyone wants to use ZK, but ZK is not a distributed DB.) End of grumble.\r\n\r\nSo, we do have schema per row group. We can thus work out the common schema as is done in this PR. In general, we have to handle the following:\r\n\r\n* Missing columns\r\n* Different types\r\n* Different cardinalities (nullable, non-nullable, repeated)\r\n\r\nThe code here handles missing columns and the nullable/non-nullable modes. We can worry about the scalar/array issue later as only a novice would change a column from one to the other. Because of the use of the common type code, I assumed that this PR might also handle the differing types issue, but maybe I misunderstood.\r\n\r\nAs explained above, the _right_ way to handle columns is to run them through Calcite. That way, Calcite can check for something like `VARCHAR * INT`, which SQL doesn't support. I can't tell if the original author did that work. Without the Calcite change, the readers will know the type, but not the SQL planner. Not great, but we can live with it since that's the way its worked until now.\r\n\r\nThanks for adding tests that show that the type inference works as intended. It would be handy if  `DESCRIBE <table>` were to work in this case. I didn't check if that is wired up for Parquet files.\r\n\r\nThere are three cases that work prior to this PR. Assume we have a column `c`:\r\n\r\n* `c` appears in no files. The type is untyped NULL. (Nullable `INT` in other readers originally, changed with EVF.)\r\n* `c` appears in all files with the same type and mode. Works for all operators. The user sees a consistent column type.\r\n* `c`' changes type or mode, or is missing in some files. Works only if the query does not contain a SORT, JOIN or other type-sensitive operator. Presents the user with results with diffing types.\r\n\r\nThis PR generalizes the third case. As it is, the \"sensitive\" operators will raise a schema change exception. To fix the SCEs we need to handle all the cases in which the schema can change so that all readers return the same schema. Cases:\r\n\r\n1. `c` appears in all files with the same type but differing modes.\r\n2. `c` appears in all files, but with differing types.\r\n3. `c` appears in all files, but with differing types and modes.\r\n4. `c` is missing in some files, but when it appears, it always has the same type. Mode must be set to nullable. Handled by this PR.\r\n5. `c` is missing in some files. In the files in which `c` does appear, it has differing types. Handled by this PR, maybe.\r\n\r\nA review response comment suggests that this PR fixes cases 4, which seems like the most reasonable form of schema change. Changing column types is just asking for trouble with tools such as Presto or Impala. Still, let's think through all the cases.\r\n\r\nThere is one additional case, just to make this more fun. The query can be of the form `SELECT * FROM myParquet`. In this case, the user might expect the union of all columns from all files and row groups, with the types reconciled for all of them. If we focus just on case 4, then the user would expect us to \"fill in the blanks\" if some of the columns are missing in some files.\r\n\r\nOnce we have the common schema, we need to ship it to the distributed readers. It looks like `AbstractParquetRowGroupScan.schema` provides the \"physical plan\" support. The `AbstractParquetScanBatchCreator` class creates a set of `ParquetRecordReader` instances from the `AbstractParquetRowGroupScan` and wraps them in the `ScanBatch` operator. The schema is placed in a `ColumnExplorer`.\r\n\r\nAs it turns out, Drill has not just one, but two different Parquet readers: `DrillParquetReader` and `ParquetRecordReader`. Both receive the list of columns, but only as a `List<SchemaPath>` which has no type information. `ParquetRecordReader` also receives the type information. It seems that the names are redundant: they appear in both the schema path and the `TupleSchema`. This may be the source of one of the bugs fixed in this PR.\r\n\r\nSo far so good.\r\n\r\n### The Problem\r\n\r\nBut, now all heck breaks loose. What we want is for each row group to honor the planner-provided schema. But, this won't work.\r\n \r\nWhat we want is that the row group either has column `c` or not. If not, we make up a column of the type provided by the `TupleSchema`. There is much code to work out the Drill type for each Parquet type. That code should no longer be used by the _reader_, but rather by the planner. At read time, we just create the vector specified by the schema to ensure consistency.\r\n\r\nBut, the Parquet column readers assume that the type of the Drill vector is the same as that of Parquet columns. As it turns out, there are two of sets of Parquet column writers: the original ones and a second set of \"bulk\" readers. I don't know if both are still used. Eventually, the Parquet column readers call down to the following line from `FixedByteAlignedReader`:\r\n\r\n```java\r\n  protected void writeData() {\r\n    vectorData.writeBytes(bytebuf, (int) readStartInBytes, (int) readLength);\r\n  }\r\n```\r\n\r\nThat is, the Drill vectors have been carefully chosen so that their byte layout of the vector matches the byte layout of Parquet. We read, say, `INT32`  values into `INT` vectors where the values are also 32 bits long. We must also assume the same endian layout, IEEE floating point layout, etc. To write to a different Drill type requires a per-value conversion.\r\n\r\nThe class `ColumnReaderFactory` chooses the column reader. It has no code to handle type conversions. To do a type conversion, we'd need a new set of readers: one for each (from type, to type) pair. EVF provides a large set of these so that EVF can perform this type coercion automatically for the common cases. Examples. read a CSV file (all VARCHAR), but into an `INT` column (requires a `VARCHAR`-to-`INT` conversion).\r\n\r\nThis code is complex, so I might be missing something. More testing would reveal the facts. It could be that writing a non-nullable column into a nullable vector works: I'm just not sure what sets the null bits to the correct values. Maybe they take on the correct values by default, if we zero out the null vector at allocation.\r\n\r\n### Handling Only Missing Columns\r\n\r\nSince the Parquet reader is not set up to handle type changes, we can choose to restrict this fix to handle only missing columns. That is, _if_ a column is missing, _and_ it has the same type when it does appear, _only then_ change the mode to nullable. Otherwise, let the schema change happen and the query will fail as today. Such a fix solves the issue for your case, but does not solve the general problem. This is still an improvement and worth doing.\r\n\r\nWe just need to ensure that if Parquet thinks it is writing to a non-nullable vector, but the vector is nullable, that the code \"does the right thing.\" Nullable vectors are a composite: they have a null vector and a data vector. Parquet should use the data vector. We just need to ensure that we somehow set the null vector bits correctly. It may be that vector allocation zeros the vectors and so the null vector starts in the proper state. Since the tests pass, this may be the case.\r\n\r\n### Alternative Solution for Type Changes\r\n\r\nSuppose we wanted to handle type changes as well. From the above description, we can't solve the problem by forcing Parquet to choose a different type of vector than the one for the column type. (I mentioned that this is possible when using EVF and suggested we could do the same for Parquet. It turns out that Parquet will not allow this solution.)\r\n\r\nThere are two possible solutions, one very hard, the other only hard. (The third, of course, is to skip this task.)\r\n\r\nThe first option is to create a type conversion mechanism as described above. These are tedious to write (we'd use code generation) and just as tedious to test. This seems an excessive amount of work to solve a problem which occurs infrequently.\r\n\r\nThe second option is simply to alter the execution plan to insert a PROJECT operator on top of the SCAN operator. We could set a flag that says that the PROJECT is needed. This flag would indicate that we found a type inconsistency. The PROJECT operator (`ProjectRecordBatch`), will handle type conversions: it is what implements `CAST()` operations.\r\n\r\nThe trick is that adding the PROJECT is, itself, complex. Basically, there needs to be a Calcite rule that rewrites a scan batch with our flag set to a project with the needed `CAST` operations. The Parquet reader should then ignore the `TupleSchema` and create vectors based on the Parquet schema.\r\n\r\nWe would want to verify that the PROJECT does what it is supposed to do: emit the same vectors even when it receives a schema change from its upstream (SCAN) operator.\r\n\r\n### Suggestion\r\n\r\nGiven the above facts (which you should certainly) verify, I suggest we choose the \"Handling Only Missing Columns\" solution and not attempt to handle column type changes. That is, don't attempt to fix the cases 3-5 (differing types) in this PR. Leave that as a future exercise. \r\n\r\nIf you found this bug due to an actual use case. ensure that the use case does not change column data types. If the type of a column is to change, just create a new column name instead. For example, if `IP_addr` is an `INT32`, don't try to make it an `INT64` for IPV6 addresses. Instead, write those to a new `IP6_addr` column. With this fix, adding and removing columns should work as expected.\r\n\r\nDoes this seem a reasonable approach?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2332920168/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2332922284","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2332922284","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2332922284,"node_id":"IC_kwDOAFa5xc6LDZGs","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-06T00:03:04Z","updated_at":"2024-09-06T00:03:04Z","author_association":"CONTRIBUTOR","body":"This PR fixes not just the type issues above, but also the name issue and the untyped null issue. Let's not forget those. As explained earlier, you are right that backticks should never appear at runtime. Backticks are a SQL only feature.\r\n\r\nFrom the comment you mentioned, it could be that the `col.toExpr()` code was an ill-fated attempt to fix a real problem.\r\nParquet (and Drill) support maps. We can thus have a map `m` with a column `foo`. The SQL name: `m.foo` or `'m'.'foo'` refer to `foo` within `m`. (Pardon the forward ticks: Markdown doesn't like nested backticks.) The bug is that the column name `m.foo` is a perfectly valid Parquet column name. So, `'m.foo'` (the entire name quoted) refers to a top level column with the `m.foo` name.\r\n\r\nWe can change the code to fix the bug you discovered. We should, however, make sure we have a test for the name-with-dot/column-within-map case. We can perhaps look for unit tests associated with DRILL-4264 to understand what the original fix was trying to do.\r\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2332922284/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2332924314","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2332924314","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2332924314,"node_id":"IC_kwDOAFa5xc6LDZma","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-06T00:05:15Z","updated_at":"2024-09-06T00:05:15Z","author_association":"CONTRIBUTOR","body":"The other fix is to change the type of a missing column from Untyped Null to Nullable `INT`.\r\n\r\nFirst, let me make sure I understand. Prior to this PR, did Parquet use Untyped Null for the type of a missing column? And, after this fix, if a column is missing from all files, it will be Nullable `INT`? If so, i worry that this may be a step backwards.\r\n\r\nThe purpose of Untyped Null is to say, \"hey, we don't know the type.\" This is a \"good thing\". It is a hack that Drill will \"helpfully\" guess nullable `INT`. Doing so can cause problems. If someone queries a set of files where some have `foo` and some don't, with a Nullable `INT`, the column type may change from `VARCHAR` (say) to `INT` depending on the query. It seems slightly more helpful to change from `VARCHAR` to Untyped Null.\r\n\r\nIs it possible to leave the type of a \"completely missing\" column as Untyped Null?\r\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2332924314/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2334189843","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2334189843","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2334189843,"node_id":"IC_kwDOAFa5xc6LIOkT","user":{"login":"ychernysh","id":101880553,"node_id":"U_kgDOBhKS6Q","avatar_url":"https://avatars.githubusercontent.com/u/101880553?v=4","gravatar_id":"","url":"https://api.github.com/users/ychernysh","html_url":"https://github.com/ychernysh","followers_url":"https://api.github.com/users/ychernysh/followers","following_url":"https://api.github.com/users/ychernysh/following{/other_user}","gists_url":"https://api.github.com/users/ychernysh/gists{/gist_id}","starred_url":"https://api.github.com/users/ychernysh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ychernysh/subscriptions","organizations_url":"https://api.github.com/users/ychernysh/orgs","repos_url":"https://api.github.com/users/ychernysh/repos","events_url":"https://api.github.com/users/ychernysh/events{/privacy}","received_events_url":"https://api.github.com/users/ychernysh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-06T14:30:21Z","updated_at":"2024-09-06T14:30:21Z","author_association":"NONE","body":"Hi @paul-rogers ,\r\n\r\n**Different types**. This PR **DOES NOT** handle different minor types, indeed. The main focus is on missing columns and different cardinalities (though I missed REPEATED case). I agree with all you say about the complexity of this task and support the suggestion to handle it as future exercise outside of this PR.\r\nAnd, just in case, in the example of IPv4 and IPv6 columns, you mean that the user should _manually_ create each column for each address type, right? \r\n\r\n**Grumble**. Isn't that what `REFRESH TABLE METADATA` does? A user have to query it explicitly though.\r\n\r\n**Star query case**. The `SELECT * FROM myParquet` is not handled in any way here, because creating null-filled vectors is skipped for such cases. See [block1](https://github.com/apache/drill/blob/11aaa3f89cb85f7ef63e6cc5416c6b2f90e8322c/exec/java-exec/src/main/java/org/apache/drill/exec/store/parquet/columnreaders/ReadState.java#L80-L82) and [block2](https://github.com/apache/drill/blob/11aaa3f89cb85f7ef63e6cc5416c6b2f90e8322c/exec/java-exec/src/main/java/org/apache/drill/exec/store/parquet/columnreaders/ReadState.java#L123-L125).\r\n\r\n**DrillParquetReader**. Indeed, Drill seems to have 2 parquet readers, but this one seems to be unsupported, see [this config](https://github.com/apache/drill/blob/1b7569d0a7ddc804ffd697fe83708c03cddfc958/exec/java-exec/src/main/java/org/apache/drill/exec/ExecConstants.java#L412-L414). That's why I also ignored it here.\r\n\r\n**Passing type information to readers**. See how I [passed](https://github.com/apache/drill/pull/2937/files#diff-533f3d7509f2db027a1bac8c5a37d2236c6668bf3fde3b5a3a409cfef1a230faR340) type information to ParquetRecordReader through `AbstractParquetRowGroupScan#getSchema`.\r\n\r\n**Reading non-nullable parquet column into a nullable vector**. With this I actually had some problems, but managed to solve them with these changes:\r\n1. Choose a nullability of a column reader based on value vector's nullability, not the parquet column's one. [Place1](https://github.com/apache/drill/pull/2937/files#diff-2643e44ab9ed0afb625631106cf390417b065b6b4e6bdfef7ef5efc3807d363bR77-R80) and [place2](https://github.com/apache/drill/pull/2937/files#diff-2643e44ab9ed0afb625631106cf390417b065b6b4e6bdfef7ef5efc3807d363bR93-R97). \r\n2. For such case, simply always put 1 in a nullability bit. [Place1](https://github.com/apache/drill/pull/2937/files#diff-aef5831173c647019325b8ece3b48b3a96ec3a9dadde0ff28b223112b5797db5R491-R495) and [place2](https://github.com/apache/drill/pull/2937/files#diff-aef5831173c647019325b8ece3b48b3a96ec3a9dadde0ff28b223112b5797db5R519-R523).\r\n\r\n**Column name with dots**. I will try to play around such cases and maybe add some tests...\r\n\r\n**UntypedNull**. Well, it's not really that I intentionally replaced `UntypedNull` with `NullableInt`... It is rather a \"side effect\" of a backticks solution. You see, there is this [if condition](https://github.com/apache/drill/blob/11aaa3f89cb85f7ef63e6cc5416c6b2f90e8322c/exec/java-exec/src/main/java/org/apache/drill/exec/vector/complex/FieldIdUtil.java#L206-L208) block in `FieldIdUtil#getFieldId` that basically says \"if the underlying field names in `expectedPath` and `vector` aren't the same, return `null`, otherwise proceed to getting the real field id\". The value we return here will later decide which if branch would we fall [here](https://github.com/apache/drill/blob/11aaa3f89cb85f7ef63e6cc5416c6b2f90e8322c/exec/java-exec/src/main/java/org/apache/drill/exec/expr/ExpressionTreeMaterializer.java#L304-L310). `null` would lead to `NullExpression.INSTANCE` (which is basically an `UntypedNull`), while a real value would lead to a real `ValueVectorReadExpression`.  Note that if we have a problem with backticks, the very first equality check in `FieldIdUtil#getFieldId` would result in _false_, because of quotes difference (say, `my_field` and `'my_field'` (you got the sense)). This leads us to an `UntypedNull` case. If the equality check would have returned _true_, we would fall in a `ValueVectorReadExpression`, which would later bring us to creating missing column vectors logic, where we use `NullableInt`. So the tests that expect `UntypedNull` passed **ONLY** because `\"my_field\".equals(\"'my_field'\")` returned _false_. When we fixed the backticks problem, we made it look like `\"my_field\".equals(\"my_field\")`, made it return _true_, use `NullableInt` and thus fail. Hope you got it...\r\nYou know that, however, I understand what you're talking about in that using `UntypedNull` for _completely missing columns_ would be more helpful than defaulting to `NullableInt`. This, indeed, doesn't confuse us with some unexisting int value and clearly tells us that the type is unknown. \r\nCurrently, if we do something like `SELECT my_column FROM left UNION ALL SELECT my_column FROM right;` where `left` has `my_column: VARCHAR`, while `right` doesn't have it at all, it would result in `NumberFormatException`, because Drill would (for some reason) prefer `INT` (from a missing column) over a `VARCHAR` and would try to cast left column to right's type, thus failing. Though if right column would came as `UntypedNull` to `UNION ALL`, the operator would certainly prefer the left type, thanks to [these lines](https://github.com/apache/drill/blob/11aaa3f89cb85f7ef63e6cc5416c6b2f90e8322c/exec/java-exec/src/main/java/org/apache/drill/exec/physical/impl/union/UnionAllRecordBatch.java#L292-L295).\r\nMaybe we should consider defaulting to `UntypedNull` instead of `NullableInt`. In theory, the only case we should _default_ is when the column is _completely missing_. I once tried doing it, but had some problems on client side reading the vector. Maybe I should try once more...","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2334189843/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2334210046","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2334210046","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2334210046,"node_id":"IC_kwDOAFa5xc6LITf-","user":{"login":"ychernysh","id":101880553,"node_id":"U_kgDOBhKS6Q","avatar_url":"https://avatars.githubusercontent.com/u/101880553?v=4","gravatar_id":"","url":"https://api.github.com/users/ychernysh","html_url":"https://github.com/ychernysh","followers_url":"https://api.github.com/users/ychernysh/followers","following_url":"https://api.github.com/users/ychernysh/following{/other_user}","gists_url":"https://api.github.com/users/ychernysh/gists{/gist_id}","starred_url":"https://api.github.com/users/ychernysh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ychernysh/subscriptions","organizations_url":"https://api.github.com/users/ychernysh/orgs","repos_url":"https://api.github.com/users/ychernysh/repos","events_url":"https://api.github.com/users/ychernysh/events{/privacy}","received_events_url":"https://api.github.com/users/ychernysh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-06T14:38:47Z","updated_at":"2024-09-06T14:39:42Z","author_association":"NONE","body":"@paul-rogers \r\nRegarding default type and `comments` example above. Yes, as I said, unhardcoding the `NullableInt` and making the default minor type configurable by user might be a good idea, but here are some concerns here:\r\n1. Wouldn't this conflict with defaulting to `UntypedNull`?\r\n2. Since the vectors for missing columns are _null-filled_, they can be casted/converted to any minor type. That is, the user can issue `CAST` or `CONVERT_TO` and it should help for a query to succeed. Well, then, if we can define a default minor type on a per-query level, does it make sense to configure it on per-session or per-system level? Note that such workaround also helps with the `UNION ALL` example I put above in my previous comment.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2334210046/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2334853752","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2334853752","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2334853752,"node_id":"IC_kwDOAFa5xc6LKwp4","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-06T21:47:20Z","updated_at":"2024-09-06T21:47:20Z","author_association":"CONTRIBUTOR","body":"@ychernysh, thank you for the detailed explanation. It is impressive how well you understand this complex code. \r\n\r\n**Scope**: We're clear now that this PR is not trying to handle conflicting types. Yes, in my example, I was suggesting that the person who creates the Parquet files manage column types themselves. There is, of course, another workaround that I did not mention: the SQL user can (I believe) insert the needed casts. Suppose that we have a set of  files where the types differ for three columns, but we know a common type. We can coerce the types manually:\r\n\r\n```sql\r\nSELECT a, b, c\r\nFROM (SELECT CAST(a AS, DOUBLE), CAST(b AS VARCHAR), CAST(c AS INT) FROM myParquet)\r\nORDER BY a, b\r\n```\r\n\r\nThe above should insert that PROJECT I mentioned. In an ideal world, Drill would figure this out from the Parquet metadata. As we said, this can be left as a future project for another time.\r\n\r\n**Wildcard Query**: Ideally, if I have a Parquet file with columns `a` and `b`, and `b` is missing in some files, the following two queries should work identically:\r\n\r\n```sql\r\nSELECT a, b FROM (SELECT * FROM myParquet) ORDER BY a, b\r\n\r\nSELECT a, b FROM myParquet ORDER BY a, b\r\n```\r\n\r\nThat is, it should not matter how we learn we will scan column `b`: if it is missing,  it should have a consistent type after this fix.\r\n\r\nThe code you mentioned reflects the original schema-on-read design: the wildcard is expanded for each row group at run time. This is one reason I was surprised that we gather the schema at plan time. Now that it is clear that Parquet does have the schema at plan time, we can work out the union of all columns from all files at plan time. We can sort out the types of missing columns. We can then tell readers that `SELECT *` expands to not just all the columns in that particular row group, but to the union of all the columns.\r\n\r\nIt is clear that we've got a mess. Drill started as schema-on-read. Then, it was found that, for Parquet (only) we need schema at plan time. But, the folks that added that code didn't fully think through the design. The result is a huge muddle that you are now starting to sort out.\r\n\r\n_Suggestion_: let's leave proper wildcard expansion to another time. You are fixing this bug for a reason: for some use case. If your use case does not use wildcard queries, then it is safe to defer this issue until someone actually needs a fix.\r\n\r\n**Reading non-nullable parquet column into a nullable vector**: Thanks for ensuring we set the null vector correctly. Sounds like this part is good.\r\n\r\n**Passing type information to readers**: I saw your fix. That is why I mentioned that we now have two lists of columns given to the reader:\r\n\r\n```java\r\n        rowGroupScan.getColumns(), // Columns as SchemaPath\r\n       ...\r\n        // each parquet SubScan shares the same table schema constructed by a GroupScan\r\n        rowGroupScan.getSchema()); // Same list of columns as above, but as TupleMetadata?\r\n```\r\n\r\nAs a reader, I have to try to understand: are the two column lists the same? Is the order the same? Is the `TupleMetadata` version a 1:1 relationship with the `getSchemaColumns()` list? If not, what are the differences?\r\n\r\nYou are adding code to an existing implementation, and so you want to avoid changing things any more than necessary. Having redundant lists is messy, but probably the simplest fix.\r\n\r\n_Suggestion_: Maybe just add a comment about the assumed relationship between the two lists.\r\n\r\n**UntypedNull (Part 1)**: Thanks for the detailed explanation. I appreciate the time you've put into fully understanding the convoluted logic.\r\n\r\nWhen faced with complex legacy code, I find it helpful to ask, _what is this trying to do_? The code itself is the ultimate truth, and we have to start there. But, to sort out what should be happening, we have to work out the developer's intent, and figure out if they made a mistake or omitted some important condition.\r\n\r\nYou pointed out that we do two checks. In the [first one](https://github.com/apache/drill/blob/11aaa3f89cb85f7ef63e6cc5416c6b2f90e8322c/exec/java-exec/src/main/java/org/apache/drill/exec/vector/complex/FieldIdUtil.java#L206-L208) :\r\n\r\n```java\r\n  public static TypedFieldId getFieldId(ValueVector vector, int id, SchemaPath expectedPath, boolean hyper) {\r\n    if (!expectedPath.getRootSegment().getPath().equalsIgnoreCase(vector.getField().getName())) {\r\n      return null;\r\n    }\r\n```\r\n\r\nThis code says, here is a `ValueVector` and an expected `SchemaPath`. Let's make sure that the vector actually is for the given schema path by checking the `MaterializedField` for the vector. In the case where the name was corrupted with backticks, this check failed: we have a vector with the name `foo`, but the expected path is `'foo'`. So, no match.\r\n\r\nThe core question is: what use case is this meant to handle? I can speculate that there are two possible cases.\r\n\r\nFirst is the top-level fields. For top level fields, the names should always match. By the time we get here, we should have created any needed \"dummy\" top-level vectors. You correctly fixed a case where the top level did not match.\r\n\r\nI speculate that this code is meant to handle a second case: a column within a `MAP` column. Suppose the Parquet file has a map field `m` that contains two columns, `a` and `b`. The query, however, is asking to project `m.c` which does not exist. Perhaps this bit of code handles that map case.\r\n\r\n_Suggestion_: your fix is probably fine. Please check if we have a test for the map case above. If we don't, consider adding one, just so we verify that this PR doesn't break anything.\r\n\r\n**UntypedNull (Part 2)**: Next, let's understand what _should_ happen if a column is missing. We have four cases:\r\n\r\n1. The column `c` exists in _none_ of the Parquet files.\r\n2. The column `c` exists in _some_ of the Parquet files.\r\n3. The column `m.c` (a column within a map) exists in _some_ Parquet files.\r\n4. The column `m.c` exists in _none_ Parquet files.\r\n \r\nYour fix handles case 2: we will now correctly use the type of existing columns. So, we're good here.\r\n\r\nCase 1 is where the Nullable `INT`/Untyped NULL question arises. I agree with you that we should default the column type to Untyped NULL. It is odd that we used  Nullable `INT` in one case, and Untyped NULL in another case. Doing so makes no sense to a user. Can we modify the code so we always use Untyped NULL in this case? We would detect case 1 in the planner, and mark the corresponding column with the Untyped Null type. (I hope `TupleSchema` handles this type! I can't recall ever testing it.) The Parquet reader would then know to use the Untyped Null when creating the dummy vector. This is based on what _should_ happen; the devil is in the details, so please check if this suggestion can actually work.\r\n\r\nCase 3 is rather special. EVF has some rather complex logic to handle missing map columns (to any depth). Your fix relies on code in the planner to work out the type for case 2 (top-level columns). Does that code handle nested columns? If so, we just do the same as we do for case 2. However, if the planner code treats all maps as a single column (does not look inside), then maybe we just leave the existing code to do whatever it already does in this case.\r\n\r\nCase 4 depends on what we do in case 1 and 3. The \"right\" answer is for the missing column to be of type Untyped NULL. But, this case is obscure, so we can leave it to do whatever it currently does.\r\n\r\n_Suggestion_: handle case 1 as described above, and just test that cases 3 and 4 still work however they used to work.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2334853752/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2338363457","html_url":"https://github.com/apache/drill/pull/2937#issuecomment-2338363457","issue_url":"https://api.github.com/repos/apache/drill/issues/2937","id":2338363457,"node_id":"IC_kwDOAFa5xc6LYJhB","user":{"login":"ychernysh","id":101880553,"node_id":"U_kgDOBhKS6Q","avatar_url":"https://avatars.githubusercontent.com/u/101880553?v=4","gravatar_id":"","url":"https://api.github.com/users/ychernysh","html_url":"https://github.com/ychernysh","followers_url":"https://api.github.com/users/ychernysh/followers","following_url":"https://api.github.com/users/ychernysh/following{/other_user}","gists_url":"https://api.github.com/users/ychernysh/gists{/gist_id}","starred_url":"https://api.github.com/users/ychernysh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ychernysh/subscriptions","organizations_url":"https://api.github.com/users/ychernysh/orgs","repos_url":"https://api.github.com/users/ychernysh/repos","events_url":"https://api.github.com/users/ychernysh/events{/privacy}","received_events_url":"https://api.github.com/users/ychernysh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-09T15:00:14Z","updated_at":"2024-09-09T15:00:14Z","author_association":"NONE","body":"@paul-rogers when I have time, I'll do some experiments and investigations on the discussed topics and get back to you","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2338363457/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2340785892","html_url":"https://github.com/apache/drill/issues/2940#issuecomment-2340785892","issue_url":"https://api.github.com/repos/apache/drill/issues/2940","id":2340785892,"node_id":"IC_kwDOAFa5xc6LhY7k","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-10T13:27:50Z","updated_at":"2024-09-10T13:27:50Z","author_association":"CONTRIBUTOR","body":"Have you tried \r\n```sql\r\nCREATE TABLE s3.root.`/datas3/joined-data/join_data`\r\n... \r\n```","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2340785892/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2340878456","html_url":"https://github.com/apache/drill/issues/2940#issuecomment-2340878456","issue_url":"https://api.github.com/repos/apache/drill/issues/2940","id":2340878456,"node_id":"IC_kwDOAFa5xc6Lhvh4","user":{"login":"egasimov","id":58927497,"node_id":"MDQ6VXNlcjU4OTI3NDk3","avatar_url":"https://avatars.githubusercontent.com/u/58927497?v=4","gravatar_id":"","url":"https://api.github.com/users/egasimov","html_url":"https://github.com/egasimov","followers_url":"https://api.github.com/users/egasimov/followers","following_url":"https://api.github.com/users/egasimov/following{/other_user}","gists_url":"https://api.github.com/users/egasimov/gists{/gist_id}","starred_url":"https://api.github.com/users/egasimov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/egasimov/subscriptions","organizations_url":"https://api.github.com/users/egasimov/orgs","repos_url":"https://api.github.com/users/egasimov/repos","events_url":"https://api.github.com/users/egasimov/events{/privacy}","received_events_url":"https://api.github.com/users/egasimov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-10T13:53:29Z","updated_at":"2024-09-10T13:56:05Z","author_association":"NONE","body":"@cgivre yes, we have checked it as well.\r\n\r\nIn `s3 storage plugin`, after setting `\"writable\"` param from `/` to `/any-subdirectory`, and then it worked well.\r\n```\r\n  \"workspaces\": {\r\n    \"root\": {\r\n      \"location\": \"/save\",\r\n      \"writable\": true,\r\n      \"defaultInputFormat\": null,\r\n      \"allowAccessOutsideWorkspace\": false\r\n    }\r\n  },\r\n```","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2340878456/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2352303815","html_url":"https://github.com/apache/drill/issues/2942#issuecomment-2352303815","issue_url":"https://api.github.com/repos/apache/drill/issues/2942","id":2352303815,"node_id":"IC_kwDOAFa5xc6MNU7H","user":{"login":"mathieuruellan","id":1267936,"node_id":"MDQ6VXNlcjEyNjc5MzY=","avatar_url":"https://avatars.githubusercontent.com/u/1267936?v=4","gravatar_id":"","url":"https://api.github.com/users/mathieuruellan","html_url":"https://github.com/mathieuruellan","followers_url":"https://api.github.com/users/mathieuruellan/followers","following_url":"https://api.github.com/users/mathieuruellan/following{/other_user}","gists_url":"https://api.github.com/users/mathieuruellan/gists{/gist_id}","starred_url":"https://api.github.com/users/mathieuruellan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mathieuruellan/subscriptions","organizations_url":"https://api.github.com/users/mathieuruellan/orgs","repos_url":"https://api.github.com/users/mathieuruellan/repos","events_url":"https://api.github.com/users/mathieuruellan/events{/privacy}","received_events_url":"https://api.github.com/users/mathieuruellan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-16T08:32:23Z","updated_at":"2024-09-16T08:32:23Z","author_association":"NONE","body":"(the screenshot has a typo with a missing quote), but the issue is still valid","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2352303815/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2353103517","html_url":"https://github.com/apache/drill/issues/2942#issuecomment-2353103517","issue_url":"https://api.github.com/repos/apache/drill/issues/2942","id":2353103517,"node_id":"IC_kwDOAFa5xc6MQYKd","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-16T14:33:55Z","updated_at":"2024-09-16T14:33:55Z","author_association":"CONTRIBUTOR","body":"@mathieuruellan  I think the `batchSize` is not a valid parameter.  Try removing that and see if it works.   The problem that you're having is that you've added some parameter that doesn't exist in the Mongo config.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2353103517/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2353155330","html_url":"https://github.com/apache/drill/issues/2942#issuecomment-2353155330","issue_url":"https://api.github.com/repos/apache/drill/issues/2942","id":2353155330,"node_id":"IC_kwDOAFa5xc6MQk0C","user":{"login":"mathieuruellan","id":1267936,"node_id":"MDQ6VXNlcjEyNjc5MzY=","avatar_url":"https://avatars.githubusercontent.com/u/1267936?v=4","gravatar_id":"","url":"https://api.github.com/users/mathieuruellan","html_url":"https://github.com/mathieuruellan","followers_url":"https://api.github.com/users/mathieuruellan/followers","following_url":"https://api.github.com/users/mathieuruellan/following{/other_user}","gists_url":"https://api.github.com/users/mathieuruellan/gists{/gist_id}","starred_url":"https://api.github.com/users/mathieuruellan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mathieuruellan/subscriptions","organizations_url":"https://api.github.com/users/mathieuruellan/orgs","repos_url":"https://api.github.com/users/mathieuruellan/repos","events_url":"https://api.github.com/users/mathieuruellan/events{/privacy}","received_events_url":"https://api.github.com/users/mathieuruellan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-16T14:53:15Z","updated_at":"2024-09-16T14:54:43Z","author_association":"NONE","body":"@cgivre thank you for your answer. It changes nothing, and i can't make it work with batchsize.\r\n\r\n![image](https://github.com/user-attachments/assets/757e0146-e72a-4f47-ac45-b358f397e613)\r\n\r\nThe same without query parameters is ok:\r\n\r\n![image](https://github.com/user-attachments/assets/fabe8052-334b-4622-8a20-6ef01a48fea8)\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2353155330/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2353278916","html_url":"https://github.com/apache/drill/issues/2942#issuecomment-2353278916","issue_url":"https://api.github.com/repos/apache/drill/issues/2942","id":2353278916,"node_id":"IC_kwDOAFa5xc6MRC_E","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-16T15:42:32Z","updated_at":"2024-09-16T15:42:32Z","author_association":"CONTRIBUTOR","body":"@mathieuruellan Sorry.. I haven't worked with Drill and Mongo in some time.   Let's try a few things:\r\n1. Execute the command `!verbose` in Drill's command line and see what kind of errors we're getting.  \r\n2. It looks like the issue is in the connection string and that Drill or Mongo isn't liking one of the arguments.  Can you try adding the arguments one by one to see if it is a specific argument that Drill isn't liking or whether Drill isn't liking the options at all.  Ideally, what I'm hoping we can get is a stack trace in the CLI that is more helpful than the crappy error message in the user interface.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2353278916/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2354869087","html_url":"https://github.com/apache/drill/issues/2942#issuecomment-2354869087","issue_url":"https://api.github.com/repos/apache/drill/issues/2942","id":2354869087,"node_id":"IC_kwDOAFa5xc6MXHNf","user":{"login":"mathieuruellan","id":1267936,"node_id":"MDQ6VXNlcjEyNjc5MzY=","avatar_url":"https://avatars.githubusercontent.com/u/1267936?v=4","gravatar_id":"","url":"https://api.github.com/users/mathieuruellan","html_url":"https://github.com/mathieuruellan","followers_url":"https://api.github.com/users/mathieuruellan/followers","following_url":"https://api.github.com/users/mathieuruellan/following{/other_user}","gists_url":"https://api.github.com/users/mathieuruellan/gists{/gist_id}","starred_url":"https://api.github.com/users/mathieuruellan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mathieuruellan/subscriptions","organizations_url":"https://api.github.com/users/mathieuruellan/orgs","repos_url":"https://api.github.com/users/mathieuruellan/repos","events_url":"https://api.github.com/users/mathieuruellan/events{/privacy}","received_events_url":"https://api.github.com/users/mathieuruellan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-17T08:25:01Z","updated_at":"2024-09-17T08:25:01Z","author_association":"NONE","body":"Actually, it was a specific parameter \"authMechanism=DEFAULT\" not supported because the driver and its mongo url parser is old.\r\nProblem solved. \r\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2354869087/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2357717410","html_url":"https://github.com/apache/drill/issues/2552#issuecomment-2357717410","issue_url":"https://api.github.com/repos/apache/drill/issues/2552","id":2357717410,"node_id":"IC_kwDOAFa5xc6Mh-mi","user":{"login":"qwertychouskie","id":13989090,"node_id":"MDQ6VXNlcjEzOTg5MDkw","avatar_url":"https://avatars.githubusercontent.com/u/13989090?v=4","gravatar_id":"","url":"https://api.github.com/users/qwertychouskie","html_url":"https://github.com/qwertychouskie","followers_url":"https://api.github.com/users/qwertychouskie/followers","following_url":"https://api.github.com/users/qwertychouskie/following{/other_user}","gists_url":"https://api.github.com/users/qwertychouskie/gists{/gist_id}","starred_url":"https://api.github.com/users/qwertychouskie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwertychouskie/subscriptions","organizations_url":"https://api.github.com/users/qwertychouskie/orgs","repos_url":"https://api.github.com/users/qwertychouskie/repos","events_url":"https://api.github.com/users/qwertychouskie/events{/privacy}","received_events_url":"https://api.github.com/users/qwertychouskie/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-18T07:32:40Z","updated_at":"2024-09-18T07:32:40Z","author_association":"NONE","body":"@jnturton Just a heads-up, although the new release is published, for some reason GitHub doesn't show it as the current active release, it's pretty minor but probably worth fixing.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2357717410/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2358242472","html_url":"https://github.com/apache/drill/issues/2552#issuecomment-2358242472","issue_url":"https://api.github.com/repos/apache/drill/issues/2552","id":2358242472,"node_id":"IC_kwDOAFa5xc6Mj-yo","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-18T11:42:16Z","updated_at":"2024-09-18T11:42:16Z","author_association":"CONTRIBUTOR","body":"@qwertychouskie thank you, fixed.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2358242472/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2362833617","html_url":"https://github.com/apache/drill/pull/2943#issuecomment-2362833617","issue_url":"https://api.github.com/repos/apache/drill/issues/2943","id":2362833617,"node_id":"IC_kwDOAFa5xc6M1frR","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-20T05:06:53Z","updated_at":"2024-09-20T05:06:53Z","author_association":"CONTRIBUTOR","body":"@rymarm, thanks for finding this issue. I believe your fix is correct. The `prepareWrite()` call exists to fill any remaining bits with 0s (i.e. \"fill empties.\"). The number to be filled is, indeed, `valueCount - 1`. So, I _think_ this is a good fix.\r\n\r\nI would feel more confident if we had a unit test. That this bug exists suggests that, despite the rather excessive number of tests I wrote way back when, I somehow omitted this case. Perhaps a reason is that the bit vector is special: it uses code different than the other vectors, and so needs its own tests. Tests for the fixed-width vectors are in `TestFixedWidthWriter` and `TestFillEmpties`. Perhaps you can whip up a `TestBitVector` that does a few tests, including for the special case you uncovered. In particular, it would be good to make sure that the following cases work:\r\n\r\n* Write some values to the bit vector to simulate the first few records setting the bits.\r\n* Claim that the batch has ended and the batch wrote a bunch of other records without writing to the bit vector.\r\n* Call `setValueCount()` with a number that is a multiple of 8, a multiple of 8 plus one, and a multiple of 8 minus one. (three cases)\r\n* Do this also so the value count/8 equals the initial allocation size, is below that size, or is above that size (three cases)\r\n\r\nThis gives us 9 cases, some that will force a resize, some that should just fit in the initial allocation.\r\n\r\nThen, read the bits out of the vector, verifying that the \"empty\" bits are the `defaultValue` (the \"default default\" is 0).\r\n\r\nWhy write tests? It is less embarrassing for a test to point out a problem than to find it in a production system. I apologize that I somehow missed doing the tests in the first place.\r\n\r\nThe second concern is whether this same error was made for other writers. The answer seems to be \"no\": the other writers use a different structure for `setValueCount()`. As the comment in `BitColumnWriter` says, it is the only vector that defers to the mechanism in the vector's own mutator. The result is that the bit vector code differs from the other vectors which handle the entire write process themselves.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2362833617/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2368315909","html_url":"https://github.com/apache/drill/pull/2943#issuecomment-2368315909","issue_url":"https://api.github.com/repos/apache/drill/issues/2943","id":2368315909,"node_id":"IC_kwDOAFa5xc6NKaIF","user":{"login":"rymarm","id":62295633,"node_id":"MDQ6VXNlcjYyMjk1NjMz","avatar_url":"https://avatars.githubusercontent.com/u/62295633?v=4","gravatar_id":"","url":"https://api.github.com/users/rymarm","html_url":"https://github.com/rymarm","followers_url":"https://api.github.com/users/rymarm/followers","following_url":"https://api.github.com/users/rymarm/following{/other_user}","gists_url":"https://api.github.com/users/rymarm/gists{/gist_id}","starred_url":"https://api.github.com/users/rymarm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymarm/subscriptions","organizations_url":"https://api.github.com/users/rymarm/orgs","repos_url":"https://api.github.com/users/rymarm/repos","events_url":"https://api.github.com/users/rymarm/events{/privacy}","received_events_url":"https://api.github.com/users/rymarm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-23T13:45:10Z","updated_at":"2024-09-23T13:45:10Z","author_association":"MEMBER","body":"@paul-rogers thank you so much for the review! I found and fixed one mistake which the failed tests highlighted already and will write additional tests for the cases you described.   \r\n\r\nI agree that test-driven development is much safer and better than a simple fix without test coverage of the affected place. It is just hard to me to write tests for Drill, they looks complicated and not isolated to me. But I'll write them. ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2368315909/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2369269842","html_url":"https://github.com/apache/drill/pull/2943#issuecomment-2369269842","issue_url":"https://api.github.com/repos/apache/drill/issues/2943","id":2369269842,"node_id":"IC_kwDOAFa5xc6NODBS","user":{"login":"paul-rogers","id":3248881,"node_id":"MDQ6VXNlcjMyNDg4ODE=","avatar_url":"https://avatars.githubusercontent.com/u/3248881?v=4","gravatar_id":"","url":"https://api.github.com/users/paul-rogers","html_url":"https://github.com/paul-rogers","followers_url":"https://api.github.com/users/paul-rogers/followers","following_url":"https://api.github.com/users/paul-rogers/following{/other_user}","gists_url":"https://api.github.com/users/paul-rogers/gists{/gist_id}","starred_url":"https://api.github.com/users/paul-rogers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/paul-rogers/subscriptions","organizations_url":"https://api.github.com/users/paul-rogers/orgs","repos_url":"https://api.github.com/users/paul-rogers/repos","events_url":"https://api.github.com/users/paul-rogers/events{/privacy}","received_events_url":"https://api.github.com/users/paul-rogers/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-23T20:07:42Z","updated_at":"2024-09-23T20:07:42Z","author_association":"CONTRIBUTOR","body":"@rymarm, thanks for looking at the tests. While writing tests for Drill can be hard, we developed a bunch of tools for particular cases. In the case of the vector writers, those tests I referenced above should show you what to do.\r\n\r\nWhat I did, back when I wrote this stuff, is to run the tests in my IDE. I've not had much luck in recent years running the whole unit test suite locally. But, I can still generally run individual unit tests. A handy way to proceed is to first create a new file that has the test frameworks included. Then, write one simple test that just writes to the vector and reads back the data. At that point, it should be clear how to create other cases.\r\n\r\nIt would be great to temporarily revert your change and create a case that fails, then restore the change and ensure things work.\r\n\r\nPlease let me know if creating the tests takes more than a small amount of time. I can perhaps help out by creating a basic bit vector use case (if I can remember how all that code works!)","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2369269842/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2369392723","html_url":"https://github.com/apache/drill/pull/2943#issuecomment-2369392723","issue_url":"https://api.github.com/repos/apache/drill/issues/2943","id":2369392723,"node_id":"IC_kwDOAFa5xc6NOhBT","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-23T21:09:14Z","updated_at":"2024-09-23T21:09:14Z","author_association":"CONTRIBUTOR","body":"Just an FYI, but the Github actions are not working well at the moment.  The two that use Hadoop 2 seem to have some connectivity issue with Hive.  @jnturton is working on it. ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2369392723/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2372234460","html_url":"https://github.com/apache/drill/pull/2944#issuecomment-2372234460","issue_url":"https://api.github.com/repos/apache/drill/issues/2944","id":2372234460,"node_id":"IC_kwDOAFa5xc6NZWzc","user":{"login":"rymarm","id":62295633,"node_id":"MDQ6VXNlcjYyMjk1NjMz","avatar_url":"https://avatars.githubusercontent.com/u/62295633?v=4","gravatar_id":"","url":"https://api.github.com/users/rymarm","html_url":"https://github.com/rymarm","followers_url":"https://api.github.com/users/rymarm/followers","following_url":"https://api.github.com/users/rymarm/following{/other_user}","gists_url":"https://api.github.com/users/rymarm/gists{/gist_id}","starred_url":"https://api.github.com/users/rymarm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymarm/subscriptions","organizations_url":"https://api.github.com/users/rymarm/orgs","repos_url":"https://api.github.com/users/rymarm/repos","events_url":"https://api.github.com/users/rymarm/events{/privacy}","received_events_url":"https://api.github.com/users/rymarm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-24T19:46:11Z","updated_at":"2024-09-24T19:46:11Z","author_association":"MEMBER","body":"@jnturton I'm unsure whether the fix is correct because calcite is a black box to me, but I think I found the correct place where the change should be made.\r\n\r\nI'll be glad if you advise me on how to cover the case with unit tests. ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2372234460/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2375207955","html_url":"https://github.com/apache/drill/pull/2944#issuecomment-2375207955","issue_url":"https://api.github.com/repos/apache/drill/issues/2944","id":2375207955,"node_id":"IC_kwDOAFa5xc6NkswT","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-25T20:37:14Z","updated_at":"2024-09-25T20:37:14Z","author_association":"CONTRIBUTOR","body":"> @jnturton I'm unsure whether the fix is correct because calcite is a black box to me, but I think I found the correct place where the change should be made.\r\n> \r\n> I'll be glad if you advise me on how to cover the case with unit tests.\r\n\r\nYou're not the only one to whom Calcite is a black box... :-)","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2375207955/reactions","total_count":1,"+1":0,"-1":0,"laugh":1,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2376185364","html_url":"https://github.com/apache/drill/pull/2944#issuecomment-2376185364","issue_url":"https://api.github.com/repos/apache/drill/issues/2944","id":2376185364,"node_id":"IC_kwDOAFa5xc6NobYU","user":{"login":"rymarm","id":62295633,"node_id":"MDQ6VXNlcjYyMjk1NjMz","avatar_url":"https://avatars.githubusercontent.com/u/62295633?v=4","gravatar_id":"","url":"https://api.github.com/users/rymarm","html_url":"https://github.com/rymarm","followers_url":"https://api.github.com/users/rymarm/followers","following_url":"https://api.github.com/users/rymarm/following{/other_user}","gists_url":"https://api.github.com/users/rymarm/gists{/gist_id}","starred_url":"https://api.github.com/users/rymarm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rymarm/subscriptions","organizations_url":"https://api.github.com/users/rymarm/orgs","repos_url":"https://api.github.com/users/rymarm/repos","events_url":"https://api.github.com/users/rymarm/events{/privacy}","received_events_url":"https://api.github.com/users/rymarm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-26T07:50:36Z","updated_at":"2024-09-26T07:50:36Z","author_association":"MEMBER","body":"I saw the failing tests. I need to find another solution to solve the issue...","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2376185364/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2378914803","html_url":"https://github.com/apache/drill/pull/2945#issuecomment-2378914803","issue_url":"https://api.github.com/repos/apache/drill/issues/2945","id":2378914803,"node_id":"IC_kwDOAFa5xc6Ny1vz","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-09-27T10:02:52Z","updated_at":"2024-09-27T10:02:52Z","author_association":"CONTRIBUTOR","body":"Test failures caused by:\r\n\r\n```\r\norg.testcontainers.containers.ContainerLaunchException: Container startup failed for image mcr.microsoft.com/mssql/server:2017-CU12\r\n\tat org.testcontainers.containers.GenericContainer.doStart(GenericContainer.java:349)\r\n\tat org.testcontainers.containers.GenericContainer.start(GenericContainer.java:322)\r\n\tat org.apache.drill.exec.store.jdbc.TestJdbcPluginWithMSSQL.initMSSQL(TestJdbcPluginWithMSSQL.java:68)\r\nCaused by: org.rnorth.ducttape.RetryCountExceededException: Retry limit hit with exception\r\n\tat org.rnorth.ducttape.unreliables.Unreliables.retryUntilSuccess(Unreliables.java:88)\r\n\tat org.testcontainers.containers.GenericContainer.doStart(GenericContainer.java:334)\r\n\t... 2 more\r\n```","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2378914803/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2393552001","html_url":"https://github.com/apache/drill/pull/2935#issuecomment-2393552001","issue_url":"https://api.github.com/repos/apache/drill/issues/2935","id":2393552001,"node_id":"IC_kwDOAFa5xc6OqrSB","user":{"login":"martingaleano","id":11686779,"node_id":"MDQ6VXNlcjExNjg2Nzc5","avatar_url":"https://avatars.githubusercontent.com/u/11686779?v=4","gravatar_id":"","url":"https://api.github.com/users/martingaleano","html_url":"https://github.com/martingaleano","followers_url":"https://api.github.com/users/martingaleano/followers","following_url":"https://api.github.com/users/martingaleano/following{/other_user}","gists_url":"https://api.github.com/users/martingaleano/gists{/gist_id}","starred_url":"https://api.github.com/users/martingaleano/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/martingaleano/subscriptions","organizations_url":"https://api.github.com/users/martingaleano/orgs","repos_url":"https://api.github.com/users/martingaleano/repos","events_url":"https://api.github.com/users/martingaleano/events{/privacy}","received_events_url":"https://api.github.com/users/martingaleano/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-04T12:05:11Z","updated_at":"2024-10-04T12:05:11Z","author_association":"NONE","body":"Hi @cgivre , thanks for adding this change! I really need it. I've noticed that this is not included in the docker versions yet (I mean, there isn't any release), do you know when I can run the docker image with your changes?\r\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2393552001/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2395415101","html_url":"https://github.com/apache/drill/pull/2935#issuecomment-2395415101","issue_url":"https://api.github.com/repos/apache/drill/issues/2935","id":2395415101,"node_id":"IC_kwDOAFa5xc6OxyI9","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-06T12:07:29Z","updated_at":"2024-10-06T12:07:29Z","author_association":"CONTRIBUTOR","body":"@martingaleano we publish Docker images that track the Drill master branch. Anything [tagged with \"master\" here](https://hub.docker.com/r/apache/drill/tags).","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2395415101/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2399450192","html_url":"https://github.com/apache/drill/pull/2946#issuecomment-2399450192","issue_url":"https://api.github.com/repos/apache/drill/issues/2946","id":2399450192,"node_id":"IC_kwDOAFa5xc6PBLRQ","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-08T10:19:20Z","updated_at":"2024-10-08T10:19:20Z","author_association":"CONTRIBUTOR","body":"same test issue as https://github.com/apache/drill/pull/2945#issuecomment-2378914803","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2399450192/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2400307909","html_url":"https://github.com/apache/drill/issues/2947#issuecomment-2400307909","issue_url":"https://api.github.com/repos/apache/drill/issues/2947","id":2400307909,"node_id":"IC_kwDOAFa5xc6PEcrF","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-08T16:17:28Z","updated_at":"2024-10-08T16:17:28Z","author_association":"CONTRIBUTOR","body":"@pjfanning We could run these tests manually.  ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2400307909/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2400861426","html_url":"https://github.com/apache/drill/issues/2947#issuecomment-2400861426","issue_url":"https://api.github.com/repos/apache/drill/issues/2947","id":2400861426,"node_id":"IC_kwDOAFa5xc6PGjzy","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-08T21:33:06Z","updated_at":"2024-10-08T21:33:06Z","author_association":"CONTRIBUTOR","body":"I get the same problem if I run this test on my laptop.\r\n\r\nWould it be possible to disable the test until someone with experience of setting up MS-SQL (specifically containerised versions of it) has a chance to look into it?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2400861426/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2400887859","html_url":"https://github.com/apache/drill/issues/2947#issuecomment-2400887859","issue_url":"https://api.github.com/repos/apache/drill/issues/2947","id":2400887859,"node_id":"IC_kwDOAFa5xc6PGqQz","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-08T21:53:34Z","updated_at":"2024-10-08T21:53:34Z","author_association":"CONTRIBUTOR","body":"> I get the same problem if I run this test on my laptop.\r\n> \r\n> Would it be possible to disable the test until someone with experience of setting up MS-SQL (specifically containerised versions of it) has a chance to look into it?\r\n\r\nI'm remembering this... I only have ARM systems and there isn't a MSSQL docker container for that.  I'm fine with disabling the MSSQL tests.   @jnturton what do you think?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2400887859/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2401330392","html_url":"https://github.com/apache/drill/issues/2947#issuecomment-2401330392","issue_url":"https://api.github.com/repos/apache/drill/issues/2947","id":2401330392,"node_id":"IC_kwDOAFa5xc6PIWTY","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-09T05:11:45Z","updated_at":"2024-10-09T12:26:40Z","author_association":"CONTRIBUTOR","body":"It looks like [this is the underlying problem](https://github.com/microsoft/mssql-docker/issues/868). I could resolve that by upgrading the MSSQL container but that brought two smaller, unrelated issues of its own so I also had to disable two MSSQL tests. ~~Patch attached~~. PR #2948 opened.\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2401330392/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2402943730","html_url":"https://github.com/apache/drill/pull/2946#issuecomment-2402943730","issue_url":"https://api.github.com/repos/apache/drill/issues/2946","id":2402943730,"node_id":"IC_kwDOAFa5xc6POgLy","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-09T17:54:56Z","updated_at":"2024-10-09T17:54:56Z","author_association":"CONTRIBUTOR","body":"@dependabot rebase","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2402943730/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2402944532","html_url":"https://github.com/apache/drill/pull/2945#issuecomment-2402944532","issue_url":"https://api.github.com/repos/apache/drill/issues/2945","id":2402944532,"node_id":"IC_kwDOAFa5xc6POgYU","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-09T17:55:24Z","updated_at":"2024-10-09T17:55:24Z","author_association":"CONTRIBUTOR","body":"@dependabot rebase","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2402944532/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2402944658","html_url":"https://github.com/apache/drill/pull/2945#issuecomment-2402944658","issue_url":"https://api.github.com/repos/apache/drill/issues/2945","id":2402944658,"node_id":"IC_kwDOAFa5xc6POgaS","user":{"login":"dependabot[bot]","id":49699333,"node_id":"MDM6Qm90NDk2OTkzMzM=","avatar_url":"https://avatars.githubusercontent.com/in/29110?v=4","gravatar_id":"","url":"https://api.github.com/users/dependabot%5Bbot%5D","html_url":"https://github.com/apps/dependabot","followers_url":"https://api.github.com/users/dependabot%5Bbot%5D/followers","following_url":"https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dependabot%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/dependabot%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/dependabot%5Bbot%5D/repos","events_url":"https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/dependabot%5Bbot%5D/received_events","type":"Bot","user_view_type":"public","site_admin":false},"created_at":"2024-10-09T17:55:28Z","updated_at":"2024-10-09T17:55:28Z","author_association":"CONTRIBUTOR","body":"Looks like this PR has been edited by someone other than Dependabot. That means Dependabot can't rebase it - sorry!\n\nIf you're happy for Dependabot to recreate it from scratch, overwriting any edits, you can request `@dependabot recreate`.\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2402944658/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":{"id":29110,"client_id":"Iv1.4f9a6346434f815e","slug":"dependabot","node_id":"MDM6QXBwMjkxMTA=","owner":{"login":"github","id":9919,"node_id":"MDEyOk9yZ2FuaXphdGlvbjk5MTk=","avatar_url":"https://avatars.githubusercontent.com/u/9919?v=4","gravatar_id":"","url":"https://api.github.com/users/github","html_url":"https://github.com/github","followers_url":"https://api.github.com/users/github/followers","following_url":"https://api.github.com/users/github/following{/other_user}","gists_url":"https://api.github.com/users/github/gists{/gist_id}","starred_url":"https://api.github.com/users/github/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/github/subscriptions","organizations_url":"https://api.github.com/users/github/orgs","repos_url":"https://api.github.com/users/github/repos","events_url":"https://api.github.com/users/github/events{/privacy}","received_events_url":"https://api.github.com/users/github/received_events","type":"Organization","user_view_type":"public","site_admin":false},"name":"Dependabot","description":"","external_url":"https://dependabot-api.githubapp.com","html_url":"https://github.com/apps/dependabot","created_at":"2019-04-16T22:34:25Z","updated_at":"2024-03-20T21:06:35Z","permissions":{"actions":"read","checks":"write","contents":"write","issues":"write","members":"read","metadata":"read","pull_requests":"write","statuses":"read","vulnerability_alerts":"read","workflows":"write"},"events":["check_suite","issues","issue_comment","label","pull_request","pull_request_review","pull_request_review_comment","repository"]}},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2402956555","html_url":"https://github.com/apache/drill/pull/2945#issuecomment-2402956555","issue_url":"https://api.github.com/repos/apache/drill/issues/2945","id":2402956555,"node_id":"IC_kwDOAFa5xc6POjUL","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-09T18:02:10Z","updated_at":"2024-10-09T18:02:10Z","author_association":"CONTRIBUTOR","body":"@cgivre Dependabot says no to rebase, I can rebase and force push.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2402956555/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2403287490","html_url":"https://github.com/apache/drill/pull/2945#issuecomment-2403287490","issue_url":"https://api.github.com/repos/apache/drill/issues/2945","id":2403287490,"node_id":"IC_kwDOAFa5xc6PP0HC","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-09T19:35:39Z","updated_at":"2024-10-09T19:35:39Z","author_association":"CONTRIBUTOR","body":"Looks like we need more changes.\r\n\r\n```\r\nDownloaded from central: https://repo.maven.apache.org/maven2/org/codehaus/plexus/plexus-utils/3.0/plexus-utils-3.0.jar (226 kB at 1.9 MB/s)\r\n[INFO] Protobuf dependency version 3.25.5\r\n[INFO] 'protoc' executable version 3.16.3\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD FAILURE\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time:  12.972 s\r\n[INFO] Finished at: 2024-10-09T18:21:13Z\r\n[INFO] ------------------------------------------------------------------------\r\nError:  Failed to execute goal com.github.igor-petruk.protobuf:protobuf-maven-plugin:0.6.5:run (default) on project drill-protocol: Protobuf installation version does not match Protobuf library version -> [Help 1]\r\n```","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2403287490/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2407477598","html_url":"https://github.com/apache/drill/issues/2950#issuecomment-2407477598","issue_url":"https://api.github.com/repos/apache/drill/issues/2950","id":2407477598,"node_id":"IC_kwDOAFa5xc6PfzFe","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-11T13:59:19Z","updated_at":"2024-10-11T13:59:19Z","author_association":"CONTRIBUTOR","body":"@ionutpopa \r\nPerhaps a little politeness might go a bit further.   Please understand that Drill is developed and maintained by volunteers who are not paid for their time.   If this is really important to you than you could either volunteer to assist, pay someone to do it, or simply ask nicely. ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2407477598/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2407599690","html_url":"https://github.com/apache/drill/issues/2950#issuecomment-2407599690","issue_url":"https://api.github.com/repos/apache/drill/issues/2950","id":2407599690,"node_id":"IC_kwDOAFa5xc6PgQ5K","user":{"login":"tdunning","id":250490,"node_id":"MDQ6VXNlcjI1MDQ5MA==","avatar_url":"https://avatars.githubusercontent.com/u/250490?v=4","gravatar_id":"","url":"https://api.github.com/users/tdunning","html_url":"https://github.com/tdunning","followers_url":"https://api.github.com/users/tdunning/followers","following_url":"https://api.github.com/users/tdunning/following{/other_user}","gists_url":"https://api.github.com/users/tdunning/gists{/gist_id}","starred_url":"https://api.github.com/users/tdunning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tdunning/subscriptions","organizations_url":"https://api.github.com/users/tdunning/orgs","repos_url":"https://api.github.com/users/tdunning/repos","events_url":"https://api.github.com/users/tdunning/events{/privacy}","received_events_url":"https://api.github.com/users/tdunning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-11T15:01:02Z","updated_at":"2024-10-11T15:01:02Z","author_association":"CONTRIBUTOR","body":"Of course, @ionutpopa is correct. Running a project with all volunteers is not an optimal process in terms of getting everything done. Running it with an infinite budget close source development team would be much more \"optimal\".\r\n\r\nBut @cgivre is even more correct. Drill enables freedom. If you want it, feel free to make it so. It may be no more than a one line patch to the CICD scripts.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2407599690/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2407638772","html_url":"https://github.com/apache/drill/issues/2950#issuecomment-2407638772","issue_url":"https://api.github.com/repos/apache/drill/issues/2950","id":2407638772,"node_id":"IC_kwDOAFa5xc6Pgab0","user":{"login":"ionutpopa","id":6348422,"node_id":"MDQ6VXNlcjYzNDg0MjI=","avatar_url":"https://avatars.githubusercontent.com/u/6348422?v=4","gravatar_id":"","url":"https://api.github.com/users/ionutpopa","html_url":"https://github.com/ionutpopa","followers_url":"https://api.github.com/users/ionutpopa/followers","following_url":"https://api.github.com/users/ionutpopa/following{/other_user}","gists_url":"https://api.github.com/users/ionutpopa/gists{/gist_id}","starred_url":"https://api.github.com/users/ionutpopa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ionutpopa/subscriptions","organizations_url":"https://api.github.com/users/ionutpopa/orgs","repos_url":"https://api.github.com/users/ionutpopa/repos","events_url":"https://api.github.com/users/ionutpopa/events{/privacy}","received_events_url":"https://api.github.com/users/ionutpopa/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-11T15:20:41Z","updated_at":"2024-10-11T15:20:41Z","author_association":"NONE","body":"Ok, I'll give a look on the CI/CD scripts later and what's there but first I'll probably search for a developer notice before doing anything.\r\nSorry for earlier, I get angry when I see old tickets.\r\n@tdunning you're talking about the workflows folder inside .github, am I right?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2407638772/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2407735576","html_url":"https://github.com/apache/drill/issues/2950#issuecomment-2407735576","issue_url":"https://api.github.com/repos/apache/drill/issues/2950","id":2407735576,"node_id":"IC_kwDOAFa5xc6PgyEY","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-11T16:17:41Z","updated_at":"2024-10-11T16:17:41Z","author_association":"CONTRIBUTOR","body":"@ionutpopa No worries.  We welcome any help you can provide.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2407735576/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2407826244","html_url":"https://github.com/apache/drill/issues/2950#issuecomment-2407826244","issue_url":"https://api.github.com/repos/apache/drill/issues/2950","id":2407826244,"node_id":"IC_kwDOAFa5xc6PhINE","user":{"login":"tdunning","id":250490,"node_id":"MDQ6VXNlcjI1MDQ5MA==","avatar_url":"https://avatars.githubusercontent.com/u/250490?v=4","gravatar_id":"","url":"https://api.github.com/users/tdunning","html_url":"https://github.com/tdunning","followers_url":"https://api.github.com/users/tdunning/followers","following_url":"https://api.github.com/users/tdunning/following{/other_user}","gists_url":"https://api.github.com/users/tdunning/gists{/gist_id}","starred_url":"https://api.github.com/users/tdunning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tdunning/subscriptions","organizations_url":"https://api.github.com/users/tdunning/orgs","repos_url":"https://api.github.com/users/tdunning/repos","events_url":"https://api.github.com/users/tdunning/events{/privacy}","received_events_url":"https://api.github.com/users/tdunning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-11T17:15:37Z","updated_at":"2024-10-11T17:15:37Z","author_association":"CONTRIBUTOR","body":"@ionutpopa That is what I would have expected, but I don't see docker image packaging there.\r\n\r\nThere is likely another workflow that is part of cutting a release that generates the docker image. I have no idea where that might be. @cgivre should know more.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2407826244/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2408341215","html_url":"https://github.com/apache/drill/issues/2950#issuecomment-2408341215","issue_url":"https://api.github.com/repos/apache/drill/issues/2950","id":2408341215,"node_id":"IC_kwDOAFa5xc6PjF7f","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-12T04:01:17Z","updated_at":"2024-10-12T04:01:17Z","author_association":"CONTRIBUTOR","body":"@ionutpopa the Docker image builds themselves happen in Docker Hub but we have custom \"hooks\" in Drill source repo, see the file hooks/build. Let's try introducing something like `--platform linux/amd64,linux/arm64`.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2408341215/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2408434490","html_url":"https://github.com/apache/drill/issues/2950#issuecomment-2408434490","issue_url":"https://api.github.com/repos/apache/drill/issues/2950","id":2408434490,"node_id":"IC_kwDOAFa5xc6Pjcs6","user":{"login":"ionutpopa","id":6348422,"node_id":"MDQ6VXNlcjYzNDg0MjI=","avatar_url":"https://avatars.githubusercontent.com/u/6348422?v=4","gravatar_id":"","url":"https://api.github.com/users/ionutpopa","html_url":"https://github.com/ionutpopa","followers_url":"https://api.github.com/users/ionutpopa/followers","following_url":"https://api.github.com/users/ionutpopa/following{/other_user}","gists_url":"https://api.github.com/users/ionutpopa/gists{/gist_id}","starred_url":"https://api.github.com/users/ionutpopa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ionutpopa/subscriptions","organizations_url":"https://api.github.com/users/ionutpopa/orgs","repos_url":"https://api.github.com/users/ionutpopa/repos","events_url":"https://api.github.com/users/ionutpopa/events{/privacy}","received_events_url":"https://api.github.com/users/ionutpopa/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-12T07:16:08Z","updated_at":"2024-10-12T07:16:08Z","author_association":"NONE","body":"Hello everyone, I am curious why I am getting an error saying I don't have permissions to push branch to apache/drill. Can someone help with that regard?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2408434490/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2408507456","html_url":"https://github.com/apache/drill/issues/2950#issuecomment-2408507456","issue_url":"https://api.github.com/repos/apache/drill/issues/2950","id":2408507456,"node_id":"IC_kwDOAFa5xc6PjuhA","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-12T10:07:46Z","updated_at":"2024-10-12T10:07:46Z","author_association":"CONTRIBUTOR","body":"Only members of the committers group have that permission. If you create a fork and open a PR to main repo then I can help with branches or tags in the main repo that will trigger image builds on Docker Hub for testing. Once we've got an arm64 image we're happy with we can merge your PR into master. When you open the PR please use the provided template to allocate this work to DRILL-8260.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2408507456/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2408875941","html_url":"https://github.com/apache/drill/issues/2950#issuecomment-2408875941","issue_url":"https://api.github.com/repos/apache/drill/issues/2950","id":2408875941,"node_id":"IC_kwDOAFa5xc6PlIel","user":{"login":"ionutpopa","id":6348422,"node_id":"MDQ6VXNlcjYzNDg0MjI=","avatar_url":"https://avatars.githubusercontent.com/u/6348422?v=4","gravatar_id":"","url":"https://api.github.com/users/ionutpopa","html_url":"https://github.com/ionutpopa","followers_url":"https://api.github.com/users/ionutpopa/followers","following_url":"https://api.github.com/users/ionutpopa/following{/other_user}","gists_url":"https://api.github.com/users/ionutpopa/gists{/gist_id}","starred_url":"https://api.github.com/users/ionutpopa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ionutpopa/subscriptions","organizations_url":"https://api.github.com/users/ionutpopa/orgs","repos_url":"https://api.github.com/users/ionutpopa/repos","events_url":"https://api.github.com/users/ionutpopa/events{/privacy}","received_events_url":"https://api.github.com/users/ionutpopa/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-13T08:09:52Z","updated_at":"2024-10-13T08:09:52Z","author_association":"NONE","body":"Tout va bien, opened a PR.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2408875941/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2409060532","html_url":"https://github.com/apache/drill/pull/2951#issuecomment-2409060532","issue_url":"https://api.github.com/repos/apache/drill/issues/2951","id":2409060532,"node_id":"IC_kwDOAFa5xc6Pl1i0","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-13T17:31:24Z","updated_at":"2024-10-13T17:31:24Z","author_association":"CONTRIBUTOR","body":"@ionutpopa Thanks for this.   Forgive the question as I'm not a Docker expert but do we need to add `windows/amd64`, and basically all other platforms that Drill should run on?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2409060532/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2409080353","html_url":"https://github.com/apache/drill/pull/2951#issuecomment-2409080353","issue_url":"https://api.github.com/repos/apache/drill/issues/2951","id":2409080353,"node_id":"IC_kwDOAFa5xc6Pl6Yh","user":{"login":"ionutpopa","id":6348422,"node_id":"MDQ6VXNlcjYzNDg0MjI=","avatar_url":"https://avatars.githubusercontent.com/u/6348422?v=4","gravatar_id":"","url":"https://api.github.com/users/ionutpopa","html_url":"https://github.com/ionutpopa","followers_url":"https://api.github.com/users/ionutpopa/followers","following_url":"https://api.github.com/users/ionutpopa/following{/other_user}","gists_url":"https://api.github.com/users/ionutpopa/gists{/gist_id}","starred_url":"https://api.github.com/users/ionutpopa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ionutpopa/subscriptions","organizations_url":"https://api.github.com/users/ionutpopa/orgs","repos_url":"https://api.github.com/users/ionutpopa/repos","events_url":"https://api.github.com/users/ionutpopa/events{/privacy}","received_events_url":"https://api.github.com/users/ionutpopa/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-13T18:35:30Z","updated_at":"2024-10-13T18:35:30Z","author_association":"NONE","body":"@cgivre IMHO we could keep only the linux platforms as the original docker works on Windows just fine.\r\nBut if we think about Drill as a software that we want to run on all platforms, maybe we need to add windows/amd64.\r\nWhat do you think?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2409080353/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2409676421","html_url":"https://github.com/apache/drill/pull/2951#issuecomment-2409676421","issue_url":"https://api.github.com/repos/apache/drill/issues/2951","id":2409676421,"node_id":"IC_kwDOAFa5xc6PoL6F","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-14T01:52:58Z","updated_at":"2024-10-14T01:52:58Z","author_association":"CONTRIBUTOR","body":"@ionutpopa \r\nPeople do run Drill on Windows.... As long as it works for them, I'm fine with keeping it as is.   @jnturton Do you have an opinion on this?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2409676421/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2409912000","html_url":"https://github.com/apache/drill/pull/2951#issuecomment-2409912000","issue_url":"https://api.github.com/repos/apache/drill/issues/2951","id":2409912000,"node_id":"IC_kwDOAFa5xc6PpFbA","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-14T04:17:40Z","updated_at":"2024-10-14T04:17:40Z","author_association":"CONTRIBUTOR","body":"The Linux container images will work for Windows users through WSL or Hyper-V which is how they must already be running most of their conatiners. Actually building [on a Windows container base image](https://hub.docker.com/r/microsoft/windows) would require deeper changes from us, I think, and someone would have to check the license to see whether we'd be free to redistribute the Microsoft binaries included as an Apache project.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2409912000/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2409927057","html_url":"https://github.com/apache/drill/pull/2951#issuecomment-2409927057","issue_url":"https://api.github.com/repos/apache/drill/issues/2951","id":2409927057,"node_id":"IC_kwDOAFa5xc6PpJGR","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-14T04:35:48Z","updated_at":"2024-10-14T04:35:48Z","author_association":"CONTRIBUTOR","body":"> The Linux container images will work for Windows users through WSL or Hyper-V which is how they must already be running most of their conatiners. Actually building [on a Windows container base image](https://hub.docker.com/r/microsoft/windows) would require deeper changes from us, I think, and someone would have to check the license to see whether we'd be free to redistribute the Microsoft binaries included as an Apache project.\r\n\r\nIn that case, LGTM +1","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2409927057/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2410157151","html_url":"https://github.com/apache/drill/pull/2951#issuecomment-2410157151","issue_url":"https://api.github.com/repos/apache/drill/issues/2951","id":2410157151,"node_id":"IC_kwDOAFa5xc6PqBRf","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-14T06:33:42Z","updated_at":"2024-10-14T06:33:42Z","author_association":"CONTRIBUTOR","body":"Marked as draft until we've triggered a test in Docker Hub (which I'll do).","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2410157151/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2411949281","html_url":"https://github.com/apache/drill/pull/2951#issuecomment-2411949281","issue_url":"https://api.github.com/repos/apache/drill/issues/2951","id":2411949281,"node_id":"IC_kwDOAFa5xc6Pw2zh","user":{"login":"ionutpopa","id":6348422,"node_id":"MDQ6VXNlcjYzNDg0MjI=","avatar_url":"https://avatars.githubusercontent.com/u/6348422?v=4","gravatar_id":"","url":"https://api.github.com/users/ionutpopa","html_url":"https://github.com/ionutpopa","followers_url":"https://api.github.com/users/ionutpopa/followers","following_url":"https://api.github.com/users/ionutpopa/following{/other_user}","gists_url":"https://api.github.com/users/ionutpopa/gists{/gist_id}","starred_url":"https://api.github.com/users/ionutpopa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ionutpopa/subscriptions","organizations_url":"https://api.github.com/users/ionutpopa/orgs","repos_url":"https://api.github.com/users/ionutpopa/repos","events_url":"https://api.github.com/users/ionutpopa/events{/privacy}","received_events_url":"https://api.github.com/users/ionutpopa/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-14T18:19:56Z","updated_at":"2024-10-14T18:19:56Z","author_association":"NONE","body":"@jnturton The ci/dockercloud-stage failed and when checking the details I saw `{\"error\": \"Our service is temporarily unavailable. We'll be back soon!\"}`, I guess that's fine?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2411949281/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2412977934","html_url":"https://github.com/apache/drill/pull/2951#issuecomment-2412977934","issue_url":"https://api.github.com/repos/apache/drill/issues/2951","id":2412977934,"node_id":"IC_kwDOAFa5xc6P0x8O","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-15T06:09:16Z","updated_at":"2024-10-15T06:11:40Z","author_association":"CONTRIBUTOR","body":"@ionutpopa, below is what happened in Docker Hub.\r\n\r\n```\r\n2024-10-14T06:58:22Z Executing build hook...\r\n2024-10-14T06:58:29Z ERROR: multiple platforms feature is currently not supported for docker driver. Please switch to a different driver (eg. \"docker buildx create --use\")\r\n```\r\n\r\nWe can read up on and try `docker buildx`. I have only skimmed the Internet but it sounds like it might resemble\r\n```\r\n# docker buildx create --use\r\ndocker buildx build --platform linux/amd64,linux/arm64\r\n```\r\n\r\nEDIT: I've commented out the `docker buildx create` command. That's meant to a once-off setup, and there's a chance it's already been done in Docker Hub and we don't need to run it at all.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2412977934/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2420485328","html_url":"https://github.com/apache/drill/issues/2920#issuecomment-2420485328","issue_url":"https://api.github.com/repos/apache/drill/issues/2920","id":2420485328,"node_id":"IC_kwDOAFa5xc6QRazQ","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-17T20:23:58Z","updated_at":"2024-10-17T20:23:58Z","author_association":"NONE","body":"how i feed in da input config for dis","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2420485328/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2422819670","html_url":"https://github.com/apache/drill/pull/2951#issuecomment-2422819670","issue_url":"https://api.github.com/repos/apache/drill/issues/2951","id":2422819670,"node_id":"IC_kwDOAFa5xc6QaUtW","user":{"login":"jnturton","id":9107319,"node_id":"MDQ6VXNlcjkxMDczMTk=","avatar_url":"https://avatars.githubusercontent.com/u/9107319?v=4","gravatar_id":"","url":"https://api.github.com/users/jnturton","html_url":"https://github.com/jnturton","followers_url":"https://api.github.com/users/jnturton/followers","following_url":"https://api.github.com/users/jnturton/following{/other_user}","gists_url":"https://api.github.com/users/jnturton/gists{/gist_id}","starred_url":"https://api.github.com/users/jnturton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jnturton/subscriptions","organizations_url":"https://api.github.com/users/jnturton/orgs","repos_url":"https://api.github.com/users/jnturton/repos","events_url":"https://api.github.com/users/jnturton/events{/privacy}","received_events_url":"https://api.github.com/users/jnturton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-18T16:16:29Z","updated_at":"2024-10-18T16:16:29Z","author_association":"CONTRIBUTOR","body":"I got a build going after putting `docker buildx create --use` back in. It appeared to make progress on two parallel builds but it got killed after running for 4 hours (see the final line below). We'll probably have to split things up differently and, given that Docker Hub access is required to see what does or doesn't work, I'll probably have to carry on with that in the 8260-arm64-image branch.\r\n\r\n```\r\n2024-10-18T12:06:49Z #21 1435.4 [output clipped, log limit 2MiB reached]\r\n2024-10-18T12:15:35Z #21 ...\r\n2024-10-18T12:15:35Z \r\n2024-10-18T12:15:35Z #20 [linux/amd64 build 4/5] RUN mvn clean install -DskipTests\r\n2024-10-18T12:15:35Z #20 DONE 1961.4s\r\n2024-10-18T12:15:35Z \r\n2024-10-18T12:15:35Z #22 [linux/amd64 build 5/5] RUN VERSION=$(mvn -q -Dexec.executable=echo -Dexec.args='${project.version}' --non-recursive exec:exec)  && mkdir /opt/drill  && mv distribution/target/apache-drill-${VERSION}/apache-drill-${VERSION}/* /opt/drill  && chmod -R +r /opt/drill\r\n2024-10-18T12:15:56Z #22 DONE 20.9s\r\n2024-10-18T12:15:56Z \r\n2024-10-18T12:15:56Z #21 [linux/arm64 build 4/5] RUN mvn clean install -DskipTests\r\n2024-10-18T12:15:57Z #21 ...\r\n2024-10-18T12:15:57Z \r\n2024-10-18T12:15:57Z #23 [linux/amd64 stage-1 3/3] COPY --from=build /opt/drill /opt/drill\r\n2024-10-18T12:16:01Z #23 DONE 3.6s\r\n2024-10-18T12:16:01Z \r\n2024-10-18T12:16:01Z #21 [linux/arm64 build 4/5] RUN mvn clean install -DskipTests\r\n2024-10-18T12:48:56Z #21 3962.5 Warning: Lookahead adequacy checking not being performed since option LOOKAHEAD is more than 1.  Set option FORCE_LA_CHECK to true to force checking.\r\n2024-10-18T13:03:45Z The build was cancelled or exceeded the maximum execution time.\r\n```","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2422819670/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2425108897","html_url":"https://github.com/apache/drill/pull/2953#issuecomment-2425108897","issue_url":"https://api.github.com/repos/apache/drill/issues/2953","id":2425108897,"node_id":"IC_kwDOAFa5xc6QjDmh","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-20T16:39:36Z","updated_at":"2024-10-20T16:39:36Z","author_association":"CONTRIBUTOR","body":"@dependabot rebase","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2425108897/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2425166576","html_url":"https://github.com/apache/drill/pull/2955#issuecomment-2425166576","issue_url":"https://api.github.com/repos/apache/drill/issues/2955","id":2425166576,"node_id":"IC_kwDOAFa5xc6QjRrw","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-20T18:18:12Z","updated_at":"2024-10-20T18:18:12Z","author_association":"CONTRIBUTOR","body":"@cgivre @jnturton Is this PR ok - I prefer it to #2946 ","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2425166576/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2425177922","html_url":"https://github.com/apache/drill/pull/2957#issuecomment-2425177922","issue_url":"https://api.github.com/repos/apache/drill/issues/2957","id":2425177922,"node_id":"IC_kwDOAFa5xc6QjUdC","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-20T18:56:30Z","updated_at":"2024-10-20T18:56:30Z","author_association":"CONTRIBUTOR","body":"@cgivre @jnturton this will hopefully unblock #2953","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2425177922/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427701716","html_url":"https://github.com/apache/drill/pull/2953#issuecomment-2427701716","issue_url":"https://api.github.com/repos/apache/drill/issues/2953","id":2427701716,"node_id":"IC_kwDOAFa5xc6Qs8nU","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-21T20:56:05Z","updated_at":"2024-10-21T20:56:05Z","author_association":"CONTRIBUTOR","body":"@dependabot rebase","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427701716/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427701783","html_url":"https://github.com/apache/drill/pull/2953#issuecomment-2427701783","issue_url":"https://api.github.com/repos/apache/drill/issues/2953","id":2427701783,"node_id":"IC_kwDOAFa5xc6Qs8oX","user":{"login":"dependabot[bot]","id":49699333,"node_id":"MDM6Qm90NDk2OTkzMzM=","avatar_url":"https://avatars.githubusercontent.com/in/29110?v=4","gravatar_id":"","url":"https://api.github.com/users/dependabot%5Bbot%5D","html_url":"https://github.com/apps/dependabot","followers_url":"https://api.github.com/users/dependabot%5Bbot%5D/followers","following_url":"https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dependabot%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/dependabot%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/dependabot%5Bbot%5D/repos","events_url":"https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/dependabot%5Bbot%5D/received_events","type":"Bot","user_view_type":"public","site_admin":false},"created_at":"2024-10-21T20:56:08Z","updated_at":"2024-10-21T20:56:08Z","author_association":"CONTRIBUTOR","body":"Looks like this PR has been edited by someone other than Dependabot. That means Dependabot can't rebase it - sorry!\n\nIf you're happy for Dependabot to recreate it from scratch, overwriting any edits, you can request `@dependabot recreate`.\n","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427701783/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":{"id":29110,"client_id":"Iv1.4f9a6346434f815e","slug":"dependabot","node_id":"MDM6QXBwMjkxMTA=","owner":{"login":"github","id":9919,"node_id":"MDEyOk9yZ2FuaXphdGlvbjk5MTk=","avatar_url":"https://avatars.githubusercontent.com/u/9919?v=4","gravatar_id":"","url":"https://api.github.com/users/github","html_url":"https://github.com/github","followers_url":"https://api.github.com/users/github/followers","following_url":"https://api.github.com/users/github/following{/other_user}","gists_url":"https://api.github.com/users/github/gists{/gist_id}","starred_url":"https://api.github.com/users/github/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/github/subscriptions","organizations_url":"https://api.github.com/users/github/orgs","repos_url":"https://api.github.com/users/github/repos","events_url":"https://api.github.com/users/github/events{/privacy}","received_events_url":"https://api.github.com/users/github/received_events","type":"Organization","user_view_type":"public","site_admin":false},"name":"Dependabot","description":"","external_url":"https://dependabot-api.githubapp.com","html_url":"https://github.com/apps/dependabot","created_at":"2019-04-16T22:34:25Z","updated_at":"2024-03-20T21:06:35Z","permissions":{"actions":"read","checks":"write","contents":"write","issues":"write","members":"read","metadata":"read","pull_requests":"write","statuses":"read","vulnerability_alerts":"read","workflows":"write"},"events":["check_suite","issues","issue_comment","label","pull_request","pull_request_review","pull_request_review_comment","repository"]}},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427703732","html_url":"https://github.com/apache/drill/pull/2955#issuecomment-2427703732","issue_url":"https://api.github.com/repos/apache/drill/issues/2955","id":2427703732,"node_id":"IC_kwDOAFa5xc6Qs9G0","user":{"login":"cgivre","id":5513150,"node_id":"MDQ6VXNlcjU1MTMxNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5513150?v=4","gravatar_id":"","url":"https://api.github.com/users/cgivre","html_url":"https://github.com/cgivre","followers_url":"https://api.github.com/users/cgivre/followers","following_url":"https://api.github.com/users/cgivre/following{/other_user}","gists_url":"https://api.github.com/users/cgivre/gists{/gist_id}","starred_url":"https://api.github.com/users/cgivre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cgivre/subscriptions","organizations_url":"https://api.github.com/users/cgivre/orgs","repos_url":"https://api.github.com/users/cgivre/repos","events_url":"https://api.github.com/users/cgivre/events{/privacy}","received_events_url":"https://api.github.com/users/cgivre/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-21T20:57:23Z","updated_at":"2024-10-21T20:57:23Z","author_association":"CONTRIBUTOR","body":"@pjfanning Are all packages using this version?","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427703732/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427707044","html_url":"https://github.com/apache/drill/pull/2955#issuecomment-2427707044","issue_url":"https://api.github.com/repos/apache/drill/issues/2955","id":2427707044,"node_id":"IC_kwDOAFa5xc6Qs96k","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-21T20:59:26Z","updated_at":"2024-10-21T20:59:26Z","author_association":"CONTRIBUTOR","body":"> @pjfanning Are all packages using this version?\r\n\r\nThe instance in this PR is the only one that does not use the commons-io.version","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427707044/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427719723","html_url":"https://github.com/apache/drill/pull/2953#issuecomment-2427719723","issue_url":"https://api.github.com/repos/apache/drill/issues/2953","id":2427719723,"node_id":"IC_kwDOAFa5xc6QtBAr","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-21T21:06:45Z","updated_at":"2024-10-21T21:06:45Z","author_association":"CONTRIBUTOR","body":"@dependabot recreate","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427719723/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427723834","html_url":"https://github.com/apache/drill/pull/2945#issuecomment-2427723834","issue_url":"https://api.github.com/repos/apache/drill/issues/2945","id":2427723834,"node_id":"IC_kwDOAFa5xc6QtCA6","user":{"login":"pjfanning","id":11783444,"node_id":"MDQ6VXNlcjExNzgzNDQ0","avatar_url":"https://avatars.githubusercontent.com/u/11783444?v=4","gravatar_id":"","url":"https://api.github.com/users/pjfanning","html_url":"https://github.com/pjfanning","followers_url":"https://api.github.com/users/pjfanning/followers","following_url":"https://api.github.com/users/pjfanning/following{/other_user}","gists_url":"https://api.github.com/users/pjfanning/gists{/gist_id}","starred_url":"https://api.github.com/users/pjfanning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pjfanning/subscriptions","organizations_url":"https://api.github.com/users/pjfanning/orgs","repos_url":"https://api.github.com/users/pjfanning/repos","events_url":"https://api.github.com/users/pjfanning/events{/privacy}","received_events_url":"https://api.github.com/users/pjfanning/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2024-10-21T21:09:19Z","updated_at":"2024-10-21T21:09:19Z","author_association":"CONTRIBUTOR","body":"@cgivre @jnturton does this PR look ok? I had to add a few changes to get the CI to pass.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2427723834/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/drill/issues/comments/2429441347","html_url":"https://github.com/apache/drill/pull/2946#issuecomment-2429441347","issue_url":"https://api.github.com/repos/apache/drill/issues/2946","id":2429441347,"node_id":"IC_kwDOAFa5xc6QzlVD","user":{"login":"dependabot[bot]","id":49699333,"node_id":"MDM6Qm90NDk2OTkzMzM=","avatar_url":"https://avatars.githubusercontent.com/in/29110?v=4","gravatar_id":"","url":"https://api.github.com/users/dependabot%5Bbot%5D","html_url":"https://github.com/apps/dependabot","followers_url":"https://api.github.com/users/dependabot%5Bbot%5D/followers","following_url":"https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dependabot%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/dependabot%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/dependabot%5Bbot%5D/repos","events_url":"https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/dependabot%5Bbot%5D/received_events","type":"Bot","user_view_type":"public","site_admin":false},"created_at":"2024-10-22T14:26:13Z","updated_at":"2024-10-22T14:26:13Z","author_association":"CONTRIBUTOR","body":"Looks like commons-io:commons-io is no longer a dependency, so this is no longer needed.","reactions":{"url":"https://api.github.com/repos/apache/drill/issues/comments/2429441347/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":{"id":29110,"client_id":"Iv1.4f9a6346434f815e","slug":"dependabot","node_id":"MDM6QXBwMjkxMTA=","owner":{"login":"github","id":9919,"node_id":"MDEyOk9yZ2FuaXphdGlvbjk5MTk=","avatar_url":"https://avatars.githubusercontent.com/u/9919?v=4","gravatar_id":"","url":"https://api.github.com/users/github","html_url":"https://github.com/github","followers_url":"https://api.github.com/users/github/followers","following_url":"https://api.github.com/users/github/following{/other_user}","gists_url":"https://api.github.com/users/github/gists{/gist_id}","starred_url":"https://api.github.com/users/github/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/github/subscriptions","organizations_url":"https://api.github.com/users/github/orgs","repos_url":"https://api.github.com/users/github/repos","events_url":"https://api.github.com/users/github/events{/privacy}","received_events_url":"https://api.github.com/users/github/received_events","type":"Organization","user_view_type":"public","site_admin":false},"name":"Dependabot","description":"","external_url":"https://dependabot-api.githubapp.com","html_url":"https://github.com/apps/dependabot","created_at":"2019-04-16T22:34:25Z","updated_at":"2024-03-20T21:06:35Z","permissions":{"actions":"read","checks":"write","contents":"write","issues":"write","members":"read","metadata":"read","pull_requests":"write","statuses":"read","vulnerability_alerts":"read","workflows":"write"},"events":["check_suite","issues","issue_comment","label","pull_request","pull_request_review","pull_request_review_comment","repository"]}}]