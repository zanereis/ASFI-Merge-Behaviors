[{"url":"https://api.github.com/repos/apache/hudi/issues/comments/767956391","html_url":"https://github.com/apache/hudi/pull/2494#issuecomment-767956391","issue_url":"https://api.github.com/repos/apache/hudi/issues/2494","id":767956391,"node_id":"MDEyOklzc3VlQ29tbWVudDc2Nzk1NjM5MQ==","user":{"login":"codecov-io","id":8655789,"node_id":"MDQ6VXNlcjg2NTU3ODk=","avatar_url":"https://avatars.githubusercontent.com/u/8655789?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-io","html_url":"https://github.com/codecov-io","followers_url":"https://api.github.com/users/codecov-io/followers","following_url":"https://api.github.com/users/codecov-io/following{/other_user}","gists_url":"https://api.github.com/users/codecov-io/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-io/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-io/subscriptions","organizations_url":"https://api.github.com/users/codecov-io/orgs","repos_url":"https://api.github.com/users/codecov-io/repos","events_url":"https://api.github.com/users/codecov-io/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-io/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T01:56:43Z","updated_at":"2021-03-15T20:10:20Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/2494?src=pr&el=h1) Report\n> Merging [#2494](https://codecov.io/gh/apache/hudi/pull/2494?src=pr&el=desc) (59b919a) into [master](https://codecov.io/gh/apache/hudi/commit/d8af24d8a2fdbead4592a36df1bd9dda333f1513?el=desc) (d8af24d) will **increase** coverage by `17.89%`.\n> The diff coverage is `n/a`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/2494/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/2494?src=pr&el=tree)\n\n```diff\n@@              Coverage Diff              @@\n##             master    #2494       +/-   ##\n=============================================\n+ Coverage     51.53%   69.43%   +17.89%     \n+ Complexity     3491      363     -3128     \n=============================================\n  Files           462       53      -409     \n  Lines         21881     1963    -19918     \n  Branches       2327      235     -2092     \n=============================================\n- Hits          11277     1363     -9914     \n+ Misses         9624      466     -9158     \n+ Partials        980      134      -846     \n```\n\n| Flag | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| hudicli | `?` | `?` | |\n| hudiclient | `?` | `?` | |\n| hudicommon | `?` | `?` | |\n| hudiflink | `?` | `?` | |\n| hudihadoopmr | `?` | `?` | |\n| hudisparkdatasource | `?` | `?` | |\n| hudisync | `?` | `?` | |\n| huditimelineservice | `?` | `?` | |\n| hudiutilities | `69.43% <ø> (-0.06%)` | `0.00 <ø> (ø)` | |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/2494?src=pr&el=tree) | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| [...ies/sources/helpers/DatePartitionPathSelector.java](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvaGVscGVycy9EYXRlUGFydGl0aW9uUGF0aFNlbGVjdG9yLmphdmE=) | `54.68% <0.00%> (-1.57%)` | `13.00% <0.00%> (ø%)` | |\n| [...e/hudi/common/util/queue/BoundedInMemoryQueue.java](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3V0aWwvcXVldWUvQm91bmRlZEluTWVtb3J5UXVldWUuamF2YQ==) | | | |\n| [...udi/operator/partitioner/BucketAssignFunction.java](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9wYXJ0aXRpb25lci9CdWNrZXRBc3NpZ25GdW5jdGlvbi5qYXZh) | | | |\n| [...pache/hudi/operator/KeyedWriteProcessOperator.java](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9LZXllZFdyaXRlUHJvY2Vzc09wZXJhdG9yLmphdmE=) | | | |\n| [...i/common/model/OverwriteWithLatestAvroPayload.java](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL21vZGVsL092ZXJ3cml0ZVdpdGhMYXRlc3RBdnJvUGF5bG9hZC5qYXZh) | | | |\n| [...til/jvm/HotSpotMemoryLayoutSpecification64bit.java](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3V0aWwvanZtL0hvdFNwb3RNZW1vcnlMYXlvdXRTcGVjaWZpY2F0aW9uNjRiaXQuamF2YQ==) | | | |\n| [...e/hudi/common/model/HoodieRollingStatMetadata.java](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL21vZGVsL0hvb2RpZVJvbGxpbmdTdGF0TWV0YWRhdGEuamF2YQ==) | | | |\n| [...he/hudi/exception/HoodieNotSupportedException.java](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvZXhjZXB0aW9uL0hvb2RpZU5vdFN1cHBvcnRlZEV4Y2VwdGlvbi5qYXZh) | | | |\n| [...udi/common/table/timeline/dto/ClusteringOpDTO.java](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3RhYmxlL3RpbWVsaW5lL2R0by9DbHVzdGVyaW5nT3BEVE8uamF2YQ==) | | | |\n| [.../apache/hudi/common/model/ClusteringOperation.java](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL21vZGVsL0NsdXN0ZXJpbmdPcGVyYXRpb24uamF2YQ==) | | | |\n| ... and [394 more](https://codecov.io/gh/apache/hudi/pull/2494/diff?src=pr&el=tree-more) | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/767956391/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/767962764","html_url":"https://github.com/apache/hudi/pull/2494#issuecomment-767962764","issue_url":"https://api.github.com/repos/apache/hudi/issues/2494","id":767962764,"node_id":"MDEyOklzc3VlQ29tbWVudDc2Nzk2Mjc2NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T02:12:20Z","updated_at":"2021-01-27T02:12:20Z","author_association":"MEMBER","body":">The size of the base file was 3MB so this means that the in-memory HFile block caching was also working.\r\n\r\nTrying to understand this part. Was the workload, trying to fetch all the keys out of the HFile or just 1?  ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/767962764/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/767988430","html_url":"https://github.com/apache/hudi/pull/2496#issuecomment-767988430","issue_url":"https://api.github.com/repos/apache/hudi/issues/2496","id":767988430,"node_id":"MDEyOklzc3VlQ29tbWVudDc2Nzk4ODQzMA==","user":{"login":"prashantwason","id":58448203,"node_id":"MDQ6VXNlcjU4NDQ4MjAz","avatar_url":"https://avatars.githubusercontent.com/u/58448203?v=4","gravatar_id":"","url":"https://api.github.com/users/prashantwason","html_url":"https://github.com/prashantwason","followers_url":"https://api.github.com/users/prashantwason/followers","following_url":"https://api.github.com/users/prashantwason/following{/other_user}","gists_url":"https://api.github.com/users/prashantwason/gists{/gist_id}","starred_url":"https://api.github.com/users/prashantwason/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashantwason/subscriptions","organizations_url":"https://api.github.com/users/prashantwason/orgs","repos_url":"https://api.github.com/users/prashantwason/repos","events_url":"https://api.github.com/users/prashantwason/events{/privacy}","received_events_url":"https://api.github.com/users/prashantwason/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T03:18:33Z","updated_at":"2021-01-27T03:18:33Z","author_association":"MEMBER","body":"@n3nash  Please review as this may provide benefits for HDFS workloads. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/767988430/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/767994932","html_url":"https://github.com/apache/hudi/pull/2430#issuecomment-767994932","issue_url":"https://api.github.com/repos/apache/hudi/issues/2430","id":767994932,"node_id":"MDEyOklzc3VlQ29tbWVudDc2Nzk5NDkzMg==","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T03:27:21Z","updated_at":"2021-01-27T03:27:21Z","author_association":"MEMBER","body":"@danny0405 sorry for the delay on review, I was super busy this week. The bloom index was merged to master, can we add the bloom index option to this PR as well?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/767994932/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768022341","html_url":"https://github.com/apache/hudi/pull/2430#issuecomment-768022341","issue_url":"https://api.github.com/repos/apache/hudi/issues/2430","id":768022341,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODAyMjM0MQ==","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T04:34:43Z","updated_at":"2021-01-27T04:34:43Z","author_association":"CONTRIBUTOR","body":"> @danny0405 sorry for the delay on review, I was super busy this week. The bloom index was merged to master, can we add the bloom index option to this PR as well?\r\n\r\nI'm not planning to using the BloomFilter index in the new pipeline, instead there is a BloomFilter index backed state index in the following PR, which is more suitable for streaming write.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768022341/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768052489","html_url":"https://github.com/apache/hudi/pull/2495#issuecomment-768052489","issue_url":"https://api.github.com/repos/apache/hudi/issues/2495","id":768052489,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODA1MjQ4OQ==","user":{"login":"codecov-io","id":8655789,"node_id":"MDQ6VXNlcjg2NTU3ODk=","avatar_url":"https://avatars.githubusercontent.com/u/8655789?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-io","html_url":"https://github.com/codecov-io","followers_url":"https://api.github.com/users/codecov-io/followers","following_url":"https://api.github.com/users/codecov-io/following{/other_user}","gists_url":"https://api.github.com/users/codecov-io/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-io/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-io/subscriptions","organizations_url":"https://api.github.com/users/codecov-io/orgs","repos_url":"https://api.github.com/users/codecov-io/repos","events_url":"https://api.github.com/users/codecov-io/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-io/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T05:59:05Z","updated_at":"2021-02-10T22:51:26Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/2495?src=pr&el=h1) Report\n> Merging [#2495](https://codecov.io/gh/apache/hudi/pull/2495?src=pr&el=desc) (d8d775f) into [master](https://codecov.io/gh/apache/hudi/commit/d74d8e208439df8cb2eb6c24019be55c002d00a5?el=desc) (d74d8e2) will **increase** coverage by `0.41%`.\n> The diff coverage is `60.00%`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/2495/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/2495?src=pr&el=tree)\n\n```diff\n@@             Coverage Diff              @@\n##             master    #2495      +/-   ##\n============================================\n+ Coverage     50.52%   50.94%   +0.41%     \n- Complexity     3123     3170      +47     \n============================================\n  Files           430      433       +3     \n  Lines         19597    19876     +279     \n  Branches       2008     2040      +32     \n============================================\n+ Hits           9901    10125     +224     \n- Misses         8887     8927      +40     \n- Partials        809      824      +15     \n```\n\n| Flag | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| hudicli | `36.90% <ø> (-0.31%)` | `0.00 <ø> (ø)` | |\n| hudiclient | `100.00% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudicommon | `51.40% <ø> (-0.03%)` | `0.00 <ø> (ø)` | |\n| hudiflink | `43.21% <ø> (+10.17%)` | `0.00 <ø> (ø)` | |\n| hudihadoopmr | `33.16% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudisparkdatasource | `69.73% <ø> (+0.26%)` | `0.00 <ø> (ø)` | |\n| hudisync | `48.61% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| huditimelineservice | `64.36% <58.90%> (-2.13%)` | `0.00 <24.00> (ø)` | |\n| hudiutilities | `69.51% <100.00%> (+0.03%)` | `0.00 <1.00> (ø)` | |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/2495?src=pr&el=tree) | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| [.../apache/hudi/timeline/service/TimelineService.java](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree#diff-aHVkaS10aW1lbGluZS1zZXJ2aWNlL3NyYy9tYWluL2phdmEvb3JnL2FwYWNoZS9odWRpL3RpbWVsaW5lL3NlcnZpY2UvVGltZWxpbmVTZXJ2aWNlLmphdmE=) | `25.26% <50.00%> (+0.84%)` | `7.00 <3.00> (+1.00)` | |\n| [...g/apache/hudi/timeline/service/RequestHandler.java](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree#diff-aHVkaS10aW1lbGluZS1zZXJ2aWNlL3NyYy9tYWluL2phdmEvb3JnL2FwYWNoZS9odWRpL3RpbWVsaW5lL3NlcnZpY2UvUmVxdWVzdEhhbmRsZXIuamF2YQ==) | `73.37% <61.01%> (-4.36%)` | `30.00 <21.00> (+1.00)` | :arrow_down: |\n| [...in/java/org/apache/hudi/utilities/UtilHelpers.java](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL1V0aWxIZWxwZXJzLmphdmE=) | `64.53% <100.00%> (+0.37%)` | `32.00 <1.00> (-1.00)` | :arrow_up: |\n| [...a/org/apache/hudi/cli/commands/CommitsCommand.java](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree#diff-aHVkaS1jbGkvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY2xpL2NvbW1hbmRzL0NvbW1pdHNDb21tYW5kLmphdmE=) | `53.50% <0.00%> (-5.30%)` | `15.00% <0.00%> (ø%)` | |\n| [...di/common/table/timeline/HoodieActiveTimeline.java](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3RhYmxlL3RpbWVsaW5lL0hvb2RpZUFjdGl2ZVRpbWVsaW5lLmphdmE=) | `70.64% <0.00%> (-1.33%)` | `42.00% <0.00%> (ø%)` | |\n| [.../hudi/operator/StreamWriteOperatorCoordinator.java](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9TdHJlYW1Xcml0ZU9wZXJhdG9yQ29vcmRpbmF0b3IuamF2YQ==) | `62.16% <0.00%> (-0.97%)` | `24.00% <0.00%> (-1.00%)` | |\n| [...pache/hudi/common/table/HoodieTableMetaClient.java](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3RhYmxlL0hvb2RpZVRhYmxlTWV0YUNsaWVudC5qYXZh) | `67.42% <0.00%> (-0.91%)` | `45.00% <0.00%> (ø%)` | |\n| [...src/main/scala/org/apache/hudi/DefaultSource.scala](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay1kYXRhc291cmNlL2h1ZGktc3Bhcmsvc3JjL21haW4vc2NhbGEvb3JnL2FwYWNoZS9odWRpL0RlZmF1bHRTb3VyY2Uuc2NhbGE=) | `88.23% <0.00%> (-0.48%)` | `15.00% <0.00%> (ø%)` | |\n| [.../org/apache/hudi/operator/StreamWriteOperator.java](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9TdHJlYW1Xcml0ZU9wZXJhdG9yLmphdmE=) | `0.00% <0.00%> (ø)` | `0.00% <0.00%> (ø%)` | |\n| [.../org/apache/hudi/streamer/FlinkStreamerConfig.java](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9zdHJlYW1lci9GbGlua1N0cmVhbWVyQ29uZmlnLmphdmE=) | `0.00% <0.00%> (ø)` | `0.00% <0.00%> (ø%)` | |\n| ... and [14 more](https://codecov.io/gh/apache/hudi/pull/2495/diff?src=pr&el=tree-more) | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768052489/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768083458","html_url":"https://github.com/apache/hudi/pull/2485#issuecomment-768083458","issue_url":"https://api.github.com/repos/apache/hudi/issues/2485","id":768083458,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODA4MzQ1OA==","user":{"login":"zhedoubushishi","id":31263084,"node_id":"MDQ6VXNlcjMxMjYzMDg0","avatar_url":"https://avatars.githubusercontent.com/u/31263084?v=4","gravatar_id":"","url":"https://api.github.com/users/zhedoubushishi","html_url":"https://github.com/zhedoubushishi","followers_url":"https://api.github.com/users/zhedoubushishi/followers","following_url":"https://api.github.com/users/zhedoubushishi/following{/other_user}","gists_url":"https://api.github.com/users/zhedoubushishi/gists{/gist_id}","starred_url":"https://api.github.com/users/zhedoubushishi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhedoubushishi/subscriptions","organizations_url":"https://api.github.com/users/zhedoubushishi/orgs","repos_url":"https://api.github.com/users/zhedoubushishi/repos","events_url":"https://api.github.com/users/zhedoubushishi/events{/privacy}","received_events_url":"https://api.github.com/users/zhedoubushishi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T07:09:05Z","updated_at":"2021-01-27T07:09:05Z","author_association":"CONTRIBUTOR","body":"Can you check if this change is compatible with Spark 3.0.0?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768083458/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768102437","html_url":"https://github.com/apache/hudi/issues/2346#issuecomment-768102437","issue_url":"https://api.github.com/repos/apache/hudi/issues/2346","id":768102437,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODEwMjQzNw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T07:48:46Z","updated_at":"2021-01-27T07:48:46Z","author_association":"CONTRIBUTOR","body":"Closing this GH as we have a jira to track it. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768102437/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768113848","html_url":"https://github.com/apache/hudi/issues/2123#issuecomment-768113848","issue_url":"https://api.github.com/repos/apache/hudi/issues/2123","id":768113848,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODExMzg0OA==","user":{"login":"satishkotha","id":2992755,"node_id":"MDQ6VXNlcjI5OTI3NTU=","avatar_url":"https://avatars.githubusercontent.com/u/2992755?v=4","gravatar_id":"","url":"https://api.github.com/users/satishkotha","html_url":"https://github.com/satishkotha","followers_url":"https://api.github.com/users/satishkotha/followers","following_url":"https://api.github.com/users/satishkotha/following{/other_user}","gists_url":"https://api.github.com/users/satishkotha/gists{/gist_id}","starred_url":"https://api.github.com/users/satishkotha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/satishkotha/subscriptions","organizations_url":"https://api.github.com/users/satishkotha/orgs","repos_url":"https://api.github.com/users/satishkotha/repos","events_url":"https://api.github.com/users/satishkotha/events{/privacy}","received_events_url":"https://api.github.com/users/satishkotha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T08:12:51Z","updated_at":"2021-01-27T08:12:51Z","author_association":"MEMBER","body":"@jonathanmorais Were you able to figure out the problem? Can you share more details on behavior you see with this flag enabled? Is the timestamp field being registered as some other type?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768113848/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768117063","html_url":"https://github.com/apache/hudi/pull/2495#issuecomment-768117063","issue_url":"https://api.github.com/repos/apache/hudi/issues/2495","id":768117063,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODExNzA2Mw==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T08:19:42Z","updated_at":"2021-01-27T08:19:42Z","author_association":"CONTRIBUTOR","body":"@bvaradar can you please review this ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768117063/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768128621","html_url":"https://github.com/apache/hudi/issues/2072#issuecomment-768128621","issue_url":"https://api.github.com/repos/apache/hudi/issues/2072","id":768128621,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODEyODYyMQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T08:41:51Z","updated_at":"2021-01-27T08:41:51Z","author_association":"CONTRIBUTOR","body":"@ashishmgofficial : Sorry for missing your comment. \r\n@nsivabalan : Thanks for the prompt. It looks like show rollbacks is not listing .restore operations. This should be fine but we would need \"show restore\" commands just like show rollbacks which needs to list all restore operations that happened on a dataset. Can you open a jira with this requirement  ? Let me know if you need more context","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768128621/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768131688","html_url":"https://github.com/apache/hudi/issues/1679#issuecomment-768131688","issue_url":"https://api.github.com/repos/apache/hudi/issues/1679","id":768131688,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODEzMTY4OA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T08:47:25Z","updated_at":"2021-01-27T08:47:25Z","author_association":"CONTRIBUTOR","body":"@kimberlyamandalu : Sorry for the delay. This is weird. Can you check if org/json/JSONException is present in /usr/lib/hive/lib/json-1.8.jar  ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768131688/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768154790","html_url":"https://github.com/apache/hudi/issues/143#issuecomment-768154790","issue_url":"https://api.github.com/repos/apache/hudi/issues/143","id":768154790,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODE1NDc5MA==","user":{"login":"renxiaoyao","id":885551,"node_id":"MDQ6VXNlcjg4NTU1MQ==","avatar_url":"https://avatars.githubusercontent.com/u/885551?v=4","gravatar_id":"","url":"https://api.github.com/users/renxiaoyao","html_url":"https://github.com/renxiaoyao","followers_url":"https://api.github.com/users/renxiaoyao/followers","following_url":"https://api.github.com/users/renxiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/renxiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/renxiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/renxiaoyao/subscriptions","organizations_url":"https://api.github.com/users/renxiaoyao/orgs","repos_url":"https://api.github.com/users/renxiaoyao/repos","events_url":"https://api.github.com/users/renxiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/renxiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T09:27:52Z","updated_at":"2021-01-27T09:27:52Z","author_association":"NONE","body":"Please add me fengjiangtao@gmail.com\r\nThanks","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768154790/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768163638","html_url":"https://github.com/apache/hudi/issues/2323#issuecomment-768163638","issue_url":"https://api.github.com/repos/apache/hudi/issues/2323","id":768163638,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODE2MzYzOA==","user":{"login":"kirqz23","id":22114492,"node_id":"MDQ6VXNlcjIyMTE0NDky","avatar_url":"https://avatars.githubusercontent.com/u/22114492?v=4","gravatar_id":"","url":"https://api.github.com/users/kirqz23","html_url":"https://github.com/kirqz23","followers_url":"https://api.github.com/users/kirqz23/followers","following_url":"https://api.github.com/users/kirqz23/following{/other_user}","gists_url":"https://api.github.com/users/kirqz23/gists{/gist_id}","starred_url":"https://api.github.com/users/kirqz23/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kirqz23/subscriptions","organizations_url":"https://api.github.com/users/kirqz23/orgs","repos_url":"https://api.github.com/users/kirqz23/repos","events_url":"https://api.github.com/users/kirqz23/events{/privacy}","received_events_url":"https://api.github.com/users/kirqz23/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T09:43:21Z","updated_at":"2021-01-27T09:43:21Z","author_association":"NONE","body":"I've found it very time and resource consuming. This is why I've decided to change my requirements to partition data by a column that should never change for a particular row (and I changed my index to SIMPLE only), therefore there shouldn't be a case that records moves from part_1 to part_2. In such approach I will pay more for AWS Athena queries (cause I will query more data due to bigger partitions), but less for AWS EMR to process such kind of data.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768163638/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768170324","html_url":"https://github.com/apache/hudi/pull/2496#issuecomment-768170324","issue_url":"https://api.github.com/repos/apache/hudi/issues/2496","id":768170324,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODE3MDMyNA==","user":{"login":"codecov-io","id":8655789,"node_id":"MDQ6VXNlcjg2NTU3ODk=","avatar_url":"https://avatars.githubusercontent.com/u/8655789?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-io","html_url":"https://github.com/codecov-io","followers_url":"https://api.github.com/users/codecov-io/followers","following_url":"https://api.github.com/users/codecov-io/following{/other_user}","gists_url":"https://api.github.com/users/codecov-io/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-io/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-io/subscriptions","organizations_url":"https://api.github.com/users/codecov-io/orgs","repos_url":"https://api.github.com/users/codecov-io/repos","events_url":"https://api.github.com/users/codecov-io/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-io/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T09:55:01Z","updated_at":"2021-02-07T18:48:32Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/2496?src=pr&el=h1) Report\n> Merging [#2496](https://codecov.io/gh/apache/hudi/pull/2496?src=pr&el=desc) (b03b269) into [master](https://codecov.io/gh/apache/hudi/commit/23f2ef3efbea5e9a686bac195cdf97605f20d91d?el=desc) (23f2ef3) will **increase** coverage by `0.48%`.\n> The diff coverage is `38.19%`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/2496/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/2496?src=pr&el=tree)\n\n```diff\n@@             Coverage Diff              @@\n##             master    #2496      +/-   ##\n============================================\n+ Coverage     50.28%   50.77%   +0.48%     \n- Complexity     3120     3182      +62     \n============================================\n  Files           430      436       +6     \n  Lines         19565    19907     +342     \n  Branches       2004     2041      +37     \n============================================\n+ Hits           9838    10107     +269     \n- Misses         8924     8979      +55     \n- Partials        803      821      +18     \n```\n\n| Flag | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| hudicli | `36.90% <ø> (-0.31%)` | `0.00 <ø> (ø)` | |\n| hudiclient | `100.00% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudicommon | `51.12% <38.19%> (-0.40%)` | `0.00 <27.00> (ø)` | |\n| hudiflink | `43.21% <ø> (+10.17%)` | `0.00 <ø> (ø)` | |\n| hudihadoopmr | `33.16% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudisparkdatasource | `69.46% <ø> (+3.60%)` | `0.00 <ø> (ø)` | |\n| hudisync | `48.61% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| huditimelineservice | `66.49% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudiutilities | `69.46% <ø> (-0.02%)` | `0.00 <ø> (ø)` | |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/2496?src=pr&el=tree) | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| [...i/common/config/HoodieWrapperFileSystemConfig.java](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL2NvbmZpZy9Ib29kaWVXcmFwcGVyRmlsZVN5c3RlbUNvbmZpZy5qYXZh) | `0.00% <0.00%> (ø)` | `0.00 <0.00> (?)` | |\n| [...apache/hudi/common/engine/HoodieEngineContext.java](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL2VuZ2luZS9Ib29kaWVFbmdpbmVDb250ZXh0LmphdmE=) | `50.00% <0.00%> (-16.67%)` | `1.00 <0.00> (ø)` | |\n| [.../hudi/common/fs/BufferedSizeAwareOutputStream.java](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL2ZzL0J1ZmZlcmVkU2l6ZUF3YXJlT3V0cHV0U3RyZWFtLmphdmE=) | `0.00% <0.00%> (ø)` | `0.00 <0.00> (?)` | |\n| [...c/main/java/org/apache/hudi/common/fs/FSUtils.java](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL2ZzL0ZTVXRpbHMuamF2YQ==) | `48.62% <0.00%> (-1.15%)` | `62.00 <2.00> (+1.00)` | :arrow_down: |\n| [...che/hudi/common/fs/TimedSizeAwareOutputStream.java](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL2ZzL1RpbWVkU2l6ZUF3YXJlT3V0cHV0U3RyZWFtLmphdmE=) | `56.66% <33.33%> (ø)` | `4.00 <1.00> (?)` | |\n| [...apache/hudi/common/fs/HoodieWrapperFileSystem.java](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL2ZzL0hvb2RpZVdyYXBwZXJGaWxlU3lzdGVtLmphdmE=) | `25.00% <47.69%> (+2.67%)` | `52.00 <13.00> (+8.00)` | |\n| [.../org/apache/hudi/common/fs/TimedFSInputStream.java](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL2ZzL1RpbWVkRlNJbnB1dFN0cmVhbS5qYXZh) | `50.00% <50.00%> (ø)` | `8.00 <8.00> (?)` | |\n| [...org/apache/hudi/common/model/HoodieFileFormat.java](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL21vZGVsL0hvb2RpZUZpbGVGb3JtYXQuamF2YQ==) | `100.00% <100.00%> (ø)` | `6.00 <3.00> (+3.00)` | |\n| [...che/hudi/common/table/log/HoodieLogFileReader.java](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3RhYmxlL2xvZy9Ib29kaWVMb2dGaWxlUmVhZGVyLmphdmE=) | `68.86% <100.00%> (+1.00%)` | `22.00 <0.00> (ø)` | |\n| [.../apache/hudi/common/fs/TimedFSDataInputStream.java](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL2ZzL1RpbWVkRlNEYXRhSW5wdXRTdHJlYW0uamF2YQ==) | `0.00% <0.00%> (-29.42%)` | `0.00% <0.00%> (-3.00%)` | |\n| ... and [32 more](https://codecov.io/gh/apache/hudi/pull/2496/diff?src=pr&el=tree-more) | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768170324/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768189870","html_url":"https://github.com/apache/hudi/issues/2489#issuecomment-768189870","issue_url":"https://api.github.com/repos/apache/hudi/issues/2489","id":768189870,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODE4OTg3MA==","user":{"login":"lshg","id":25452281,"node_id":"MDQ6VXNlcjI1NDUyMjgx","avatar_url":"https://avatars.githubusercontent.com/u/25452281?v=4","gravatar_id":"","url":"https://api.github.com/users/lshg","html_url":"https://github.com/lshg","followers_url":"https://api.github.com/users/lshg/followers","following_url":"https://api.github.com/users/lshg/following{/other_user}","gists_url":"https://api.github.com/users/lshg/gists{/gist_id}","starred_url":"https://api.github.com/users/lshg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lshg/subscriptions","organizations_url":"https://api.github.com/users/lshg/orgs","repos_url":"https://api.github.com/users/lshg/repos","events_url":"https://api.github.com/users/lshg/events{/privacy}","received_events_url":"https://api.github.com/users/lshg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T10:28:36Z","updated_at":"2021-01-27T10:28:36Z","author_association":"NONE","body":"think you发自我的华为手机-------- 原始邮件 --------主题：Re: [apache/hudi] [SUPPORT] (#2489)发件人：Balaji Varadarajan 收件人：apache/hudi 抄送：李仕辉 ,Author \r\nIt looks like you may be having multiple hudi bundles (or multiple versions) in the classpath of execution. Can you check if this is the case ?\r\n\r\n—You are receiving this because you authored the thread.Reply to this email directly, view it on GitHub, or unsubscribe.\r\n[\r\n{\r\n\"@context\": \"http://schema.org\",\r\n\"@type\": \"EmailMessage\",\r\n\"potentialAction\": {\r\n\"@type\": \"ViewAction\",\r\n\"target\": \"https://github.com/apache/hudi/issues/2489#issuecomment-767390678\",\r\n\"url\": \"https://github.com/apache/hudi/issues/2489#issuecomment-767390678\",\r\n\"name\": \"View Issue\"\r\n},\r\n\"description\": \"View this Issue on GitHub\",\r\n\"publisher\": {\r\n\"@type\": \"Organization\",\r\n\"name\": \"GitHub\",\r\n\"url\": \"https://github.com\"\r\n}\r\n}\r\n]","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768189870/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768221064","html_url":"https://github.com/apache/hudi/pull/2485#issuecomment-768221064","issue_url":"https://api.github.com/repos/apache/hudi/issues/2485","id":768221064,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODIyMTA2NA==","user":{"login":"pengzhiwei2018","id":42458891,"node_id":"MDQ6VXNlcjQyNDU4ODkx","avatar_url":"https://avatars.githubusercontent.com/u/42458891?v=4","gravatar_id":"","url":"https://api.github.com/users/pengzhiwei2018","html_url":"https://github.com/pengzhiwei2018","followers_url":"https://api.github.com/users/pengzhiwei2018/followers","following_url":"https://api.github.com/users/pengzhiwei2018/following{/other_user}","gists_url":"https://api.github.com/users/pengzhiwei2018/gists{/gist_id}","starred_url":"https://api.github.com/users/pengzhiwei2018/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pengzhiwei2018/subscriptions","organizations_url":"https://api.github.com/users/pengzhiwei2018/orgs","repos_url":"https://api.github.com/users/pengzhiwei2018/repos","events_url":"https://api.github.com/users/pengzhiwei2018/events{/privacy}","received_events_url":"https://api.github.com/users/pengzhiwei2018/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T11:25:48Z","updated_at":"2021-02-03T20:21:07Z","author_association":"NONE","body":"> Can you check if this change is compatible with Spark 3.0.0?\r\n\r\nHi @zhedoubushishi , The `Source` and `Offset` implement is still available  in the spark 3.0.0, But it needs to be integrated into the new `SourceProvider` before use it in the 3.0.0.\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768221064/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768269863","html_url":"https://github.com/apache/hudi/pull/2430#issuecomment-768269863","issue_url":"https://api.github.com/repos/apache/hudi/issues/2430","id":768269863,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODI2OTg2Mw==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T13:01:52Z","updated_at":"2021-01-27T13:01:52Z","author_association":"CONTRIBUTOR","body":"@danny0405 oh, CI failed... Please fix it before merging, 3ks.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768269863/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768296704","html_url":"https://github.com/apache/hudi/issues/2423#issuecomment-768296704","issue_url":"https://api.github.com/repos/apache/hudi/issues/2423","id":768296704,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODI5NjcwNA==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T13:48:16Z","updated_at":"2021-01-27T13:51:41Z","author_association":"CONTRIBUTOR","body":"@bvaradar : do you think we need a config on this? btw, we have so many mkdirs() calls within hudi (HoodieRowCreateHandle, SpillableMapBasedFileSystemView, HoodieTableMetaClient, etc). Do you think we need to fix all places and may be guard by a flag? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768296704/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768353537","html_url":"https://github.com/apache/hudi/pull/2430#issuecomment-768353537","issue_url":"https://api.github.com/repos/apache/hudi/issues/2430","id":768353537,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODM1MzUzNw==","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T15:14:23Z","updated_at":"2021-01-27T15:14:23Z","author_association":"MEMBER","body":"> > @danny0405 sorry for the delay on review, I was super busy this week. The bloom index was merged to master, can we add the bloom index option to this PR as well?\r\n> \r\n> I'm not planning to using the BloomFilter index in the new pipeline, instead there is a BloomFilter index backed state index in the following PR, which is more suitable for streaming write.\r\n\r\n@danny0405 yes, using bloom index in a streaming fashion is what we are planning to do next as well. No worry for now, we can try this PR out and continue the work on top of this. Really appreciate your work! This PR LGTM. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768353537/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768373302","html_url":"https://github.com/apache/hudi/issues/2423#issuecomment-768373302","issue_url":"https://api.github.com/repos/apache/hudi/issues/2423","id":768373302,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODM3MzMwMg==","user":{"login":"sam-wmt","id":67726885,"node_id":"MDQ6VXNlcjY3NzI2ODg1","avatar_url":"https://avatars.githubusercontent.com/u/67726885?v=4","gravatar_id":"","url":"https://api.github.com/users/sam-wmt","html_url":"https://github.com/sam-wmt","followers_url":"https://api.github.com/users/sam-wmt/followers","following_url":"https://api.github.com/users/sam-wmt/following{/other_user}","gists_url":"https://api.github.com/users/sam-wmt/gists{/gist_id}","starred_url":"https://api.github.com/users/sam-wmt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sam-wmt/subscriptions","organizations_url":"https://api.github.com/users/sam-wmt/orgs","repos_url":"https://api.github.com/users/sam-wmt/repos","events_url":"https://api.github.com/users/sam-wmt/events{/privacy}","received_events_url":"https://api.github.com/users/sam-wmt/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T15:41:40Z","updated_at":"2021-01-27T15:41:40Z","author_association":"NONE","body":"Happy to submit a PR with or without config depending on if you think this should be the only behavior, default behavior, or optional behavior.  We've seen drastic improvements in our Azure storage accounts and containers which were in an unhealthy state have recovered nicely after this patch.  Please let me know and I can submit the PR.\r\n\r\n@nsivabalan , @bvaradar ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768373302/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768386541","html_url":"https://github.com/apache/hudi/issues/2423#issuecomment-768386541","issue_url":"https://api.github.com/repos/apache/hudi/issues/2423","id":768386541,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODM4NjU0MQ==","user":{"login":"christoph-wmt","id":67316352,"node_id":"MDQ6VXNlcjY3MzE2MzUy","avatar_url":"https://avatars.githubusercontent.com/u/67316352?v=4","gravatar_id":"","url":"https://api.github.com/users/christoph-wmt","html_url":"https://github.com/christoph-wmt","followers_url":"https://api.github.com/users/christoph-wmt/followers","following_url":"https://api.github.com/users/christoph-wmt/following{/other_user}","gists_url":"https://api.github.com/users/christoph-wmt/gists{/gist_id}","starred_url":"https://api.github.com/users/christoph-wmt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/christoph-wmt/subscriptions","organizations_url":"https://api.github.com/users/christoph-wmt/orgs","repos_url":"https://api.github.com/users/christoph-wmt/repos","events_url":"https://api.github.com/users/christoph-wmt/events{/privacy}","received_events_url":"https://api.github.com/users/christoph-wmt/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T16:00:04Z","updated_at":"2021-01-27T16:00:04Z","author_association":"NONE","body":"@bvaradar while this one code path already has made a huge difference I think it's worth approaching this elsewhere aswell.\r\nWe've observed: if successful (on average) ~2200ms (CreatePathDir) VS ~70ms (GetFileProperties) for ADLS / Azure.  \r\nSo making this configurable and minimizing create operations as much as possible would be huge for Azure users. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768386541/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768405930","html_url":"https://github.com/apache/hudi/pull/2283#issuecomment-768405930","issue_url":"https://api.github.com/repos/apache/hudi/issues/2283","id":768405930,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODQwNTkzMA==","user":{"login":"pengzhiwei2018","id":42458891,"node_id":"MDQ6VXNlcjQyNDU4ODkx","avatar_url":"https://avatars.githubusercontent.com/u/42458891?v=4","gravatar_id":"","url":"https://api.github.com/users/pengzhiwei2018","html_url":"https://github.com/pengzhiwei2018","followers_url":"https://api.github.com/users/pengzhiwei2018/followers","following_url":"https://api.github.com/users/pengzhiwei2018/following{/other_user}","gists_url":"https://api.github.com/users/pengzhiwei2018/gists{/gist_id}","starred_url":"https://api.github.com/users/pengzhiwei2018/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pengzhiwei2018/subscriptions","organizations_url":"https://api.github.com/users/pengzhiwei2018/orgs","repos_url":"https://api.github.com/users/pengzhiwei2018/repos","events_url":"https://api.github.com/users/pengzhiwei2018/events{/privacy}","received_events_url":"https://api.github.com/users/pengzhiwei2018/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T16:28:55Z","updated_at":"2021-01-27T16:28:55Z","author_association":"NONE","body":"> I had the same problem, but I saw less rows not more.\r\n> Reading with spark datasource I have more than 30 million rows and using spark sql with hive only 4 million.\r\n> \r\n> I had this problem only these two options are enabled\r\n> \r\n> \"spark.sql.hive.convertMetastoreParquet\": \"false\"\r\n> \"spark.hadoop.hoodie.metadata.enable\": \"true\"\r\n> \r\n> @pengzhiwei2018\r\n\r\nHi @rubenssoto ,currently spark sql will try hoodie table as a hive table and read it as a parquet format.So it will result in read more record as the update & delete to the table. So i think the your problem  maybe different with this one. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768405930/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768477641","html_url":"https://github.com/apache/hudi/pull/2486#issuecomment-768477641","issue_url":"https://api.github.com/repos/apache/hudi/issues/2486","id":768477641,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODQ3NzY0MQ==","user":{"login":"pratyakshsharma","id":30863489,"node_id":"MDQ6VXNlcjMwODYzNDg5","avatar_url":"https://avatars.githubusercontent.com/u/30863489?v=4","gravatar_id":"","url":"https://api.github.com/users/pratyakshsharma","html_url":"https://github.com/pratyakshsharma","followers_url":"https://api.github.com/users/pratyakshsharma/followers","following_url":"https://api.github.com/users/pratyakshsharma/following{/other_user}","gists_url":"https://api.github.com/users/pratyakshsharma/gists{/gist_id}","starred_url":"https://api.github.com/users/pratyakshsharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pratyakshsharma/subscriptions","organizations_url":"https://api.github.com/users/pratyakshsharma/orgs","repos_url":"https://api.github.com/users/pratyakshsharma/repos","events_url":"https://api.github.com/users/pratyakshsharma/events{/privacy}","received_events_url":"https://api.github.com/users/pratyakshsharma/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T18:17:48Z","updated_at":"2021-01-27T18:17:48Z","author_association":"CONTRIBUTOR","body":"@quitozang There are compilation errors in the travis build. Also please raise a jira and add it to the PR title.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768477641/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768487034","html_url":"https://github.com/apache/hudi/pull/2210#issuecomment-768487034","issue_url":"https://api.github.com/repos/apache/hudi/issues/2210","id":768487034,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODQ4NzAzNA==","user":{"login":"pratyakshsharma","id":30863489,"node_id":"MDQ6VXNlcjMwODYzNDg5","avatar_url":"https://avatars.githubusercontent.com/u/30863489?v=4","gravatar_id":"","url":"https://api.github.com/users/pratyakshsharma","html_url":"https://github.com/pratyakshsharma","followers_url":"https://api.github.com/users/pratyakshsharma/followers","following_url":"https://api.github.com/users/pratyakshsharma/following{/other_user}","gists_url":"https://api.github.com/users/pratyakshsharma/gists{/gist_id}","starred_url":"https://api.github.com/users/pratyakshsharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pratyakshsharma/subscriptions","organizations_url":"https://api.github.com/users/pratyakshsharma/orgs","repos_url":"https://api.github.com/users/pratyakshsharma/repos","events_url":"https://api.github.com/users/pratyakshsharma/events{/privacy}","received_events_url":"https://api.github.com/users/pratyakshsharma/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T18:33:53Z","updated_at":"2021-01-27T18:33:53Z","author_association":"CONTRIBUTOR","body":"@hotienvu Still working on this? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768487034/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768495604","html_url":"https://github.com/apache/hudi/pull/2494#issuecomment-768495604","issue_url":"https://api.github.com/repos/apache/hudi/issues/2494","id":768495604,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODQ5NTYwNA==","user":{"login":"prashantwason","id":58448203,"node_id":"MDQ6VXNlcjU4NDQ4MjAz","avatar_url":"https://avatars.githubusercontent.com/u/58448203?v=4","gravatar_id":"","url":"https://api.github.com/users/prashantwason","html_url":"https://github.com/prashantwason","followers_url":"https://api.github.com/users/prashantwason/followers","following_url":"https://api.github.com/users/prashantwason/following{/other_user}","gists_url":"https://api.github.com/users/prashantwason/gists{/gist_id}","starred_url":"https://api.github.com/users/prashantwason/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashantwason/subscriptions","organizations_url":"https://api.github.com/users/prashantwason/orgs","repos_url":"https://api.github.com/users/prashantwason/repos","events_url":"https://api.github.com/users/prashantwason/events{/privacy}","received_events_url":"https://api.github.com/users/prashantwason/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T18:48:50Z","updated_at":"2021-01-27T18:48:50Z","author_association":"MEMBER","body":"> > The size of the base file was 3MB so this means that the in-memory HFile block caching was also working.\r\n> \r\n> Trying to understand this part. Was the workload, trying to fetch all the keys out of the HFile or just 1?\r\n\r\nThe workload was a commit followed by a Clean operation with num_versions_retained=1 so it will clean all partitions. Hence, number of key lookups should be equal to number of partitions and all the keys should have been read from the HFile.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768495604/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768502144","html_url":"https://github.com/apache/hudi/issues/2437#issuecomment-768502144","issue_url":"https://api.github.com/repos/apache/hudi/issues/2437","id":768502144,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODUwMjE0NA==","user":{"login":"jiangok2006","id":14916370,"node_id":"MDQ6VXNlcjE0OTE2Mzcw","avatar_url":"https://avatars.githubusercontent.com/u/14916370?v=4","gravatar_id":"","url":"https://api.github.com/users/jiangok2006","html_url":"https://github.com/jiangok2006","followers_url":"https://api.github.com/users/jiangok2006/followers","following_url":"https://api.github.com/users/jiangok2006/following{/other_user}","gists_url":"https://api.github.com/users/jiangok2006/gists{/gist_id}","starred_url":"https://api.github.com/users/jiangok2006/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jiangok2006/subscriptions","organizations_url":"https://api.github.com/users/jiangok2006/orgs","repos_url":"https://api.github.com/users/jiangok2006/repos","events_url":"https://api.github.com/users/jiangok2006/events{/privacy}","received_events_url":"https://api.github.com/users/jiangok2006/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T18:59:40Z","updated_at":"2021-01-27T19:03:23Z","author_association":"NONE","body":"@bvaradar it is already all info that displayed. Just fyi, I attached the raw info below. As you can see, there is a lot of dup and no more useful info that I gave above. After you reply, I will delete below info to keep the posting clean. This blocks us using delta streamer to dump kafka to datalake. Thanks for your help very much!\r\n\r\n`21/01/27 18:53:42 INFO DAGScheduler: ResultStage 25 (sum at DeltaSync.java:398) failed in 9.092 s due to Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n21/01/27 18:53:42 INFO DAGScheduler: Job 10 failed: sum at DeltaSync.java:398, took 15.060037 s\r\n21/01/27 18:53:42 ERROR HoodieDeltaStreamer: Shutting down delta-sync due to exception\r\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2041)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2029)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2028)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2028)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2262)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2211)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2200)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1098)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1092)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:34)\r\n\tat org.apache.spark.api.java.JavaDoubleRDD.sum(JavaDoubleRDD.scala:165)\r\n\tat org.apache.hudi.utilities.deltastreamer.DeltaSync.writeToSink(DeltaSync.java:398)\r\n\tat org.apache.hudi.utilities.deltastreamer.DeltaSync.syncOnce(DeltaSync.java:244)\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer$DeltaSyncService.lambda$startService$0(HoodieDeltaStreamer.java:579)\r\n\tat java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\t... 3 more\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n21/01/27 18:53:42 ERROR AbstractAsyncService: Service shutdown with error\r\njava.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)\r\n\tat java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)\r\n\tat org.apache.hudi.async.AbstractAsyncService.waitForShutdown(AbstractAsyncService.java:79)\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.lambda$sync$1(HoodieDeltaStreamer.java:150)\r\n\tat org.apache.hudi.common.util.Option.ifPresent(Option.java:96)\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.sync(HoodieDeltaStreamer.java:147)\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.main(HoodieDeltaStreamer.java:464)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:853)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:928)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:937)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: org.apache.hudi.exception.HoodieException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer$DeltaSyncService.lambda$startService$0(HoodieDeltaStreamer.java:595)\r\n\tat java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2041)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2029)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2028)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2028)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2262)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2211)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2200)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1098)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1092)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:34)\r\n\tat org.apache.spark.api.java.JavaDoubleRDD.sum(JavaDoubleRDD.scala:165)\r\n\tat org.apache.hudi.utilities.deltastreamer.DeltaSync.writeToSink(DeltaSync.java:398)\r\n\tat org.apache.hudi.utilities.deltastreamer.DeltaSync.syncOnce(DeltaSync.java:244)\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer$DeltaSyncService.lambda$startService$0(HoodieDeltaStreamer.java:579)\r\n\t... 4 more\r\nCaused by: org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\t... 3 more\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n21/01/27 18:53:42 ERROR AbstractAsyncService: Monitor noticed one or more threads failed. Requesting graceful shutdown of other threads\r\njava.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)\r\n\tat java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)\r\n\tat org.apache.hudi.async.AbstractAsyncService.lambda$monitorThreads$1(AbstractAsyncService.java:147)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.hudi.exception.HoodieException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer$DeltaSyncService.lambda$startService$0(HoodieDeltaStreamer.java:595)\r\n\tat java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)\r\n\t... 3 more\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2041)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2029)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2028)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2028)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2262)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2211)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2200)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1098)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1092)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:34)\r\n\tat org.apache.spark.api.java.JavaDoubleRDD.sum(JavaDoubleRDD.scala:165)\r\n\tat org.apache.hudi.utilities.deltastreamer.DeltaSync.writeToSink(DeltaSync.java:398)\r\n\tat org.apache.hudi.utilities.deltastreamer.DeltaSync.syncOnce(DeltaSync.java:244)\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer$DeltaSyncService.lambda$startService$0(HoodieDeltaStreamer.java:579)\r\n\t... 4 more\r\nCaused by: org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\t... 3 more\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n21/01/27 18:53:42 INFO Javalin: Stopping Javalin ...\r\n21/01/27 18:53:42 WARN TaskSetManager: Lost task 21.2 in stage 25.0 (TID 14015, ip-100-106-216-136.us-west-2.compute.internal, executor 13): TaskKilled (Stage cancelled)\r\n21/01/27 18:53:42 INFO SparkUI: Stopped Spark web UI at http://ip-100-106-228-202.us-west-2.compute.internal:4045\r\n21/01/27 18:53:42 WARN TaskSetManager: Lost task 33.2 in stage 25.0 (TID 14016, ip-100-106-205-108.us-west-2.compute.internal, executor 9): TaskKilled (Stage cancelled)\r\n21/01/27 18:53:42 WARN TaskSetManager: Lost task 28.3 in stage 25.0 (TID 13999, ip-100-106-205-108.us-west-2.compute.internal, executor 9): TaskKilled (Stage cancelled)\r\n21/01/27 18:53:42 INFO Javalin: Javalin has stopped\r\n21/01/27 18:53:42 INFO YarnClientSchedulerBackend: Interrupting monitor thread\r\n21/01/27 18:53:42 WARN TaskSetManager: Lost task 29.3 in stage 25.0 (TID 14019, ip-100-106-216-136.us-west-2.compute.internal, executor 10): TaskKilled (Stage cancelled)\r\n21/01/27 18:53:42 INFO YarnClientSchedulerBackend: Shutting down all executors\r\n21/01/27 18:53:42 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\r\n21/01/27 18:53:42 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices\r\n(serviceOption=None,\r\n services=List(),\r\n started=false)\r\n21/01/27 18:53:42 INFO YarnClientSchedulerBackend: Stopped\r\n21/01/27 18:53:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\r\n21/01/27 18:53:42 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.\r\norg.apache.spark.SparkException: Could not find CoarseGrainedScheduler.\r\n\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160)\r\n\tat org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:140)\r\n\tat org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:655)\r\n\tat org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:274)\r\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:105)\r\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n21/01/27 18:53:42 INFO MemoryStore: MemoryStore cleared\r\n21/01/27 18:53:42 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.\r\norg.apache.spark.SparkException: Could not find CoarseGrainedScheduler.\r\n\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160)\r\n\tat org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:140)\r\n\tat org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:655)\r\n\tat org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:274)\r\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:105)\r\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n21/01/27 18:53:42 INFO BlockManager: BlockManager stopped\r\n21/01/27 18:53:42 INFO BlockManagerMaster: BlockManagerMaster stopped\r\n21/01/27 18:53:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\r\n21/01/27 18:53:42 INFO SparkContext: Successfully stopped SparkContext\r\nException in thread \"main\" org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.lambda$sync$1(HoodieDeltaStreamer.java:152)\r\n\tat org.apache.hudi.common.util.Option.ifPresent(Option.java:96)\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.sync(HoodieDeltaStreamer.java:147)\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.main(HoodieDeltaStreamer.java:464)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:853)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:928)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:937)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)\r\n\tat java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)\r\n\tat org.apache.hudi.async.AbstractAsyncService.waitForShutdown(AbstractAsyncService.java:79)\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer.lambda$sync$1(HoodieDeltaStreamer.java:150)\r\n\t... 15 more\r\nCaused by: org.apache.hudi.exception.HoodieException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer$DeltaSyncService.lambda$startService$0(HoodieDeltaStreamer.java:595)\r\n\tat java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 17 in stage 25.0 failed 4 times, most recent failure: Lost task 17.3 in stage 25.0 (TID 14000, ip-100-106-216-136.us-west-2.compute.internal, executor 10): org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n\r\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2041)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2029)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2028)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2028)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2262)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2211)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2200)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1098)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1092)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:35)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:34)\r\n\tat org.apache.spark.api.java.JavaDoubleRDD.sum(JavaDoubleRDD.scala:165)\r\n\tat org.apache.hudi.utilities.deltastreamer.DeltaSync.writeToSink(DeltaSync.java:398)\r\n\tat org.apache.hudi.utilities.deltastreamer.DeltaSync.syncOnce(DeltaSync.java:244)\r\n\tat org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer$DeltaSyncService.lambda$startService$0(HoodieDeltaStreamer.java:579)\r\n\t... 4 more\r\nCaused by: org.apache.hudi.exception.HoodieUpsertException: Error upserting bucketType UPDATE for partition :17\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.handleUpsertPartition(BaseCommitActionExecutor.java:264)\r\n\tat org.apache.hudi.table.action.commit.BaseCommitActionExecutor.lambda$execute$caffe4c4$1(BaseCommitActionExecutor.java:97)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(JavaRDDLike.scala:102)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:853)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\t... 3 more\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException\r\n21/01/27 18:53:42 INFO ShutdownHookManager: Shutdown hook called\r\n21/01/27 18:53:42 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-de321b8f-9255-4bdf-907f-a7ef1659f210\r\n21/01/27 18:53:42 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-156d6dd4-b47d-4346-85f3-700d556bd7eb`","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768502144/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768538848","html_url":"https://github.com/apache/hudi/pull/1650#issuecomment-768538848","issue_url":"https://api.github.com/repos/apache/hudi/issues/1650","id":768538848,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODUzODg0OA==","user":{"login":"pratyakshsharma","id":30863489,"node_id":"MDQ6VXNlcjMwODYzNDg5","avatar_url":"https://avatars.githubusercontent.com/u/30863489?v=4","gravatar_id":"","url":"https://api.github.com/users/pratyakshsharma","html_url":"https://github.com/pratyakshsharma","followers_url":"https://api.github.com/users/pratyakshsharma/followers","following_url":"https://api.github.com/users/pratyakshsharma/following{/other_user}","gists_url":"https://api.github.com/users/pratyakshsharma/gists{/gist_id}","starred_url":"https://api.github.com/users/pratyakshsharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pratyakshsharma/subscriptions","organizations_url":"https://api.github.com/users/pratyakshsharma/orgs","repos_url":"https://api.github.com/users/pratyakshsharma/repos","events_url":"https://api.github.com/users/pratyakshsharma/events{/privacy}","received_events_url":"https://api.github.com/users/pratyakshsharma/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T19:56:38Z","updated_at":"2021-01-27T19:56:38Z","author_association":"CONTRIBUTOR","body":"@bvaradar Please take a pass. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768538848/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768566060","html_url":"https://github.com/apache/hudi/pull/2499#issuecomment-768566060","issue_url":"https://api.github.com/repos/apache/hudi/issues/2499","id":768566060,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODU2NjA2MA==","user":{"login":"satishkotha","id":2992755,"node_id":"MDQ6VXNlcjI5OTI3NTU=","avatar_url":"https://avatars.githubusercontent.com/u/2992755?v=4","gravatar_id":"","url":"https://api.github.com/users/satishkotha","html_url":"https://github.com/satishkotha","followers_url":"https://api.github.com/users/satishkotha/followers","following_url":"https://api.github.com/users/satishkotha/following{/other_user}","gists_url":"https://api.github.com/users/satishkotha/gists{/gist_id}","starred_url":"https://api.github.com/users/satishkotha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/satishkotha/subscriptions","organizations_url":"https://api.github.com/users/satishkotha/orgs","repos_url":"https://api.github.com/users/satishkotha/repos","events_url":"https://api.github.com/users/satishkotha/events{/privacy}","received_events_url":"https://api.github.com/users/satishkotha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T20:46:01Z","updated_at":"2021-01-27T20:46:01Z","author_association":"MEMBER","body":"> Looks great satish. Only minor comments.\r\n> \r\n> We can land if you could address them and add a small snippet showing how to cluster.\r\n> \r\n> Also suggest reposting this on linkedin as a pot\r\n\r\n@vinothchandar Please take another look.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768566060/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768576158","html_url":"https://github.com/apache/hudi/pull/2494#issuecomment-768576158","issue_url":"https://api.github.com/repos/apache/hudi/issues/2494","id":768576158,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODU3NjE1OA==","user":{"login":"prashantwason","id":58448203,"node_id":"MDQ6VXNlcjU4NDQ4MjAz","avatar_url":"https://avatars.githubusercontent.com/u/58448203?v=4","gravatar_id":"","url":"https://api.github.com/users/prashantwason","html_url":"https://github.com/prashantwason","followers_url":"https://api.github.com/users/prashantwason/followers","following_url":"https://api.github.com/users/prashantwason/following{/other_user}","gists_url":"https://api.github.com/users/prashantwason/gists{/gist_id}","starred_url":"https://api.github.com/users/prashantwason/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashantwason/subscriptions","organizations_url":"https://api.github.com/users/prashantwason/orgs","repos_url":"https://api.github.com/users/prashantwason/repos","events_url":"https://api.github.com/users/prashantwason/events{/privacy}","received_events_url":"https://api.github.com/users/prashantwason/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T21:04:22Z","updated_at":"2021-01-27T21:04:22Z","author_association":"MEMBER","body":"With enableReuse=false, the caching of readers needs special handling because:\r\n1. Multiple threads may call into HoodieBackedTableMetadata.getRecordByKeyFromMetadata() to read their respective keys\r\n2. If enableReuse=false, then each of these threads will try to close the readers after reading the key\r\n\r\nHence, we essentially have two codepaths:\r\n1. enableReuse=false then  readers cannot be cached\r\n2. enableReuse=true then the readers can be cached.\r\n\r\n\r\nI have updated the patch to handle both these cases by modifying the openFileSliceIfNeeded function (renamed to getReader) which returns either:\r\n1. cached readers when enableReuse=true\r\n2. newly opened readers when enableReuse=false","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768576158/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768598837","html_url":"https://github.com/apache/hudi/issues/2367#issuecomment-768598837","issue_url":"https://api.github.com/repos/apache/hudi/issues/2367","id":768598837,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODU5ODgzNw==","user":{"login":"stackfun","id":68627128,"node_id":"MDQ6VXNlcjY4NjI3MTI4","avatar_url":"https://avatars.githubusercontent.com/u/68627128?v=4","gravatar_id":"","url":"https://api.github.com/users/stackfun","html_url":"https://github.com/stackfun","followers_url":"https://api.github.com/users/stackfun/followers","following_url":"https://api.github.com/users/stackfun/following{/other_user}","gists_url":"https://api.github.com/users/stackfun/gists{/gist_id}","starred_url":"https://api.github.com/users/stackfun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stackfun/subscriptions","organizations_url":"https://api.github.com/users/stackfun/orgs","repos_url":"https://api.github.com/users/stackfun/repos","events_url":"https://api.github.com/users/stackfun/events{/privacy}","received_events_url":"https://api.github.com/users/stackfun/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-27T21:47:49Z","updated_at":"2021-01-27T21:47:49Z","author_association":"NONE","body":"New error in 0.7.0, somewhat related to this issue.\r\n\r\nHere's the stack trace:\r\n```rg.apache.hudi.exception.HoodieException: Exception when reading log file \r\n\tat org.apache.hudi.common.table.log.AbstractHoodieLogRecordScanner.scan(AbstractHoodieLogRecordScanner.java:250)\r\n\tat org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner.performScan(HoodieMergedLogRecordScanner.java:100)\r\n\tat org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner.<init>(HoodieMergedLogRecordScanner.java:93)\r\n\tat org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner.<init>(HoodieMergedLogRecordScanner.java:75)\r\n\tat org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner$Builder.build(HoodieMergedLogRecordScanner.java:230)\r\n\tat org.apache.hudi.HoodieMergeOnReadRDD$.scanLog(HoodieMergeOnReadRDD.scala:316)\r\n\tat org.apache.hudi.HoodieMergeOnReadRDD$$anon$3.<init>(HoodieMergeOnReadRDD.scala:203)\r\n\tat org.apache.hudi.HoodieMergeOnReadRDD.payloadCombineFileIterator(HoodieMergeOnReadRDD.scala:193)\r\n\tat org.apache.hudi.HoodieMergeOnReadRDD.compute(HoodieMergeOnReadRDD.scala:68)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ClassCastException: com.google.cloud.hadoop.fs.gcs.GoogleHadoopFSInputStream cannot be cast to org.apache.hadoop.fs.FSDataInputStream\r\n\tat org.apache.hudi.common.table.log.HoodieLogFileReader.<init>(HoodieLogFileReader.java:81)\r\n\tat org.apache.hudi.common.table.log.HoodieLogFormatReader.<init>(HoodieLogFormatReader.java:62)\r\n\tat org.apache.hudi.common.table.log.AbstractHoodieLogRecordScanner.scan(AbstractHoodieLogRecordScanner.java:131)\r\n\t... 25 more\r\n\r\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1892)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1879)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2113)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2062)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2051)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2836)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2835)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.Dataset.count(Dataset.scala:2835)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.hudi.exception.HoodieException: Exception when reading log file \r\n\tat org.apache.hudi.common.table.log.AbstractHoodieLogRecordScanner.scan(AbstractHoodieLogRecordScanner.java:250)\r\n\tat org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner.performScan(HoodieMergedLogRecordScanner.java:100)\r\n\tat org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner.<init>(HoodieMergedLogRecordScanner.java:93)\r\n\tat org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner.<init>(HoodieMergedLogRecordScanner.java:75)\r\n\tat org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner$Builder.build(HoodieMergedLogRecordScanner.java:230)\r\n\tat org.apache.hudi.HoodieMergeOnReadRDD$.scanLog(HoodieMergeOnReadRDD.scala:316)\r\n\tat org.apache.hudi.HoodieMergeOnReadRDD$$anon$3.<init>(HoodieMergeOnReadRDD.scala:203)\r\n\tat org.apache.hudi.HoodieMergeOnReadRDD.payloadCombineFileIterator(HoodieMergeOnReadRDD.scala:193)\r\n\tat org.apache.hudi.HoodieMergeOnReadRDD.compute(HoodieMergeOnReadRDD.scala:68)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\nCaused by: java.lang.ClassCastException: com.google.cloud.hadoop.fs.gcs.GoogleHadoopFSInputStream cannot be cast to org.apache.hadoop.fs.FSDataInputStream\r\n\tat org.apache.hudi.common.table.log.HoodieLogFileReader.<init>(HoodieLogFileReader.java:81)\r\n\tat org.apache.hudi.common.table.log.HoodieLogFormatReader.<init>(HoodieLogFormatReader.java:62)\r\n\tat org.apache.hudi.common.table.log.AbstractHoodieLogRecordScanner.scan(AbstractHoodieLogRecordScanner.java:131)\r\n\t... 25 more```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768598837/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768659539","html_url":"https://github.com/apache/hudi/issues/2367#issuecomment-768659539","issue_url":"https://api.github.com/repos/apache/hudi/issues/2367","id":768659539,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODY1OTUzOQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T00:03:20Z","updated_at":"2021-01-28T00:03:20Z","author_association":"CONTRIBUTOR","body":"https://github.com/apache/hudi/pull/2500\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768659539/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768664594","html_url":"https://github.com/apache/hudi/issues/2423#issuecomment-768664594","issue_url":"https://api.github.com/repos/apache/hudi/issues/2423","id":768664594,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODY2NDU5NA==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T00:17:14Z","updated_at":"2021-01-28T00:17:14Z","author_association":"CONTRIBUTOR","body":"https://github.com/apache/hudi/pull/2501\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768664594/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768674793","html_url":"https://github.com/apache/hudi/pull/2445#issuecomment-768674793","issue_url":"https://api.github.com/repos/apache/hudi/issues/2445","id":768674793,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODY3NDc5Mw==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T00:43:58Z","updated_at":"2021-01-28T00:43:58Z","author_association":"CONTRIBUTOR","body":"if the scope increases to log any data as per config/props, can you create a jira and link it. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768674793/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768679130","html_url":"https://github.com/apache/hudi/pull/2316#issuecomment-768679130","issue_url":"https://api.github.com/repos/apache/hudi/issues/2316","id":768679130,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODY3OTEzMA==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T00:55:38Z","updated_at":"2021-01-28T00:55:51Z","author_association":"CONTRIBUTOR","body":"@sbernauer : I landed another patch on this regard. can you please check the latest release and let us know if the the issue still persist ? If not, we can close this out. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768679130/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768679558","html_url":"https://github.com/apache/hudi/pull/2325#issuecomment-768679558","issue_url":"https://api.github.com/repos/apache/hudi/issues/2325","id":768679558,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODY3OTU1OA==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T00:56:52Z","updated_at":"2021-01-28T00:56:52Z","author_association":"CONTRIBUTOR","body":"@yanghua : you are planning to review this patch is it? Or if you are looking for someone else, let me know. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768679558/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768679586","html_url":"https://github.com/apache/hudi/pull/2445#issuecomment-768679586","issue_url":"https://api.github.com/repos/apache/hudi/issues/2445","id":768679586,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODY3OTU4Ng==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T00:56:57Z","updated_at":"2021-01-28T00:56:57Z","author_association":"CONTRIBUTOR","body":"> if the scope increases to log any data as per config/props, can you create a jira and link it.\r\n\r\n+1","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768679586/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768679917","html_url":"https://github.com/apache/hudi/issues/2479#issuecomment-768679917","issue_url":"https://api.github.com/repos/apache/hudi/issues/2479","id":768679917,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODY3OTkxNw==","user":{"login":"NickCodeJourney","id":72905543,"node_id":"MDQ6VXNlcjcyOTA1NTQz","avatar_url":"https://avatars.githubusercontent.com/u/72905543?v=4","gravatar_id":"","url":"https://api.github.com/users/NickCodeJourney","html_url":"https://github.com/NickCodeJourney","followers_url":"https://api.github.com/users/NickCodeJourney/followers","following_url":"https://api.github.com/users/NickCodeJourney/following{/other_user}","gists_url":"https://api.github.com/users/NickCodeJourney/gists{/gist_id}","starred_url":"https://api.github.com/users/NickCodeJourney/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/NickCodeJourney/subscriptions","organizations_url":"https://api.github.com/users/NickCodeJourney/orgs","repos_url":"https://api.github.com/users/NickCodeJourney/repos","events_url":"https://api.github.com/users/NickCodeJourney/events{/privacy}","received_events_url":"https://api.github.com/users/NickCodeJourney/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T00:57:57Z","updated_at":"2021-01-28T00:57:57Z","author_association":"CONTRIBUTOR","body":"how to deel the proplem","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768679917/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768682276","html_url":"https://github.com/apache/hudi/issues/2479#issuecomment-768682276","issue_url":"https://api.github.com/repos/apache/hudi/issues/2479","id":768682276,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODY4MjI3Ng==","user":{"login":"NickCodeJourney","id":72905543,"node_id":"MDQ6VXNlcjcyOTA1NTQz","avatar_url":"https://avatars.githubusercontent.com/u/72905543?v=4","gravatar_id":"","url":"https://api.github.com/users/NickCodeJourney","html_url":"https://github.com/NickCodeJourney","followers_url":"https://api.github.com/users/NickCodeJourney/followers","following_url":"https://api.github.com/users/NickCodeJourney/following{/other_user}","gists_url":"https://api.github.com/users/NickCodeJourney/gists{/gist_id}","starred_url":"https://api.github.com/users/NickCodeJourney/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/NickCodeJourney/subscriptions","organizations_url":"https://api.github.com/users/NickCodeJourney/orgs","repos_url":"https://api.github.com/users/NickCodeJourney/repos","events_url":"https://api.github.com/users/NickCodeJourney/events{/privacy}","received_events_url":"https://api.github.com/users/NickCodeJourney/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T01:04:35Z","updated_at":"2021-01-28T01:04:35Z","author_association":"CONTRIBUTOR","body":"> Thank you so much @vinothchandar !!!!!\r\n> \r\n> It worked, I will close this issue.\r\n\r\nhow to deel that","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768682276/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768687345","html_url":"https://github.com/apache/hudi/pull/2325#issuecomment-768687345","issue_url":"https://api.github.com/repos/apache/hudi/issues/2325","id":768687345,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODY4NzM0NQ==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T01:18:15Z","updated_at":"2021-01-28T01:18:15Z","author_association":"CONTRIBUTOR","body":"> @yanghua : you are planning to review this patch is it? Or if you are looking for someone else, let me know.\r\n\r\nTried to review this PR ago, however, it did not have a review condition(draft and CI failed) before. You go ahead. please","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768687345/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768747934","html_url":"https://github.com/apache/hudi/pull/2091#issuecomment-768747934","issue_url":"https://api.github.com/repos/apache/hudi/issues/2091","id":768747934,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODc0NzkzNA==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T02:16:21Z","updated_at":"2021-01-28T02:16:21Z","author_association":"CONTRIBUTOR","body":"May be we can guard it by a config. So only interested users can leverage it and default behavior is untouched. \r\n@umehrot2 @vinothchandar @bvaradar ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768747934/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768748851","html_url":"https://github.com/apache/hudi/pull/1706#issuecomment-768748851","issue_url":"https://api.github.com/repos/apache/hudi/issues/1706","id":768748851,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODc0ODg1MQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T02:18:55Z","updated_at":"2021-01-28T02:18:55Z","author_association":"CONTRIBUTOR","body":"@lamber-ken : are you planning to work on this. \r\n@n3nash : do we need this, or close it out. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768748851/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768866751","html_url":"https://github.com/apache/hudi/pull/1706#issuecomment-768866751","issue_url":"https://api.github.com/repos/apache/hudi/issues/1706","id":768866751,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODg2Njc1MQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T07:47:10Z","updated_at":"2021-01-28T07:47:10Z","author_association":"MEMBER","body":"we need this ultimately. \r\n@lamber-ken  we miss you man. where have you been? :) ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768866751/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768867873","html_url":"https://github.com/apache/hudi/pull/2404#issuecomment-768867873","issue_url":"https://api.github.com/repos/apache/hudi/issues/2404","id":768867873,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODg2Nzg3Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T07:49:46Z","updated_at":"2021-01-28T07:49:46Z","author_association":"MEMBER","body":"yes. thanks @wangxianghu ! ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768867873/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768877476","html_url":"https://github.com/apache/hudi/pull/2316#issuecomment-768877476","issue_url":"https://api.github.com/repos/apache/hudi/issues/2316","id":768877476,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODg3NzQ3Ng==","user":{"login":"sbernauer","id":29303194,"node_id":"MDQ6VXNlcjI5MzAzMTk0","avatar_url":"https://avatars.githubusercontent.com/u/29303194?v=4","gravatar_id":"","url":"https://api.github.com/users/sbernauer","html_url":"https://github.com/sbernauer","followers_url":"https://api.github.com/users/sbernauer/followers","following_url":"https://api.github.com/users/sbernauer/following{/other_user}","gists_url":"https://api.github.com/users/sbernauer/gists{/gist_id}","starred_url":"https://api.github.com/users/sbernauer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sbernauer/subscriptions","organizations_url":"https://api.github.com/users/sbernauer/orgs","repos_url":"https://api.github.com/users/sbernauer/repos","events_url":"https://api.github.com/users/sbernauer/events{/privacy}","received_events_url":"https://api.github.com/users/sbernauer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T08:10:07Z","updated_at":"2021-01-28T08:10:07Z","author_association":"CONTRIBUTOR","body":"Hi @nsivabalan sorry for missing the notification and thanks for your work! I get the `java.lang.NoClassDefFoundError: org/apache/hudi/org/apache/commons/codec/binary/Base64` when using an Hive Server with Thrift over HTTP.\r\n`hoodie.datasource.hive_sync.jdbcurl=jdbc:hive2://hive.{{ .Values.namespace | required \"Value namespace is required\" }}.svc.cluster.local:10001/default;transportMode=http;ssl=false;httpPath=cliservice;user=hudi;password=notneeded`\r\nIm updated to `hudi-utilities-bundle_2.12-0.7.0.jar` and `hudi-spark-bundle_2.12-0.7.0.jar`. Im getting the NoClassDefFoundError. My original provided patch with the `<include>commons-codec:commons-codec</include>` in the packaging/hudi-spark-bundle/pom.xml and packaging/hudi-utilities-bundle/pom.xml Tag did indeed work.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768877476/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768892942","html_url":"https://github.com/apache/hudi/issues/1498#issuecomment-768892942","issue_url":"https://api.github.com/repos/apache/hudi/issues/1498","id":768892942,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODg5Mjk0Mg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T08:40:01Z","updated_at":"2021-01-28T08:40:01Z","author_association":"MEMBER","body":"the row writer in 0.6.0 should have addressed this. we can close","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768892942/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768939469","html_url":"https://github.com/apache/hudi/pull/2501#issuecomment-768939469","issue_url":"https://api.github.com/repos/apache/hudi/issues/2501","id":768939469,"node_id":"MDEyOklzc3VlQ29tbWVudDc2ODkzOTQ2OQ==","user":{"login":"codecov-io","id":8655789,"node_id":"MDQ6VXNlcjg2NTU3ODk=","avatar_url":"https://avatars.githubusercontent.com/u/8655789?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-io","html_url":"https://github.com/codecov-io","followers_url":"https://api.github.com/users/codecov-io/followers","following_url":"https://api.github.com/users/codecov-io/following{/other_user}","gists_url":"https://api.github.com/users/codecov-io/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-io/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-io/subscriptions","organizations_url":"https://api.github.com/users/codecov-io/orgs","repos_url":"https://api.github.com/users/codecov-io/repos","events_url":"https://api.github.com/users/codecov-io/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-io/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T09:59:57Z","updated_at":"2021-01-30T17:57:20Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/2501?src=pr&el=h1) Report\n> Merging [#2501](https://codecov.io/gh/apache/hudi/pull/2501?src=pr&el=desc) (4d4a3c2) into [master](https://codecov.io/gh/apache/hudi/commit/5d053b495b8cb44cce88a67e82cbdfdc3d8b3180?el=desc) (5d053b4) will **increase** coverage by `19.69%`.\n> The diff coverage is `n/a`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/2501/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/2501?src=pr&el=tree)\n\n```diff\n@@              Coverage Diff              @@\n##             master    #2501       +/-   ##\n=============================================\n+ Coverage     49.78%   69.48%   +19.69%     \n+ Complexity     3089      358     -2731     \n=============================================\n  Files           430       53      -377     \n  Lines         19566     1930    -17636     \n  Branches       2004      230     -1774     \n=============================================\n- Hits           9741     1341     -8400     \n+ Misses         9033      456     -8577     \n+ Partials        792      133      -659     \n```\n\n| Flag | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| hudicli | `?` | `?` | |\n| hudiclient | `?` | `?` | |\n| hudicommon | `?` | `?` | |\n| hudiflink | `?` | `?` | |\n| hudihadoopmr | `?` | `?` | |\n| hudisparkdatasource | `?` | `?` | |\n| hudisync | `?` | `?` | |\n| huditimelineservice | `?` | `?` | |\n| hudiutilities | `69.48% <ø> (+7.61%)` | `0.00 <ø> (ø)` | |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/2501?src=pr&el=tree) | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| [...hudi/common/table/log/block/HoodieDeleteBlock.java](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3RhYmxlL2xvZy9ibG9jay9Ib29kaWVEZWxldGVCbG9jay5qYXZh) | | | |\n| [.../hudi/common/table/log/HoodieLogFormatVersion.java](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3RhYmxlL2xvZy9Ib29kaWVMb2dGb3JtYXRWZXJzaW9uLmphdmE=) | | | |\n| [...e/hudi/common/engine/LocalTaskContextSupplier.java](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL2VuZ2luZS9Mb2NhbFRhc2tDb250ZXh0U3VwcGxpZXIuamF2YQ==) | | | |\n| [...he/hudi/operator/event/BatchWriteSuccessEvent.java](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9ldmVudC9CYXRjaFdyaXRlU3VjY2Vzc0V2ZW50LmphdmE=) | | | |\n| [.../hadoop/realtime/AbstractRealtimeRecordReader.java](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree#diff-aHVkaS1oYWRvb3AtbXIvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvaGFkb29wL3JlYWx0aW1lL0Fic3RyYWN0UmVhbHRpbWVSZWNvcmRSZWFkZXIuamF2YQ==) | | | |\n| [.../src/main/java/org/apache/hudi/dla/util/Utils.java](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree#diff-aHVkaS1zeW5jL2h1ZGktZGxhLXN5bmMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvZGxhL3V0aWwvVXRpbHMuamF2YQ==) | | | |\n| [.../java/org/apache/hudi/common/util/FileIOUtils.java](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3V0aWwvRmlsZUlPVXRpbHMuamF2YQ==) | | | |\n| [...src/main/java/org/apache/hudi/QuickstartUtils.java](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay1kYXRhc291cmNlL2h1ZGktc3Bhcmsvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvUXVpY2tzdGFydFV0aWxzLmphdmE=) | | | |\n| [...va/org/apache/hudi/metadata/BaseTableMetadata.java](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvbWV0YWRhdGEvQmFzZVRhYmxlTWV0YWRhdGEuamF2YQ==) | | | |\n| [.../hadoop/realtime/RealtimeUnmergedRecordReader.java](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree#diff-aHVkaS1oYWRvb3AtbXIvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvaGFkb29wL3JlYWx0aW1lL1JlYWx0aW1lVW5tZXJnZWRSZWNvcmRSZWFkZXIuamF2YQ==) | | | |\n| ... and [373 more](https://codecov.io/gh/apache/hudi/pull/2501/diff?src=pr&el=tree-more) | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/768939469/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769027722","html_url":"https://github.com/apache/hudi/pull/2497#issuecomment-769027722","issue_url":"https://api.github.com/repos/apache/hudi/issues/2497","id":769027722,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTAyNzcyMg==","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T12:43:20Z","updated_at":"2021-01-28T12:43:20Z","author_association":"MEMBER","body":"@pengzhiwei2018 the build failure seems related. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769027722/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769038357","html_url":"https://github.com/apache/hudi/pull/2210#issuecomment-769038357","issue_url":"https://api.github.com/repos/apache/hudi/issues/2210","id":769038357,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTAzODM1Nw==","user":{"login":"hotienvu","id":1747423,"node_id":"MDQ6VXNlcjE3NDc0MjM=","avatar_url":"https://avatars.githubusercontent.com/u/1747423?v=4","gravatar_id":"","url":"https://api.github.com/users/hotienvu","html_url":"https://github.com/hotienvu","followers_url":"https://api.github.com/users/hotienvu/followers","following_url":"https://api.github.com/users/hotienvu/following{/other_user}","gists_url":"https://api.github.com/users/hotienvu/gists{/gist_id}","starred_url":"https://api.github.com/users/hotienvu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hotienvu/subscriptions","organizations_url":"https://api.github.com/users/hotienvu/orgs","repos_url":"https://api.github.com/users/hotienvu/repos","events_url":"https://api.github.com/users/hotienvu/events{/privacy}","received_events_url":"https://api.github.com/users/hotienvu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T13:03:59Z","updated_at":"2021-01-28T13:03:59Z","author_association":"CONTRIBUTOR","body":"@pratyakshsharma @nsivabalan  thanks for the feedback, I will resolve it as early as I could ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769038357/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769063418","html_url":"https://github.com/apache/hudi/pull/2502#issuecomment-769063418","issue_url":"https://api.github.com/repos/apache/hudi/issues/2502","id":769063418,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTA2MzQxOA==","user":{"login":"codecov-io","id":8655789,"node_id":"MDQ6VXNlcjg2NTU3ODk=","avatar_url":"https://avatars.githubusercontent.com/u/8655789?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-io","html_url":"https://github.com/codecov-io","followers_url":"https://api.github.com/users/codecov-io/followers","following_url":"https://api.github.com/users/codecov-io/following{/other_user}","gists_url":"https://api.github.com/users/codecov-io/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-io/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-io/subscriptions","organizations_url":"https://api.github.com/users/codecov-io/orgs","repos_url":"https://api.github.com/users/codecov-io/repos","events_url":"https://api.github.com/users/codecov-io/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-io/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T13:46:56Z","updated_at":"2021-01-29T05:42:18Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/2502?src=pr&el=h1) Report\n> Merging [#2502](https://codecov.io/gh/apache/hudi/pull/2502?src=pr&el=desc) (f903c85) into [master](https://codecov.io/gh/apache/hudi/commit/c8ee40f8ae34607072a27d4e7ccb21fc4df13ca1?el=desc) (c8ee40f) will **increase** coverage by `0.08%`.\n> The diff coverage is `0.00%`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/2502/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/2502?src=pr&el=tree)\n\n```diff\n@@             Coverage Diff              @@\n##             master    #2502      +/-   ##\n============================================\n+ Coverage     50.18%   50.27%   +0.08%     \n- Complexity     3051     3120      +69     \n============================================\n  Files           419      430      +11     \n  Lines         18931    19565     +634     \n  Branches       1948     2004      +56     \n============================================\n+ Hits           9501     9836     +335     \n- Misses         8656     8925     +269     \n- Partials        774      804      +30     \n```\n\n| Flag | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| hudicli | `37.21% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudiclient | `100.00% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudicommon | `51.49% <ø> (+<0.01%)` | `0.00 <ø> (ø)` | |\n| hudiflink | `33.03% <0.00%> (+33.03%)` | `0.00 <0.00> (ø)` | |\n| hudihadoopmr | `33.16% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudisparkdatasource | `65.85% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudisync | `48.61% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| huditimelineservice | `66.49% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudiutilities | `69.48% <ø> (ø)` | `0.00 <ø> (ø)` | |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/2502?src=pr&el=tree) | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| [.../apache/hudi/operator/InstantGenerateOperator.java](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9JbnN0YW50R2VuZXJhdGVPcGVyYXRvci5qYXZh) | `0.00% <0.00%> (ø)` | `0.00 <0.00> (ø)` | |\n| [...i/common/model/OverwriteWithLatestAvroPayload.java](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL21vZGVsL092ZXJ3cml0ZVdpdGhMYXRlc3RBdnJvUGF5bG9hZC5qYXZh) | `60.00% <0.00%> (-4.71%)` | `10.00% <0.00%> (ø%)` | |\n| [...e/hudi/common/table/log/HoodieLogFormatWriter.java](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3RhYmxlL2xvZy9Ib29kaWVMb2dGb3JtYXRXcml0ZXIuamF2YQ==) | `78.12% <0.00%> (-1.57%)` | `26.00% <0.00%> (ø%)` | |\n| [...ain/java/org/apache/hudi/avro/HoodieAvroUtils.java](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvYXZyby9Ib29kaWVBdnJvVXRpbHMuamF2YQ==) | `56.09% <0.00%> (ø)` | `38.00% <0.00%> (+1.00%)` | |\n| [...main/java/org/apache/hudi/HoodieFlinkStreamer.java](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9Ib29kaWVGbGlua1N0cmVhbWVyLmphdmE=) | | | |\n| [...ache/hudi/operator/StreamWriteOperatorFactory.java](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9TdHJlYW1Xcml0ZU9wZXJhdG9yRmFjdG9yeS5qYXZh) | `0.00% <0.00%> (ø)` | `0.00% <0.00%> (?%)` | |\n| [...he/hudi/operator/event/BatchWriteSuccessEvent.java](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9ldmVudC9CYXRjaFdyaXRlU3VjY2Vzc0V2ZW50LmphdmE=) | `100.00% <0.00%> (ø)` | `4.00% <0.00%> (?%)` | |\n| [.../org/apache/hudi/operator/StreamWriteFunction.java](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9TdHJlYW1Xcml0ZUZ1bmN0aW9uLmphdmE=) | `80.55% <0.00%> (ø)` | `14.00% <0.00%> (?%)` | |\n| [.../org/apache/hudi/util/RowDataToAvroConverters.java](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS91dGlsL1Jvd0RhdGFUb0F2cm9Db252ZXJ0ZXJzLmphdmE=) | `42.05% <0.00%> (ø)` | `8.00% <0.00%> (?%)` | |\n| [...java/org/apache/hudi/util/AvroSchemaConverter.java](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS91dGlsL0F2cm9TY2hlbWFDb252ZXJ0ZXIuamF2YQ==) | `0.00% <0.00%> (ø)` | `0.00% <0.00%> (?%)` | |\n| ... and [11 more](https://codecov.io/gh/apache/hudi/pull/2502/diff?src=pr&el=tree-more) | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769063418/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769144965","html_url":"https://github.com/apache/hudi/pull/2497#issuecomment-769144965","issue_url":"https://api.github.com/repos/apache/hudi/issues/2497","id":769144965,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTE0NDk2NQ==","user":{"login":"pengzhiwei2018","id":42458891,"node_id":"MDQ6VXNlcjQyNDU4ODkx","avatar_url":"https://avatars.githubusercontent.com/u/42458891?v=4","gravatar_id":"","url":"https://api.github.com/users/pengzhiwei2018","html_url":"https://github.com/pengzhiwei2018","followers_url":"https://api.github.com/users/pengzhiwei2018/followers","following_url":"https://api.github.com/users/pengzhiwei2018/following{/other_user}","gists_url":"https://api.github.com/users/pengzhiwei2018/gists{/gist_id}","starred_url":"https://api.github.com/users/pengzhiwei2018/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pengzhiwei2018/subscriptions","organizations_url":"https://api.github.com/users/pengzhiwei2018/orgs","repos_url":"https://api.github.com/users/pengzhiwei2018/repos","events_url":"https://api.github.com/users/pengzhiwei2018/events{/privacy}","received_events_url":"https://api.github.com/users/pengzhiwei2018/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T15:02:32Z","updated_at":"2021-01-28T15:02:32Z","author_association":"NONE","body":"> @pengzhiwei2018 the build failure seems related.\r\n\r\nYes, I have fix it now.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769144965/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769315395","html_url":"https://github.com/apache/hudi/pull/2496#issuecomment-769315395","issue_url":"https://api.github.com/repos/apache/hudi/issues/2496","id":769315395,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTMxNTM5NQ==","user":{"login":"prashantwason","id":58448203,"node_id":"MDQ6VXNlcjU4NDQ4MjAz","avatar_url":"https://avatars.githubusercontent.com/u/58448203?v=4","gravatar_id":"","url":"https://api.github.com/users/prashantwason","html_url":"https://github.com/prashantwason","followers_url":"https://api.github.com/users/prashantwason/followers","following_url":"https://api.github.com/users/prashantwason/following{/other_user}","gists_url":"https://api.github.com/users/prashantwason/gists{/gist_id}","starred_url":"https://api.github.com/users/prashantwason/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashantwason/subscriptions","organizations_url":"https://api.github.com/users/prashantwason/orgs","repos_url":"https://api.github.com/users/prashantwason/repos","events_url":"https://api.github.com/users/prashantwason/events{/privacy}","received_events_url":"https://api.github.com/users/prashantwason/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T19:21:27Z","updated_at":"2021-01-28T19:21:27Z","author_association":"MEMBER","body":"> High level question , should we always buffer or make this configurable for HDFS only?\r\n\r\nI don't have idea about other file systems and their inherent buffering. You can decide. I did not see an easy way to restrict this as HoodieWrapperFileSystem currently does not take any properties.  ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769315395/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769390677","html_url":"https://github.com/apache/hudi/pull/2506#issuecomment-769390677","issue_url":"https://api.github.com/repos/apache/hudi/issues/2506","id":769390677,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTM5MDY3Nw==","user":{"login":"codecov-io","id":8655789,"node_id":"MDQ6VXNlcjg2NTU3ODk=","avatar_url":"https://avatars.githubusercontent.com/u/8655789?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-io","html_url":"https://github.com/codecov-io","followers_url":"https://api.github.com/users/codecov-io/followers","following_url":"https://api.github.com/users/codecov-io/following{/other_user}","gists_url":"https://api.github.com/users/codecov-io/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-io/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-io/subscriptions","organizations_url":"https://api.github.com/users/codecov-io/orgs","repos_url":"https://api.github.com/users/codecov-io/repos","events_url":"https://api.github.com/users/codecov-io/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-io/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T21:01:55Z","updated_at":"2021-02-05T13:52:13Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/2506?src=pr&el=h1) Report\n> Merging [#2506](https://codecov.io/gh/apache/hudi/pull/2506?src=pr&el=desc) (5129df4) into [master](https://codecov.io/gh/apache/hudi/commit/bc0325f6ea0a734f106f21a2fcd4ead413a6cf7b?el=desc) (bc0325f) will **increase** coverage by `0.67%`.\n> The diff coverage is `70.19%`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/2506/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/2506?src=pr&el=tree)\n\n```diff\n@@             Coverage Diff              @@\n##             master    #2506      +/-   ##\n============================================\n+ Coverage     50.26%   50.94%   +0.67%     \n- Complexity     3119     3167      +48     \n============================================\n  Files           430      433       +3     \n  Lines         19565    19788     +223     \n  Branches       2004     2031      +27     \n============================================\n+ Hits           9835    10081     +246     \n+ Misses         8925     8887      -38     \n- Partials        805      820      +15     \n```\n\n| Flag | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| hudicli | `37.21% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudiclient | `100.00% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudicommon | `51.38% <0.00%> (-0.12%)` | `0.00 <0.00> (ø)` | |\n| hudiflink | `43.21% <71.31%> (+10.17%)` | `0.00 <39.00> (ø)` | |\n| hudihadoopmr | `33.16% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudisparkdatasource | `69.46% <ø> (+3.60%)` | `0.00 <ø> (ø)` | |\n| hudisync | `48.61% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| huditimelineservice | `66.49% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudiutilities | `69.46% <ø> (+0.03%)` | `0.00 <ø> (ø)` | |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/2506?src=pr&el=tree) | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| [...di/common/table/timeline/HoodieActiveTimeline.java](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3RhYmxlL3RpbWVsaW5lL0hvb2RpZUFjdGl2ZVRpbWVsaW5lLmphdmE=) | `70.64% <0.00%> (-1.33%)` | `42.00 <0.00> (ø)` | |\n| [.../apache/hudi/operator/InstantGenerateOperator.java](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9JbnN0YW50R2VuZXJhdGVPcGVyYXRvci5qYXZh) | `0.00% <0.00%> (ø)` | `0.00 <0.00> (ø)` | |\n| [...pache/hudi/operator/KeyedWriteProcessFunction.java](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9LZXllZFdyaXRlUHJvY2Vzc0Z1bmN0aW9uLmphdmE=) | `0.00% <0.00%> (ø)` | `0.00 <0.00> (ø)` | |\n| [.../org/apache/hudi/operator/StreamWriteOperator.java](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9TdHJlYW1Xcml0ZU9wZXJhdG9yLmphdmE=) | `0.00% <0.00%> (ø)` | `0.00 <0.00> (ø)` | |\n| [...ache/hudi/operator/StreamWriteOperatorFactory.java](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9TdHJlYW1Xcml0ZU9wZXJhdG9yRmFjdG9yeS5qYXZh) | `0.00% <0.00%> (ø)` | `0.00 <0.00> (ø)` | |\n| [.../org/apache/hudi/streamer/FlinkStreamerConfig.java](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9zdHJlYW1lci9GbGlua1N0cmVhbWVyQ29uZmlnLmphdmE=) | `0.00% <ø> (ø)` | `0.00 <0.00> (ø)` | |\n| [.../org/apache/hudi/streamer/HoodieFlinkStreamer.java](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9zdHJlYW1lci9Ib29kaWVGbGlua1N0cmVhbWVyLmphdmE=) | `0.00% <0.00%> (ø)` | `0.00 <0.00> (ø)` | |\n| [...rg/apache/hudi/streamer/HoodieFlinkStreamerV2.java](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9zdHJlYW1lci9Ib29kaWVGbGlua1N0cmVhbWVyVjIuamF2YQ==) | `0.00% <0.00%> (ø)` | `0.00 <0.00> (ø)` | |\n| [...ache/hudi/operator/partitioner/BucketAssigner.java](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9vcGVyYXRvci9wYXJ0aXRpb25lci9CdWNrZXRBc3NpZ25lci5qYXZh) | `80.00% <80.00%> (ø)` | `18.00 <18.00> (?)` | |\n| [...c/main/java/org/apache/hudi/util/StreamerUtil.java](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree#diff-aHVkaS1mbGluay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS91dGlsL1N0cmVhbWVyVXRpbC5qYXZh) | `43.68% <82.35%> (+11.13%)` | `13.00 <3.00> (+4.00)` | |\n| ... and [21 more](https://codecov.io/gh/apache/hudi/pull/2506/diff?src=pr&el=tree-more) | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769390677/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769423274","html_url":"https://github.com/apache/hudi/issues/2498#issuecomment-769423274","issue_url":"https://api.github.com/repos/apache/hudi/issues/2498","id":769423274,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTQyMzI3NA==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T21:51:57Z","updated_at":"2021-01-28T21:51:57Z","author_association":"CONTRIBUTOR","body":"Can you try this config \r\n\"hoodie.datasource.write.table.type\" and set it to MERGE_ON_READ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769423274/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769433405","html_url":"https://github.com/apache/hudi/issues/2323#issuecomment-769433405","issue_url":"https://api.github.com/repos/apache/hudi/issues/2323","id":769433405,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTQzMzQwNQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-28T22:12:52Z","updated_at":"2021-01-28T22:12:52Z","author_association":"CONTRIBUTOR","body":"got it. Hudi is looking to add record level indexing in next release, and global lookup should become lot faster with that. Hopefully it helps you. Can we close this ticket if you don't have any more questions? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769433405/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769488067","html_url":"https://github.com/apache/hudi/issues/2367#issuecomment-769488067","issue_url":"https://api.github.com/repos/apache/hudi/issues/2367","id":769488067,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTQ4ODA2Nw==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T00:26:48Z","updated_at":"2021-01-29T00:26:48Z","author_association":"CONTRIBUTOR","body":"@stackfun : have you encountered the issue reported here: https://issues.apache.org/jira/browse/HUDI-1063\r\nif not, would you mind responding to it if you know the fix/workaround. thanks for your assistance :) ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769488067/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769513621","html_url":"https://github.com/apache/hudi/pull/2500#issuecomment-769513621","issue_url":"https://api.github.com/repos/apache/hudi/issues/2500","id":769513621,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTUxMzYyMQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T01:36:19Z","updated_at":"2021-01-29T01:36:19Z","author_association":"MEMBER","body":"cc @vburenin could you please review this as well? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769513621/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769513904","html_url":"https://github.com/apache/hudi/pull/2497#issuecomment-769513904","issue_url":"https://api.github.com/repos/apache/hudi/issues/2497","id":769513904,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTUxMzkwNA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T01:37:07Z","updated_at":"2021-01-29T01:37:07Z","author_association":"MEMBER","body":"cc @nsivabalan to also triage","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769513904/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769517183","html_url":"https://github.com/apache/hudi/pull/2475#issuecomment-769517183","issue_url":"https://api.github.com/repos/apache/hudi/issues/2475","id":769517183,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTUxNzE4Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T01:47:06Z","updated_at":"2021-01-29T01:47:06Z","author_association":"MEMBER","body":"@zhedoubushishi @umehrot2 could you please take a first pass","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769517183/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769517737","html_url":"https://github.com/apache/hudi/pull/2455#issuecomment-769517737","issue_url":"https://api.github.com/repos/apache/hudi/issues/2455","id":769517737,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTUxNzczNw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T01:48:42Z","updated_at":"2021-01-29T01:48:42Z","author_association":"MEMBER","body":"Its been a while. So okay to drop this now. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769517737/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769518155","html_url":"https://github.com/apache/hudi/pull/2431#issuecomment-769518155","issue_url":"https://api.github.com/repos/apache/hudi/issues/2431","id":769518155,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTUxODE1NQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T01:49:55Z","updated_at":"2021-01-29T01:49:55Z","author_association":"MEMBER","body":"@nsivabalan @zhedoubushishi  also to review.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769518155/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769518711","html_url":"https://github.com/apache/hudi/pull/2452#issuecomment-769518711","issue_url":"https://api.github.com/repos/apache/hudi/issues/2452","id":769518711,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTUxODcxMQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T01:51:46Z","updated_at":"2021-01-29T01:51:46Z","author_association":"MEMBER","body":"@n3nash can you also please review this?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769518711/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769525257","html_url":"https://github.com/apache/hudi/pull/1975#issuecomment-769525257","issue_url":"https://api.github.com/repos/apache/hudi/issues/1975","id":769525257,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTUyNTI1Nw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T02:09:33Z","updated_at":"2021-01-29T02:09:33Z","author_association":"MEMBER","body":"@lw309637554 could you review this as well? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769525257/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769557231","html_url":"https://github.com/apache/hudi/pull/2505#issuecomment-769557231","issue_url":"https://api.github.com/repos/apache/hudi/issues/2505","id":769557231,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTU1NzIzMQ==","user":{"login":"codecov-io","id":8655789,"node_id":"MDQ6VXNlcjg2NTU3ODk=","avatar_url":"https://avatars.githubusercontent.com/u/8655789?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-io","html_url":"https://github.com/codecov-io","followers_url":"https://api.github.com/users/codecov-io/followers","following_url":"https://api.github.com/users/codecov-io/following{/other_user}","gists_url":"https://api.github.com/users/codecov-io/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-io/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-io/subscriptions","organizations_url":"https://api.github.com/users/codecov-io/orgs","repos_url":"https://api.github.com/users/codecov-io/repos","events_url":"https://api.github.com/users/codecov-io/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-io/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T03:53:06Z","updated_at":"2021-01-29T16:53:40Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/2505?src=pr&el=h1) Report\n> Merging [#2505](https://codecov.io/gh/apache/hudi/pull/2505?src=pr&el=desc) (453c184) into [master](https://codecov.io/gh/apache/hudi/commit/c4afd179c1983a382b8a5197d800b0f5dba254de?el=desc) (c4afd17) will **decrease** coverage by `40.49%`.\n> The diff coverage is `n/a`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/2505/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/2505?src=pr&el=tree)\n\n```diff\n@@             Coverage Diff              @@\n##             master   #2505       +/-   ##\n============================================\n- Coverage     50.18%   9.68%   -40.50%     \n+ Complexity     3050      48     -3002     \n============================================\n  Files           419      53      -366     \n  Lines         18931    1930    -17001     \n  Branches       1948     230     -1718     \n============================================\n- Hits           9500     187     -9313     \n+ Misses         8656    1730     -6926     \n+ Partials        775      13      -762     \n```\n\n| Flag | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| hudicli | `?` | `?` | |\n| hudiclient | `?` | `?` | |\n| hudicommon | `?` | `?` | |\n| hudiflink | `?` | `?` | |\n| hudihadoopmr | `?` | `?` | |\n| hudisparkdatasource | `?` | `?` | |\n| hudisync | `?` | `?` | |\n| huditimelineservice | `?` | `?` | |\n| hudiutilities | `9.68% <ø> (-59.75%)` | `0.00 <ø> (ø)` | |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/2505?src=pr&el=tree) | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| [...va/org/apache/hudi/utilities/IdentitySplitter.java](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL0lkZW50aXR5U3BsaXR0ZXIuamF2YQ==) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-2.00%)` | |\n| [...va/org/apache/hudi/utilities/schema/SchemaSet.java](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NjaGVtYS9TY2hlbWFTZXQuamF2YQ==) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-3.00%)` | |\n| [...a/org/apache/hudi/utilities/sources/RowSource.java](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvUm93U291cmNlLmphdmE=) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-4.00%)` | |\n| [.../org/apache/hudi/utilities/sources/AvroSource.java](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvQXZyb1NvdXJjZS5qYXZh) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-1.00%)` | |\n| [.../org/apache/hudi/utilities/sources/JsonSource.java](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvSnNvblNvdXJjZS5qYXZh) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-1.00%)` | |\n| [...rg/apache/hudi/utilities/sources/CsvDFSSource.java](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvQ3N2REZTU291cmNlLmphdmE=) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-10.00%)` | |\n| [...g/apache/hudi/utilities/sources/JsonDFSSource.java](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvSnNvbkRGU1NvdXJjZS5qYXZh) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-4.00%)` | |\n| [...apache/hudi/utilities/sources/JsonKafkaSource.java](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvSnNvbkthZmthU291cmNlLmphdmE=) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-6.00%)` | |\n| [...pache/hudi/utilities/sources/ParquetDFSSource.java](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvUGFycXVldERGU1NvdXJjZS5qYXZh) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-5.00%)` | |\n| [...lities/schema/SchemaProviderWithPostProcessor.java](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NjaGVtYS9TY2hlbWFQcm92aWRlcldpdGhQb3N0UHJvY2Vzc29yLmphdmE=) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-4.00%)` | |\n| ... and [395 more](https://codecov.io/gh/apache/hudi/pull/2505/diff?src=pr&el=tree-more) | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769557231/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769566404","html_url":"https://github.com/apache/hudi/issues/1829#issuecomment-769566404","issue_url":"https://api.github.com/repos/apache/hudi/issues/1829","id":769566404,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTU2NjQwNA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T04:26:19Z","updated_at":"2021-01-29T04:26:19Z","author_association":"MEMBER","body":"0.7.0 is out! ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769566404/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769568185","html_url":"https://github.com/apache/hudi/pull/2419#issuecomment-769568185","issue_url":"https://api.github.com/repos/apache/hudi/issues/2419","id":769568185,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTU2ODE4NQ==","user":{"login":"wangxianghu","id":49835526,"node_id":"MDQ6VXNlcjQ5ODM1NTI2","avatar_url":"https://avatars.githubusercontent.com/u/49835526?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxianghu","html_url":"https://github.com/wangxianghu","followers_url":"https://api.github.com/users/wangxianghu/followers","following_url":"https://api.github.com/users/wangxianghu/following{/other_user}","gists_url":"https://api.github.com/users/wangxianghu/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxianghu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxianghu/subscriptions","organizations_url":"https://api.github.com/users/wangxianghu/orgs","repos_url":"https://api.github.com/users/wangxianghu/repos","events_url":"https://api.github.com/users/wangxianghu/events{/privacy}","received_events_url":"https://api.github.com/users/wangxianghu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T04:32:55Z","updated_at":"2021-01-29T04:32:55Z","author_association":"CONTRIBUTOR","body":"@loukey-lj sorry for the delay, please fix the conficts first","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769568185/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769600129","html_url":"https://github.com/apache/hudi/issues/2100#issuecomment-769600129","issue_url":"https://api.github.com/repos/apache/hudi/issues/2100","id":769600129,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTYwMDEyOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T06:09:57Z","updated_at":"2021-01-29T06:10:06Z","author_association":"MEMBER","body":"> I feel that the independent timeline service may be helpful in identifying hudi tables in a cluster.\r\n\r\n@cdmikechen This is actually very interesting to me too. Can we start a DISCUSS thread around this? we can also embed the Hive MetaStore instance within and make it very simple for everyone to deploy ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769600129/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769607086","html_url":"https://github.com/apache/hudi/issues/2149#issuecomment-769607086","issue_url":"https://api.github.com/repos/apache/hudi/issues/2149","id":769607086,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTYwNzA4Ng==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T06:28:18Z","updated_at":"2021-01-29T06:28:18Z","author_association":"MEMBER","body":"@toninis this is kind of weird, given the snippet that has the constructor. the class seems to be there in the build. \r\ndo you have a branch where you have the code stashed? We can open a new issue or JIRA and work through this cc @nsivabalan ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769607086/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769682139","html_url":"https://github.com/apache/hudi/issues/2323#issuecomment-769682139","issue_url":"https://api.github.com/repos/apache/hudi/issues/2323","id":769682139,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTY4MjEzOQ==","user":{"login":"kirqz23","id":22114492,"node_id":"MDQ6VXNlcjIyMTE0NDky","avatar_url":"https://avatars.githubusercontent.com/u/22114492?v=4","gravatar_id":"","url":"https://api.github.com/users/kirqz23","html_url":"https://github.com/kirqz23","followers_url":"https://api.github.com/users/kirqz23/followers","following_url":"https://api.github.com/users/kirqz23/following{/other_user}","gists_url":"https://api.github.com/users/kirqz23/gists{/gist_id}","starred_url":"https://api.github.com/users/kirqz23/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kirqz23/subscriptions","organizations_url":"https://api.github.com/users/kirqz23/orgs","repos_url":"https://api.github.com/users/kirqz23/repos","events_url":"https://api.github.com/users/kirqz23/events{/privacy}","received_events_url":"https://api.github.com/users/kirqz23/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T09:16:16Z","updated_at":"2021-01-29T09:16:16Z","author_association":"NONE","body":"Yes, feel free to close it. I'll check that in the new release.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769682139/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769697170","html_url":"https://github.com/apache/hudi/pull/2502#issuecomment-769697170","issue_url":"https://api.github.com/repos/apache/hudi/issues/2502","id":769697170,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTY5NzE3MA==","user":{"login":"lw309637554","id":8501994,"node_id":"MDQ6VXNlcjg1MDE5OTQ=","avatar_url":"https://avatars.githubusercontent.com/u/8501994?v=4","gravatar_id":"","url":"https://api.github.com/users/lw309637554","html_url":"https://github.com/lw309637554","followers_url":"https://api.github.com/users/lw309637554/followers","following_url":"https://api.github.com/users/lw309637554/following{/other_user}","gists_url":"https://api.github.com/users/lw309637554/gists{/gist_id}","starred_url":"https://api.github.com/users/lw309637554/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lw309637554/subscriptions","organizations_url":"https://api.github.com/users/lw309637554/orgs","repos_url":"https://api.github.com/users/lw309637554/repos","events_url":"https://api.github.com/users/lw309637554/events{/privacy}","received_events_url":"https://api.github.com/users/lw309637554/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T09:43:51Z","updated_at":"2021-01-29T09:43:51Z","author_association":"CONTRIBUTOR","body":"LGTM","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769697170/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769721260","html_url":"https://github.com/apache/hudi/issues/2498#issuecomment-769721260","issue_url":"https://api.github.com/repos/apache/hudi/issues/2498","id":769721260,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTcyMTI2MA==","user":{"login":"zafer-sahin","id":63556382,"node_id":"MDQ6VXNlcjYzNTU2Mzgy","avatar_url":"https://avatars.githubusercontent.com/u/63556382?v=4","gravatar_id":"","url":"https://api.github.com/users/zafer-sahin","html_url":"https://github.com/zafer-sahin","followers_url":"https://api.github.com/users/zafer-sahin/followers","following_url":"https://api.github.com/users/zafer-sahin/following{/other_user}","gists_url":"https://api.github.com/users/zafer-sahin/gists{/gist_id}","starred_url":"https://api.github.com/users/zafer-sahin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zafer-sahin/subscriptions","organizations_url":"https://api.github.com/users/zafer-sahin/orgs","repos_url":"https://api.github.com/users/zafer-sahin/repos","events_url":"https://api.github.com/users/zafer-sahin/events{/privacy}","received_events_url":"https://api.github.com/users/zafer-sahin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T10:30:10Z","updated_at":"2021-01-29T10:31:29Z","author_association":"NONE","body":"Hi, I am still getting a similar error at the time of reading.\r\n\r\n\r\n\r\n>>> hudi_options_insert = {\r\n...     \"hoodie.table.name\": \"the_table_name\",\r\n...     \"hoodie.datasource.write.storage.type\": \"MERGE_ON_READ\",\r\n...     \"hoodie.datasource.write.table.type\": \"MERGE_ON_READ\",\r\n...     \"hoodie.datasource.write.recordkey.field\": \"id\",\r\n...     \"hoodie.datasource.write.operation\": \"bulk_insert\",\r\n...     \"hoodie.datasource.write.partitionpath.field\": \"ds\",\r\n...     \"hoodie.datasource.write.precombine.field\": \"id\",\r\n...     \"hoodie.insert.shuffle.parallelism\": 135\r\n...     }\r\n>>> df.write.format(\"hudi\").options(**hudi_options_insert).mode(\"overwrite\").save(S3_MERGE_ON_READ)\r\n>>> df_mor = spark.read.format(\"hudi\").load(S3_MERGE_ON_READ + \"/*\") \r\n\r\n\r\n`Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/spark/python/pyspark/sql/readwriter.py\", line 178, in load\r\n    return self._df(self._jreader.load(path))\r\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\r\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 128, in deco\r\n    return f(*a, **kw)\r\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 328, in get_return_value\r\npy4j.protocol.Py4JJavaError: An error occurred while calling o87.load.\r\n: java.lang.NoSuchMethodError: org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(Lorg/apache/spark/sql/SparkSession;Lscala/collection/Seq;Lscala/collection/immutable/Map;Lscala/Option;Lorg/apache/spark/sql/execution/datasources/FileStatusCache;)V\r\n\tat org.apache.hudi.HoodieSparkUtils$.createInMemoryFileIndex(HoodieSparkUtils.scala:89)\r\n\tat org.apache.hudi.MergeOnReadSnapshotRelation.buildFileIndex(MergeOnReadSnapshotRelation.scala:127)\r\n\tat org.apache.hudi.MergeOnReadSnapshotRelation.<init>(MergeOnReadSnapshotRelation.scala:72)\r\n\tat org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:89)\r\n\tat org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:53)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:344)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:232)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)`","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769721260/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769762431","html_url":"https://github.com/apache/hudi/pull/2505#issuecomment-769762431","issue_url":"https://api.github.com/repos/apache/hudi/issues/2505","id":769762431,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTc2MjQzMQ==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T11:57:20Z","updated_at":"2021-01-29T11:57:20Z","author_association":"CONTRIBUTOR","body":"@wangxianghu You can try to merge after the CI is OK.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769762431/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769764823","html_url":"https://github.com/apache/hudi/pull/2506#issuecomment-769764823","issue_url":"https://api.github.com/repos/apache/hudi/issues/2506","id":769764823,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTc2NDgyMw==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T12:02:41Z","updated_at":"2021-01-29T12:02:41Z","author_association":"CONTRIBUTOR","body":"@danny0405 ping us, when you are ready to review.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769764823/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769918590","html_url":"https://github.com/apache/hudi/issues/2498#issuecomment-769918590","issue_url":"https://api.github.com/repos/apache/hudi/issues/2498","id":769918590,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTkxODU5MA==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T16:47:15Z","updated_at":"2021-01-29T16:48:42Z","author_association":"CONTRIBUTOR","body":"@zafer-sahin : not sure if its some env issue. Were you able to run the pyspark examples given in [quick start](https://hudi.apache.org/docs/quick-start-guide.html). If that works, but just MOR fails, then we can look into it. If you haven't tried it, can you try it and let us know. Also, your Precombine field should be something like timestamp and can't be same as record key field. Basically this is used to determine the ordering of multiple entries for the same record keys. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769918590/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769948718","html_url":"https://github.com/apache/hudi/issues/2470#issuecomment-769948718","issue_url":"https://api.github.com/repos/apache/hudi/issues/2470","id":769948718,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTk0ODcxOA==","user":{"login":"jtmzheng","id":3466206,"node_id":"MDQ6VXNlcjM0NjYyMDY=","avatar_url":"https://avatars.githubusercontent.com/u/3466206?v=4","gravatar_id":"","url":"https://api.github.com/users/jtmzheng","html_url":"https://github.com/jtmzheng","followers_url":"https://api.github.com/users/jtmzheng/followers","following_url":"https://api.github.com/users/jtmzheng/following{/other_user}","gists_url":"https://api.github.com/users/jtmzheng/gists{/gist_id}","starred_url":"https://api.github.com/users/jtmzheng/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jtmzheng/subscriptions","organizations_url":"https://api.github.com/users/jtmzheng/orgs","repos_url":"https://api.github.com/users/jtmzheng/repos","events_url":"https://api.github.com/users/jtmzheng/events{/privacy}","received_events_url":"https://api.github.com/users/jtmzheng/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T17:42:27Z","updated_at":"2021-01-29T17:42:27Z","author_association":"NONE","body":"Sorry for the delay, I believe the slowness was because compaction wasn't keeping up with the number of files (we partition by date and we have many partitions updated with a small number of updates with most coming in current date) and file count was growing faster than dataset size. I saw that IO was bounded on compaction and its based on log file size so the smaller updates were never getting compacted. \r\n\r\nI've since increased the IO bound 3x and performance is slowly improving as file count goes down (ie. getting small files stage is faster). I'll update once we test rollback performance but I suspect it will also be better.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769948718/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769977226","html_url":"https://github.com/apache/hudi/issues/2367#issuecomment-769977226","issue_url":"https://api.github.com/repos/apache/hudi/issues/2367","id":769977226,"node_id":"MDEyOklzc3VlQ29tbWVudDc2OTk3NzIyNg==","user":{"login":"stackfun","id":68627128,"node_id":"MDQ6VXNlcjY4NjI3MTI4","avatar_url":"https://avatars.githubusercontent.com/u/68627128?v=4","gravatar_id":"","url":"https://api.github.com/users/stackfun","html_url":"https://github.com/stackfun","followers_url":"https://api.github.com/users/stackfun/followers","following_url":"https://api.github.com/users/stackfun/following{/other_user}","gists_url":"https://api.github.com/users/stackfun/gists{/gist_id}","starred_url":"https://api.github.com/users/stackfun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stackfun/subscriptions","organizations_url":"https://api.github.com/users/stackfun/orgs","repos_url":"https://api.github.com/users/stackfun/repos","events_url":"https://api.github.com/users/stackfun/events{/privacy}","received_events_url":"https://api.github.com/users/stackfun/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T18:37:21Z","updated_at":"2021-01-29T18:37:21Z","author_association":"NONE","body":"I'll test this patch in the next few days.\r\n\r\nWondering what level of testing is done on GCP before a release?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/769977226/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770011435","html_url":"https://github.com/apache/hudi/pull/2496#issuecomment-770011435","issue_url":"https://api.github.com/repos/apache/hudi/issues/2496","id":770011435,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDAxMTQzNQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T19:45:49Z","updated_at":"2021-01-29T19:45:49Z","author_association":"MEMBER","body":"cc @umehrot2 would this additional buffering pose inefficiencies for S3 FileSystem? TL;DR HDFS's `DistributedFileSystem` does not buffer reads, neither does the parquet reader. so this just cuts down a ton of RPC calls to NameNode.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770011435/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770018126","html_url":"https://github.com/apache/hudi/pull/2496#issuecomment-770018126","issue_url":"https://api.github.com/repos/apache/hudi/issues/2496","id":770018126,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDAxODEyNg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T19:59:03Z","updated_at":"2021-01-29T19:59:03Z","author_association":"MEMBER","body":"Once we fix CI and the minor stuff, we can land","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770018126/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770029110","html_url":"https://github.com/apache/hudi/issues/2470#issuecomment-770029110","issue_url":"https://api.github.com/repos/apache/hudi/issues/2470","id":770029110,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDAyOTExMA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T20:21:19Z","updated_at":"2021-01-29T20:21:19Z","author_association":"MEMBER","body":"Thanks @jtmzheng . WIth 0.7.0 and `hoodie.metadata.enable=true`, this should be much faster to go over the file listings. marker based rollback avoids that altogether and can efficiently just find out the files that were written to.\r\n\r\nIf you feel, we need to add a new compaction strategy/enhance, please feel free to raise a JIRA and also mention @nsivabalan ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770029110/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770090356","html_url":"https://github.com/apache/hudi/pull/2497#issuecomment-770090356","issue_url":"https://api.github.com/repos/apache/hudi/issues/2497","id":770090356,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDA5MDM1Ng==","user":{"login":"codecov-io","id":8655789,"node_id":"MDQ6VXNlcjg2NTU3ODk=","avatar_url":"https://avatars.githubusercontent.com/u/8655789?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-io","html_url":"https://github.com/codecov-io","followers_url":"https://api.github.com/users/codecov-io/followers","following_url":"https://api.github.com/users/codecov-io/following{/other_user}","gists_url":"https://api.github.com/users/codecov-io/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-io/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-io/subscriptions","organizations_url":"https://api.github.com/users/codecov-io/orgs","repos_url":"https://api.github.com/users/codecov-io/repos","events_url":"https://api.github.com/users/codecov-io/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-io/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-29T22:47:12Z","updated_at":"2021-01-31T09:02:12Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/2497?src=pr&el=h1) Report\n> Merging [#2497](https://codecov.io/gh/apache/hudi/pull/2497?src=pr&el=desc) (2f23040) into [master](https://codecov.io/gh/apache/hudi/commit/23f2ef3efbea5e9a686bac195cdf97605f20d91d?el=desc) (23f2ef3) will **increase** coverage by `0.24%`.\n> The diff coverage is `58.33%`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/2497/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/2497?src=pr&el=tree)\n\n```diff\n@@             Coverage Diff              @@\n##             master    #2497      +/-   ##\n============================================\n+ Coverage     50.28%   50.53%   +0.24%     \n- Complexity     3120     3123       +3     \n============================================\n  Files           430      430              \n  Lines         19565    19597      +32     \n  Branches       2004     2008       +4     \n============================================\n+ Hits           9838     9903      +65     \n+ Misses         8924     8886      -38     \n- Partials        803      808       +5     \n```\n\n| Flag | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| hudicli | `37.21% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudiclient | `100.00% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudicommon | `51.45% <0.00%> (-0.07%)` | `0.00 <0.00> (ø)` | |\n| hudiflink | `33.03% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudihadoopmr | `33.16% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudisparkdatasource | `69.46% <72.41%> (+3.60%)` | `0.00 <4.00> (ø)` | |\n| hudisync | `48.61% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| huditimelineservice | `66.49% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudiutilities | `69.48% <ø> (ø)` | `0.00 <ø> (ø)` | |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/2497?src=pr&el=tree) | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| [...rg/apache/hudi/common/table/HoodieTableConfig.java](https://codecov.io/gh/apache/hudi/pull/2497/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3RhYmxlL0hvb2RpZVRhYmxlQ29uZmlnLmphdmE=) | `45.45% <0.00%> (-0.60%)` | `17.00 <0.00> (ø)` | |\n| [...pache/hudi/common/table/HoodieTableMetaClient.java](https://codecov.io/gh/apache/hudi/pull/2497/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL3RhYmxlL0hvb2RpZVRhYmxlTWV0YUNsaWVudC5qYXZh) | `68.33% <0.00%> (-2.36%)` | `45.00 <0.00> (ø)` | |\n| [...n/scala/org/apache/hudi/HoodieMergeOnReadRDD.scala](https://codecov.io/gh/apache/hudi/pull/2497/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay1kYXRhc291cmNlL2h1ZGktc3Bhcmsvc3JjL21haW4vc2NhbGEvb3JnL2FwYWNoZS9odWRpL0hvb2RpZU1lcmdlT25SZWFkUkRELnNjYWxh) | `89.78% <60.00%> (-1.70%)` | `14.00 <2.00> (+2.00)` | :arrow_down: |\n| [...g/apache/hudi/MergeOnReadIncrementalRelation.scala](https://codecov.io/gh/apache/hudi/pull/2497/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay1kYXRhc291cmNlL2h1ZGktc3Bhcmsvc3JjL21haW4vc2NhbGEvb3JnL2FwYWNoZS9odWRpL01lcmdlT25SZWFkSW5jcmVtZW50YWxSZWxhdGlvbi5zY2FsYQ==) | `81.45% <71.42%> (-0.76%)` | `22.00 <1.00> (+1.00)` | :arrow_down: |\n| [.../org/apache/hudi/MergeOnReadSnapshotRelation.scala](https://codecov.io/gh/apache/hudi/pull/2497/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay1kYXRhc291cmNlL2h1ZGktc3Bhcmsvc3JjL21haW4vc2NhbGEvb3JnL2FwYWNoZS9odWRpL01lcmdlT25SZWFkU25hcHNob3RSZWxhdGlvbi5zY2FsYQ==) | `89.13% <77.77%> (-1.46%)` | `17.00 <1.00> (+1.00)` | :arrow_down: |\n| [...n/scala/org/apache/hudi/HoodieSparkSqlWriter.scala](https://codecov.io/gh/apache/hudi/pull/2497/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay1kYXRhc291cmNlL2h1ZGktc3Bhcmsvc3JjL21haW4vc2NhbGEvb3JnL2FwYWNoZS9odWRpL0hvb2RpZVNwYXJrU3FsV3JpdGVyLnNjYWxh) | `48.76% <100.00%> (+0.18%)` | `0.00 <0.00> (ø)` | |\n| [...ache/hudi/common/fs/inline/InMemoryFileSystem.java](https://codecov.io/gh/apache/hudi/pull/2497/diff?src=pr&el=tree#diff-aHVkaS1jb21tb24vc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY29tbW9uL2ZzL2lubGluZS9Jbk1lbW9yeUZpbGVTeXN0ZW0uamF2YQ==) | `79.31% <0.00%> (-10.35%)` | `15.00% <0.00%> (-1.00%)` | |\n| [...src/main/java/org/apache/hudi/QuickstartUtils.java](https://codecov.io/gh/apache/hudi/pull/2497/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay1kYXRhc291cmNlL2h1ZGktc3Bhcmsvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvUXVpY2tzdGFydFV0aWxzLmphdmE=) | `60.46% <0.00%> (+60.46%)` | `0.00% <0.00%> (ø%)` | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770090356/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770133276","html_url":"https://github.com/apache/hudi/pull/2496#issuecomment-770133276","issue_url":"https://api.github.com/repos/apache/hudi/issues/2496","id":770133276,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDEzMzI3Ng==","user":{"login":"prashantwason","id":58448203,"node_id":"MDQ6VXNlcjU4NDQ4MjAz","avatar_url":"https://avatars.githubusercontent.com/u/58448203?v=4","gravatar_id":"","url":"https://api.github.com/users/prashantwason","html_url":"https://github.com/prashantwason","followers_url":"https://api.github.com/users/prashantwason/followers","following_url":"https://api.github.com/users/prashantwason/following{/other_user}","gists_url":"https://api.github.com/users/prashantwason/gists{/gist_id}","starred_url":"https://api.github.com/users/prashantwason/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashantwason/subscriptions","organizations_url":"https://api.github.com/users/prashantwason/orgs","repos_url":"https://api.github.com/users/prashantwason/repos","events_url":"https://api.github.com/users/prashantwason/events{/privacy}","received_events_url":"https://api.github.com/users/prashantwason/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-30T01:39:52Z","updated_at":"2021-01-30T01:39:52Z","author_association":"MEMBER","body":"> On passing configs, the way I can think of is to transfer the values from writeConfig to the hadoop configuration object\r\n\r\nImplemented this. @vinothchandar PTAL","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770133276/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770134465","html_url":"https://github.com/apache/hudi/pull/2496#issuecomment-770134465","issue_url":"https://api.github.com/repos/apache/hudi/issues/2496","id":770134465,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDEzNDQ2NQ==","user":{"login":"prashantwason","id":58448203,"node_id":"MDQ6VXNlcjU4NDQ4MjAz","avatar_url":"https://avatars.githubusercontent.com/u/58448203?v=4","gravatar_id":"","url":"https://api.github.com/users/prashantwason","html_url":"https://github.com/prashantwason","followers_url":"https://api.github.com/users/prashantwason/followers","following_url":"https://api.github.com/users/prashantwason/following{/other_user}","gists_url":"https://api.github.com/users/prashantwason/gists{/gist_id}","starred_url":"https://api.github.com/users/prashantwason/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashantwason/subscriptions","organizations_url":"https://api.github.com/users/prashantwason/orgs","repos_url":"https://api.github.com/users/prashantwason/repos","events_url":"https://api.github.com/users/prashantwason/events{/privacy}","received_events_url":"https://api.github.com/users/prashantwason/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-30T01:48:09Z","updated_at":"2021-01-30T01:48:09Z","author_association":"MEMBER","body":"@n3nash  I have implemented the on/off config. PTAL and approve.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770134465/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770140718","html_url":"https://github.com/apache/hudi/pull/2505#issuecomment-770140718","issue_url":"https://api.github.com/repos/apache/hudi/issues/2505","id":770140718,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDE0MDcxOA==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-30T02:26:30Z","updated_at":"2021-01-30T02:26:30Z","author_association":"CONTRIBUTOR","body":"> @wangxianghu You can try to merge after the CI is OK.\r\n\r\nSince you still did not get merge permission, I'd like to merge it right now.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770140718/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770142516","html_url":"https://github.com/apache/hudi/pull/2337#issuecomment-770142516","issue_url":"https://api.github.com/repos/apache/hudi/issues/2337","id":770142516,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDE0MjUxNg==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-30T02:40:44Z","updated_at":"2021-01-30T02:40:44Z","author_association":"CONTRIBUTOR","body":"conflicting files should be fixed","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770142516/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770146052","html_url":"https://github.com/apache/hudi/pull/2271#issuecomment-770146052","issue_url":"https://api.github.com/repos/apache/hudi/issues/2271","id":770146052,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDE0NjA1Mg==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-30T03:08:38Z","updated_at":"2021-01-30T03:08:38Z","author_association":"CONTRIBUTOR","body":"@wangxianghu Please fix the conflicting file.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770146052/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770377916","html_url":"https://github.com/apache/hudi/pull/2210#issuecomment-770377916","issue_url":"https://api.github.com/repos/apache/hudi/issues/2210","id":770377916,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDM3NzkxNg==","user":{"login":"codecov-io","id":8655789,"node_id":"MDQ6VXNlcjg2NTU3ODk=","avatar_url":"https://avatars.githubusercontent.com/u/8655789?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-io","html_url":"https://github.com/codecov-io","followers_url":"https://api.github.com/users/codecov-io/followers","following_url":"https://api.github.com/users/codecov-io/following{/other_user}","gists_url":"https://api.github.com/users/codecov-io/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-io/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-io/subscriptions","organizations_url":"https://api.github.com/users/codecov-io/orgs","repos_url":"https://api.github.com/users/codecov-io/repos","events_url":"https://api.github.com/users/codecov-io/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-io/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-31T12:52:28Z","updated_at":"2021-01-31T17:57:10Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/2210?src=pr&el=h1) Report\n> Merging [#2210](https://codecov.io/gh/apache/hudi/pull/2210?src=pr&el=desc) (7338e25) into [master](https://codecov.io/gh/apache/hudi/commit/5d053b495b8cb44cce88a67e82cbdfdc3d8b3180?el=desc) (5d053b4) will **increase** coverage by `0.92%`.\n> The diff coverage is `79.64%`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/2210/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/2210?src=pr&el=tree)\n\n```diff\n@@             Coverage Diff              @@\n##             master    #2210      +/-   ##\n============================================\n+ Coverage     49.78%   50.70%   +0.92%     \n- Complexity     3089     3140      +51     \n============================================\n  Files           430      431       +1     \n  Lines         19566    19678     +112     \n  Branches       2004     2015      +11     \n============================================\n+ Hits           9741     9978     +237     \n+ Misses         9033     8890     -143     \n- Partials        792      810      +18     \n```\n\n| Flag | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| hudicli | `37.21% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudiclient | `100.00% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudicommon | `51.49% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudiflink | `33.03% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudihadoopmr | `33.16% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudisparkdatasource | `69.51% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudisync | `48.61% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| huditimelineservice | `66.49% <ø> (ø)` | `0.00 <ø> (ø)` | |\n| hudiutilities | `70.07% <79.64%> (+8.21%)` | `0.00 <21.00> (ø)` | |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/2210?src=pr&el=tree) | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| [...g/apache/hudi/utilities/sources/AvroDFSSource.java](https://codecov.io/gh/apache/hudi/pull/2210/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvQXZyb0RGU1NvdXJjZS5qYXZh) | `0.00% <0.00%> (ø)` | `0.00 <0.00> (ø)` | |\n| [...i/utilities/sources/helpers/FileSourceCleaner.java](https://codecov.io/gh/apache/hudi/pull/2210/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvaGVscGVycy9GaWxlU291cmNlQ2xlYW5lci5qYXZh) | `80.28% <80.28%> (ø)` | `9.00 <9.00> (?)` | |\n| [...apache/hudi/utilities/deltastreamer/DeltaSync.java](https://codecov.io/gh/apache/hudi/pull/2210/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL2RlbHRhc3RyZWFtZXIvRGVsdGFTeW5jLmphdmE=) | `70.60% <100.00%> (+0.10%)` | `50.00 <0.00> (ø)` | |\n| [...i/utilities/deltastreamer/SourceFormatAdapter.java](https://codecov.io/gh/apache/hudi/pull/2210/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL2RlbHRhc3RyZWFtZXIvU291cmNlRm9ybWF0QWRhcHRlci5qYXZh) | `87.17% <100.00%> (+0.69%)` | `12.00 <1.00> (+1.00)` | |\n| [...rg/apache/hudi/utilities/sources/CsvDFSSource.java](https://codecov.io/gh/apache/hudi/pull/2210/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvQ3N2REZTU291cmNlLmphdmE=) | `100.00% <100.00%> (ø)` | `13.00 <3.00> (+3.00)` | |\n| [...g/apache/hudi/utilities/sources/JsonDFSSource.java](https://codecov.io/gh/apache/hudi/pull/2210/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvSnNvbkRGU1NvdXJjZS5qYXZh) | `100.00% <100.00%> (ø)` | `7.00 <3.00> (+3.00)` | |\n| [...pache/hudi/utilities/sources/ParquetDFSSource.java](https://codecov.io/gh/apache/hudi/pull/2210/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvUGFycXVldERGU1NvdXJjZS5qYXZh) | `100.00% <100.00%> (ø)` | `8.00 <3.00> (+3.00)` | |\n| [...java/org/apache/hudi/utilities/sources/Source.java](https://codecov.io/gh/apache/hudi/pull/2210/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvU291cmNlLmphdmE=) | `88.23% <100.00%> (+0.73%)` | `6.00 <1.00> (+1.00)` | |\n| [...udi/utilities/sources/helpers/DFSPathSelector.java](https://codecov.io/gh/apache/hudi/pull/2210/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvaGVscGVycy9ERlNQYXRoU2VsZWN0b3IuamF2YQ==) | `85.10% <100.00%> (+0.32%)` | `16.00 <1.00> (+1.00)` | |\n| ... and [5 more](https://codecov.io/gh/apache/hudi/pull/2210/diff?src=pr&el=tree-more) | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770377916/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770383571","html_url":"https://github.com/apache/hudi/pull/2497#issuecomment-770383571","issue_url":"https://api.github.com/repos/apache/hudi/issues/2497","id":770383571,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDM4MzU3MQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-31T13:35:23Z","updated_at":"2021-01-31T13:35:23Z","author_association":"CONTRIBUTOR","body":"> thanks @pengzhiwei2018 , LGTM! @nsivabalan I agree we should use a builder pattern to init the table. Looks like @lw309637554 is working on the refactoring https://issues.apache.org/jira/browse/HUDI-1315.\r\n\r\nthnx Gary. I have asked liwei. If he is not working on it as of now, probably I will take it up and put up a diff. \r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770383571/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770391800","html_url":"https://github.com/apache/hudi/issues/2479#issuecomment-770391800","issue_url":"https://api.github.com/repos/apache/hudi/issues/2479","id":770391800,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDM5MTgwMA==","user":{"login":"pavelbelenkovich","id":78308764,"node_id":"MDQ6VXNlcjc4MzA4NzY0","avatar_url":"https://avatars.githubusercontent.com/u/78308764?v=4","gravatar_id":"","url":"https://api.github.com/users/pavelbelenkovich","html_url":"https://github.com/pavelbelenkovich","followers_url":"https://api.github.com/users/pavelbelenkovich/followers","following_url":"https://api.github.com/users/pavelbelenkovich/following{/other_user}","gists_url":"https://api.github.com/users/pavelbelenkovich/gists{/gist_id}","starred_url":"https://api.github.com/users/pavelbelenkovich/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pavelbelenkovich/subscriptions","organizations_url":"https://api.github.com/users/pavelbelenkovich/orgs","repos_url":"https://api.github.com/users/pavelbelenkovich/repos","events_url":"https://api.github.com/users/pavelbelenkovich/events{/privacy}","received_events_url":"https://api.github.com/users/pavelbelenkovich/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-31T14:34:42Z","updated_at":"2021-01-31T14:34:42Z","author_association":"NONE","body":"> > Thank you so much @vinothchandar !!!!!\r\n> > It worked, I will close this issue.\r\n> \r\n> how to deel that\r\n\r\njust delete repo.spring.io repos from pom.xml as in #2481 above","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770391800/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770475266","html_url":"https://github.com/apache/hudi/issues/2508#issuecomment-770475266","issue_url":"https://api.github.com/repos/apache/hudi/issues/2508","id":770475266,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDQ3NTI2Ng==","user":{"login":"rubenssoto","id":36298331,"node_id":"MDQ6VXNlcjM2Mjk4MzMx","avatar_url":"https://avatars.githubusercontent.com/u/36298331?v=4","gravatar_id":"","url":"https://api.github.com/users/rubenssoto","html_url":"https://github.com/rubenssoto","followers_url":"https://api.github.com/users/rubenssoto/followers","following_url":"https://api.github.com/users/rubenssoto/following{/other_user}","gists_url":"https://api.github.com/users/rubenssoto/gists{/gist_id}","starred_url":"https://api.github.com/users/rubenssoto/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rubenssoto/subscriptions","organizations_url":"https://api.github.com/users/rubenssoto/orgs","repos_url":"https://api.github.com/users/rubenssoto/repos","events_url":"https://api.github.com/users/rubenssoto/events{/privacy}","received_events_url":"https://api.github.com/users/rubenssoto/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-01-31T23:54:36Z","updated_at":"2021-02-01T00:01:22Z","author_association":"NONE","body":"I made more tests and I only had the problem when my bulk insert operation has the option hoodie.datasource.write.row.writer.enable true.\r\n\r\nI only had this problem on this table, this table has a column type array\r\nwith that option false the column on hive:\r\n\r\n`order_details_line_items` array<struct<product_variant_id:int,item_inventory_id:int,price:decimal(14,2),total_price:decimal(14,2),subtotal_price:decimal(14,2),total_item_price:decimal(14,2),total_tax:decimal(14,2),total_coupon_discount:decimal(14,2),total_offer_discount:decimal(14,2),total_discount:decimal(14,2),quantity:int,description:string,short_description:string,image_url:string,title:string,subtitle:string,product:struct<product_id:int,title:string,tags:string,label:string,image_url:string,description:string,short_description:string,rgb:boolean,has_fixed_price:boolean>,category:struct<id:int,title:string>,brand:struct<id:int,title:string>,applicable_discount:struct<discount_value:decimal(14,2),discount_type:string,discount_value_type:int,presented_discount_value:decimal(14,2),final_price:decimal(14,2),final_unit_price:decimal(14,2)>>>\r\n\r\n\r\nwith that option true:\r\n`order_details_line_items` array<struct<product_variant_id:int,item_inventory_id:int,price:decimal(14,2),total_price:decimal(14,2),subtotal_price:decimal(14,2),total_item_price:decimal(14,2),total_tax:decimal(14,2),total_coupon_discount:decimal(14,2),total_offer_discount:decimal(14,2),total_discount:decimal(14,2),quantity:int,description:string,short_description:string,image_url:string,title:string,subtitle:string,product:struct<product_id:int,title:string,tags:string,label:string,image_url:string,description:string,short_description:string,rgb:boolean,has_fixed_price:boolean>,category:struct<id:int,title:string>,brand:struct<id:int,title:string>,applicable_discount:struct<discount_value:decimal(14,2),discount_type:string,discount_value_type:int,presented_discount_value:decimal(14,2),final_price:decimal(14,2),final_unit_price:decimal(14,2)>>>\r\n\r\nThe original column it is a json and I struct the column in spark with this schema:\r\nStructField(\r\n          \"line_items\",\r\n          ArrayType(\r\n            StructType(\r\n              List(\r\n                StructField(\"product_variant_id\", IntegerType),\r\n                StructField(\"item_inventory_id\", IntegerType),\r\n                StructField(\"price\", DecimalType(14, 2)),\r\n                StructField(\"total_price\", DecimalType(14, 2)),\r\n                StructField(\"subtotal_price\", DecimalType(14, 2)),\r\n                StructField(\"total_item_price\", DecimalType(14, 2)),\r\n                StructField(\"total_tax\", DecimalType(14, 2)),\r\n                StructField(\"total_coupon_discount\", DecimalType(14, 2)),\r\n                StructField(\"total_offer_discount\", DecimalType(14, 2)),\r\n                StructField(\"total_discount\", DecimalType(14, 2)),\r\n                StructField(\"quantity\", IntegerType),\r\n                StructField(\"description\", StringType),\r\n                StructField(\"short_description\", StringType),\r\n                StructField(\"image_url\", StringType),\r\n                StructField(\"title\", StringType),\r\n                StructField(\"subtitle\", StringType),\r\n                StructField(\r\n                  \"product\",\r\n                  StructType(\r\n                    List(\r\n                      StructField(\"product_id\", IntegerType),\r\n                      StructField(\"title\", StringType),\r\n                      StructField(\"tags\", StringType),\r\n                      StructField(\"label\", StringType),\r\n                      StructField(\"image_url\", StringType),\r\n                      StructField(\"description\", StringType),\r\n                      StructField(\"short_description\", StringType),\r\n                      StructField(\"rgb\", BooleanType),\r\n                      StructField(\"has_fixed_price\", BooleanType)\r\n                    )\r\n                  )\r\n                )\r\n\r\nI will try to convert the column to string....","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770475266/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770483807","html_url":"https://github.com/apache/hudi/issues/2508#issuecomment-770483807","issue_url":"https://api.github.com/repos/apache/hudi/issues/2508","id":770483807,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDQ4MzgwNw==","user":{"login":"rubenssoto","id":36298331,"node_id":"MDQ6VXNlcjM2Mjk4MzMx","avatar_url":"https://avatars.githubusercontent.com/u/36298331?v=4","gravatar_id":"","url":"https://api.github.com/users/rubenssoto","html_url":"https://github.com/rubenssoto","followers_url":"https://api.github.com/users/rubenssoto/followers","following_url":"https://api.github.com/users/rubenssoto/following{/other_user}","gists_url":"https://api.github.com/users/rubenssoto/gists{/gist_id}","starred_url":"https://api.github.com/users/rubenssoto/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rubenssoto/subscriptions","organizations_url":"https://api.github.com/users/rubenssoto/orgs","repos_url":"https://api.github.com/users/rubenssoto/repos","events_url":"https://api.github.com/users/rubenssoto/events{/privacy}","received_events_url":"https://api.github.com/users/rubenssoto/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T00:32:54Z","updated_at":"2021-02-01T01:02:43Z","author_association":"NONE","body":"I changed the type to string and the problem was not solved same behavior.\r\nIt could be a bug?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770483807/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770526630","html_url":"https://github.com/apache/hudi/pull/2506#issuecomment-770526630","issue_url":"https://api.github.com/repos/apache/hudi/issues/2506","id":770526630,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDUyNjYzMA==","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T02:45:13Z","updated_at":"2021-02-01T02:45:13Z","author_association":"CONTRIBUTOR","body":"> @danny0405 ping us, when you are ready to review.\r\n\r\n@yanghua @garyli1019 Yes, this PR is ready to review, thanks for the review if you have time.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770526630/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770527676","html_url":"https://github.com/apache/hudi/pull/2497#issuecomment-770527676","issue_url":"https://api.github.com/repos/apache/hudi/issues/2497","id":770527676,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDUyNzY3Ng==","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T02:48:38Z","updated_at":"2021-02-01T02:48:38Z","author_association":"MEMBER","body":"> thnx Gary. I have asked liwei. If he is not working on it as of now, probably I will take it up and put up a diff.\r\n\r\nhi @nsivabalan , do you think we can merge this PR and do the refactoring in a separate PR or on hold for now? WDYT?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770527676/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770535798","html_url":"https://github.com/apache/hudi/issues/2508#issuecomment-770535798","issue_url":"https://api.github.com/repos/apache/hudi/issues/2508","id":770535798,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDUzNTc5OA==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T03:16:50Z","updated_at":"2021-02-01T03:16:50Z","author_association":"CONTRIBUTOR","body":"@rubenssoto Have you changed the schema from the last time you did a bulkInsert into this table ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770535798/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770541514","html_url":"https://github.com/apache/hudi/issues/2508#issuecomment-770541514","issue_url":"https://api.github.com/repos/apache/hudi/issues/2508","id":770541514,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDU0MTUxNA==","user":{"login":"rubenssoto","id":36298331,"node_id":"MDQ6VXNlcjM2Mjk4MzMx","avatar_url":"https://avatars.githubusercontent.com/u/36298331?v=4","gravatar_id":"","url":"https://api.github.com/users/rubenssoto","html_url":"https://github.com/rubenssoto","followers_url":"https://api.github.com/users/rubenssoto/followers","following_url":"https://api.github.com/users/rubenssoto/following{/other_user}","gists_url":"https://api.github.com/users/rubenssoto/gists{/gist_id}","starred_url":"https://api.github.com/users/rubenssoto/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rubenssoto/subscriptions","organizations_url":"https://api.github.com/users/rubenssoto/orgs","repos_url":"https://api.github.com/users/rubenssoto/repos","events_url":"https://api.github.com/users/rubenssoto/events{/privacy}","received_events_url":"https://api.github.com/users/rubenssoto/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T03:37:25Z","updated_at":"2021-02-01T03:37:25Z","author_association":"NONE","body":"No, the same schema, no changes.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770541514/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770546985","html_url":"https://github.com/apache/hudi/issues/2508#issuecomment-770546985","issue_url":"https://api.github.com/repos/apache/hudi/issues/2508","id":770546985,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDU0Njk4NQ==","user":{"login":"rubenssoto","id":36298331,"node_id":"MDQ6VXNlcjM2Mjk4MzMx","avatar_url":"https://avatars.githubusercontent.com/u/36298331?v=4","gravatar_id":"","url":"https://api.github.com/users/rubenssoto","html_url":"https://github.com/rubenssoto","followers_url":"https://api.github.com/users/rubenssoto/followers","following_url":"https://api.github.com/users/rubenssoto/following{/other_user}","gists_url":"https://api.github.com/users/rubenssoto/gists{/gist_id}","starred_url":"https://api.github.com/users/rubenssoto/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rubenssoto/subscriptions","organizations_url":"https://api.github.com/users/rubenssoto/orgs","repos_url":"https://api.github.com/users/rubenssoto/repos","events_url":"https://api.github.com/users/rubenssoto/events{/privacy}","received_events_url":"https://api.github.com/users/rubenssoto/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T03:57:50Z","updated_at":"2021-02-01T03:57:50Z","author_association":"NONE","body":"I made the same procedure, the only difference was\r\none time I tried with hoodie.datasource.write.row.writer.enable true and didn't work and another time with the same config false and it worked.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770546985/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770580791","html_url":"https://github.com/apache/hudi/issues/1973#issuecomment-770580791","issue_url":"https://api.github.com/repos/apache/hudi/issues/1973","id":770580791,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDU4MDc5MQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T05:35:07Z","updated_at":"2021-02-01T05:35:07Z","author_association":"CONTRIBUTOR","body":"@satishkotha : I am trying to fix all documentation related jiras. Can you throw some light on which config is this exactly. All I could see is \"hoodie.datasource.read.begin.instanttime\" [here](https://hudi.apache.org/docs/configurations.html#read-options). But guess you mentioned about some other config. Can you point me in code where this config is used. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770580791/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770583049","html_url":"https://github.com/apache/hudi/issues/1973#issuecomment-770583049","issue_url":"https://api.github.com/repos/apache/hudi/issues/1973","id":770583049,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDU4MzA0OQ==","user":{"login":"satishkotha","id":2992755,"node_id":"MDQ6VXNlcjI5OTI3NTU=","avatar_url":"https://avatars.githubusercontent.com/u/2992755?v=4","gravatar_id":"","url":"https://api.github.com/users/satishkotha","html_url":"https://github.com/satishkotha","followers_url":"https://api.github.com/users/satishkotha/followers","following_url":"https://api.github.com/users/satishkotha/following{/other_user}","gists_url":"https://api.github.com/users/satishkotha/gists{/gist_id}","starred_url":"https://api.github.com/users/satishkotha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/satishkotha/subscriptions","organizations_url":"https://api.github.com/users/satishkotha/orgs","repos_url":"https://api.github.com/users/satishkotha/repos","events_url":"https://api.github.com/users/satishkotha/events{/privacy}","received_events_url":"https://api.github.com/users/satishkotha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T05:38:50Z","updated_at":"2021-02-01T05:38:50Z","author_association":"MEMBER","body":"@nsivabalan  see here for hive config attributes: https://github.com/apache/hudi/blob/master/hudi-hadoop-mr/src/main/java/org/apache/hudi/hadoop/utils/HoodieHiveUtils.java#L40\r\n\r\nThe one you pointed out is for spark datasource API.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770583049/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770686131","html_url":"https://github.com/apache/hudi/pull/2510#issuecomment-770686131","issue_url":"https://api.github.com/repos/apache/hudi/issues/2510","id":770686131,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDY4NjEzMQ==","user":{"login":"codecov-io","id":8655789,"node_id":"MDQ6VXNlcjg2NTU3ODk=","avatar_url":"https://avatars.githubusercontent.com/u/8655789?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-io","html_url":"https://github.com/codecov-io","followers_url":"https://api.github.com/users/codecov-io/followers","following_url":"https://api.github.com/users/codecov-io/following{/other_user}","gists_url":"https://api.github.com/users/codecov-io/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-io/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-io/subscriptions","organizations_url":"https://api.github.com/users/codecov-io/orgs","repos_url":"https://api.github.com/users/codecov-io/repos","events_url":"https://api.github.com/users/codecov-io/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-io/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T08:50:51Z","updated_at":"2021-02-01T08:51:46Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/2510?src=pr&el=h1) Report\n> Merging [#2510](https://codecov.io/gh/apache/hudi/pull/2510?src=pr&el=desc) (3bd625d) into [master](https://codecov.io/gh/apache/hudi/commit/5d053b495b8cb44cce88a67e82cbdfdc3d8b3180?el=desc) (5d053b4) will **decrease** coverage by `29.31%`.\n> The diff coverage is `n/a`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/2510/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/2510?src=pr&el=tree)\n\n```diff\n@@              Coverage Diff              @@\n##             master    #2510       +/-   ##\n=============================================\n- Coverage     49.78%   20.46%   -29.32%     \n+ Complexity     3089      101     -2988     \n=============================================\n  Files           430       53      -377     \n  Lines         19566     1930    -17636     \n  Branches       2004      230     -1774     \n=============================================\n- Hits           9741      395     -9346     \n+ Misses         9033     1517     -7516     \n+ Partials        792       18      -774     \n```\n\n| Flag | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| hudicli | `?` | `?` | |\n| hudiclient | `?` | `?` | |\n| hudicommon | `?` | `?` | |\n| hudiflink | `?` | `?` | |\n| hudihadoopmr | `?` | `?` | |\n| hudisparkdatasource | `?` | `?` | |\n| hudisync | `?` | `?` | |\n| huditimelineservice | `?` | `?` | |\n| hudiutilities | `20.46% <ø> (-41.40%)` | `0.00 <ø> (ø)` | |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/2510?src=pr&el=tree) | Coverage Δ | Complexity Δ | |\n|---|---|---|---|\n| [...va/org/apache/hudi/utilities/IdentitySplitter.java](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL0lkZW50aXR5U3BsaXR0ZXIuamF2YQ==) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-2.00%)` | |\n| [...va/org/apache/hudi/utilities/schema/SchemaSet.java](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NjaGVtYS9TY2hlbWFTZXQuamF2YQ==) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-3.00%)` | |\n| [...a/org/apache/hudi/utilities/sources/RowSource.java](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvUm93U291cmNlLmphdmE=) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-4.00%)` | |\n| [.../org/apache/hudi/utilities/sources/AvroSource.java](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvQXZyb1NvdXJjZS5qYXZh) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-1.00%)` | |\n| [.../org/apache/hudi/utilities/sources/JsonSource.java](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvSnNvblNvdXJjZS5qYXZh) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-1.00%)` | |\n| [...rg/apache/hudi/utilities/sources/CsvDFSSource.java](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvQ3N2REZTU291cmNlLmphdmE=) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-10.00%)` | |\n| [...g/apache/hudi/utilities/sources/JsonDFSSource.java](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvSnNvbkRGU1NvdXJjZS5qYXZh) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-4.00%)` | |\n| [...apache/hudi/utilities/sources/JsonKafkaSource.java](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvSnNvbkthZmthU291cmNlLmphdmE=) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-6.00%)` | |\n| [...pache/hudi/utilities/sources/ParquetDFSSource.java](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NvdXJjZXMvUGFycXVldERGU1NvdXJjZS5qYXZh) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-5.00%)` | |\n| [...lities/schema/SchemaProviderWithPostProcessor.java](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL3NjaGVtYS9TY2hlbWFQcm92aWRlcldpdGhQb3N0UHJvY2Vzc29yLmphdmE=) | `0.00% <0.00%> (-100.00%)` | `0.00% <0.00%> (-4.00%)` | |\n| ... and [394 more](https://codecov.io/gh/apache/hudi/pull/2510/diff?src=pr&el=tree-more) | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770686131/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770769437","html_url":"https://github.com/apache/hudi/issues/2498#issuecomment-770769437","issue_url":"https://api.github.com/repos/apache/hudi/issues/2498","id":770769437,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDc2OTQzNw==","user":{"login":"zafer-sahin","id":63556382,"node_id":"MDQ6VXNlcjYzNTU2Mzgy","avatar_url":"https://avatars.githubusercontent.com/u/63556382?v=4","gravatar_id":"","url":"https://api.github.com/users/zafer-sahin","html_url":"https://github.com/zafer-sahin","followers_url":"https://api.github.com/users/zafer-sahin/followers","following_url":"https://api.github.com/users/zafer-sahin/following{/other_user}","gists_url":"https://api.github.com/users/zafer-sahin/gists{/gist_id}","starred_url":"https://api.github.com/users/zafer-sahin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zafer-sahin/subscriptions","organizations_url":"https://api.github.com/users/zafer-sahin/orgs","repos_url":"https://api.github.com/users/zafer-sahin/repos","events_url":"https://api.github.com/users/zafer-sahin/events{/privacy}","received_events_url":"https://api.github.com/users/zafer-sahin/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T10:59:33Z","updated_at":"2021-02-01T11:00:11Z","author_association":"NONE","body":"@nsivabalan I was able to execute all steps successfully in the [quick start](https://hudi.apache.org/docs/quick-start-guide.html) and I could reproduce the issue by changing the storage type in the hudi options. I have changed the storage type of quick start example to merge_on_read and it failed as well. Here is the modification I have applied. \r\n\r\n` pyspark --packages org.apache.hudi:hudi-spark-bundle_2.12:0.7.0,org.apache.spark:spark-avro_2.12:3.0.0 --conf 'spark.serializer=org.apache.spark.serializer.KryoSerializer' \r\n`\r\n\r\n```\r\ntableName = \"hudi_trips_cow\"\r\nbasePath = \"S3:///tmp/hudi_trips_mor\"\r\ndataGen = sc._jvm.org.apache.hudi.QuickstartUtils.DataGenerator()\r\ninserts = sc._jvm.org.apache.hudi.QuickstartUtils.convertToStringList(dataGen.generateInserts(10))\r\ndf = spark.read.json(spark.sparkContext.parallelize(inserts, 2))\r\n```\r\n\r\nBelow **storage type** has modified. And I am getting an error **when I read the file.**\r\n```\r\nhudi_options = {\r\n  'hoodie.table.name': tableName,\r\n  \"hoodie.datasource.write.storage.type\": \"MERGE_ON_READ\",  \r\n  'hoodie.datasource.write.recordkey.field': 'uuid',\r\n  'hoodie.datasource.write.partitionpath.field': 'partitionpath',\r\n  'hoodie.datasource.write.table.name': tableName,\r\n  'hoodie.datasource.write.operation': 'insert',\r\n  'hoodie.datasource.write.precombine.field': 'ts',\r\n  'hoodie.upsert.shuffle.parallelism': 2, \r\n  'hoodie.insert.shuffle.parallelism': 2\r\n}\r\n\r\ndf.write.format(\"hudi\"). \\\r\n  options(**hudi_options). \\\r\n  mode(\"overwrite\"). \\\r\n  save(basePath)\r\n\r\ntripsSnapshotDF = spark. \\\r\n  read. \\\r\n  format(\"hudi\"). \\\r\n  load(basePath + \"/*/*/*/*\")\r\n```\r\n\r\n\r\nPlease find the error stack below.\r\n```\r\nAn error occurred while calling o267.load.\r\n: java.lang.NoSuchMethodError: org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(Lorg/apache/spark/sql/SparkSession;Lscala/collection/Seq;Lscala/collection/immutable/Map;Lscala/Option;Lorg/apache/spark/sql/execution/datasources/FileStatusCache;)V\r\n\tat org.apache.hudi.HoodieSparkUtils$.createInMemoryFileIndex(HoodieSparkUtils.scala:89)\r\n\tat org.apache.hudi.MergeOnReadSnapshotRelation.buildFileIndex(MergeOnReadSnapshotRelation.scala:127)\r\n\tat org.apache.hudi.MergeOnReadSnapshotRelation.<init>(MergeOnReadSnapshotRelation.scala:72)\r\n\tat org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:89)\r\n\tat org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:53)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:344)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:232)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770769437/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770809175","html_url":"https://github.com/apache/hudi/pull/2486#issuecomment-770809175","issue_url":"https://api.github.com/repos/apache/hudi/issues/2486","id":770809175,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDgwOTE3NQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-01T12:07:28Z","updated_at":"2021-02-01T12:07:57Z","author_association":"CONTRIBUTOR","body":"Few suggestions: \r\n- Can you rebase and also fix the CI issue please. We will review once these are done and the patch is ready. \r\n- Also, suggest to create a jira and link it. \r\n- Also, please do follow template to create a new PR(I see you have removed most parts in the description). Hudi community follows a standard template. So would be nice to follow the same. \r\nDo ping us here once the patch is ready to be reviewed. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/770809175/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]