[{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513335051","html_url":"https://github.com/apache/hudi/issues/779#issuecomment-513335051","issue_url":"https://api.github.com/repos/apache/hudi/issues/779","id":513335051,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzMzNTA1MQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-19T18:41:37Z","updated_at":"2019-07-19T18:41:37Z","author_association":"CONTRIBUTOR","body":"@eisig  mentioned that he is not able to reproduce this issue after applying #775 .  \r\n\r\nWill close this ticket. @eisig : Please open an issue with details if you find a newer occurrence","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513335051/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513336036","html_url":"https://github.com/apache/hudi/issues/786#issuecomment-513336036","issue_url":"https://api.github.com/repos/apache/hudi/issues/786","id":513336036,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzMzNjAzNg==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-19T18:44:54Z","updated_at":"2019-07-19T18:44:54Z","author_association":"CONTRIBUTOR","body":"@eisig confirmed it works fine. Alex also confirmed both write and read side is working fine in his setup.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513336036/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513336805","html_url":"https://github.com/apache/hudi/issues/789#issuecomment-513336805","issue_url":"https://api.github.com/repos/apache/hudi/issues/789","id":513336805,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzMzNjgwNQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-19T18:47:18Z","updated_at":"2019-07-19T18:48:18Z","author_association":"CONTRIBUTOR","body":"@bhasudha : @eisig is seeing some issues in master branch with the docker setup. \r\n\r\nRelevant Info: \r\nhttps://github.com/apache/incubator-hudi/issues/789#issuecomment-512740619\r\nhttps://github.com/apache/incubator-hudi/issues/789#issuecomment-512741943\r\n\r\nFYI: The rollback issue is resolved","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513336805/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513457579","html_url":"https://github.com/apache/hudi/pull/798#issuecomment-513457579","issue_url":"https://api.github.com/repos/apache/hudi/issues/798","id":513457579,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzQ1NzU3OQ==","user":{"login":"eisig","id":1745057,"node_id":"MDQ6VXNlcjE3NDUwNTc=","avatar_url":"https://avatars.githubusercontent.com/u/1745057?v=4","gravatar_id":"","url":"https://api.github.com/users/eisig","html_url":"https://github.com/eisig","followers_url":"https://api.github.com/users/eisig/followers","following_url":"https://api.github.com/users/eisig/following{/other_user}","gists_url":"https://api.github.com/users/eisig/gists{/gist_id}","starred_url":"https://api.github.com/users/eisig/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eisig/subscriptions","organizations_url":"https://api.github.com/users/eisig/orgs","repos_url":"https://api.github.com/users/eisig/repos","events_url":"https://api.github.com/users/eisig/events{/privacy}","received_events_url":"https://api.github.com/users/eisig/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-20T10:52:37Z","updated_at":"2019-07-20T10:52:37Z","author_association":"CONTRIBUTOR","body":"@vinothchandar   happy to do this.My jira id is eisig.g\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513457579/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513488488","html_url":"https://github.com/apache/hudi/issues/796#issuecomment-513488488","issue_url":"https://api.github.com/repos/apache/hudi/issues/796","id":513488488,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzQ4ODQ4OA==","user":{"login":"anchalkataria","id":9292326,"node_id":"MDQ6VXNlcjkyOTIzMjY=","avatar_url":"https://avatars.githubusercontent.com/u/9292326?v=4","gravatar_id":"","url":"https://api.github.com/users/anchalkataria","html_url":"https://github.com/anchalkataria","followers_url":"https://api.github.com/users/anchalkataria/followers","following_url":"https://api.github.com/users/anchalkataria/following{/other_user}","gists_url":"https://api.github.com/users/anchalkataria/gists{/gist_id}","starred_url":"https://api.github.com/users/anchalkataria/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/anchalkataria/subscriptions","organizations_url":"https://api.github.com/users/anchalkataria/orgs","repos_url":"https://api.github.com/users/anchalkataria/repos","events_url":"https://api.github.com/users/anchalkataria/events{/privacy}","received_events_url":"https://api.github.com/users/anchalkataria/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-20T18:15:33Z","updated_at":"2019-07-20T18:15:33Z","author_association":"NONE","body":"I am using hive 2.0 and Hudi 0.4.5.\r\nAnd when I turned off hive sync from DeltaStreamer and manually register the table via HiveSync tool it worked successfully.\r\nPlease suggest what could be the solution for running same thing from DeltaStreamer.\r\n\r\nAlso when i tried updating record through Merge_on_read storage type the _rt table shows the updated column values as null.Not showing the updated value for that field in _rt table.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513488488/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513513092","html_url":"https://github.com/apache/hudi/pull/780#issuecomment-513513092","issue_url":"https://api.github.com/repos/apache/hudi/issues/780","id":513513092,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzUxMzA5Mg==","user":{"login":"thesuperzapper","id":5735406,"node_id":"MDQ6VXNlcjU3MzU0MDY=","avatar_url":"https://avatars.githubusercontent.com/u/5735406?v=4","gravatar_id":"","url":"https://api.github.com/users/thesuperzapper","html_url":"https://github.com/thesuperzapper","followers_url":"https://api.github.com/users/thesuperzapper/followers","following_url":"https://api.github.com/users/thesuperzapper/following{/other_user}","gists_url":"https://api.github.com/users/thesuperzapper/gists{/gist_id}","starred_url":"https://api.github.com/users/thesuperzapper/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/thesuperzapper/subscriptions","organizations_url":"https://api.github.com/users/thesuperzapper/orgs","repos_url":"https://api.github.com/users/thesuperzapper/repos","events_url":"https://api.github.com/users/thesuperzapper/events{/privacy}","received_events_url":"https://api.github.com/users/thesuperzapper/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-21T02:09:16Z","updated_at":"2019-07-21T02:09:16Z","author_association":"NONE","body":"@vinothchandar, I just pushed the small changes.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513513092/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513581765","html_url":"https://github.com/apache/hudi/issues/714#issuecomment-513581765","issue_url":"https://api.github.com/repos/apache/hudi/issues/714","id":513581765,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzU4MTc2NQ==","user":{"login":"NetsanetGeb","id":25975892,"node_id":"MDQ6VXNlcjI1OTc1ODky","avatar_url":"https://avatars.githubusercontent.com/u/25975892?v=4","gravatar_id":"","url":"https://api.github.com/users/NetsanetGeb","html_url":"https://github.com/NetsanetGeb","followers_url":"https://api.github.com/users/NetsanetGeb/followers","following_url":"https://api.github.com/users/NetsanetGeb/following{/other_user}","gists_url":"https://api.github.com/users/NetsanetGeb/gists{/gist_id}","starred_url":"https://api.github.com/users/NetsanetGeb/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/NetsanetGeb/subscriptions","organizations_url":"https://api.github.com/users/NetsanetGeb/orgs","repos_url":"https://api.github.com/users/NetsanetGeb/repos","events_url":"https://api.github.com/users/NetsanetGeb/events{/privacy}","received_events_url":"https://api.github.com/users/NetsanetGeb/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-21T19:39:34Z","updated_at":"2019-07-21T19:47:39Z","author_association":"NONE","body":"@vinothchandar, yes am on slack and next week sounds good.   We can do it  on Monday or Tuesday. The time zone here is Central European Summer Time (GMT + 2) and  I think we have 9 hours time zone difference . So we can arrange a time which is convenient for both of us, like evening  time here and morning time there or any other suggestion if you have.  Does this work for you?   ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513581765/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513610583","html_url":"https://github.com/apache/hudi/pull/635#issuecomment-513610583","issue_url":"https://api.github.com/repos/apache/hudi/issues/635","id":513610583,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzYxMDU4Mw==","user":{"login":"zhangxinjian123","id":30996853,"node_id":"MDQ6VXNlcjMwOTk2ODUz","avatar_url":"https://avatars.githubusercontent.com/u/30996853?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangxinjian123","html_url":"https://github.com/zhangxinjian123","followers_url":"https://api.github.com/users/zhangxinjian123/followers","following_url":"https://api.github.com/users/zhangxinjian123/following{/other_user}","gists_url":"https://api.github.com/users/zhangxinjian123/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangxinjian123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangxinjian123/subscriptions","organizations_url":"https://api.github.com/users/zhangxinjian123/orgs","repos_url":"https://api.github.com/users/zhangxinjian123/repos","events_url":"https://api.github.com/users/zhangxinjian123/events{/privacy}","received_events_url":"https://api.github.com/users/zhangxinjian123/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-22T01:45:46Z","updated_at":"2019-07-22T01:45:46Z","author_association":"NONE","body":"Why did I report \"Cannot resolve symbol'HoodieRestoreMetadata'in the latest version of 0.48 today? There's nothing wrong with downloading a week ago.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513610583/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513617090","html_url":"https://github.com/apache/hudi/pull/635#issuecomment-513617090","issue_url":"https://api.github.com/repos/apache/hudi/issues/635","id":513617090,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzYxNzA5MA==","user":{"login":"zhangxinjian123","id":30996853,"node_id":"MDQ6VXNlcjMwOTk2ODUz","avatar_url":"https://avatars.githubusercontent.com/u/30996853?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangxinjian123","html_url":"https://github.com/zhangxinjian123","followers_url":"https://api.github.com/users/zhangxinjian123/followers","following_url":"https://api.github.com/users/zhangxinjian123/following{/other_user}","gists_url":"https://api.github.com/users/zhangxinjian123/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangxinjian123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangxinjian123/subscriptions","organizations_url":"https://api.github.com/users/zhangxinjian123/orgs","repos_url":"https://api.github.com/users/zhangxinjian123/repos","events_url":"https://api.github.com/users/zhangxinjian123/events{/privacy}","received_events_url":"https://api.github.com/users/zhangxinjian123/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-22T02:27:53Z","updated_at":"2019-07-22T02:27:53Z","author_association":"NONE","body":"When I upgrade the Spark version to 2.4.3, I will make an error when I execute the program under hoodie-spark. The error is as follows:\r\nException in thread \"main\" java.util.ServiceConfigurationError: org.apache.spark.sql.sources.DataSourceRegister: Provider org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat could not be instantiated\r\n\tat java.util.ServiceLoader.fail(ServiceLoader.java:232)\r\n\tat java.util.ServiceLoader.access$100(ServiceLoader.java:185)\r\n\tat java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384)\r\n\tat java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)\r\n\tat java.util.ServiceLoader$1.next(ServiceLoader.java:480)\r\n\tat scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\r\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\r\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\r\n\tat scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)\r\n\tat scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)\r\n\tat scala.collection.AbstractTraversable.filter(Traversable.scala:104)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:630)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:245)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\r\n\tat HoodieWriteApp.runs(HoodieWriteApp.java:121)\r\n\tat HoodieWriteApp.main(HoodieWriteApp.java:68)\r\nCaused by: java.lang.NoClassDefFoundError: org/apache/parquet/hadoop/ParquetOutputFormat$JobSummaryLevel\r\n\tat java.lang.Class.getDeclaredConstructors0(Native Method)\r\n\tat java.lang.Class.privateGetDeclaredConstructors(Class.java:2671)\r\n\tat java.lang.Class.getConstructor0(Class.java:3075)\r\n\tat java.lang.Class.newInstance(Class.java:412)\r\n\tat java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:380)\r\n\t... 15 more\r\nCaused by: java.lang.ClassNotFoundException: org.apache.parquet.hadoop.ParquetOutputFormat$JobSummaryLevel\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513617090/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513894055","html_url":"https://github.com/apache/hudi/issues/789#issuecomment-513894055","issue_url":"https://api.github.com/repos/apache/hudi/issues/789","id":513894055,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzg5NDA1NQ==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-22T18:11:12Z","updated_at":"2019-07-22T18:11:12Z","author_association":"CONTRIBUTOR","body":"@eisig I am trying to reproduce the issue. Will update soon. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513894055/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513896573","html_url":"https://github.com/apache/hudi/pull/798#issuecomment-513896573","issue_url":"https://api.github.com/repos/apache/hudi/issues/798","id":513896573,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzg5NjU3Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-22T18:18:16Z","updated_at":"2019-07-22T18:18:16Z","author_association":"MEMBER","body":"https://issues.apache.org/jira/browse/HUDI-175 is now assigned to you. welcome your contributions! ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513896573/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513994462","html_url":"https://github.com/apache/hudi/issues/796#issuecomment-513994462","issue_url":"https://api.github.com/repos/apache/hudi/issues/796","id":513994462,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzk5NDQ2Mg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-22T23:37:56Z","updated_at":"2019-07-22T23:37:56Z","author_association":"MEMBER","body":"@anchalkataria can you upgrade to current master and see if this has been fixed? we have fixed few things since 0.4.5 .. \r\n\r\nUnrelated, there is #751 #780 which we are working on revamping poms/bundles here. So might have something for you to test soonish ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513994462/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513994793","html_url":"https://github.com/apache/hudi/pull/635#issuecomment-513994793","issue_url":"https://api.github.com/repos/apache/hudi/issues/635","id":513994793,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzk5NDc5Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-22T23:39:25Z","updated_at":"2019-07-22T23:39:25Z","author_association":"MEMBER","body":"@zhangxinjian123 can you please open a separate mailing list thread/issue if you got past the payload issue","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/513994793/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514050654","html_url":"https://github.com/apache/hudi/issues/796#issuecomment-514050654","issue_url":"https://api.github.com/repos/apache/hudi/issues/796","id":514050654,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDA1MDY1NA==","user":{"login":"anchalkataria","id":9292326,"node_id":"MDQ6VXNlcjkyOTIzMjY=","avatar_url":"https://avatars.githubusercontent.com/u/9292326?v=4","gravatar_id":"","url":"https://api.github.com/users/anchalkataria","html_url":"https://github.com/anchalkataria","followers_url":"https://api.github.com/users/anchalkataria/followers","following_url":"https://api.github.com/users/anchalkataria/following{/other_user}","gists_url":"https://api.github.com/users/anchalkataria/gists{/gist_id}","starred_url":"https://api.github.com/users/anchalkataria/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/anchalkataria/subscriptions","organizations_url":"https://api.github.com/users/anchalkataria/orgs","repos_url":"https://api.github.com/users/anchalkataria/repos","events_url":"https://api.github.com/users/anchalkataria/events{/privacy}","received_events_url":"https://api.github.com/users/anchalkataria/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-23T04:36:14Z","updated_at":"2019-07-23T04:36:14Z","author_association":"NONE","body":"So @vinothchandar will upgrading the version also fix the null value issue while updating the records in storage type MOR ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514050654/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514137876","html_url":"https://github.com/apache/hudi/issues/796#issuecomment-514137876","issue_url":"https://api.github.com/repos/apache/hudi/issues/796","id":514137876,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDEzNzg3Ng==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-23T09:48:00Z","updated_at":"2019-07-23T09:48:00Z","author_association":"MEMBER","body":"Not sure the exact issue you are hitting on 0.4.5. Dont recall any issues on that release with these symptoms. Once you are on master, we can work thru that as well. Hope that helps","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514137876/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514140879","html_url":"https://github.com/apache/hudi/issues/800#issuecomment-514140879","issue_url":"https://api.github.com/repos/apache/hudi/issues/800","id":514140879,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDE0MDg3OQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-23T09:56:13Z","updated_at":"2019-07-23T09:58:43Z","author_association":"MEMBER","body":"That job pretty much just writes out parquet (or versions parquet files if you have updates). From what I see single tasks are gc-ing for hours when though the input is more or less 7M records or so. I have seen similar issue (not this bad though) caused on yarn due to interference from other jobs or yarn not blacklisting a bad host.. \r\n\r\nAs a next step, can we try configuring a larger heap (say double it) or obtain a heapdump of such a process and we can see whats going on (i.e if there is a leak)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514140879/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514141998","html_url":"https://github.com/apache/hudi/issues/800#issuecomment-514141998","issue_url":"https://api.github.com/repos/apache/hudi/issues/800","id":514141998,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDE0MTk5OA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-23T09:59:05Z","updated_at":"2019-07-23T09:59:05Z","author_association":"MEMBER","body":"@n3nash any ideas?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514141998/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514142511","html_url":"https://github.com/apache/hudi/pull/780#issuecomment-514142511","issue_url":"https://api.github.com/repos/apache/hudi/issues/780","id":514142511,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDE0MjUxMQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-23T10:00:24Z","updated_at":"2019-07-23T10:00:24Z","author_association":"MEMBER","body":"Great. Will prep a branch with this as well and we can pick off from there.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514142511/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514194492","html_url":"https://github.com/apache/hudi/issues/143#issuecomment-514194492","issue_url":"https://api.github.com/repos/apache/hudi/issues/143","id":514194492,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDE5NDQ5Mg==","user":{"login":"tkakantousis","id":2674116,"node_id":"MDQ6VXNlcjI2NzQxMTY=","avatar_url":"https://avatars.githubusercontent.com/u/2674116?v=4","gravatar_id":"","url":"https://api.github.com/users/tkakantousis","html_url":"https://github.com/tkakantousis","followers_url":"https://api.github.com/users/tkakantousis/followers","following_url":"https://api.github.com/users/tkakantousis/following{/other_user}","gists_url":"https://api.github.com/users/tkakantousis/gists{/gist_id}","starred_url":"https://api.github.com/users/tkakantousis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tkakantousis/subscriptions","organizations_url":"https://api.github.com/users/tkakantousis/orgs","repos_url":"https://api.github.com/users/tkakantousis/repos","events_url":"https://api.github.com/users/tkakantousis/events{/privacy}","received_events_url":"https://api.github.com/users/tkakantousis/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-23T12:46:54Z","updated_at":"2019-07-23T12:46:54Z","author_association":"NONE","body":"Hi, can I join the channel? Thanks! theo@logicalclocks.com","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514194492/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514328868","html_url":"https://github.com/apache/hudi/issues/714#issuecomment-514328868","issue_url":"https://api.github.com/repos/apache/hudi/issues/714","id":514328868,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDMyODg2OA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-23T18:28:50Z","updated_at":"2019-07-23T18:28:50Z","author_association":"MEMBER","body":"https://github.com/apache/incubator-hudi/pull/799 has the logging changes for timing handles that actually write data.\r\n\r\nhttps://github.com/apache/incubator-hudi/blob/9857c4b21ccb77a97817e1e448c4c54bdd409562/hoodie-utilities/src/main/java/com/uber/hoodie/utilities/deltastreamer/DeltaSync.java#L333 I would suggest to insert some code right after the ` log.info(\"Starting commit  : \" + commitTime);` that does similar countByKey on the `records` RDD and see where we go from there..  ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514328868/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514332156","html_url":"https://github.com/apache/hudi/issues/800#issuecomment-514332156","issue_url":"https://api.github.com/repos/apache/hudi/issues/800","id":514332156,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDMzMjE1Ng==","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-23T18:37:50Z","updated_at":"2019-07-23T18:37:50Z","author_association":"MEMBER","body":"Sure, I can try that.\r\nThe delta data was very dirty for sure(many incoming old data need to rewrite existing parquet files). The task duration seems to increase exponentially with the shuffle read size. \r\n\r\nAlso, this job is not releasing executors when the tasks were finished. e.g. I gave this job 100 executors. Two tasks are running for 20 hours and others finished in minutes. This job will keep 100 executors for 20 hours. Is that possible to improve this?\r\n\r\n![Screen Shot 2019-07-23 at 11 22 37 AM](https://user-images.githubusercontent.com/23007841/61737200-94f15e00-ad3c-11e9-8016-d4f7cd5f8ead.png)\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514332156/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514415847","html_url":"https://github.com/apache/hudi/issues/800#issuecomment-514415847","issue_url":"https://api.github.com/repos/apache/hudi/issues/800","id":514415847,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDQxNTg0Nw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-23T23:08:18Z","updated_at":"2019-07-23T23:08:18Z","author_association":"MEMBER","body":"So, this seems more about the memory per executor rather than number of executors.. Not releasing the executors is very weird for a spark app to do tbh.. interesting.. You already have 12GB executor memory, which should be plenty .. \r\n\r\nAll in all, its GC-ing constantly and if you let it run, as with any java app, it will keep GCing and chew up cpu .. Can you try to do a heapdump using `jmap` and pull it into something like Eclipse MAT ? we can then see whats taking up the memory.. \r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514415847/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514430604","html_url":"https://github.com/apache/hudi/issues/800#issuecomment-514430604","issue_url":"https://api.github.com/repos/apache/hudi/issues/800","id":514430604,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDQzMDYwNA==","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-24T00:22:31Z","updated_at":"2019-07-24T00:22:31Z","author_association":"MEMBER","body":"Maybe this https://github.com/apache/incubator-hudi/blob/master/hoodie-common/src/main/java/com/uber/hoodie/common/util/SerializationUtils.java#L85 is too small? Seems like this is not related to `spark.kryoserializer.buffer.max`? \r\n\r\nAlso could be https://github.com/apache/incubator-hudi/blob/master/hoodie-client/src/main/java/com/uber/hoodie/config/HoodieMemoryConfig.java#L119 is too small. `12G * 0.4 * 0.6 = 2.88G` seems enough for split merge, but I will try larger executor memory to confirm...","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514430604/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514615177","html_url":"https://github.com/apache/hudi/issues/801#issuecomment-514615177","issue_url":"https://api.github.com/repos/apache/hudi/issues/801","id":514615177,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDYxNTE3Nw==","user":{"login":"zhangxinjian123","id":30996853,"node_id":"MDQ6VXNlcjMwOTk2ODUz","avatar_url":"https://avatars.githubusercontent.com/u/30996853?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangxinjian123","html_url":"https://github.com/zhangxinjian123","followers_url":"https://api.github.com/users/zhangxinjian123/followers","following_url":"https://api.github.com/users/zhangxinjian123/following{/other_user}","gists_url":"https://api.github.com/users/zhangxinjian123/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangxinjian123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangxinjian123/subscriptions","organizations_url":"https://api.github.com/users/zhangxinjian123/orgs","repos_url":"https://api.github.com/users/zhangxinjian123/repos","events_url":"https://api.github.com/users/zhangxinjian123/events{/privacy}","received_events_url":"https://api.github.com/users/zhangxinjian123/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-24T12:41:06Z","updated_at":"2019-07-24T12:41:06Z","author_association":"NONE","body":"How to set schema to null when reading Kafka data？","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514615177/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514686692","html_url":"https://github.com/apache/hudi/issues/800#issuecomment-514686692","issue_url":"https://api.github.com/repos/apache/hudi/issues/800","id":514686692,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDY4NjY5Mg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-24T15:42:18Z","updated_at":"2019-07-24T15:42:18Z","author_association":"MEMBER","body":"Still think getting a heapdump is the best way, since that will tell us what’s actually held in memory. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514686692/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514688964","html_url":"https://github.com/apache/hudi/issues/801#issuecomment-514688964","issue_url":"https://api.github.com/repos/apache/hudi/issues/801","id":514688964,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDY4ODk2NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-24T15:48:03Z","updated_at":"2019-07-24T15:48:03Z","author_association":"MEMBER","body":"Hi. If you are using the deltastreamer, then there are a couple of options to specify schema. Either you can use FileBasedSchemaProvider to read it off a file or use the Confluent schema registry","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514688964/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514799616","html_url":"https://github.com/apache/hudi/issues/801#issuecomment-514799616","issue_url":"https://api.github.com/repos/apache/hudi/issues/801","id":514799616,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDc5OTYxNg==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-24T21:04:47Z","updated_at":"2019-07-24T21:04:47Z","author_association":"CONTRIBUTOR","body":"@zhangxinjian123 You can evolve your schema in a backwards compatible way. Mark the fields you don't want to produce to as optional and add new fields to the schema as your produce them. Read more here : https://avro.apache.org/docs/current/spec.html. \r\n\r\nAs @vinothchandar pointed out, there are multiple ways to pass this schema to the job and as your evolve them, you can just swap those schemas in those registries.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514799616/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514890134","html_url":"https://github.com/apache/hudi/issues/796#issuecomment-514890134","issue_url":"https://api.github.com/repos/apache/hudi/issues/796","id":514890134,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDg5MDEzNA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-25T04:24:29Z","updated_at":"2019-07-25T04:24:29Z","author_association":"MEMBER","body":"@bhasudha is looking into the null issue..","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514890134/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514890780","html_url":"https://github.com/apache/hudi/pull/782#issuecomment-514890780","issue_url":"https://api.github.com/repos/apache/hudi/issues/782","id":514890780,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDg5MDc4MA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-25T04:28:18Z","updated_at":"2019-07-25T04:28:18Z","author_association":"MEMBER","body":"https://github.com/vinothchandar/incubator-hudi/tree/pom-cleanup has both the commits and still fails ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514890780/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514891837","html_url":"https://github.com/apache/hudi/pull/771#issuecomment-514891837","issue_url":"https://api.github.com/repos/apache/hudi/issues/771","id":514891837,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDg5MTgzNw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-25T04:34:46Z","updated_at":"2019-07-25T04:34:46Z","author_association":"MEMBER","body":"Closing since #775 is already. please reopen if you feel this is still needed","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514891837/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514893508","html_url":"https://github.com/apache/hudi/pull/782#issuecomment-514893508","issue_url":"https://api.github.com/repos/apache/hudi/issues/782","id":514893508,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDg5MzUwOA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-25T04:45:26Z","updated_at":"2019-07-25T04:45:26Z","author_association":"MEMBER","body":"```\r\n182743 [main] ERROR com.uber.hoodie.integ.ITTestBase  - Stderr is :ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.\r\nException in thread \"main\" com.uber.hoodie.exception.HoodieIOException: Could not load Hoodie properties from /user/hive/warehouse/stock_ticks_cow/.hoodie/hoodie.properties\r\n\tat com.uber.hoodie.common.table.HoodieTableConfig.<init>(HoodieTableConfig.java:77)\r\n\tat com.uber.hoodie.common.table.HoodieTableMetaClient.<init>(HoodieTableMetaClient.java:106)\r\n\tat com.uber.hoodie.common.table.HoodieTableMetaClient.<init>(HoodieTableMetaClient.java:91)\r\n\tat com.uber.hoodie.utilities.deltastreamer.HoodieDeltaStreamer$DeltaSyncService.<init>(HoodieDeltaStreamer.java:343)\r\n\tat com.uber.hoodie.utilities.deltastreamer.HoodieDeltaStreamer.<init>(HoodieDeltaStreamer.java:100)\r\n\tat com.uber.hoodie.utilities.deltastreamer.HoodieDeltaStreamer.<init>(HoodieDeltaStreamer.java:94)\r\n\tat com.uber.hoodie.utilities.deltastreamer.HoodieDeltaStreamer.main(HoodieDeltaStreamer.java:284)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-681376592-172.30.0.5-1563217137227:blk_1073741833_1009 file=/user/hive/warehouse/stock_ticks_cow/.hoodie/hoodie.properties\r\n\tat org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:984)\r\n\tat org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:642)\r\n\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)\r\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)\r\n\tat java.io.DataInputStream.read(DataInputStream.java:100)\r\n\tat java.util.Properties$LineReader.readLine(Properties.java:435)\r\n\tat java.util.Properties.load0(Properties.java:353)\r\n\tat java.util.Properties.load(Properties.java:341)\r\n\tat com.uber.hoodie.common.table.HoodieTableConfig.<init>(HoodieTableConfig.java:74)\r\n\t... 16 more\r\n\r\n[ERROR] Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 30.559 s <<< FAILURE! - in com.uber.hoodie.integ.ITTestHoodieDemo\r\n[ERROR] testDemo(com.uber.hoodie.integ.ITTestHoodieDemo)  Time elapsed: 30.558 s  <<< FAILURE!\r\njava.lang.AssertionError: Command ([spark-submit, --class, com.uber.hoodie.utilities.deltastreamer.HoodieDeltaStreamer, /var/hoodie/ws/docker/hoodie/hadoop/hive_base/target/hoodie-utilities.jar, --storage-type, COPY_ON_WRITE, --source-class, com.uber.hoodie.utilities.sources.JsonDFSSource, --source-ordering-field, ts, --target-base-path, /user/hive/warehouse/stock_ticks_cow, --target-table, stock_ticks_cow, --props, /var/demo/config/dfs-source.properties, --schemaprovider-class, com.uber.hoodie.utilities.schema.FilebasedSchemaProvider]) expected to succeed. Exit (1)\r\n\tat com.uber.hoodie.integ.ITTestHoodieDemo.ingestFirstBatchAndHiveSync(ITTestHoodieDemo.java:95)\r\n\tat com.uber.hoodie.integ.ITTestHoodieDemo.testDemo(ITTestHoodieDemo.java:55)\r\n\r\n[INFO]\r\n[INFO] Results:\r\n[INFO]\r\n[ERROR] Failures:\r\n[ERROR]   ITTestHoodieDemo.testDemo:55->ingestFirstBatchAndHiveSync:95->ITTestBase.executeCommandsInDocker:152->ITTestBase.executeCommandInDocker:140 Command ([spark-submit, --class, com.uber.hoodie.utilities.deltastreamer.HoodieDeltaStreamer, /var/hoodie/ws/docker/hoodie/hadoop/hive_base/target/hoodie-utilities.jar, --storage-type, COPY_ON_WRITE, --source-class, com.uber.hoodie.utilities.sources.JsonDFSSource, --source-ordering-field, ts, --target-base-path, /user/hive/warehouse/stock_ticks_cow, --target-table, stock_ticks_cow, --props, /var/demo/config/dfs-source.properties, --schemaprovider-class, com.uber.hoodie.utilities.schema.FilebasedSchemaProvider]) expected to succeed. Exit (1)\r\n[ERROR]   ITTestHoodieSanity.testRunHoodieJavaAppOnMultiPartitionKeysCOWTable:66->testRunHoodieJavaAppOnCOWTable:139->ITTestBase.executeCommandInDocker:140 Command ([/var/hoodie/ws/hoodie-spark/run_hoodie_app.sh, --hive-sync, --table-path, hdfs://namenode/docker_hoodie_multi_partition_key_cow_test, --hive-url, jdbc:hive2://hiveserver:10000, --use-multi-partition-keys, --hive-table, docker_hoodie_multi_partition_key_cow_test]) expected to succeed. Exit (1)\r\n[ERROR]   ITTestHoodieSanity.testRunHoodieJavaAppOnNonPartitionedCOWTable:77->testRunHoodieJavaAppOnCOWTable:139->ITTestBase.executeCommandInDocker:140 Command ([/var/hoodie/ws/hoodie-spark/run_hoodie_app.sh, --hive-sync, --table-path, hdfs://namenode/docker_hoodie_non_partition_key_cow_test, --hive-url, jdbc:hive2://hiveserver:10000, --non-partitioned, --hive-table, docker_hoodie_non_partition_key_cow_test]) expected to succeed. Exit (1)\r\n[ERROR]   ITTestHoodieSanity.testRunHoodieJavaAppOnSinglePartitionKeyCOWTable:55->testRunHoodieJavaAppOnCOWTable:139->ITTestBase.executeCommandInDocker:140 Command ([/var/hoodie/ws/hoodie-spark/run_hoodie_app.sh, --hive-sync, --table-path, hdfs://namenode/docker_hoodie_single_partition_key_cow_test, --hive-url, jdbc:hive2://hiveserver:10000, --hive-table, docker_hoodie_single_partition_key_cow_test]) expected to succeed. Exit (1)\r\n[INFO]\r\n[ERROR] Tests run: 5, Failures: 4, Errors: 0, Skipped: 0\r\n[INFO]\r\n[INFO]\r\n[INFO] --- docker-compose-maven-plugin:2.0.1:down (down) @ hoodie-integ-test ---\r\n[INFO] Removing volumes\r\n[INFO] Dockerfile: /Users/vchandar/Code/incubator-hudi/hoodie-integ-test/../docker/compose/docker-compose_hadoop284_hive233_spark231.yml\r\n[INFO] Running: docker-compose -f /Users/vchandar/Code/incubator-hudi/hoodie-integ-test/../docker/compose/docker-compose_hadoop284_hive233_spark231.yml down -v\r\nStopping adhoc-1                   ... done\r\nStopping adhoc-2                   ... done\r\nStopping spark-worker-1            ... done\r\nStopping sparkmaster               ... done\r\nStopping datanode1                 ... done\r\nStopping hiveserver                ... done\r\nStopping historyserver             ... done\r\nStopping hivemetastore             ... done\r\nStopping namenode                  ... done\r\nStopping kafkabroker               ... done\r\nStopping zookeeper                 ... done\r\nStopping hive-metastore-postgresql ... done\r\nRemoving adhoc-1                   ... done\r\nRemoving adhoc-2                   ... done\r\nRemoving spark-worker-1            ... done\r\nRemoving sparkmaster               ... done\r\nRemoving datanode1                 ... done\r\nRemoving hiveserver                ... done\r\nRemoving historyserver             ... done\r\nRemoving hivemetastore             ... done\r\nRemoving namenode                  ... done\r\nRemoving kafkabroker               ... done\r\nRemoving zookeeper                 ... done\r\nRemoving hive-metastore-postgresql ... done\r\nRemoving network compose_default\r\nRemoving volume compose_namenode\r\nRemoving volume compose_historyserver\r\nRemoving volume compose_hive-metastore-postgresql\r\n[INFO]\r\n[INFO] --- maven-failsafe-plugin:2.22.0:verify (verify) @ hoodie-integ-test ---\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Summary for Hoodie 0.4.8-SNAPSHOT:\r\n[INFO]\r\n[INFO] Hoodie ............................................. SUCCESS [  1.588 s]\r\n[INFO] hoodie-common ...................................... SUCCESS [ 10.354 s]\r\n[INFO] hoodie-timeline-service ............................ SUCCESS [  8.044 s]\r\n[INFO] hoodie-hadoop-mr ................................... SUCCESS [  1.690 s]\r\n[INFO] hoodie-client ...................................... SUCCESS [  3.978 s]\r\n[INFO] hoodie-hive ........................................ SUCCESS [  1.072 s]\r\n[INFO] hoodie-spark ....................................... SUCCESS [ 22.175 s]\r\n[INFO] hoodie-utilities ................................... SUCCESS [  2.226 s]\r\n[INFO] hoodie-cli ......................................... SUCCESS [  8.503 s]\r\n[INFO] hoodie-hadoop-mr-bundle ............................ SUCCESS [  1.916 s]\r\n[INFO] hoodie-hive-bundle ................................. SUCCESS [ 11.984 s]\r\n[INFO] hoodie-spark-bundle ................................ SUCCESS [01:14 min]\r\n[INFO] hoodie-presto-bundle ............................... SUCCESS [  9.329 s]\r\n[INFO] hoodie-utilities-bundle ............................ SUCCESS [ 19.238 s]\r\n[INFO] hoodie-hadoop-docker ............................... SUCCESS [  0.350 s]\r\n[INFO] hoodie-hadoop-base-docker .......................... SUCCESS [  0.325 s]\r\n[INFO] hoodie-hadoop-namenode-docker ...................... SUCCESS [  0.073 s]\r\n[INFO] hoodie-hadoop-datanode-docker ...................... SUCCESS [  0.081 s]\r\n[INFO] hoodie-hadoop-history-docker ....................... SUCCESS [  0.068 s]\r\n[INFO] hoodie-hadoop-hive-docker .......................... SUCCESS [  0.456 s]\r\n[INFO] hoodie-hadoop-sparkbase-docker ..................... SUCCESS [  0.079 s]\r\n[INFO] hoodie-hadoop-sparkmaster-docker ................... SUCCESS [  0.070 s]\r\n[INFO] hoodie-hadoop-sparkworker-docker ................... SUCCESS [  0.069 s]\r\n[INFO] hoodie-hadoop-sparkadhoc-docker .................... SUCCESS [  0.072 s]\r\n[INFO] hoodie-integ-test .................................. FAILURE [04:09 min]\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD FAILURE\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time:  07:07 min\r\n[INFO] Finished at: 2019-07-24T19:49:17-07:00\r\n[INFO] ------------------------------------------------------------------------\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-failsafe-plugin:2.22.0:verify (verify) on project hoodie-integ-test: There are test failures.\r\n[ERROR]\r\n[ERROR] Please refer to /Users/vchandar/Code/incubator-hudi/hoodie-integ-test/target/failsafe-reports for the individual test results.\r\n[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.\r\n[ERROR] -> [Help 1]\r\n[ERROR]\r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR]\r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\r\n[ERROR]\r\n[ERROR] After correcting the problems, you can resume the build with the command\r\n[ERROR]   mvn <goals> -rf :hoodie-integ-test\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514893508/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514916744","html_url":"https://github.com/apache/hudi/issues/801#issuecomment-514916744","issue_url":"https://api.github.com/repos/apache/hudi/issues/801","id":514916744,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDkxNjc0NA==","user":{"login":"zhangxinjian123","id":30996853,"node_id":"MDQ6VXNlcjMwOTk2ODUz","avatar_url":"https://avatars.githubusercontent.com/u/30996853?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangxinjian123","html_url":"https://github.com/zhangxinjian123","followers_url":"https://api.github.com/users/zhangxinjian123/followers","following_url":"https://api.github.com/users/zhangxinjian123/following{/other_user}","gists_url":"https://api.github.com/users/zhangxinjian123/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangxinjian123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangxinjian123/subscriptions","organizations_url":"https://api.github.com/users/zhangxinjian123/orgs","repos_url":"https://api.github.com/users/zhangxinjian123/repos","events_url":"https://api.github.com/users/zhangxinjian123/events{/privacy}","received_events_url":"https://api.github.com/users/zhangxinjian123/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-25T06:35:22Z","updated_at":"2019-07-25T06:35:22Z","author_association":"NONE","body":"The hoodie-spark module offers the DataSource API to write (and also read) any data frame into a Hudi dataset. Can I use hoodie-spark to read Kafka data?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/514916744/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515130163","html_url":"https://github.com/apache/hudi/pull/782#issuecomment-515130163","issue_url":"https://api.github.com/repos/apache/hudi/issues/782","id":515130163,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTEzMDE2Mw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-25T17:13:03Z","updated_at":"2019-07-25T17:13:03Z","author_association":"CONTRIBUTOR","body":"@vinothchandar : After rebasing master and fixing/workingaround a connectivity issue with hivemetastore, the demo is passing. the sanity tests though fails with \"NoSuchMethodError xxx\" . I had applied #780 on top of this change and created a new test PR #803.  All the tests are passing here. We can use this as a baseline and apply #751 and fix any new failures.\r\n\r\n@bhasudha @n3nash : On a related note, I saw a different failure in RT query on one of Travis CI runs : https://api.travis-ci.org/v3/job/563406198/log.txt\r\n\r\nI did not see the same issue in subsequent runs. Please also include this in your investigation and see your potential fix also addresses this.\r\n\r\n\"\"\"\r\n[ERROR] testDemo(com.uber.hoodie.integ.ITTestHoodieDemo)  Time elapsed: 243.786 s  <<< FAILURE!\r\norg.junit.ComparisonFailure: expected:<GOOG\t2018-08-31 [10]:59:00> but was:<GOOG\t2018-08-31 [09]:59:00>\r\n\"\"\"\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515130163/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515358302","html_url":"https://github.com/apache/hudi/issues/801#issuecomment-515358302","issue_url":"https://api.github.com/repos/apache/hudi/issues/801","id":515358302,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTM1ODMwMg==","user":{"login":"zhangxinjian123","id":30996853,"node_id":"MDQ6VXNlcjMwOTk2ODUz","avatar_url":"https://avatars.githubusercontent.com/u/30996853?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangxinjian123","html_url":"https://github.com/zhangxinjian123","followers_url":"https://api.github.com/users/zhangxinjian123/followers","following_url":"https://api.github.com/users/zhangxinjian123/following{/other_user}","gists_url":"https://api.github.com/users/zhangxinjian123/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangxinjian123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangxinjian123/subscriptions","organizations_url":"https://api.github.com/users/zhangxinjian123/orgs","repos_url":"https://api.github.com/users/zhangxinjian123/repos","events_url":"https://api.github.com/users/zhangxinjian123/events{/privacy}","received_events_url":"https://api.github.com/users/zhangxinjian123/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-26T08:20:58Z","updated_at":"2019-07-26T08:20:58Z","author_association":"NONE","body":"From the value consumed by kafka, which section of code can be printed out？","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515358302/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515406238","html_url":"https://github.com/apache/hudi/pull/782#issuecomment-515406238","issue_url":"https://api.github.com/repos/apache/hudi/issues/782","id":515406238,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTQwNjIzOA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-26T10:45:47Z","updated_at":"2019-07-26T10:45:47Z","author_association":"MEMBER","body":"is this what you fixed on top of what I had? \r\n\r\n```\r\n$ gd bvaradar/demo_automat_with_pom_dep_order_fixes\r\ndiff --git a/.travis.yml b/.travis.yml\r\nindex e4b23f79..493270ce 100644\r\n--- a/.travis.yml\r\n+++ b/.travis.yml\r\n@@ -5,7 +5,6 @@ sudo: required\r\n env:\r\n   - HUDI_QUIETER_LOGGING=1 TEST_SUITE=unit\r\n   - TEST_SUITE=integration\r\n-install: true\r\n services:\r\n - docker\r\n cache:\r\ndiff --git a/hoodie-integ-test/src/test/java/com/uber/hoodie/integ/ITTestHoodieSanity.java b/hoodie-integ-test/src/test/java/com/uber/hoodie/integ/ITTestHoodieSanity.java\r\nindex 9335fe6e..d5d5220d 100644\r\n--- a/hoodie-integ-test/src/test/java/com/uber/hoodie/integ/ITTestHoodieSanity.java\r\n+++ b/hoodie-integ-test/src/test/java/com/uber/hoodie/integ/ITTestHoodieSanity.java\r\n@@ -91,14 +91,7 @@ public class ITTestHoodieSanity extends ITTestBase {\r\n     // Drop Table if it exists\r\n     {\r\n       String[] hiveDropCmd = getHiveConsoleCommand(\"drop table if exists \" + hiveTableName);\r\n-      try {\r\n-        executeCommandInDocker(HIVESERVER, hiveDropCmd, true);\r\n-      } catch (AssertionError ex) {\r\n-        // In travis, sometimes, the hivemetastore is not ready even though we wait for the port to be up\r\n-        // Workaround to sleep for 5 secs and retry\r\n-        Thread.sleep(5000);\r\n-        executeCommandInDocker(HIVESERVER, hiveDropCmd, true);\r\n-      }\r\n+      executeCommandInDocker(HIVESERVER, hiveDropCmd, true);\r\n     }\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515406238/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515414731","html_url":"https://github.com/apache/hudi/pull/782#issuecomment-515414731","issue_url":"https://api.github.com/repos/apache/hudi/issues/782","id":515414731,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTQxNDczMQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-26T11:19:40Z","updated_at":"2019-07-26T11:19:57Z","author_association":"MEMBER","body":"@bvaradar general question.. are the changes to /etc/hosts needs for the integ-tests as well (both local and on travis)? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515414731/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515417503","html_url":"https://github.com/apache/hudi/pull/782#issuecomment-515417503","issue_url":"https://api.github.com/repos/apache/hudi/issues/782","id":515417503,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTQxNzUwMw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-26T11:31:39Z","updated_at":"2019-07-26T11:31:39Z","author_association":"MEMBER","body":"Made #804 with three comments..we can focus efforts there.. (the test still does not pass for me locally. as long as it passes in travis, lets go with it for now. I ll circle back and fix it) .. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515417503/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515417853","html_url":"https://github.com/apache/hudi/pull/780#issuecomment-515417853","issue_url":"https://api.github.com/repos/apache/hudi/issues/780","id":515417853,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTQxNzg1Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-26T11:33:13Z","updated_at":"2019-07-26T11:33:13Z","author_association":"MEMBER","body":"Made #804 and a new branch `pom-bundle-cleanup` with the changes in this PR.. You can send more PRs there to that branch.. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515417853/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515534223","html_url":"https://github.com/apache/hudi/issues/789#issuecomment-515534223","issue_url":"https://api.github.com/repos/apache/hudi/issues/789","id":515534223,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTUzNDIyMw==","user":{"login":"eisig","id":1745057,"node_id":"MDQ6VXNlcjE3NDUwNTc=","avatar_url":"https://avatars.githubusercontent.com/u/1745057?v=4","gravatar_id":"","url":"https://api.github.com/users/eisig","html_url":"https://github.com/eisig","followers_url":"https://api.github.com/users/eisig/followers","following_url":"https://api.github.com/users/eisig/following{/other_user}","gists_url":"https://api.github.com/users/eisig/gists{/gist_id}","starred_url":"https://api.github.com/users/eisig/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eisig/subscriptions","organizations_url":"https://api.github.com/users/eisig/orgs","repos_url":"https://api.github.com/users/eisig/repos","events_url":"https://api.github.com/users/eisig/events{/privacy}","received_events_url":"https://api.github.com/users/eisig/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-26T17:22:49Z","updated_at":"2019-07-26T17:22:49Z","author_association":"CONTRIBUTOR","body":"@bhasudha  any update about this?\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515534223/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515611514","html_url":"https://github.com/apache/hudi/issues/801#issuecomment-515611514","issue_url":"https://api.github.com/repos/apache/hudi/issues/801","id":515611514,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTYxMTUxNA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-26T21:57:33Z","updated_at":"2019-07-26T21:57:33Z","author_association":"MEMBER","body":"yes. as long as you can obtain a dataFrame, you can write it out as a Hudi dataset.\r\n\r\nI am not following the last question. what do you mean by \"code can be printed out\"? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515611514/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515634785","html_url":"https://github.com/apache/hudi/pull/782#issuecomment-515634785","issue_url":"https://api.github.com/repos/apache/hudi/issues/782","id":515634785,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTYzNDc4NQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-27T00:20:48Z","updated_at":"2019-07-27T00:23:24Z","author_association":"CONTRIBUTOR","body":"> @bvaradar general question.. are the changes to /etc/hosts needs for the integ-tests as well (both local and on travis)?\r\n\r\n@vinothchandar it worked without changes to /etc/hosts\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515634785/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515841504","html_url":"https://github.com/apache/hudi/issues/143#issuecomment-515841504","issue_url":"https://api.github.com/repos/apache/hudi/issues/143","id":515841504,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTg0MTUwNA==","user":{"login":"nbijub","id":12442492,"node_id":"MDQ6VXNlcjEyNDQyNDky","avatar_url":"https://avatars.githubusercontent.com/u/12442492?v=4","gravatar_id":"","url":"https://api.github.com/users/nbijub","html_url":"https://github.com/nbijub","followers_url":"https://api.github.com/users/nbijub/followers","following_url":"https://api.github.com/users/nbijub/following{/other_user}","gists_url":"https://api.github.com/users/nbijub/gists{/gist_id}","starred_url":"https://api.github.com/users/nbijub/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nbijub/subscriptions","organizations_url":"https://api.github.com/users/nbijub/orgs","repos_url":"https://api.github.com/users/nbijub/repos","events_url":"https://api.github.com/users/nbijub/events{/privacy}","received_events_url":"https://api.github.com/users/nbijub/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-29T04:38:27Z","updated_at":"2019-07-29T04:38:27Z","author_association":"NONE","body":"Hi @vinothchandar , could you please add me nbijub@gmail.com to the slack channel ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/515841504/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516075033","html_url":"https://github.com/apache/hudi/issues/789#issuecomment-516075033","issue_url":"https://api.github.com/repos/apache/hudi/issues/789","id":516075033,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjA3NTAzMw==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-29T17:01:23Z","updated_at":"2019-07-29T17:01:23Z","author_association":"CONTRIBUTOR","body":"@eisig I have been trying to reproduce this for sometime. It's very intermittent in my setup. Are you able to deterministically reproduce this ? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516075033/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516090339","html_url":"https://github.com/apache/hudi/pull/798#issuecomment-516090339","issue_url":"https://api.github.com/repos/apache/hudi/issues/798","id":516090339,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjA5MDMzOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-29T17:39:08Z","updated_at":"2019-07-29T17:39:08Z","author_association":"MEMBER","body":"LGTM. thanks for the contribution @eisig ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516090339/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516250310","html_url":"https://github.com/apache/hudi/issues/789#issuecomment-516250310","issue_url":"https://api.github.com/repos/apache/hudi/issues/789","id":516250310,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjI1MDMxMA==","user":{"login":"eisig","id":1745057,"node_id":"MDQ6VXNlcjE3NDUwNTc=","avatar_url":"https://avatars.githubusercontent.com/u/1745057?v=4","gravatar_id":"","url":"https://api.github.com/users/eisig","html_url":"https://github.com/eisig","followers_url":"https://api.github.com/users/eisig/followers","following_url":"https://api.github.com/users/eisig/following{/other_user}","gists_url":"https://api.github.com/users/eisig/gists{/gist_id}","starred_url":"https://api.github.com/users/eisig/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eisig/subscriptions","organizations_url":"https://api.github.com/users/eisig/orgs","repos_url":"https://api.github.com/users/eisig/repos","events_url":"https://api.github.com/users/eisig/events{/privacy}","received_events_url":"https://api.github.com/users/eisig/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-30T03:54:47Z","updated_at":"2019-07-30T03:54:47Z","author_association":"CONTRIBUTOR","body":"@bhasudha It happens every time.\r\n1. https://github.com/apache/incubator-hudi/issues/789#issuecomment-512740619\r\n1. https://github.com/apache/incubator-hudi/issues/789#issuecomment-512741943\r\n\r\n(2) is import to me. If it's  by design, how to use the MERGE_ON_READ ro view?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516250310/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516274161","html_url":"https://github.com/apache/hudi/issues/801#issuecomment-516274161","issue_url":"https://api.github.com/repos/apache/hudi/issues/801","id":516274161,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjI3NDE2MQ==","user":{"login":"zhangxinjian123","id":30996853,"node_id":"MDQ6VXNlcjMwOTk2ODUz","avatar_url":"https://avatars.githubusercontent.com/u/30996853?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangxinjian123","html_url":"https://github.com/zhangxinjian123","followers_url":"https://api.github.com/users/zhangxinjian123/followers","following_url":"https://api.github.com/users/zhangxinjian123/following{/other_user}","gists_url":"https://api.github.com/users/zhangxinjian123/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangxinjian123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangxinjian123/subscriptions","organizations_url":"https://api.github.com/users/zhangxinjian123/orgs","repos_url":"https://api.github.com/users/zhangxinjian123/repos","events_url":"https://api.github.com/users/zhangxinjian123/events{/privacy}","received_events_url":"https://api.github.com/users/zhangxinjian123/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-30T05:55:43Z","updated_at":"2019-07-30T05:55:43Z","author_association":"NONE","body":"Can I upgrade the Spark version to 2.4.3 using Structured Streaming?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516274161/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516377266","html_url":"https://github.com/apache/hudi/issues/590#issuecomment-516377266","issue_url":"https://api.github.com/repos/apache/hudi/issues/590","id":516377266,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjM3NzI2Ng==","user":{"login":"arw357","id":8440059,"node_id":"MDQ6VXNlcjg0NDAwNTk=","avatar_url":"https://avatars.githubusercontent.com/u/8440059?v=4","gravatar_id":"","url":"https://api.github.com/users/arw357","html_url":"https://github.com/arw357","followers_url":"https://api.github.com/users/arw357/followers","following_url":"https://api.github.com/users/arw357/following{/other_user}","gists_url":"https://api.github.com/users/arw357/gists{/gist_id}","starred_url":"https://api.github.com/users/arw357/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arw357/subscriptions","organizations_url":"https://api.github.com/users/arw357/orgs","repos_url":"https://api.github.com/users/arw357/repos","events_url":"https://api.github.com/users/arw357/events{/privacy}","received_events_url":"https://api.github.com/users/arw357/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-30T11:21:25Z","updated_at":"2019-07-30T14:03:29Z","author_association":"NONE","body":"I found something alike . I have only one datanode - it happens when the archive log is being appended.  I can reproduce it.  It happens on a simple 2x2 csv file which i'm upserting . It happens on bigger files as well. This is for a COW.\r\nI see that this build failed as well : https://api.travis-ci.org/v3/job/547004744/log.txt \r\n\r\n```:08:04.613 [DataLakeSystem-akka.actor.default-dispatcher-5]  INFO com.uber.hoodie.common.table.log.HoodieLogFormat$WriterBuilder  - Building HoodieLogFormat Writer\r\n11:08:04.613 [DataLakeSystem-akka.actor.default-dispatcher-5]  INFO com.uber.hoodie.common.table.log.HoodieLogFormat$WriterBuilder  - Computing the next log version for commits in hdfs://namenode:8020/data/lake/3ecfc2fc-8f48-46e1-8e0c-be8fc13eb596/converted/.hoodie/archived\r\n11:08:04.621 [DataLakeSystem-akka.actor.default-dispatcher-5]  INFO com.uber.hoodie.common.table.log.HoodieLogFormat$WriterBuilder  - Computed the next log version for commits in hdfs://namenode:8020/data/lake/3ecfc2fc-8f48-46e1-8e0c-be8fc13eb596/converted/.hoodie/archived as 1\r\n11:08:04.621 [DataLakeSystem-akka.actor.default-dispatcher-5]  INFO com.uber.hoodie.common.table.log.HoodieLogFormat$WriterBuilder  - HoodieLogFile on path hdfs://namenode:8020/data/lake/3ecfc2fc-8f48-46e1-8e0c-be8fc13eb596/converted/.hoodie/archived/.commits_.archive.1\r\n11:08:04.630 [DataLakeSystem-akka.actor.default-dispatcher-5]  INFO com.uber.hoodie.common.table.log.HoodieLogFormatWriter  - HoodieLogFile {hdfs://namenode:8020/data/lake/3ecfc2fc-8f48-46e1-8e0c-be8fc13eb596/converted/.hoodie/archived/.commits_.archive.1} exists. Appending to existing file\r\n11:08:04.652 [DataLakeSystem-akka.actor.default-dispatcher-5]  INFO com.uber.hoodie.io.HoodieCommitArchiveLog  - Archiving instants [[20190730104047__clean__COMPLETED], [20190730104512__clean__COMPLETED], [20190730104605__clean__COMPLETED], [20190730104628__clean__COMPLETED], [20190730104651__clean__COMPLETED], [20190730104721__clean__COMPLETED], [20190730104758__clean__COMPLETED], [20190730104821__clean__COMPLETED], [20190730104843__clean__COMPLETED], [20190730104905__clean__COMPLETED], [20190730104926__clean__COMPLETED]]\r\n11:08:04.653 [DataLakeSystem-akka.actor.default-dispatcher-5]  INFO com.uber.hoodie.io.HoodieCommitArchiveLog  - Wrapper schema {\"type\":\"record\",\"name\":\"HoodieArchivedMetaEntry\",\"namespace\":\"com.uber.hoodie.avro.model\",\"fields\":[{\"name\":\"hoodieCommitMetadata\",\"type\":[\"null\",{\"type\":\"record\",\"name\":\"HoodieCommitMetadata\",\"fields\":[{\"name\":\"partitionToWriteStats\",\"type\":[\"null\",{\"type\":\"map\",\"values\":{\"type\":\"array\",\"items\":{\"type\":\"record\",\"name\":\"HoodieWriteStat\",\"fields\":[{\"name\":\"fileId\",\"type\":[\"null\",{\"type\":\"string\",\"avro.java.string\":\"String\"}],\"default\":null},{\"name\":\"path\",\"type\":[\"null\",{\"type\":\"string\",\"avro.java.string\":\"String\"}],\"default\":null},{\"name\":\"prevCommit\",\"type\":[\"null\",{\"type\":\"string\",\"avro.java.string\":\"String\"}],\"default\":null},{\"name\":\"numWrites\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"numDeletes\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"numUpdateWrites\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"totalWriteBytes\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"totalWriteErrors\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"partitionPath\",\"type\":[\"null\",{\"type\":\"string\",\"avro.java.string\":\"String\"}],\"default\":null},{\"name\":\"totalLogRecords\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"totalLogFiles\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"totalUpdatedRecordsCompacted\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"numInserts\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"totalLogBlocks\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"totalCorruptLogBlock\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"totalRollbackBlocks\",\"type\":[\"null\",\"long\"],\"default\":null}]}},\"avro.java.string\":\"String\"}]},{\"name\":\"extraMetadata\",\"type\":[\"null\",{\"type\":\"map\",\"values\":{\"type\":\"string\",\"avro.java.string\":\"String\"},\"avro.java.string\":\"String\"}]}]}],\"default\":\"null\"},{\"name\":\"hoodieCleanMetadata\",\"type\":[\"null\",{\"type\":\"record\",\"name\":\"HoodieCleanMetadata\",\"fields\":[{\"name\":\"startCleanTime\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"timeTakenInMillis\",\"type\":\"long\"},{\"name\":\"totalFilesDeleted\",\"type\":\"int\"},{\"name\":\"earliestCommitToRetain\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"partitionMetadata\",\"type\":{\"type\":\"map\",\"values\":{\"type\":\"record\",\"name\":\"HoodieCleanPartitionMetadata\",\"fields\":[{\"name\":\"partitionPath\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"policy\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"deletePathPatterns\",\"type\":{\"type\":\"array\",\"items\":{\"type\":\"string\",\"avro.java.string\":\"String\"}}},{\"name\":\"successDeleteFiles\",\"type\":{\"type\":\"array\",\"items\":{\"type\":\"string\",\"avro.java.string\":\"String\"}}},{\"name\":\"failedDeleteFiles\",\"type\":{\"type\":\"array\",\"items\":{\"type\":\"string\",\"avro.java.string\":\"String\"}}}]},\"avro.java.string\":\"String\"}}]}],\"default\":\"null\"},{\"name\":\"hoodieCompactionMetadata\",\"type\":[\"null\",{\"type\":\"record\",\"name\":\"HoodieCompactionMetadata\",\"fields\":[{\"name\":\"partitionToCompactionWriteStats\",\"type\":[\"null\",{\"type\":\"map\",\"values\":{\"type\":\"array\",\"items\":{\"type\":\"record\",\"name\":\"HoodieCompactionWriteStat\",\"fields\":[{\"name\":\"partitionPath\",\"type\":[\"null\",{\"type\":\"string\",\"avro.java.string\":\"String\"}]},{\"name\":\"totalLogRecords\",\"type\":[\"null\",\"long\"]},{\"name\":\"totalLogFiles\",\"type\":[\"null\",\"long\"]},{\"name\":\"totalUpdatedRecordsCompacted\",\"type\":[\"null\",\"long\"]},{\"name\":\"hoodieWriteStat\",\"type\":[\"null\",\"HoodieWriteStat\"]}]}},\"avro.java.string\":\"String\"}]}]}],\"default\":\"null\"},{\"name\":\"hoodieRollbackMetadata\",\"type\":[\"null\",{\"type\":\"record\",\"name\":\"HoodieRollbackMetadata\",\"fields\":[{\"name\":\"startRollbackTime\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"timeTakenInMillis\",\"type\":\"long\"},{\"name\":\"totalFilesDeleted\",\"type\":\"int\"},{\"name\":\"commitsRollback\",\"type\":{\"type\":\"array\",\"items\":{\"type\":\"string\",\"avro.java.string\":\"String\"}}},{\"name\":\"partitionMetadata\",\"type\":{\"type\":\"map\",\"values\":{\"type\":\"record\",\"name\":\"HoodieRollbackPartitionMetadata\",\"fields\":[{\"name\":\"partitionPath\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"successDeleteFiles\",\"type\":{\"type\":\"array\",\"items\":{\"type\":\"string\",\"avro.java.string\":\"String\"}}},{\"name\":\"failedDeleteFiles\",\"type\":{\"type\":\"array\",\"items\":{\"type\":\"string\",\"avro.java.string\":\"String\"}}}]},\"avro.java.string\":\"String\"}}]}],\"default\":\"null\"},{\"name\":\"hoodieSavePointMetadata\",\"type\":[\"null\",{\"type\":\"record\",\"name\":\"HoodieSavepointMetadata\",\"fields\":[{\"name\":\"savepointedBy\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"savepointedAt\",\"type\":\"long\"},{\"name\":\"comments\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"partitionMetadata\",\"type\":{\"type\":\"map\",\"values\":{\"type\":\"record\",\"name\":\"HoodieSavepointPartitionMetadata\",\"fields\":[{\"name\":\"partitionPath\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"savepointDataFile\",\"type\":{\"type\":\"array\",\"items\":{\"type\":\"string\",\"avro.java.string\":\"String\"}}}]},\"avro.java.string\":\"String\"}}]}],\"default\":\"null\"},{\"name\":\"commitTime\",\"type\":[\"null\",{\"type\":\"string\",\"avro.java.string\":\"String\"}]},{\"name\":\"actionType\",\"type\":[\"null\",{\"type\":\"string\",\"avro.java.string\":\"String\"}]}]}\r\n11:08:04.706 [DataLakeSystem-akka.actor.default-dispatcher-5] ERROR  \r\ncom.uber.hoodie.exception.HoodieException: Unable to close HoodieLogFormat writer\r\n\tat com.uber.hoodie.io.HoodieCommitArchiveLog.close(HoodieCommitArchiveLog.java:103)\r\n\tat com.uber.hoodie.io.HoodieCommitArchiveLog.archiveIfRequired(HoodieCommitArchiveLog.java:124)\r\n\tat com.uber.hoodie.HoodieWriteClient.commit(HoodieWriteClient.java:542)\r\n\tat com.uber.hoodie.HoodieWriteClient.commit(HoodieWriteClient.java:489)\r\n\tat com.uber.hoodie.HoodieWriteClient.commit(HoodieWriteClient.java:480)\r\n\tat com.uber.hoodie.HoodieSparkSqlWriter$.write(HoodieSparkSqlWriter.scala:155)\r\n\tat com.uber.hoodie.DefaultSource.createRelation(DefaultSource.scala:91)\r\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\r\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\r\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:654)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:225)\r\n\t\r\n\t....\r\n\tat akka.stream.impl.fusing.Map$$anon$10.onPush(Ops.scala:52)\r\n\tat akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:519)\r\n\tat akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:411)\r\n\tat akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:588)\r\n\tat akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(ActorGraphInterpreter.scala:472)\r\n\tat akka.stream.impl.fusing.GraphInterpreterShell.processEvent(ActorGraphInterpreter.scala:563)\r\n\tat akka.stream.impl.fusing.ActorGraphInterpreter.akka$stream$impl$fusing$ActorGraphInterpreter$$processEvent(ActorGraphInterpreter.scala:745)\r\n\tat akka.stream.impl.fusing.ActorGraphInterpreter$$anonfun$receive$1.applyOrElse(ActorGraphInterpreter.scala:760)\r\n\tat akka.actor.Actor$class.aroundReceive(Actor.scala:517)\r\n\tat akka.stream.impl.fusing.ActorGraphInterpreter.aroundReceive(ActorGraphInterpreter.scala:670)\r\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)\r\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:561)\r\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)\r\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:225)\r\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:235)\r\n\tat akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\r\n\tat akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\r\n\tat akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\r\n\tat akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\r\nCaused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.21.0.14:9866,DS-3b46b080-0c8e-4d74-a090-734caebd4a16,DISK]], original=[DatanodeInfoWithStorage[172.21.0.14:9866,DS-3b46b080-0c8e-4d74-a090-734caebd4a16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.\r\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1044)\r\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1107)\r\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1276)\r\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:560)\r\n\r\n```\r\n\r\nAny clue  ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516377266/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516512385","html_url":"https://github.com/apache/hudi/issues/590#issuecomment-516512385","issue_url":"https://api.github.com/repos/apache/hudi/issues/590","id":516512385,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjUxMjM4NQ==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-30T17:18:40Z","updated_at":"2019-07-30T17:18:40Z","author_association":"CONTRIBUTOR","body":"> Can you check if all data nodes are alive in your cluster and you have enough capacity to ingest new data.\r\n> http://namenode:50070/\r\n\r\n@arw357 Could you do the above ? This issue can happen when enough datanodes are not alive to reach the minimum replication factor.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516512385/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516512834","html_url":"https://github.com/apache/hudi/issues/801#issuecomment-516512834","issue_url":"https://api.github.com/repos/apache/hudi/issues/801","id":516512834,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjUxMjgzNA==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-30T17:19:52Z","updated_at":"2019-07-30T17:19:52Z","author_association":"CONTRIBUTOR","body":"There is an effort to upgrade Hudi to using Spark 2.4.x. here is the PR : https://github.com/apache/incubator-hudi/pull/638. You should be able to use 2.4 after this is merged.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516512834/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516522986","html_url":"https://github.com/apache/hudi/issues/789#issuecomment-516522986","issue_url":"https://api.github.com/repos/apache/hudi/issues/789","id":516522986,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjUyMjk4Ng==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-30T17:48:29Z","updated_at":"2019-07-30T17:48:29Z","author_association":"MEMBER","body":"Weird that it is intermittent.  @bhasudha lets meet and take a stab at this sometime.. this also blocks #751  and related efforts , which blocks spark upgrade which blocks timestamp support :) ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516522986/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516612426","html_url":"https://github.com/apache/hudi/pull/799#issuecomment-516612426","issue_url":"https://api.github.com/repos/apache/hudi/issues/799","id":516612426,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjYxMjQyNg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-30T22:00:10Z","updated_at":"2019-07-30T22:00:10Z","author_association":"MEMBER","body":"@bvaradar can you please review this and merge","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516612426/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516652593","html_url":"https://github.com/apache/hudi/pull/809#issuecomment-516652593","issue_url":"https://api.github.com/repos/apache/hudi/issues/809","id":516652593,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjY1MjU5Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T01:08:21Z","updated_at":"2019-07-31T01:08:21Z","author_association":"MEMBER","body":"this is HUDI-180 no? can you please add context into why we are doing and the tradeoffs with the current approach into JIRA or commit message? Commit message also, can you expand into few bullets that describe actual change\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516652593/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516653416","html_url":"https://github.com/apache/hudi/pull/809#issuecomment-516653416","issue_url":"https://api.github.com/repos/apache/hudi/issues/809","id":516653416,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjY1MzQxNg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T01:13:14Z","updated_at":"2019-07-31T01:13:14Z","author_association":"MEMBER","body":"@n3nash also, can you comment on what dependencies we can shed if we simply supported the one mode - talking to metastore.. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516653416/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516717346","html_url":"https://github.com/apache/hudi/issues/590#issuecomment-516717346","issue_url":"https://api.github.com/repos/apache/hudi/issues/590","id":516717346,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjcxNzM0Ng==","user":{"login":"arw357","id":8440059,"node_id":"MDQ6VXNlcjg0NDAwNTk=","avatar_url":"https://avatars.githubusercontent.com/u/8440059?v=4","gravatar_id":"","url":"https://api.github.com/users/arw357","html_url":"https://github.com/arw357","followers_url":"https://api.github.com/users/arw357/followers","following_url":"https://api.github.com/users/arw357/following{/other_user}","gists_url":"https://api.github.com/users/arw357/gists{/gist_id}","starred_url":"https://api.github.com/users/arw357/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arw357/subscriptions","organizations_url":"https://api.github.com/users/arw357/orgs","repos_url":"https://api.github.com/users/arw357/repos","events_url":"https://api.github.com/users/arw357/events{/privacy}","received_events_url":"https://api.github.com/users/arw357/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T06:34:07Z","updated_at":"2019-07-31T06:34:07Z","author_association":"NONE","body":"Hey @n3nash  , the datanode (only one) is alive and kicking, I can use it for other ingestions with no issue.\r\n\r\n````\r\nConfigured Capacity:\t749.96 GB\r\nConfigured Remote Capacity:\t0 B\r\nDFS Used:\t748.36 MB (0.1%)\r\nNon DFS Used:\t105.37 GB\r\nDFS Remaining:\t605.7 GB (80.76%)\r\nBlock Pool Used:\t748.36 MB (0.1%)\r\nDataNodes usages% (Min/Median/Max/stdDev):\t0.10% / 0.10% / 0.10% / 0.00%\r\nLive Nodes\t1 (Decommissioned: 0, In Maintenance: 0)\r\nDead Nodes\t0 (Decommissioned: 0, In Maintenance: 0)\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516717346/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516719772","html_url":"https://github.com/apache/hudi/issues/774#issuecomment-516719772","issue_url":"https://api.github.com/repos/apache/hudi/issues/774","id":516719772,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjcxOTc3Mg==","user":{"login":"cdmikechen","id":12069428,"node_id":"MDQ6VXNlcjEyMDY5NDI4","avatar_url":"https://avatars.githubusercontent.com/u/12069428?v=4","gravatar_id":"","url":"https://api.github.com/users/cdmikechen","html_url":"https://github.com/cdmikechen","followers_url":"https://api.github.com/users/cdmikechen/followers","following_url":"https://api.github.com/users/cdmikechen/following{/other_user}","gists_url":"https://api.github.com/users/cdmikechen/gists{/gist_id}","starred_url":"https://api.github.com/users/cdmikechen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cdmikechen/subscriptions","organizations_url":"https://api.github.com/users/cdmikechen/orgs","repos_url":"https://api.github.com/users/cdmikechen/repos","events_url":"https://api.github.com/users/cdmikechen/events{/privacy}","received_events_url":"https://api.github.com/users/cdmikechen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T06:43:26Z","updated_at":"2019-07-31T06:43:42Z","author_association":"CONTRIBUTOR","body":"@vinothchandar  I think we should try to use Spark's basic functions as the standard. It means we use spark-hive libs when building, but exclude it when packaging.\r\nI think if we need spark to connect hive to syn some table, we will use `Sparksession.enableHiveSupport()`. It will let spark open a hive connection client itself. we can use it, so that we don't need to import `hoodie-hive` in spark. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516719772/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516722052","html_url":"https://github.com/apache/hudi/issues/774#issuecomment-516722052","issue_url":"https://api.github.com/repos/apache/hudi/issues/774","id":516722052,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjcyMjA1Mg==","user":{"login":"cdmikechen","id":12069428,"node_id":"MDQ6VXNlcjEyMDY5NDI4","avatar_url":"https://avatars.githubusercontent.com/u/12069428?v=4","gravatar_id":"","url":"https://api.github.com/users/cdmikechen","html_url":"https://github.com/cdmikechen","followers_url":"https://api.github.com/users/cdmikechen/followers","following_url":"https://api.github.com/users/cdmikechen/following{/other_user}","gists_url":"https://api.github.com/users/cdmikechen/gists{/gist_id}","starred_url":"https://api.github.com/users/cdmikechen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cdmikechen/subscriptions","organizations_url":"https://api.github.com/users/cdmikechen/orgs","repos_url":"https://api.github.com/users/cdmikechen/repos","events_url":"https://api.github.com/users/cdmikechen/events{/privacy}","received_events_url":"https://api.github.com/users/cdmikechen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T06:52:10Z","updated_at":"2019-07-31T06:52:10Z","author_association":"CONTRIBUTOR","body":"Another things. I found that Hive2 use log4j2 and spark use log4j. If I commit a spark task like\r\n```bash\r\nspark-submit --class xxxxxx.Main --jars xxx.jar,hoodie-spark-bundle-0.4.8-SNAPSHOT.jar  xxx/sparkserver.jar\r\n```\r\nIt will report error:\r\n```log\r\nERROR StatusLogger Unrecognized format specifier [d]\r\nERROR StatusLogger Unrecognized conversion specifier [d] starting at position 16 in conversion pattern.\r\nERROR StatusLogger Unrecognized format specifier [thread]\r\nERROR StatusLogger Unrecognized conversion specifier [thread] starting at position 25 in conversion pattern.\r\nERROR StatusLogger Unrecognized format specifier [level]\r\nERROR StatusLogger Unrecognized conversion specifier [level] starting at position 35 in conversion pattern.\r\nERROR StatusLogger Unrecognized format specifier [logger]\r\nERROR StatusLogger Unrecognized conversion specifier [logger] starting at position 47 in conversion pattern.\r\nERROR StatusLogger Unrecognized format specifier [msg]\r\nERROR StatusLogger Unrecognized conversion specifier [msg] starting at position 54 in conversion pattern.\r\nERROR StatusLogger Unrecognized format specifier [n]\r\nERROR StatusLogger Unrecognized conversion specifier [n] starting at position 56 in conversion pattern.\r\nException in thread \"main\" java.lang.AbstractMethodError: org.apache.logging.log4j.core.config.ConfigurationFactory.getConfiguration(Lorg/apache/logging/log4j/core/config/ConfigurationSource;)Lorg/apache/logging/log4j/core/config/Configuration;\r\n        at org.apache.logging.log4j.core.config.ConfigurationFactory$Factory.getConfiguration(ConfigurationFactory.java:509)\r\n        at org.apache.logging.log4j.core.config.ConfigurationFactory$Factory.getConfiguration(ConfigurationFactory.java:449)\r\n...\r\n...\r\n```\r\nSo that I need to remove some hive dependencies in pom like\r\n```xml\r\n    <dependency>\r\n      <groupId>${hive.groupid}</groupId>\r\n      <artifactId>hive-jdbc</artifactId>\r\n      <version>${hive.version}</version>\r\n      <exclusions>\r\n        <exclusion>\r\n          <groupId>org.eclipse.jetty.aggregate</groupId>\r\n          <artifactId>jetty-all</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>org.apache.logging.log4j</groupId>\r\n          <artifactId>log4j-1.2-api</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>org.apache.logging.log4j</groupId>\r\n          <artifactId>log4j-web</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>org.apache.logging.log4j</groupId>\r\n          <artifactId>log4j-slf4j-impl</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>${hive.groupid}</groupId>\r\n          <artifactId>hive-exec</artifactId>\r\n        </exclusion>\r\n      </exclusions>\r\n    </dependency>\r\n```\r\nAfter that spark can work.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516722052/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516753477","html_url":"https://github.com/apache/hudi/issues/714#issuecomment-516753477","issue_url":"https://api.github.com/repos/apache/hudi/issues/714","id":516753477,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjc1MzQ3Nw==","user":{"login":"NetsanetGeb","id":25975892,"node_id":"MDQ6VXNlcjI1OTc1ODky","avatar_url":"https://avatars.githubusercontent.com/u/25975892?v=4","gravatar_id":"","url":"https://api.github.com/users/NetsanetGeb","html_url":"https://github.com/NetsanetGeb","followers_url":"https://api.github.com/users/NetsanetGeb/followers","following_url":"https://api.github.com/users/NetsanetGeb/following{/other_user}","gists_url":"https://api.github.com/users/NetsanetGeb/gists{/gist_id}","starred_url":"https://api.github.com/users/NetsanetGeb/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/NetsanetGeb/subscriptions","organizations_url":"https://api.github.com/users/NetsanetGeb/orgs","repos_url":"https://api.github.com/users/NetsanetGeb/repos","events_url":"https://api.github.com/users/NetsanetGeb/events{/privacy}","received_events_url":"https://api.github.com/users/NetsanetGeb/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T08:34:36Z","updated_at":"2019-07-31T15:25:35Z","author_association":"NONE","body":"After i used hoodie 0.4.6 version, the performance improved and now its taking 4 minutes. \r\n\r\n![per2](https://user-images.githubusercontent.com/25975892/62195353-1c158600-b37c-11e9-905f-0b04213e614f.png)\r\n\r\n I also added a similar code to the countByKey for counting the records in the HoodieDeltaStreamer class and  check why its taking long in the HoodieBloomIndex and it took about 9 seconds.  While the countByKey of the HoodieBloomIndex is still taking 39 seconds.  This change seems to occur  due to parallelism because on the first countByKey it have 22 and on the HoodieBloomIndex its 2 as observed from the Spark UI below.  \r\n\r\n![per1](https://user-images.githubusercontent.com/25975892/62196336-1caf1c00-b37e-11e9-89f1-894387485ec7.png)\r\n\r\nThe effect is clearly seen as we increase the size of the input data from 2 GB to 27 GB. For stage 2, 3, and 4,  it was using the 90 executors as provided and decreases it accordingly. While for stage 5, only 2 executors were running from the start.\r\n![per3](https://user-images.githubusercontent.com/25975892/62214909-3f552b00-b3a6-11e9-92b5-df197378795d.png)\r\n\r\n\r\nHow do we enhance the parallelism of the bloom index since hoodie is calculating the parallelism for bloom index inside without the need to set it as a configuration? \r\nIn general, are there specific ways to enhance the performance of bloom indexing?\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516753477/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516801178","html_url":"https://github.com/apache/hudi/pull/811#issuecomment-516801178","issue_url":"https://api.github.com/repos/apache/hudi/issues/811","id":516801178,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjgwMTE3OA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T10:58:16Z","updated_at":"2019-07-31T10:58:16Z","author_association":"MEMBER","body":"@n3nash I think checkstyle is failing? what Hive version does this correspond to? can we also document that in the class comments","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516801178/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516807719","html_url":"https://github.com/apache/hudi/issues/789#issuecomment-516807719","issue_url":"https://api.github.com/repos/apache/hudi/issues/789","id":516807719,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjgwNzcxOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T11:21:35Z","updated_at":"2019-07-31T11:21:35Z","author_association":"MEMBER","body":"I can reproduce this actually and what I see is that the user columns are removed off the column projection list,before being passed on to AbstractRealtimeRecordReader ? \r\n\r\n```\r\n2019-07-31T10:37:19,108 INFO  [d71b59a8-15fd-4339-a60b-158fa67a3901 HiveServer2-Handler-Pool: Thread-45]: realtime.HoodieRealtimeInputFormat (HoodieRealtimeInputFormat.java:getRecordReader(223)) - Before adding Hoodie columns, Projections :_hoodie_commit_time,volume,ts,symbol,close,open, Ids :0,5,6,7,14,15\r\n2019-07-31T10:37:19,108 INFO  [d71b59a8-15fd-4339-a60b-158fa67a3901 HiveServer2-Handler-Pool: Thread-45]: realtime.HoodieRealtimeInputFormat (HoodieRealtimeInputFormat.java:getRecordReader(235)) - Creating record reader with readCols :_hoodie_commit_time,volume,ts,symbol,close,open,_hoodie_record_key,_hoodie_partition_path, Ids :0,5,6,7,14,15,2,3\r\n2019-07-31T10:37:19,200 INFO  [d71b59a8-15fd-4339-a60b-158fa67a3901 HiveServer2-Handler-Pool: Thread-45]: realtime.AbstractRealtimeRecordReader (AbstractRealtimeRecordReader.java:<init>(97)) - cfg ==> ts,symbol,_hoodie_record_key,_hoodie_commit_time,_hoodie_partition_path\r\n2019-07-31T10:37:19,200 INFO  [d71b59a8-15fd-4339-a60b-158fa67a3901 HiveServer2-Handler-Pool: Thread-45]: realtime.AbstractRealtimeRecordReader (AbstractRealtimeRecordReader.java:<init>(98)) - columnIds ==> 6,7,2,0,3\r\n2019-07-31T10:37:19,200 INFO  [d71b59a8-15fd-4339-a60b-158fa67a3901 HiveServer2-Handler-Pool: Thread-45]: realtime.AbstractRealtimeRecordReader (AbstractRealtimeRecordReader.java:<init>(99)) - partitioningColumns ==> dt\r\n```\r\n\r\nSeems like a regression to me.. is HUDI-151 related? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516807719/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516813828","html_url":"https://github.com/apache/hudi/issues/789#issuecomment-516813828","issue_url":"https://api.github.com/repos/apache/hudi/issues/789","id":516813828,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjgxMzgyOA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T11:44:08Z","updated_at":"2019-07-31T11:44:08Z","author_association":"MEMBER","body":"With disabling of these static variables introduced, I can get the query to work now.. \r\n\r\n```\r\ndiff --git a/hoodie-hadoop-mr/src/main/java/com/uber/hoodie/hadoop/realtime/HoodieRealtimeInputFormat.java b/hoodie-hadoop-mr/src/main/java/com/uber/hoodie/hadoop/realtime/HoodieRealtimeInputFormat.java\r\nindex 14263738..00c36e26 100644\r\n--- a/hoodie-hadoop-mr/src/main/java/com/uber/hoodie/hadoop/realtime/HoodieRealtimeInputFormat.java\r\n+++ b/hoodie-hadoop-mr/src/main/java/com/uber/hoodie/hadoop/realtime/HoodieRealtimeInputFormat.java\r\n@@ -208,11 +208,13 @@ public class HoodieRealtimeInputFormat extends HoodieInputFormat implements Conf\r\n         HOODIE_COMMIT_TIME_COL_POS);\r\n     configuration = addProjectionField(configuration, HoodieRecord.PARTITION_PATH_METADATA_FIELD,\r\n         HOODIE_PARTITION_PATH_COL_POS);\r\n+    /*\r\n     if (!isReadColumnsSet) {\r\n       READ_COLUMN_IDS = configuration.get(ColumnProjectionUtils.READ_COLUMN_IDS_CONF_STR);\r\n       READ_COLUMN_NAMES = configuration.get(ColumnProjectionUtils.READ_COLUMN_NAMES_CONF_STR);\r\n       isReadColumnsSet = true;\r\n     }\r\n+    */\r\n     return configuration;\r\n   }\r\n \r\n@@ -241,8 +243,8 @@ public class HoodieRealtimeInputFormat extends HoodieInputFormat implements Conf\r\n             + split);\r\n \r\n     // Reset the original column ids and names\r\n-    job.set(ColumnProjectionUtils.READ_COLUMN_IDS_CONF_STR, READ_COLUMN_IDS);\r\n-    job.set(ColumnProjectionUtils.READ_COLUMN_NAMES_CONF_STR, READ_COLUMN_NAMES);\r\n+    /*job.set(ColumnProjectionUtils.READ_COLUMN_IDS_CONF_STR, READ_COLUMN_IDS);\r\n+    job.set(ColumnProjectionUtils.READ_COLUMN_NAMES_CONF_STR, READ_COLUMN_NAMES);*/\r\n \r\n     return new HoodieRealtimeRecordReader((HoodieRealtimeFileSplit) split, job,\r\n         super.getRecordReader(split, job, reporter));\r\n```\r\n\r\nthose static variables seem to be fixing for some hive version, while breaking hive 2.x.. I dont recall the reasoning behind it. @n3nash ? But, high level caching these values across queries in a static variables does not make a ton of sense to me.. @bvaradar  as well for input","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516813828/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516820770","html_url":"https://github.com/apache/hudi/issues/789#issuecomment-516820770","issue_url":"https://api.github.com/repos/apache/hudi/issues/789","id":516820770,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjgyMDc3MA==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T12:08:28Z","updated_at":"2019-07-31T12:08:28Z","author_association":"CONTRIBUTOR","body":"Oh this could also be causing the join issue then?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516820770/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516965553","html_url":"https://github.com/apache/hudi/issues/812#issuecomment-516965553","issue_url":"https://api.github.com/repos/apache/hudi/issues/812","id":516965553,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjk2NTU1Mw==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T18:25:54Z","updated_at":"2019-07-31T18:25:54Z","author_association":"CONTRIBUTOR","body":"This looks more like a spark issue. So whenever spark shuffles data, if you choose kryo for serialization, one has to register java objects with kryo under a name, it looks like kryo is unable to find that object under the name and hence throws class not found. Does your application change over time in any way ? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/516965553/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517005269","html_url":"https://github.com/apache/hudi/pull/813#issuecomment-517005269","issue_url":"https://api.github.com/repos/apache/hudi/issues/813","id":517005269,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzAwNTI2OQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T20:21:15Z","updated_at":"2019-07-31T20:21:15Z","author_association":"CONTRIBUTOR","body":"@vinothchandar @n3nash : Checked by running the website locally. Needed for making website checks all green. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517005269/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517022364","html_url":"https://github.com/apache/hudi/pull/815#issuecomment-517022364","issue_url":"https://api.github.com/repos/apache/hudi/issues/815","id":517022364,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzAyMjM2NA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T21:10:21Z","updated_at":"2019-07-31T21:10:21Z","author_association":"CONTRIBUTOR","body":"@vinothchandar @n3nash : Fixed some doc formatting in Writing Data page and updating the website to make Whimsy website check green. \r\n\r\nI see some additional changes replacing 0.0.0.0 with localhost. Have you seen this before. Guess this is due to version change in the tool - bundle.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517022364/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517025307","html_url":"https://github.com/apache/hudi/pull/814#issuecomment-517025307","issue_url":"https://api.github.com/repos/apache/hudi/issues/814","id":517025307,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzAyNTMwNw==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T21:19:33Z","updated_at":"2019-07-31T21:19:33Z","author_association":"CONTRIBUTOR","body":"The code being removed was added to make Hive on Spark work. Due to a bug in Hive, Hive on Spark does not work seamlessly with RT tables. \r\n\r\n> Issue with Hive on Spark (that was fixed by caching some information) :\r\n\r\n\r\nHive on Spark allows for multiple tasks to run in the same executor. Since the executor/JVM' lifetime is longer than 1 task, the job conf variable is shared across different file splits. Due to a bug in hive (find in the comments of HoodieRealtimeInputFormat class), the columnids and columnnames are messed up. The same columnids and names are added multiple times to the same key in job conf. As a workaround this : https://issues.apache.org/jira/browse/HUDI-151 was added. But this leads to some other issues which results in breaking the RT queries.\r\n\r\n> Current issue : \r\n\r\n\r\nIdeally, a single query in Hive either starts a MapReduce job or a Spark job. Once the query finishes, the mapper/reduces or the spark tasks die. As a result, this caching of column_ids and column_names does not carry across different queries. Hence, this works fine in production environments at the moment.\r\nIn the case of the demo, it seems like this cache is somehow kept across different queries.\r\n\r\n> Steps to reproduce the issue : \r\n\r\n\r\n_Execute the following sequence in step 4(a)_ \r\n\r\n`0: jdbc:hive2://hiveserver:10000> select symbol, max(ts) from stock_ticks_mor_rt group by symbol HAVING symbol = 'GOOG';`\r\n\r\nWhen this is done, the COLUMN_NAMES and COLUMN_IDS for this query is cached as follows : \r\n\r\n`\r\nCOLUMN_NAMES ==> ts,symbol,_hoodie_record_key,_hoodie_commit_time,_hoodie_partition_path\r\nCOLUMN_IDS ==> 6,7,2,0,3\r\n`\r\n\r\n_Now run the second query :_ \r\n\r\n`0: jdbc:hive2://hiveserver:10000> select `_hoodie_commit_time`, symbol, ts, volume, open, close from stock_ticks_mor_rt where  symbol = 'GOOG';`\r\n\r\nAt this time, although the projection cols are as follows : \r\n`\r\nProjection Column Names => _hoodie_commit_time,volume,ts,symbol,close,open,_hoodie_record_key,_hoodie_partition_path\r\nProjection Column Ids => 0,5,6,7,14,15,2,3\r\n`\r\ndue to the fact that we cache these values (to fix hive on spark), these values are replaced with the earlier values (see [here](https://github.com/apache/incubator-hudi/blob/master/hoodie-hadoop-mr/src/main/java/com/uber/hoodie/hadoop/realtime/HoodieRealtimeInputFormat.java#L243)) : \r\n`\r\nCOLUMN_NAMES ==> ts,symbol,_hoodie_record_key,_hoodie_commit_time,_hoodie_partition_path\r\nCOLUMN_IDS ==> 6,7,2,0,3\r\n`\r\nNotice that the column names and ids for columns volume, open & close are omitted (since they were not part of the first query and hence the cached values don't have it). Hence these columns are never read/projected and return NULL. \r\n\r\nThis happens intermittently and cannot be reproduced everytime. My suspicion is that it has to do with which datanode the query runs in and if the datanode caches the job conf but I'm not very sure about this.\r\n\r\nIn any case, I'm reverting the change made to have Hive on Spark work. This means Hive on Spark queries will be broken in RT (for some specific types of queries, not all). Since the docker image does not have a way to debug hive on spark queries, I'm figuring out an environment where I can do this (the internal environment that i was using earlier is broken) after which I will find a permanent fix that will not break RT queries and also make hive on spark run.\r\n\r\n@vinothchandar \r\n@bvaradar \r\n@bhasudha \r\nFYI\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517025307/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517026353","html_url":"https://github.com/apache/hudi/pull/814#issuecomment-517026353","issue_url":"https://api.github.com/repos/apache/hudi/issues/814","id":517026353,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzAyNjM1Mw==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T21:22:42Z","updated_at":"2019-07-31T21:22:42Z","author_association":"CONTRIBUTOR","body":"On another note, I debugged the issue with join queries as reported here : https://github.com/apache/incubator-hudi/issues/789 and found weird results (nothing to do with the change in this PR or the hive on spark fix). Essentially, looks like due to some hive join optimizations, only 1 table format gets picked up (either hoodierealtimeinputformat or hoodieinputformat) when joining 2 tables with different table formats. May be some bug on our end, have to dig deeper and will open a different ticket around it. This is just FYI","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517026353/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517042646","html_url":"https://github.com/apache/hudi/pull/815#issuecomment-517042646","issue_url":"https://api.github.com/repos/apache/hudi/issues/815","id":517042646,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzA0MjY0Ng==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T22:14:52Z","updated_at":"2019-07-31T22:14:52Z","author_association":"MEMBER","body":"No. have not seen them.. its auto generated content, so may be it reflects the localhost name or ip (0.0.0.0).. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517042646/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517043325","html_url":"https://github.com/apache/hudi/pull/803#issuecomment-517043325","issue_url":"https://api.github.com/repos/apache/hudi/issues/803","id":517043325,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzA0MzMyNQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-07-31T22:17:29Z","updated_at":"2019-07-31T22:17:29Z","author_association":"MEMBER","body":"have this code and #780 both testing in `pom-bundle-cleanup` branch.. Closing this. Will open a new one when ready. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517043325/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517066426","html_url":"https://github.com/apache/hudi/pull/816#issuecomment-517066426","issue_url":"https://api.github.com/repos/apache/hudi/issues/816","id":517066426,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzA2NjQyNg==","user":{"login":"tweise","id":263695,"node_id":"MDQ6VXNlcjI2MzY5NQ==","avatar_url":"https://avatars.githubusercontent.com/u/263695?v=4","gravatar_id":"","url":"https://api.github.com/users/tweise","html_url":"https://github.com/tweise","followers_url":"https://api.github.com/users/tweise/followers","following_url":"https://api.github.com/users/tweise/following{/other_user}","gists_url":"https://api.github.com/users/tweise/gists{/gist_id}","starred_url":"https://api.github.com/users/tweise/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tweise/subscriptions","organizations_url":"https://api.github.com/users/tweise/orgs","repos_url":"https://api.github.com/users/tweise/repos","events_url":"https://api.github.com/users/tweise/events{/privacy}","received_events_url":"https://api.github.com/users/tweise/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T00:02:50Z","updated_at":"2019-08-01T00:02:50Z","author_association":"NONE","body":"The KEYS file needs to be added to the dist area, not here.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517066426/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517076737","html_url":"https://github.com/apache/hudi/issues/764#issuecomment-517076737","issue_url":"https://api.github.com/repos/apache/hudi/issues/764","id":517076737,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzA3NjczNw==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T01:00:09Z","updated_at":"2019-08-01T01:00:57Z","author_association":"CONTRIBUTOR","body":"It looks like the \"Not an Avro data file\" exception is thrown when there is a 0 byte stream read into the datafilereader as can be seen here : https://github.com/apache/avro/blob/master/lang/java/avro/src/main/java/org/apache/avro/file/DataFileReader.java#L55 and here : https://github.com/apache/avro/blob/master/lang/java/avro/src/main/java/org/apache/avro/file/DataFileConstants.java#L29\r\n\r\nFrom the stack trace (by tracing the line numbers), it looks like the CLEAN file is failing to be archived. I looked at the clean logic and we do create clean files even when we don't have anything to clean but that does not result in a 0 bytes file, it still has some valid avro data. Although we need to fix not creating a clean file when there is nothing to clean, this still doesn't result into the error. I'm wondering if this has anything to do with any sort of race condition leading to archiving running when clean is a 0 sized file.\r\n\r\n@jackwang2 How are you running the cleaner and the archival process ? Are you explicitly doing anything there ?\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517076737/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517089256","html_url":"https://github.com/apache/hudi/issues/764#issuecomment-517089256","issue_url":"https://api.github.com/repos/apache/hudi/issues/764","id":517089256,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzA4OTI1Ng==","user":{"login":"jackwang2","id":26425937,"node_id":"MDQ6VXNlcjI2NDI1OTM3","avatar_url":"https://avatars.githubusercontent.com/u/26425937?v=4","gravatar_id":"","url":"https://api.github.com/users/jackwang2","html_url":"https://github.com/jackwang2","followers_url":"https://api.github.com/users/jackwang2/followers","following_url":"https://api.github.com/users/jackwang2/following{/other_user}","gists_url":"https://api.github.com/users/jackwang2/gists{/gist_id}","starred_url":"https://api.github.com/users/jackwang2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jackwang2/subscriptions","organizations_url":"https://api.github.com/users/jackwang2/orgs","repos_url":"https://api.github.com/users/jackwang2/repos","events_url":"https://api.github.com/users/jackwang2/events{/privacy}","received_events_url":"https://api.github.com/users/jackwang2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T02:07:52Z","updated_at":"2019-08-01T02:07:52Z","author_association":"NONE","body":"@n3nash No, I didn't. The main logic is for just global deduplication, and\ncode is pasted as below:\n\n  df.dropDuplicates(recordKey)\n    .write\n    .format(\"com.uber.hoodie\")\n    .mode(SaveMode.Append)\n    .option(HoodieWriteConfig.TABLE_NAME, tableName)\n    .option(HoodieIndexConfig.INDEX_TYPE_PROP,\nHoodieIndex.IndexType.GLOBAL_BLOOM.name)\n    .option(DataSourceWriteOptions.RECORDKEY_FIELD_OPT_KEY, recordKey)\n    .option(DataSourceWriteOptions.PARTITIONPATH_FIELD_OPT_KEY,\npartitionCol)\n    .option(DataSourceWriteOptions.OPERATION_OPT_KEY,\nDataSourceWriteOptions.INSERT_OPERATION_OPT_VAL)\n    .option(DataSourceWriteOptions.STORAGE_TYPE_OPT_KEY, storageType)\n    .option(DataSourceWriteOptions.PRECOMBINE_FIELD_OPT_KEY, preCombineCol)\n    .option(\"hoodie.consistency.check.enabled\", \"true\")\n    .option(\"hoodie.parquet.small.file.limit\", 1024 * 1024 * 128)\n    .save(tgtFilePath)\n\nThanks,\nJack\n\nOn Thu, Aug 1, 2019 at 9:01 AM n3nash <notifications@github.com> wrote:\n\n> It looks like the \"Not an Avro data file\" exception is thrown when there\n> is a 0 byte stream read into the datafilereader as can be seen here :\n> https://github.com/apache/avro/blob/master/lang/java/avro/src/main/java/org/apache/avro/file/DataFileReader.java#L55\n> and here :\n> https://github.com/apache/avro/blob/master/lang/java/avro/src/main/java/org/apache/avro/file/DataFileConstants.java#L29\n>\n> From the stack trace (by tracing the line numbers), it looks like the\n> CLEAN file is failing to be archived. I looked at the clean logic and we do\n> create clean files even when we don't have anything to clean but that does\n> not result in a 0 bytes file, it still has some valid avro data. I'm\n> wondering if this has anything to do with any sort of race condition\n> leading to archiving running when clean is a 0 sized file.\n>\n> @jackwang2 <https://github.com/jackwang2> How are you running the cleaner\n> and the archival process ? Are you explicitly doing anything there ?\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/incubator-hudi/issues/764?email_source=notifications&email_token=AGJTUUM7FLWXHG52WO2DEUTQCIYW5A5CNFSM4H3Z6GB2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3I7OAI#issuecomment-517076737>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AGJTUULNELHUUHGR5OAMMBDQCIYW5ANCNFSM4H3Z6GBQ>\n> .\n>\n\n\n-- \n[image: vshapesaqua11553186012.gif] <https://vungle.com/>   *Jianbin Wang*\nSr. Engineer II, Data\n+86 18633600964\n\n[image: in1552694272.png] <https://www.linkedin.com/company/vungle>    [image:\nfb1552694203.png] <https://facebook.com/vungle>      [image:\ntw1552694330.png] <https://twitter.com/vungle>      [image:\nig1552694392.png] <https://www.instagram.com/vungle>\nUnits 3801, 3804, 38F, C Block, Beijing Yintai Center, Beijing, China\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517089256/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517123554","html_url":"https://github.com/apache/hudi/issues/801#issuecomment-517123554","issue_url":"https://api.github.com/repos/apache/hudi/issues/801","id":517123554,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzEyMzU1NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T05:19:50Z","updated_at":"2019-08-01T05:19:50Z","author_association":"MEMBER","body":"Closing. Reopen new issues on JIRA or mailing list as needed","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517123554/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517123657","html_url":"https://github.com/apache/hudi/issues/800#issuecomment-517123657","issue_url":"https://api.github.com/repos/apache/hudi/issues/800","id":517123657,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzEyMzY1Nw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T05:20:21Z","updated_at":"2019-08-01T05:20:21Z","author_association":"MEMBER","body":"hi.. any updates? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517123657/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517123959","html_url":"https://github.com/apache/hudi/issues/796#issuecomment-517123959","issue_url":"https://api.github.com/repos/apache/hudi/issues/796","id":517123959,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzEyMzk1OQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T05:21:44Z","updated_at":"2019-08-01T05:21:44Z","author_association":"MEMBER","body":"@anchalkataria we have some leads on the null issue. we expect it to be fixed on master soon.. \r\n\r\non your original registration issue, I actually was able to register through delta streamer in the demo setup on master branch... Would you be able to give it a shot? I can give you commands.. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517123959/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517124229","html_url":"https://github.com/apache/hudi/issues/796#issuecomment-517124229","issue_url":"https://api.github.com/repos/apache/hudi/issues/796","id":517124229,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzEyNDIyOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T05:22:51Z","updated_at":"2019-08-01T05:22:51Z","author_association":"MEMBER","body":"@n3nash can you paste the error you got hive syncing on the apache hive 2.x servers if any? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517124229/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517124343","html_url":"https://github.com/apache/hudi/issues/789#issuecomment-517124343","issue_url":"https://api.github.com/repos/apache/hudi/issues/789","id":517124343,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzEyNDM0Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T05:23:28Z","updated_at":"2019-08-01T05:23:28Z","author_association":"MEMBER","body":"@n3nash is debugging the join issue, which seems different? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517124343/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517124662","html_url":"https://github.com/apache/hudi/issues/774#issuecomment-517124662","issue_url":"https://api.github.com/repos/apache/hudi/issues/774","id":517124662,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzEyNDY2Mg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T05:25:01Z","updated_at":"2019-08-01T05:25:01Z","author_association":"MEMBER","body":"@cdmikechen can we have a call or can you write up how we can take a fresh look at the hive sync aspects? It definitely works in certain versions, but runs into snags like this with certain versions.. Its a pretty hairy issue IMO ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517124662/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517125538","html_url":"https://github.com/apache/hudi/issues/714#issuecomment-517125538","issue_url":"https://api.github.com/repos/apache/hudi/issues/714","id":517125538,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzEyNTUzOA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T05:28:49Z","updated_at":"2019-08-01T05:28:49Z","author_association":"MEMBER","body":"@NetsanetGeb 2 comes from the configs you are setting? \r\nhoodie.upsert.shuffle.parallellism & hoodie.insert.shuffle.parallellism? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517125538/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517127576","html_url":"https://github.com/apache/hudi/issues/796#issuecomment-517127576","issue_url":"https://api.github.com/repos/apache/hudi/issues/796","id":517127576,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzEyNzU3Ng==","user":{"login":"anchalkataria","id":9292326,"node_id":"MDQ6VXNlcjkyOTIzMjY=","avatar_url":"https://avatars.githubusercontent.com/u/9292326?v=4","gravatar_id":"","url":"https://api.github.com/users/anchalkataria","html_url":"https://github.com/anchalkataria","followers_url":"https://api.github.com/users/anchalkataria/followers","following_url":"https://api.github.com/users/anchalkataria/following{/other_user}","gists_url":"https://api.github.com/users/anchalkataria/gists{/gist_id}","starred_url":"https://api.github.com/users/anchalkataria/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/anchalkataria/subscriptions","organizations_url":"https://api.github.com/users/anchalkataria/orgs","repos_url":"https://api.github.com/users/anchalkataria/repos","events_url":"https://api.github.com/users/anchalkataria/events{/privacy}","received_events_url":"https://api.github.com/users/anchalkataria/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T05:38:24Z","updated_at":"2019-08-01T05:38:24Z","author_association":"NONE","body":"> @anchalkataria we have some leads on the null issue. we expect it to be fixed on master soon..\r\n> \r\n> on your original registration issue, I actually was able to register through delta streamer in the demo setup on master branch... Would you be able to give it a shot? I can give you commands..\r\n\r\n@vinothchandar So now I am not trying this on local anymore . I am directly running the tool on AWS Emr cluster and able to sync data in hive through DeltaStreamer.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517127576/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517150981","html_url":"https://github.com/apache/hudi/issues/812#issuecomment-517150981","issue_url":"https://api.github.com/repos/apache/hudi/issues/812","id":517150981,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzE1MDk4MQ==","user":{"login":"arw357","id":8440059,"node_id":"MDQ6VXNlcjg0NDAwNTk=","avatar_url":"https://avatars.githubusercontent.com/u/8440059?v=4","gravatar_id":"","url":"https://api.github.com/users/arw357","html_url":"https://github.com/arw357","followers_url":"https://api.github.com/users/arw357/followers","following_url":"https://api.github.com/users/arw357/following{/other_user}","gists_url":"https://api.github.com/users/arw357/gists{/gist_id}","starred_url":"https://api.github.com/users/arw357/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arw357/subscriptions","organizations_url":"https://api.github.com/users/arw357/orgs","repos_url":"https://api.github.com/users/arw357/repos","events_url":"https://api.github.com/users/arw357/events{/privacy}","received_events_url":"https://api.github.com/users/arw357/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T07:07:55Z","updated_at":"2019-08-01T07:07:55Z","author_association":"NONE","body":"Nothing - it's a simplu upsert over a cow - I do it in a loop -","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517150981/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517345661","html_url":"https://github.com/apache/hudi/pull/818#issuecomment-517345661","issue_url":"https://api.github.com/repos/apache/hudi/issues/818","id":517345661,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzM0NTY2MQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T15:49:16Z","updated_at":"2019-08-01T15:49:16Z","author_association":"MEMBER","body":"yikes.. @bhasudha FYI .. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517345661/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517346302","html_url":"https://github.com/apache/hudi/pull/818#issuecomment-517346302","issue_url":"https://api.github.com/repos/apache/hudi/issues/818","id":517346302,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzM0NjMwMg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T15:50:52Z","updated_at":"2019-08-01T15:50:52Z","author_association":"MEMBER","body":"Thanks for catching this @luke-zhu . Other bundles dont have this issue.. This could explain some jackson errors hit by few users on presto ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517346302/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517347293","html_url":"https://github.com/apache/hudi/pull/818#issuecomment-517347293","issue_url":"https://api.github.com/repos/apache/hudi/issues/818","id":517347293,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzM0NzI5Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T15:53:15Z","updated_at":"2019-08-01T15:53:15Z","author_association":"MEMBER","body":"with jackson being excluded, the import should now be fine? can you build the bundle off master and see if it works? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517347293/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517350066","html_url":"https://github.com/apache/hudi/issues/812#issuecomment-517350066","issue_url":"https://api.github.com/repos/apache/hudi/issues/812","id":517350066,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzM1MDA2Ng==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T15:59:39Z","updated_at":"2019-08-01T15:59:39Z","author_association":"MEMBER","body":"trace shows that it happens during cleaning.. So increasing the limit, you are just kicking the can down the road.. you ll eventually hit it.. Default `  private static final String DEFAULT_CLEANER_COMMITS_RETAINED = \"10\";` is 10, so you are probably hitting it on first cleaning.. \r\n\r\nthe error itself is weird.. Why is it trying to match this string as a class? @n3nash this data is avro right?  is kryo trying to deserialize it? \r\n\r\n\r\n```\r\ncom.esotericsoftware.kryo.KryoException: Unable to find class: hdfs://namenode:8020/test/20190731-091411-373/1564557251826_551/converted/A/4/2c5790b6-eb12-4c15-a84a-f287d9cd9984_1_20190731091435.parquet����A/4\r\n```\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517350066/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517350517","html_url":"https://github.com/apache/hudi/issues/796#issuecomment-517350517","issue_url":"https://api.github.com/repos/apache/hudi/issues/796","id":517350517,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzM1MDUxNw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T16:00:47Z","updated_at":"2019-08-01T16:00:47Z","author_association":"MEMBER","body":"@anchalkataria thats great to hear.. Do you mind sharing your spark, hive and hadoop versions? \r\n\r\nWe are actively trying to ease the jar pain .. It 'd be helpful to know few combinations that work well ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517350517/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517353773","html_url":"https://github.com/apache/hudi/pull/814#issuecomment-517353773","issue_url":"https://api.github.com/repos/apache/hudi/issues/814","id":517353773,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzM1Mzc3Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T16:08:28Z","updated_at":"2019-08-01T16:08:28Z","author_association":"MEMBER","body":"@n3nash can you please attach a JIRA for this issue.. and link the PR and we can move the conversation there..  ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517353773/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517354304","html_url":"https://github.com/apache/hudi/pull/814#issuecomment-517354304","issue_url":"https://api.github.com/repos/apache/hudi/issues/814","id":517354304,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzM1NDMwNA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T16:09:52Z","updated_at":"2019-08-01T16:09:52Z","author_association":"MEMBER","body":">>Once the query finishes, the mapper/reduces or the spark tasks die. As a result, this caching of column_ids and column_names does not carry across different queries.\r\n\r\nI m bit confused.. how does this not hit the earlier issue you cited with multiple tasks running on the same executor? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517354304/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517411074","html_url":"https://github.com/apache/hudi/pull/802#issuecomment-517411074","issue_url":"https://api.github.com/repos/apache/hudi/issues/802","id":517411074,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzQxMTA3NA==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T18:45:51Z","updated_at":"2019-08-01T18:45:51Z","author_association":"CONTRIBUTOR","body":"@v3nkatesh left some more comments","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517411074/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517420101","html_url":"https://github.com/apache/hudi/issues/800#issuecomment-517420101","issue_url":"https://api.github.com/repos/apache/hudi/issues/800","id":517420101,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzQyMDEwMQ==","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-01T19:12:58Z","updated_at":"2019-08-01T19:12:58Z","author_association":"MEMBER","body":"Hi, sorry been a little busy this week. I will write a summary once I get enough information. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517420101/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517682090","html_url":"https://github.com/apache/hudi/pull/822#issuecomment-517682090","issue_url":"https://api.github.com/repos/apache/hudi/issues/822","id":517682090,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzY4MjA5MA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T12:31:02Z","updated_at":"2019-08-02T12:31:02Z","author_association":"MEMBER","body":"LGTM. you can merge once CI passes","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517682090/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517757553","html_url":"https://github.com/apache/hudi/pull/816#issuecomment-517757553","issue_url":"https://api.github.com/repos/apache/hudi/issues/816","id":517757553,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzc1NzU1Mw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T16:07:33Z","updated_at":"2019-08-02T16:07:33Z","author_association":"CONTRIBUTOR","body":"No longer needed.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517757553/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517783249","html_url":"https://github.com/apache/hudi/pull/825#issuecomment-517783249","issue_url":"https://api.github.com/repos/apache/hudi/issues/825","id":517783249,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzc4MzI0OQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T17:28:12Z","updated_at":"2019-08-02T17:28:12Z","author_association":"CONTRIBUTOR","body":"@vinothchandar @n3nash : Forgot to mention that ITTestHoodieDemo (demo automation ) passes with this change. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517783249/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517793064","html_url":"https://github.com/apache/hudi/pull/825#issuecomment-517793064","issue_url":"https://api.github.com/repos/apache/hudi/issues/825","id":517793064,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzc5MzA2NA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T18:00:06Z","updated_at":"2019-08-02T18:00:06Z","author_association":"CONTRIBUTOR","body":"@vinothchandar @n3nash : looks like some unit test failure. Please hold on to this review","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517793064/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517796993","html_url":"https://github.com/apache/hudi/pull/814#issuecomment-517796993","issue_url":"https://api.github.com/repos/apache/hudi/issues/814","id":517796993,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzc5Njk5Mw==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T18:13:09Z","updated_at":"2019-08-02T18:13:09Z","author_association":"CONTRIBUTOR","body":"@vinothchandar Not sure about your confusion. Basically, I've reverted the change that I had made to enable realtime to work on Hive on Spark. So after this change, the code is back to where it was and does NOT work for hive on spark. This is to fix the regression issue while I find the actual root cause and solution. Let me know if it's still unclear.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517796993/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517800177","html_url":"https://github.com/apache/hudi/pull/814#issuecomment-517800177","issue_url":"https://api.github.com/repos/apache/hudi/issues/814","id":517800177,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzgwMDE3Nw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T18:24:21Z","updated_at":"2019-08-02T18:24:21Z","author_association":"MEMBER","body":">how does this not hit the earlier issue you cited with multiple tasks running on the same executor?\r\n\r\nIn other words, is hive-on-spark on RT view now broken after this patch? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517800177/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517818408","html_url":"https://github.com/apache/hudi/pull/802#issuecomment-517818408","issue_url":"https://api.github.com/repos/apache/hudi/issues/802","id":517818408,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzgxODQwOA==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T19:29:27Z","updated_at":"2019-08-02T19:29:27Z","author_association":"CONTRIBUTOR","body":"Merging this PR understanding that close() isn't the best method for an index but we couldn't find another workaround/solution to release hbase index resources earlier than the JVM shutdown but also making sure that rdd retries don't result in overwhelming the hbase. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517818408/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517819134","html_url":"https://github.com/apache/hudi/pull/814#issuecomment-517819134","issue_url":"https://api.github.com/repos/apache/hudi/issues/814","id":517819134,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzgxOTEzNA==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T19:32:02Z","updated_at":"2019-08-02T19:32:02Z","author_association":"CONTRIBUTOR","body":"Yes, hive on spark is back to being broken (as it was before we made these changes)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517819134/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517820193","html_url":"https://github.com/apache/hudi/pull/811#issuecomment-517820193","issue_url":"https://api.github.com/repos/apache/hudi/issues/811","id":517820193,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzgyMDE5Mw==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T19:35:46Z","updated_at":"2019-08-02T19:35:46Z","author_association":"CONTRIBUTOR","body":"@bvaradar @vinothchandar Fixed checkstyle and added comment about hive version","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517820193/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517820333","html_url":"https://github.com/apache/hudi/pull/809#issuecomment-517820333","issue_url":"https://api.github.com/repos/apache/hudi/issues/809","id":517820333,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzgyMDMzMw==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T19:36:17Z","updated_at":"2019-08-02T19:36:17Z","author_association":"CONTRIBUTOR","body":"@vinothchandar @bvaradar fixed checkstyle and added comments. Look at the jira for more detailed information.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517820333/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517828653","html_url":"https://github.com/apache/hudi/pull/802#issuecomment-517828653","issue_url":"https://api.github.com/repos/apache/hudi/issues/802","id":517828653,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNzgyODY1Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2019-08-02T20:06:39Z","updated_at":"2019-08-02T20:06:39Z","author_association":"MEMBER","body":"@v3nkatesh can you please create a JIRA as well and link this PR there.. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/517828653/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]