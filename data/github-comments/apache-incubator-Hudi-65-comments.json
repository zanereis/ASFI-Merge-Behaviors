[{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647792654","html_url":"https://github.com/apache/hudi/pull/1753#issuecomment-647792654","issue_url":"https://api.github.com/repos/apache/hudi/issues/1753","id":647792654,"node_id":"MDEyOklzc3VlQ29tbWVudDY0Nzc5MjY1NA==","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T22:05:38Z","updated_at":"2020-06-22T22:06:12Z","author_association":"MEMBER","body":"> > Merging #1753 into master will increase coverage by 42.55%.\r\n> \r\n> this does seem problematic?\r\n\r\n@vinothchandar I think the coverage dropped to ~18% at some point in the past by some commit. You can see the trend here. https://codecov.io/gh/apache/hudi \r\nNot sure what caused that drop..this codecov change also brings back to the normal coverage level.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647792654/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647798545","html_url":"https://github.com/apache/hudi/pull/1433#issuecomment-647798545","issue_url":"https://api.github.com/repos/apache/hudi/issues/1433","id":647798545,"node_id":"MDEyOklzc3VlQ29tbWVudDY0Nzc5ODU0NQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T22:21:52Z","updated_at":"2020-06-22T22:21:52Z","author_association":"MEMBER","body":"cc @wangxianghu .. \r\n\r\n@pratyakshsharma confirmed, he will resume this wiork and take it across finish line^P^P ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647798545/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647798688","html_url":"https://github.com/apache/hudi/pull/1753#issuecomment-647798688","issue_url":"https://api.github.com/repos/apache/hudi/issues/1753","id":647798688,"node_id":"MDEyOklzc3VlQ29tbWVudDY0Nzc5ODY4OA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T22:22:14Z","updated_at":"2020-06-22T22:22:14Z","author_association":"MEMBER","body":"is that the record size estimation commit, from gary? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647798688/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647799639","html_url":"https://github.com/apache/hudi/issues/1694#issuecomment-647799639","issue_url":"https://api.github.com/repos/apache/hudi/issues/1694","id":647799639,"node_id":"MDEyOklzc3VlQ29tbWVudDY0Nzc5OTYzOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T22:24:52Z","updated_at":"2020-06-22T22:24:52Z","author_association":"MEMBER","body":"@Raghvendradubey thanks for the info.. you may also want to understand how much of the existing data changes every minute.. if its 70% updates, I would suggest using MOR as it can absorb updates more quickly..  \r\n\r\nLet's target a lenient 5 min Spark streaming batch interval, see how the commit durations look like and go from there?\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647799639/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647800356","html_url":"https://github.com/apache/hudi/pull/1739#issuecomment-647800356","issue_url":"https://api.github.com/repos/apache/hudi/issues/1739","id":647800356,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NzgwMDM1Ng==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T22:27:03Z","updated_at":"2020-06-22T22:27:03Z","author_association":"MEMBER","body":"@n3nash can you take a quick second pass here? and we can merge?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647800356/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647802515","html_url":"https://github.com/apache/hudi/pull/1753#issuecomment-647802515","issue_url":"https://api.github.com/repos/apache/hudi/issues/1753","id":647802515,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NzgwMjUxNQ==","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T22:33:48Z","updated_at":"2020-06-22T22:33:48Z","author_association":"MEMBER","body":"> is that the record size estimation commit, from gary?\r\n\r\nIt seems so, but I don't think that change itself affected the coverage. it's more likely codecov itself reported erroneously.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647802515/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647803654","html_url":"https://github.com/apache/hudi/pull/1753#issuecomment-647803654","issue_url":"https://api.github.com/repos/apache/hudi/issues/1753","id":647803654,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NzgwMzY1NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T22:37:16Z","updated_at":"2020-06-22T22:37:16Z","author_association":"MEMBER","body":"I know.. that PR cannot be affecting this.. \r\n\r\nlets wait for @ramachandranms to chime in :) I am fine with the approach you have taken","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647803654/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647805153","html_url":"https://github.com/apache/hudi/issues/1751#issuecomment-647805153","issue_url":"https://api.github.com/repos/apache/hudi/issues/1751","id":647805153,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NzgwNTE1Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T22:42:20Z","updated_at":"2020-06-22T22:42:20Z","author_association":"MEMBER","body":"lets wait for @lyogev to chime in.. I think @n3nash did explicitly test Spark 3 and confirmed it working as of 0.5.1/0.5.2 ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647805153/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647808188","html_url":"https://github.com/apache/hudi/pull/1687#issuecomment-647808188","issue_url":"https://api.github.com/repos/apache/hudi/issues/1687","id":647808188,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NzgwODE4OA==","user":{"login":"prashantwason","id":58448203,"node_id":"MDQ6VXNlcjU4NDQ4MjAz","avatar_url":"https://avatars.githubusercontent.com/u/58448203?v=4","gravatar_id":"","url":"https://api.github.com/users/prashantwason","html_url":"https://github.com/prashantwason","followers_url":"https://api.github.com/users/prashantwason/followers","following_url":"https://api.github.com/users/prashantwason/following{/other_user}","gists_url":"https://api.github.com/users/prashantwason/gists{/gist_id}","starred_url":"https://api.github.com/users/prashantwason/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashantwason/subscriptions","organizations_url":"https://api.github.com/users/prashantwason/orgs","repos_url":"https://api.github.com/users/prashantwason/repos","events_url":"https://api.github.com/users/prashantwason/events{/privacy}","received_events_url":"https://api.github.com/users/prashantwason/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T22:52:43Z","updated_at":"2020-06-22T22:52:43Z","author_association":"MEMBER","body":"@bvaradar @nsivabalan \r\nI had reduced the scope of this PR to only the storage abstractions needed to support another base/log file format. The rest of my change will be part of future PRs. I have also addressed all the previous review comments. \r\n\r\nPlease take a look.\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647808188/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647825299","html_url":"https://github.com/apache/hudi/pull/1721#issuecomment-647825299","issue_url":"https://api.github.com/repos/apache/hudi/issues/1721","id":647825299,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NzgyNTI5OQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T23:50:06Z","updated_at":"2020-06-22T23:50:06Z","author_association":"MEMBER","body":"Can you please include the jira number in the pr title ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647825299/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647825579","html_url":"https://github.com/apache/hudi/pull/1712#issuecomment-647825579","issue_url":"https://api.github.com/repos/apache/hudi/issues/1712","id":647825579,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NzgyNTU3OQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-22T23:51:08Z","updated_at":"2020-06-22T23:51:08Z","author_association":"MEMBER","body":"IS this still relevant? Closing. Please reopen if needed","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647825579/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647912047","html_url":"https://github.com/apache/hudi/issues/1675#issuecomment-647912047","issue_url":"https://api.github.com/repos/apache/hudi/issues/1675","id":647912047,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NzkxMjA0Nw==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T05:12:35Z","updated_at":"2020-06-23T05:12:35Z","author_association":"CONTRIBUTOR","body":"@abhibhat98  were you able to progress on this ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647912047/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647932695","html_url":"https://github.com/apache/hudi/issues/588#issuecomment-647932695","issue_url":"https://api.github.com/repos/apache/hudi/issues/588","id":647932695,"node_id":"MDEyOklzc3VlQ29tbWVudDY0NzkzMjY5NQ==","user":{"login":"luffyd","id":2287345,"node_id":"MDQ6VXNlcjIyODczNDU=","avatar_url":"https://avatars.githubusercontent.com/u/2287345?v=4","gravatar_id":"","url":"https://api.github.com/users/luffyd","html_url":"https://github.com/luffyd","followers_url":"https://api.github.com/users/luffyd/followers","following_url":"https://api.github.com/users/luffyd/following{/other_user}","gists_url":"https://api.github.com/users/luffyd/gists{/gist_id}","starred_url":"https://api.github.com/users/luffyd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/luffyd/subscriptions","organizations_url":"https://api.github.com/users/luffyd/orgs","repos_url":"https://api.github.com/users/luffyd/repos","events_url":"https://api.github.com/users/luffyd/events{/privacy}","received_events_url":"https://api.github.com/users/luffyd/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T06:15:54Z","updated_at":"2020-06-23T06:15:54Z","author_association":"NONE","body":"> BUG:Transient no such file or directory\r\n> \r\n> ```\r\n> scala>     splits.zipWithIndex.foreach{case (x,i)=>{\r\n>      |       println(s\"adding split $i\")\r\n>      | \r\n>      |       val path = s\"hdfs:///tmp/ap-invoices-all-snapshot-slice-stg/\"\r\n>      | \r\n>      |       x.write.mode(\"overwrite\").parquet(path)//stage the subset\r\n>      | \r\n>      |       new HorizonCompactionUtil().saveToHudiTable(\r\n>      |         spark.read.parquet(path),\r\n>      |         tableName = \"ap_invoices_all_hudi\",\r\n>      |         tablePath = \"s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/\",\r\n>      |         primaryKey = \"invoice_id\",\r\n>      |         pkOrderingCol = \"capture_timestamp\",\r\n>      |         enableHiveSync = false,\r\n>      |         partitionCol = None,\r\n>      |         insertMode = \"append\",\r\n>      |         parallelism = 5000,\r\n>      |         fakePartitionCol = false\r\n>      |       )\r\n>      |     }}\r\n> adding split 0\r\n> 19/02/27 22:33:11 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.\r\n> 19/02/27 22:33:11 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.\r\n> [Stage 34:===========================>                        (138 + 124) / 262]19/02/27 22:39:35 WARN TaskSetManager: Lost task 103.0 in stage 34.0 (TID 38146, ip-172-31-25-39.ec2.internal, executor 2674): java.lang.RuntimeException: com.uber.hoodie.exception.HoodieException: com.uber.hoodie.exception.HoodieException: java.util.concurrent.ExecutionException: com.uber.hoodie.exception.HoodieInsertException: Failed to close the Insert Handle for path s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet\r\n>         at com.uber.hoodie.func.LazyIterableIterator.next(LazyIterableIterator.java:121)\r\n>         at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)\r\n>         at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\r\n>         at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\r\n>         at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:220)\r\n>         at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:348)\r\n>         at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n>         at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n>         at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n>         at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n>         at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n>         at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n>         at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n>         at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n>         at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n>         at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n>         at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n>         at org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n>         at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\r\n>         at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n>         at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\r\n>         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n>         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n>         at java.lang.Thread.run(Thread.java:748)\r\n> Caused by: com.uber.hoodie.exception.HoodieException: com.uber.hoodie.exception.HoodieException: java.util.concurrent.ExecutionException: com.uber.hoodie.exception.HoodieInsertException: Failed to close the Insert Handle for path s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet\r\n>         at com.uber.hoodie.func.CopyOnWriteLazyInsertIterable.computeNext(CopyOnWriteLazyInsertIterable.java:106)\r\n>         at com.uber.hoodie.func.CopyOnWriteLazyInsertIterable.computeNext(CopyOnWriteLazyInsertIterable.java:45)\r\n>         at com.uber.hoodie.func.LazyIterableIterator.next(LazyIterableIterator.java:119)\r\n>         ... 23 more\r\n> Caused by: com.uber.hoodie.exception.HoodieException: java.util.concurrent.ExecutionException: com.uber.hoodie.exception.HoodieInsertException: Failed to close the Insert Handle for path s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet\r\n>         at com.uber.hoodie.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:146)\r\n>         at com.uber.hoodie.func.CopyOnWriteLazyInsertIterable.computeNext(CopyOnWriteLazyInsertIterable.java:102)\r\n>         ... 25 more\r\n> Caused by: java.util.concurrent.ExecutionException: com.uber.hoodie.exception.HoodieInsertException: Failed to close the Insert Handle for path s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet\r\n>         at java.util.concurrent.FutureTask.report(FutureTask.java:122)\r\n>         at java.util.concurrent.FutureTask.get(FutureTask.java:192)\r\n>         at com.uber.hoodie.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:144)\r\n>         ... 26 more\r\n> Caused by: com.uber.hoodie.exception.HoodieInsertException: Failed to close the Insert Handle for path s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet\r\n>         at com.uber.hoodie.io.HoodieCreateHandle.close(HoodieCreateHandle.java:165)\r\n>         at com.uber.hoodie.func.CopyOnWriteLazyInsertIterable$CopyOnWriteInsertHandler.finish(CopyOnWriteLazyInsertIterable.java:168)\r\n>         at com.uber.hoodie.common.util.queue.BoundedInMemoryQueueConsumer.consume(BoundedInMemoryQueueConsumer.java:42)\r\n>         at com.uber.hoodie.common.util.queue.BoundedInMemoryExecutor.lambda$null$2(BoundedInMemoryExecutor.java:124)\r\n>         at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n>         ... 3 more\r\n> Caused by: java.io.FileNotFoundException: No such file or directory 's3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet'\r\n>         at com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.getFileStatus(S3NativeFileSystem.java:808)\r\n>         at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.getFileStatus(EmrFileSystem.java:548)\r\n>         at com.uber.hoodie.common.util.FSUtils.getFileSize(FSUtils.java:126)\r\n>         at com.uber.hoodie.io.HoodieCreateHandle.close(HoodieCreateHandle.java:156)\r\n>         ... 7 more\r\n> ```\r\n\r\nHave noticed similar failures","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647932695/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647941035","html_url":"https://github.com/apache/hudi/issues/588#issuecomment-647941035","issue_url":"https://api.github.com/repos/apache/hudi/issues/588","id":647941035,"node_id":"MDEyOklzc3VlQ29tbWVudDY0Nzk0MTAzNQ==","user":{"login":"luffyd","id":2287345,"node_id":"MDQ6VXNlcjIyODczNDU=","avatar_url":"https://avatars.githubusercontent.com/u/2287345?v=4","gravatar_id":"","url":"https://api.github.com/users/luffyd","html_url":"https://github.com/luffyd","followers_url":"https://api.github.com/users/luffyd/followers","following_url":"https://api.github.com/users/luffyd/following{/other_user}","gists_url":"https://api.github.com/users/luffyd/gists{/gist_id}","starred_url":"https://api.github.com/users/luffyd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/luffyd/subscriptions","organizations_url":"https://api.github.com/users/luffyd/orgs","repos_url":"https://api.github.com/users/luffyd/repos","events_url":"https://api.github.com/users/luffyd/events{/privacy}","received_events_url":"https://api.github.com/users/luffyd/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T06:38:35Z","updated_at":"2020-06-23T06:38:35Z","author_association":"NONE","body":"> > BUG:Transient no such file or directory\r\n> > ```\r\n> > scala>     splits.zipWithIndex.foreach{case (x,i)=>{\r\n> >      |       println(s\"adding split $i\")\r\n> >      | \r\n> >      |       val path = s\"hdfs:///tmp/ap-invoices-all-snapshot-slice-stg/\"\r\n> >      | \r\n> >      |       x.write.mode(\"overwrite\").parquet(path)//stage the subset\r\n> >      | \r\n> >      |       new HorizonCompactionUtil().saveToHudiTable(\r\n> >      |         spark.read.parquet(path),\r\n> >      |         tableName = \"ap_invoices_all_hudi\",\r\n> >      |         tablePath = \"s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/\",\r\n> >      |         primaryKey = \"invoice_id\",\r\n> >      |         pkOrderingCol = \"capture_timestamp\",\r\n> >      |         enableHiveSync = false,\r\n> >      |         partitionCol = None,\r\n> >      |         insertMode = \"append\",\r\n> >      |         parallelism = 5000,\r\n> >      |         fakePartitionCol = false\r\n> >      |       )\r\n> >      |     }}\r\n> > adding split 0\r\n> > 19/02/27 22:33:11 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.\r\n> > 19/02/27 22:33:11 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.\r\n> > [Stage 34:===========================>                        (138 + 124) / 262]19/02/27 22:39:35 WARN TaskSetManager: Lost task 103.0 in stage 34.0 (TID 38146, ip-172-31-25-39.ec2.internal, executor 2674): java.lang.RuntimeException: com.uber.hoodie.exception.HoodieException: com.uber.hoodie.exception.HoodieException: java.util.concurrent.ExecutionException: com.uber.hoodie.exception.HoodieInsertException: Failed to close the Insert Handle for path s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet\r\n> >         at com.uber.hoodie.func.LazyIterableIterator.next(LazyIterableIterator.java:121)\r\n> >         at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)\r\n> >         at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\r\n> >         at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\r\n> >         at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:220)\r\n> >         at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:348)\r\n> >         at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1182)\r\n> >         at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\r\n> >         at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n> >         at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n> >         at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n> >         at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n> >         at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n> >         at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n> >         at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n> >         at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n> >         at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n> >         at org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n> >         at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\r\n> >         at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n> >         at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\r\n> >         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n> >         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n> >         at java.lang.Thread.run(Thread.java:748)\r\n> > Caused by: com.uber.hoodie.exception.HoodieException: com.uber.hoodie.exception.HoodieException: java.util.concurrent.ExecutionException: com.uber.hoodie.exception.HoodieInsertException: Failed to close the Insert Handle for path s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet\r\n> >         at com.uber.hoodie.func.CopyOnWriteLazyInsertIterable.computeNext(CopyOnWriteLazyInsertIterable.java:106)\r\n> >         at com.uber.hoodie.func.CopyOnWriteLazyInsertIterable.computeNext(CopyOnWriteLazyInsertIterable.java:45)\r\n> >         at com.uber.hoodie.func.LazyIterableIterator.next(LazyIterableIterator.java:119)\r\n> >         ... 23 more\r\n> > Caused by: com.uber.hoodie.exception.HoodieException: java.util.concurrent.ExecutionException: com.uber.hoodie.exception.HoodieInsertException: Failed to close the Insert Handle for path s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet\r\n> >         at com.uber.hoodie.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:146)\r\n> >         at com.uber.hoodie.func.CopyOnWriteLazyInsertIterable.computeNext(CopyOnWriteLazyInsertIterable.java:102)\r\n> >         ... 25 more\r\n> > Caused by: java.util.concurrent.ExecutionException: com.uber.hoodie.exception.HoodieInsertException: Failed to close the Insert Handle for path s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet\r\n> >         at java.util.concurrent.FutureTask.report(FutureTask.java:122)\r\n> >         at java.util.concurrent.FutureTask.get(FutureTask.java:192)\r\n> >         at com.uber.hoodie.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:144)\r\n> >         ... 26 more\r\n> > Caused by: com.uber.hoodie.exception.HoodieInsertException: Failed to close the Insert Handle for path s3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet\r\n> >         at com.uber.hoodie.io.HoodieCreateHandle.close(HoodieCreateHandle.java:165)\r\n> >         at com.uber.hoodie.func.CopyOnWriteLazyInsertIterable$CopyOnWriteInsertHandler.finish(CopyOnWriteLazyInsertIterable.java:168)\r\n> >         at com.uber.hoodie.common.util.queue.BoundedInMemoryQueueConsumer.consume(BoundedInMemoryQueueConsumer.java:42)\r\n> >         at com.uber.hoodie.common.util.queue.BoundedInMemoryExecutor.lambda$null$2(BoundedInMemoryExecutor.java:124)\r\n> >         at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n> >         ... 3 more\r\n> > Caused by: java.io.FileNotFoundException: No such file or directory 's3://horizon-hudi-dev/data/direct-write-ap-invoices-all/db15bed7-b959-41fd-ac98-0e04d7058a20_103_20190227223315.parquet'\r\n> >         at com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.getFileStatus(S3NativeFileSystem.java:808)\r\n> >         at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.getFileStatus(EmrFileSystem.java:548)\r\n> >         at com.uber.hoodie.common.util.FSUtils.getFileSize(FSUtils.java:126)\r\n> >         at com.uber.hoodie.io.HoodieCreateHandle.close(HoodieCreateHandle.java:156)\r\n> >         ... 7 more\r\n> > ```\r\n> \r\n> Have noticed similar failures\r\n\r\nNot seeing this issue after using consistent view setting https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-consistent-view.html","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647941035/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647944784","html_url":"https://github.com/apache/hudi/issues/1751#issuecomment-647944784","issue_url":"https://api.github.com/repos/apache/hudi/issues/1751","id":647944784,"node_id":"MDEyOklzc3VlQ29tbWVudDY0Nzk0NDc4NA==","user":{"login":"lyogev","id":23477645,"node_id":"MDQ6VXNlcjIzNDc3NjQ1","avatar_url":"https://avatars.githubusercontent.com/u/23477645?v=4","gravatar_id":"","url":"https://api.github.com/users/lyogev","html_url":"https://github.com/lyogev","followers_url":"https://api.github.com/users/lyogev/followers","following_url":"https://api.github.com/users/lyogev/following{/other_user}","gists_url":"https://api.github.com/users/lyogev/gists{/gist_id}","starred_url":"https://api.github.com/users/lyogev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lyogev/subscriptions","organizations_url":"https://api.github.com/users/lyogev/orgs","repos_url":"https://api.github.com/users/lyogev/repos","events_url":"https://api.github.com/users/lyogev/events{/privacy}","received_events_url":"https://api.github.com/users/lyogev/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T06:47:55Z","updated_at":"2020-06-23T06:47:55Z","author_association":"CONTRIBUTOR","body":"Sorry for not responding sooner.\r\nI am working on this PR: https://github.com/YotpoLtd/metorikku/pull/335 which is right now failing in CI.\r\nThis PR in spark (merged for version 3.0.0): https://github.com/apache/spark/pull/28223\r\nmoved fromRow from ExpressionEncoder into another class.\r\nAnd it is used in hudi in https://github.com/apache/hudi/blob/89e37d5273ea1c6bf2fe3a8f7053e7a3cc44011d/hudi-spark/src/main/scala/org/apache/hudi/AvroConversionUtils.scala#L42","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647944784/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647950765","html_url":"https://github.com/apache/hudi/issues/588#issuecomment-647950765","issue_url":"https://api.github.com/repos/apache/hudi/issues/588","id":647950765,"node_id":"MDEyOklzc3VlQ29tbWVudDY0Nzk1MDc2NQ==","user":{"login":"AndrewKL","id":2659018,"node_id":"MDQ6VXNlcjI2NTkwMTg=","avatar_url":"https://avatars.githubusercontent.com/u/2659018?v=4","gravatar_id":"","url":"https://api.github.com/users/AndrewKL","html_url":"https://github.com/AndrewKL","followers_url":"https://api.github.com/users/AndrewKL/followers","following_url":"https://api.github.com/users/AndrewKL/following{/other_user}","gists_url":"https://api.github.com/users/AndrewKL/gists{/gist_id}","starred_url":"https://api.github.com/users/AndrewKL/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AndrewKL/subscriptions","organizations_url":"https://api.github.com/users/AndrewKL/orgs","repos_url":"https://api.github.com/users/AndrewKL/repos","events_url":"https://api.github.com/users/AndrewKL/events{/privacy}","received_events_url":"https://api.github.com/users/AndrewKL/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T07:02:01Z","updated_at":"2020-06-23T07:02:01Z","author_association":"NONE","body":"FYI most of these issues are historical from before Hudi was on EMR.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/647950765/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648045079","html_url":"https://github.com/apache/hudi/issues/1758#issuecomment-648045079","issue_url":"https://api.github.com/repos/apache/hudi/issues/1758","id":648045079,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODA0NTA3OQ==","user":{"login":"christoph-wmt","id":67316352,"node_id":"MDQ6VXNlcjY3MzE2MzUy","avatar_url":"https://avatars.githubusercontent.com/u/67316352?v=4","gravatar_id":"","url":"https://api.github.com/users/christoph-wmt","html_url":"https://github.com/christoph-wmt","followers_url":"https://api.github.com/users/christoph-wmt/followers","following_url":"https://api.github.com/users/christoph-wmt/following{/other_user}","gists_url":"https://api.github.com/users/christoph-wmt/gists{/gist_id}","starred_url":"https://api.github.com/users/christoph-wmt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/christoph-wmt/subscriptions","organizations_url":"https://api.github.com/users/christoph-wmt/orgs","repos_url":"https://api.github.com/users/christoph-wmt/repos","events_url":"https://api.github.com/users/christoph-wmt/events{/privacy}","received_events_url":"https://api.github.com/users/christoph-wmt/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T10:08:58Z","updated_at":"2020-06-23T10:08:58Z","author_association":"NONE","body":"sorry, i realize this might be a duplicate of https://github.com/apache/hudi/issues/1552\r\nI'll build off master and give it a shot.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648045079/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648329807","html_url":"https://github.com/apache/hudi/pull/1687#issuecomment-648329807","issue_url":"https://api.github.com/repos/apache/hudi/issues/1687","id":648329807,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODMyOTgwNw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T18:10:51Z","updated_at":"2020-06-23T18:10:51Z","author_association":"MEMBER","body":"thanks ! @bvaradar if we can get this landed soon and then work on top, that'd be awesome.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648329807/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648381931","html_url":"https://github.com/apache/hudi/issues/1757#issuecomment-648381931","issue_url":"https://api.github.com/repos/apache/hudi/issues/1757","id":648381931,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODM4MTkzMQ==","user":{"login":"somebol","id":29965228,"node_id":"MDQ6VXNlcjI5OTY1MjI4","avatar_url":"https://avatars.githubusercontent.com/u/29965228?v=4","gravatar_id":"","url":"https://api.github.com/users/somebol","html_url":"https://github.com/somebol","followers_url":"https://api.github.com/users/somebol/followers","following_url":"https://api.github.com/users/somebol/following{/other_user}","gists_url":"https://api.github.com/users/somebol/gists{/gist_id}","starred_url":"https://api.github.com/users/somebol/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/somebol/subscriptions","organizations_url":"https://api.github.com/users/somebol/orgs","repos_url":"https://api.github.com/users/somebol/repos","events_url":"https://api.github.com/users/somebol/events{/privacy}","received_events_url":"https://api.github.com/users/somebol/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T19:49:48Z","updated_at":"2020-06-23T19:49:48Z","author_association":"NONE","body":"@vinothchandar are you able suggest some tweaks?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648381931/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648396783","html_url":"https://github.com/apache/hudi/issues/1757#issuecomment-648396783","issue_url":"https://api.github.com/repos/apache/hudi/issues/1757","id":648396783,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODM5Njc4Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T20:21:29Z","updated_at":"2020-06-23T20:21:29Z","author_association":"MEMBER","body":"@somebol assuming this is an initial load and after this, you would do insert/upsert operations incrementally? \r\n\r\nHigh level, `bulk_insert` does a sort and writes out the data. From what I can tell, you have sufficient parallelism. But a bunch of tasks are failing and retrying probably adds a bunch of time to the runs? (stage 2, 4). Could you look into how skewed task runtimes within those stages are? \r\n\r\nP.S:  We do incur the cost of Row -> GenericRecord -> Parquet (@nsivabalan has a branch with a fix, that will make it to 0.6.0) ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648396783/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648397610","html_url":"https://github.com/apache/hudi/issues/1751#issuecomment-648397610","issue_url":"https://api.github.com/repos/apache/hudi/issues/1751","id":648397610,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODM5NzYxMA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T20:23:19Z","updated_at":"2020-06-23T20:23:19Z","author_association":"MEMBER","body":"Does #1760  help? If you could try that out & report back.. it'd be awesome.. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648397610/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648432948","html_url":"https://github.com/apache/hudi/issues/1757#issuecomment-648432948","issue_url":"https://api.github.com/repos/apache/hudi/issues/1757","id":648432948,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODQzMjk0OA==","user":{"login":"somebol","id":29965228,"node_id":"MDQ6VXNlcjI5OTY1MjI4","avatar_url":"https://avatars.githubusercontent.com/u/29965228?v=4","gravatar_id":"","url":"https://api.github.com/users/somebol","html_url":"https://github.com/somebol","followers_url":"https://api.github.com/users/somebol/followers","following_url":"https://api.github.com/users/somebol/following{/other_user}","gists_url":"https://api.github.com/users/somebol/gists{/gist_id}","starred_url":"https://api.github.com/users/somebol/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/somebol/subscriptions","organizations_url":"https://api.github.com/users/somebol/orgs","repos_url":"https://api.github.com/users/somebol/repos","events_url":"https://api.github.com/users/somebol/events{/privacy}","received_events_url":"https://api.github.com/users/somebol/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T21:17:05Z","updated_at":"2020-06-23T21:17:05Z","author_association":"NONE","body":"@vinothchandar yes, this is an initial load and we plan to use upsert for incrementals. The task failures are mainly due to preemption.\r\nwould there be any benefit say increasing bulkimport parallelism to say ~10000?\r\n\r\nThe tuning guide mentions \" `hoodie.[insert|upsert|bulkinsert].shuffle.parallelism` such that its atleast input_data_size/500MB\" in our case the input data size is 5.5 TB, so by that calculation our parallelism should be around 11000.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648432948/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648435649","html_url":"https://github.com/apache/hudi/issues/1757#issuecomment-648435649","issue_url":"https://api.github.com/repos/apache/hudi/issues/1757","id":648435649,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODQzNTY0OQ==","user":{"login":"somebol","id":29965228,"node_id":"MDQ6VXNlcjI5OTY1MjI4","avatar_url":"https://avatars.githubusercontent.com/u/29965228?v=4","gravatar_id":"","url":"https://api.github.com/users/somebol","html_url":"https://github.com/somebol","followers_url":"https://api.github.com/users/somebol/followers","following_url":"https://api.github.com/users/somebol/following{/other_user}","gists_url":"https://api.github.com/users/somebol/gists{/gist_id}","starred_url":"https://api.github.com/users/somebol/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/somebol/subscriptions","organizations_url":"https://api.github.com/users/somebol/orgs","repos_url":"https://api.github.com/users/somebol/repos","events_url":"https://api.github.com/users/somebol/events{/privacy}","received_events_url":"https://api.github.com/users/somebol/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T21:23:16Z","updated_at":"2020-06-23T21:24:17Z","author_association":"NONE","body":"stages 4 & 6 seem to have the most skew.\r\n\r\n***screenshots of stage details***\r\n**stage 6**\r\n![image](https://user-images.githubusercontent.com/29965228/85464858-77331580-b5eb-11ea-8530-093bda1829a0.png)\r\n![image](https://user-images.githubusercontent.com/29965228/85464771-5ec2fb00-b5eb-11ea-92a3-733702f33a9b.png)\r\n\r\n**stage 4**\r\n![image](https://user-images.githubusercontent.com/29965228/85464361-e2301c80-b5ea-11ea-8518-6f3e3b347639.png)\r\n![image](https://user-images.githubusercontent.com/29965228/85464416-f2e09280-b5ea-11ea-98fb-4a1e29ebf241.png)\r\n\r\n**stage 3**\r\n![image](https://user-images.githubusercontent.com/29965228/85464559-23c0c780-b5eb-11ea-99b5-0c134f40fdec.png)\r\n\r\n**stage 2**\r\n![image](https://user-images.githubusercontent.com/29965228/85464637-3cc97880-b5eb-11ea-989f-4043cee25afb.png)\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648435649/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648460431","html_url":"https://github.com/apache/hudi/issues/1751#issuecomment-648460431","issue_url":"https://api.github.com/repos/apache/hudi/issues/1751","id":648460431,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODQ2MDQzMQ==","user":{"login":"lyogev","id":23477645,"node_id":"MDQ6VXNlcjIzNDc3NjQ1","avatar_url":"https://avatars.githubusercontent.com/u/23477645?v=4","gravatar_id":"","url":"https://api.github.com/users/lyogev","html_url":"https://github.com/lyogev","followers_url":"https://api.github.com/users/lyogev/followers","following_url":"https://api.github.com/users/lyogev/following{/other_user}","gists_url":"https://api.github.com/users/lyogev/gists{/gist_id}","starred_url":"https://api.github.com/users/lyogev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lyogev/subscriptions","organizations_url":"https://api.github.com/users/lyogev/orgs","repos_url":"https://api.github.com/users/lyogev/repos","events_url":"https://api.github.com/users/lyogev/events{/privacy}","received_events_url":"https://api.github.com/users/lyogev/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T22:25:51Z","updated_at":"2020-06-23T22:25:51Z","author_association":"CONTRIBUTOR","body":"Looks like it is! now I'm stuck at hive sync:\r\n```\r\nException in thread \"main\" java.lang.NoClassDefFoundError: org/apache/calcite/rel/type/RelDataTypeSystem\r\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzerFactory.get(SemanticAnalyzerFactory.java:318)\r\n\tat org.apache.hadoop.hive.ql.Driver.compile(Driver.java:484)\r\n\tat org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)\r\n\tat org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)\r\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)\r\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)\r\n\tat org.apache.hudi.hive.HoodieHiveClient.updateHiveSQLs(HoodieHiveClient.java:401)\r\n\tat org.apache.hudi.hive.HoodieHiveClient.updateHiveSQLUsingHiveDriver(HoodieHiveClient.java:384)\r\n\tat org.apache.hudi.hive.HoodieHiveClient.updateHiveSQL(HoodieHiveClient.java:374)\r\n\tat org.apache.hudi.hive.HoodieHiveClient.createTable(HoodieHiveClient.java:266)\r\n\tat org.apache.hudi.hive.HiveSyncTool.syncSchema(HiveSyncTool.java:152)\r\n\tat org.apache.hudi.hive.HiveSyncTool.syncHoodieTable(HiveSyncTool.java:120)\r\n\tat org.apache.hudi.hive.HiveSyncTool.syncHoodieTable(HiveSyncTool.java:93)\r\n\tat org.apache.hudi.HoodieSparkSqlWriter$.syncHive(HoodieSparkSqlWriter.scala:235)\r\n\tat org.apache.hudi.HoodieSparkSqlWriter$.checkWriteStatus(HoodieSparkSqlWriter.scala:286)\r\n\tat org.apache.hudi.HoodieSparkSqlWriter$.write(HoodieSparkSqlWriter.scala:189)\r\n\tat org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:108)\r\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:46)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:90)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:944)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:944)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:396)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:380)\r\n```\r\n\r\nI think calcite was removed from spark as a dependency","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648460431/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648470434","html_url":"https://github.com/apache/hudi/issues/1751#issuecomment-648470434","issue_url":"https://api.github.com/repos/apache/hudi/issues/1751","id":648470434,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODQ3MDQzNA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T22:57:54Z","updated_at":"2020-06-23T22:57:54Z","author_association":"MEMBER","body":"@lyogev could you try including it explcitly in `hudi-spark-bundle` pom under `packaging` and give it a shot? (if not, i will make sometime to try this later tonight or tomorrow morning and push a PR)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648470434/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648478687","html_url":"https://github.com/apache/hudi/issues/1757#issuecomment-648478687","issue_url":"https://api.github.com/repos/apache/hudi/issues/1757","id":648478687,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODQ3ODY4Nw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T23:24:23Z","updated_at":"2020-06-23T23:24:51Z","author_association":"MEMBER","body":"> \" hoodie.[insert|upsert|bulkinsert].shuffle.parallelism such that its atleast input_data_size/500MB\r\n\r\nThe reason for this was the 2GB limitation in Spark shuffle.. I see you are on Spark 2.4, which should work with larger than 2GB partitions. \r\n\r\nStill worth trying to increase the parallelism to 10K , may be.. it will ensure that the memory needed for each partition is lower (spark's own datastructures).. Also notice how much data it's shuffle spilling.. In all your runs, GC time is very high.. stage 4 75th percentile, for e.g 45 mins out of 3.5h. Consider giving large heap and tune gc bit? https://cwiki.apache.org/confluence/display/HUDI/Tuning+Guide has a sample to try.. \r\n\r\nLooking at stage 4: \r\nit's the actual write.. line [here](https://github.com/apache/hudi/blob/release-0.5.3/hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkSqlWriter.scala#L262) triggers the DAG and counts the errors during write.. The workload distribution there is based on Spark sort's range partitioner.. seems like it does a reasonable job (2.5x swing between min and max records).. Guess it is what it is.. the sorting here is useful down the line as you perform upserts.. e.g if you have ordered keys , this pre-sort gives you very good index performance.\r\n\r\nLooking at stage 6:\r\nSeems like Spark lost a partition in the mean time and thus recomputed the RDD from scratch.. You can see one max task taking up 3hrs there.. My guess is its recomputing. if we make stage 4 more scalable, then I think this will also go away IMO.. Since shuffle uses local disk, I will also ensure cluster is big enough to hold the data needed for shuffle.. \r\n\r\nBtw all these are spark shuffle tuning, not Hudi specific per se.. and a 5.5TB shuffle is a good size :)  \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648478687/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648481221","html_url":"https://github.com/apache/hudi/issues/1751#issuecomment-648481221","issue_url":"https://api.github.com/repos/apache/hudi/issues/1751","id":648481221,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODQ4MTIyMQ==","user":{"login":"bschell","id":8600774,"node_id":"MDQ6VXNlcjg2MDA3NzQ=","avatar_url":"https://avatars.githubusercontent.com/u/8600774?v=4","gravatar_id":"","url":"https://api.github.com/users/bschell","html_url":"https://github.com/bschell","followers_url":"https://api.github.com/users/bschell/followers","following_url":"https://api.github.com/users/bschell/following{/other_user}","gists_url":"https://api.github.com/users/bschell/gists{/gist_id}","starred_url":"https://api.github.com/users/bschell/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bschell/subscriptions","organizations_url":"https://api.github.com/users/bschell/orgs","repos_url":"https://api.github.com/users/bschell/repos","events_url":"https://api.github.com/users/bschell/events{/privacy}","received_events_url":"https://api.github.com/users/bschell/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T23:33:02Z","updated_at":"2020-06-23T23:33:02Z","author_association":"CONTRIBUTOR","body":"I did not run into this when testing #1760 myself, I think it might be because we have internal changes for hive3.\r\n\r\nI just checked and it looks like we have calcite added and shaded in hudi-hive-bundle\r\n<dependency>  \r\n      <groupId>org.apache.calcite</groupId>  \r\n      <artifactId>calcite-core</artifactId>  \r\n      <version>1.16.0</version>  \r\n </dependency>\r\n\r\nI think you might also need to add and shade libfb303 for hive-sync\r\n<dependency>\r\n      <groupId>org.apache.thrift</groupId>\r\n      <artifactId>libfb303</artifactId>\r\n      <version>0.9.3</version>\r\n</dependency>\r\n\r\nWe had these dependency changes for hive3 compatibility, however, didn't realize this was needed for spark3 also. I will try to update #1760 with what is needed.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648481221/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648482064","html_url":"https://github.com/apache/hudi/issues/1751#issuecomment-648482064","issue_url":"https://api.github.com/repos/apache/hudi/issues/1751","id":648482064,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODQ4MjA2NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T23:36:02Z","updated_at":"2020-06-23T23:36:02Z","author_association":"MEMBER","body":"Thanks @bschell ..","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648482064/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648488394","html_url":"https://github.com/apache/hudi/pull/1702#issuecomment-648488394","issue_url":"https://api.github.com/repos/apache/hudi/issues/1702","id":648488394,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODQ4ODM5NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-23T23:59:44Z","updated_at":"2020-06-23T23:59:44Z","author_association":"MEMBER","body":"@umehrot2 does this PR some of @bvaradar 's changes included? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648488394/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648489647","html_url":"https://github.com/apache/hudi/pull/1753#issuecomment-648489647","issue_url":"https://api.github.com/repos/apache/hudi/issues/1753","id":648489647,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODQ4OTY0Nw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T00:04:14Z","updated_at":"2020-06-24T00:04:14Z","author_association":"MEMBER","body":"@ramachandranms can you please take a quick pass :)^P.. \r\n@xushiyan we can time out tomorrow and go ahead merge..","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648489647/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648490993","html_url":"https://github.com/apache/hudi/pull/1756#issuecomment-648490993","issue_url":"https://api.github.com/repos/apache/hudi/issues/1756","id":648490993,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODQ5MDk5Mw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T00:08:48Z","updated_at":"2020-06-24T00:08:48Z","author_association":"MEMBER","body":"@lw309637554 is this ready for review?  seems like we have unit test failures?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648490993/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648509194","html_url":"https://github.com/apache/hudi/issues/1758#issuecomment-648509194","issue_url":"https://api.github.com/repos/apache/hudi/issues/1758","id":648509194,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODUwOTE5NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T00:29:43Z","updated_at":"2020-06-24T00:29:43Z","author_association":"MEMBER","body":"0.5.3 has the fix already IIUC.. So please let me know how things go on master.. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648509194/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648512548","html_url":"https://github.com/apache/hudi/issues/1759#issuecomment-648512548","issue_url":"https://api.github.com/repos/apache/hudi/issues/1759","id":648512548,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODUxMjU0OA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T00:33:11Z","updated_at":"2020-06-24T00:33:11Z","author_association":"MEMBER","body":"@davidsheard sorry to hear that. do you get an error on the spark driver? What the hive version on CDH? We sometimes get CDH issues with Hive 1.x .. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648512548/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648514644","html_url":"https://github.com/apache/hudi/issues/1759#issuecomment-648514644","issue_url":"https://api.github.com/repos/apache/hudi/issues/1759","id":648514644,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODUxNDY0NA==","user":{"login":"davidsheard","id":15660932,"node_id":"MDQ6VXNlcjE1NjYwOTMy","avatar_url":"https://avatars.githubusercontent.com/u/15660932?v=4","gravatar_id":"","url":"https://api.github.com/users/davidsheard","html_url":"https://github.com/davidsheard","followers_url":"https://api.github.com/users/davidsheard/followers","following_url":"https://api.github.com/users/davidsheard/following{/other_user}","gists_url":"https://api.github.com/users/davidsheard/gists{/gist_id}","starred_url":"https://api.github.com/users/davidsheard/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/davidsheard/subscriptions","organizations_url":"https://api.github.com/users/davidsheard/orgs","repos_url":"https://api.github.com/users/davidsheard/repos","events_url":"https://api.github.com/users/davidsheard/events{/privacy}","received_events_url":"https://api.github.com/users/davidsheard/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T00:37:56Z","updated_at":"2020-06-24T00:37:56Z","author_association":"NONE","body":"We had issues with the jdbc and kerberos to play nicely with the sync tool. \r\nWe wrapped the tool into our own Java class and added the appropriate configs. \r\nWorking like we bought one :)\r\n\r\nCheers","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648514644/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648529008","html_url":"https://github.com/apache/hudi/pull/1721#issuecomment-648529008","issue_url":"https://api.github.com/repos/apache/hudi/issues/1721","id":648529008,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODUyOTAwOA==","user":{"login":"EdwinGuo","id":8300535,"node_id":"MDQ6VXNlcjgzMDA1MzU=","avatar_url":"https://avatars.githubusercontent.com/u/8300535?v=4","gravatar_id":"","url":"https://api.github.com/users/EdwinGuo","html_url":"https://github.com/EdwinGuo","followers_url":"https://api.github.com/users/EdwinGuo/followers","following_url":"https://api.github.com/users/EdwinGuo/following{/other_user}","gists_url":"https://api.github.com/users/EdwinGuo/gists{/gist_id}","starred_url":"https://api.github.com/users/EdwinGuo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EdwinGuo/subscriptions","organizations_url":"https://api.github.com/users/EdwinGuo/orgs","repos_url":"https://api.github.com/users/EdwinGuo/repos","events_url":"https://api.github.com/users/EdwinGuo/events{/privacy}","received_events_url":"https://api.github.com/users/EdwinGuo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T01:30:36Z","updated_at":"2020-06-24T01:30:36Z","author_association":"CONTRIBUTOR","body":"> Can you please include the jira number in the pr title\r\n\r\nDone. https://issues.apache.org/jira/browse/HUDI-1041","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648529008/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648532688","html_url":"https://github.com/apache/hudi/pull/1721#issuecomment-648532688","issue_url":"https://api.github.com/repos/apache/hudi/issues/1721","id":648532688,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODUzMjY4OA==","user":{"login":"EdwinGuo","id":8300535,"node_id":"MDQ6VXNlcjgzMDA1MzU=","avatar_url":"https://avatars.githubusercontent.com/u/8300535?v=4","gravatar_id":"","url":"https://api.github.com/users/EdwinGuo","html_url":"https://github.com/EdwinGuo","followers_url":"https://api.github.com/users/EdwinGuo/followers","following_url":"https://api.github.com/users/EdwinGuo/following{/other_user}","gists_url":"https://api.github.com/users/EdwinGuo/gists{/gist_id}","starred_url":"https://api.github.com/users/EdwinGuo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EdwinGuo/subscriptions","organizations_url":"https://api.github.com/users/EdwinGuo/orgs","repos_url":"https://api.github.com/users/EdwinGuo/repos","events_url":"https://api.github.com/users/EdwinGuo/events{/privacy}","received_events_url":"https://api.github.com/users/EdwinGuo/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T01:44:48Z","updated_at":"2020-06-24T01:44:48Z","author_association":"CONTRIBUTOR","body":"> @EdwinGuo @nsivabalan let's hash this out.. its an interesting one.. Although it may seem like we are computing the fully exploded RDD in both places.. if you look closely, we do\r\n> \r\n> ```\r\n> fileToComparisons = explodeRecordRDDWithFileComparisons(partitionToFileInfo, partitionRecordKeyPairRDD)\r\n>           .mapToPair(t -> t).countByKey();\r\n> ```\r\n> \r\n> countByKey() does not shuffle actual data, but just the counts per file.. We only pay the compute cost of exploding twice.. And all this to estimate the parallelism. given this is jsut an estimate, would it be better to introduce an option to simply down sample and estimate, rather than adding caching?\r\n> \r\n> eg.\r\n> \r\n> ```\r\n> fileToComparisons = explodeRecordRDDWithFileComparisons(partitionToFileInfo, partitionRecordKeyPairRDD.sample(true, 0.1))\r\n>           .mapToPair(t -> t).countByKey();\r\n> ```\r\n> \r\n> would cut the cost down by 90% .. we need to adjust the computations in the map accordingly ofc..\r\n> Even spark sort does some kind of reservoir sampling.. So this could be a valid approach overall.\r\n> \r\n> What do you both think? I am bit concerned about caching this exploded RDD (that's why I chose to recompute to begin with)\r\n\r\nI can provide some performance comparison tomorrow.  fileComparisonsRDD is being compute in a different patterns within findMatchingFilesForRecordKeys and computeComparisonsPerFileGroup, so yes, countByKey is light in shuffle but could be heavy in IO for some of the cases. I agree StorageLevel.MEMORY_AND_DISK_SER() could be heavy than recompute in some of the scenario, so let me conduct some performance testing and get back to you.\r\n\r\nRegarding sampling, what if some of the partitions are skewed? Will that cause more overhead than flush the file out?   ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648532688/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648541535","html_url":"https://github.com/apache/hudi/pull/1756#issuecomment-648541535","issue_url":"https://api.github.com/repos/apache/hudi/issues/1756","id":648541535,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODU0MTUzNQ==","user":{"login":"lw309637554","id":8501994,"node_id":"MDQ6VXNlcjg1MDE5OTQ=","avatar_url":"https://avatars.githubusercontent.com/u/8501994?v=4","gravatar_id":"","url":"https://api.github.com/users/lw309637554","html_url":"https://github.com/lw309637554","followers_url":"https://api.github.com/users/lw309637554/followers","following_url":"https://api.github.com/users/lw309637554/following{/other_user}","gists_url":"https://api.github.com/users/lw309637554/gists{/gist_id}","starred_url":"https://api.github.com/users/lw309637554/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lw309637554/subscriptions","organizations_url":"https://api.github.com/users/lw309637554/orgs","repos_url":"https://api.github.com/users/lw309637554/repos","events_url":"https://api.github.com/users/lw309637554/events{/privacy}","received_events_url":"https://api.github.com/users/lw309637554/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T02:18:31Z","updated_at":"2020-06-24T02:18:31Z","author_association":"CONTRIBUTOR","body":"> Took a quick pass at the three test classes you have added.. LGTM .\r\n> Will do a detailed pass once you confirm PR is indeed ready..\r\n\r\nThanks,i will fix the failed unit test ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648541535/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648698394","html_url":"https://github.com/apache/hudi/issues/1758#issuecomment-648698394","issue_url":"https://api.github.com/repos/apache/hudi/issues/1758","id":648698394,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODY5ODM5NA==","user":{"login":"christoph-wmt","id":67316352,"node_id":"MDQ6VXNlcjY3MzE2MzUy","avatar_url":"https://avatars.githubusercontent.com/u/67316352?v=4","gravatar_id":"","url":"https://api.github.com/users/christoph-wmt","html_url":"https://github.com/christoph-wmt","followers_url":"https://api.github.com/users/christoph-wmt/followers","following_url":"https://api.github.com/users/christoph-wmt/following{/other_user}","gists_url":"https://api.github.com/users/christoph-wmt/gists{/gist_id}","starred_url":"https://api.github.com/users/christoph-wmt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/christoph-wmt/subscriptions","organizations_url":"https://api.github.com/users/christoph-wmt/orgs","repos_url":"https://api.github.com/users/christoph-wmt/repos","events_url":"https://api.github.com/users/christoph-wmt/events{/privacy}","received_events_url":"https://api.github.com/users/christoph-wmt/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T09:10:17Z","updated_at":"2020-06-24T09:10:17Z","author_association":"NONE","body":"oh really, my assumption was it would only make it in 6.0.  It turns out we are on 5.0 and adding above fix into our build resolved the issue.  We still have significant time spend on the driver on every batch which now is in the region of 10s of seconds and no longer minutes and we'll dig deeper on that. The immediate issue is resolved though - thank you!","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648698394/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648872791","html_url":"https://github.com/apache/hudi/issues/1758#issuecomment-648872791","issue_url":"https://api.github.com/repos/apache/hudi/issues/1758","id":648872791,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODg3Mjc5MQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T14:56:35Z","updated_at":"2020-06-24T14:56:35Z","author_association":"MEMBER","body":"@christoph-wmt Good to know.. My guess is EMR picked up 0.5.0 even though you put in 0.5.3?\r\n\r\nwe are all working on 0.6.0 release where all of this is going to be much better.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648872791/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648882567","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-648882567","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":648882567,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODg4MjU2Nw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T15:13:07Z","updated_at":"2020-06-24T15:13:17Z","author_association":"MEMBER","body":"@zuyanton thanks for reporting this.. let's work together to resolve this. can you please paste the `.hoodie/hoodie.properties` file? The .inflight file hanging around could be normal or not, depending on the timeline layout version.. So checking for that. \r\n\r\nThe consistency check itself is tunable.. See https://github.com/apache/hudi/blob/release-0.5.3/hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java#L92 although I would expect the defaults to be sufficient most of the time (have not seen a lot of issues like this so far).. cc @umehrot2  any suggestions here? \r\n\r\nOn the second problem, \r\n>like log files with the same fileID as parquet files that were part of failed compaction never get compacted,\r\nThe next run of compaction should try and attempt to complete this inflight compaction again.. cc @bvaradar can you confirm \r\n\r\na) with inline compaction, a failed compaction would be re-attempted in the next run \r\nb) we will perform clean up from .aux for all marker files that we may not have deleted yet (due to such finalize errors).. \r\n \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648882567/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648885633","html_url":"https://github.com/apache/hudi/pull/1721#issuecomment-648885633","issue_url":"https://api.github.com/repos/apache/hudi/issues/1721","id":648885633,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODg4NTYzMw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T15:18:02Z","updated_at":"2020-06-24T15:18:02Z","author_association":"MEMBER","body":"> Regarding sampling, what if some of the partitions are skewed? Will that cause more overhead than flush the file out?\r\n\r\nIIRC the partitionRecordKeyPairRDD would have even distribution of keys from the precombine step which just does a `reduceByKey`. We can always support a config to increase the sampling rate, right? All depends on how much difference there is in the computed parallelism with samplingRate=0.1 and 1.0?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648885633/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648886584","html_url":"https://github.com/apache/hudi/issues/1763#issuecomment-648886584","issue_url":"https://api.github.com/repos/apache/hudi/issues/1763","id":648886584,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODg4NjU4NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T15:19:39Z","updated_at":"2020-06-24T15:19:39Z","author_association":"MEMBER","body":"@venkee14 can you give 0.5.3 a shot? it has bunch of perf fixes that might help you.. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648886584/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648887040","html_url":"https://github.com/apache/hudi/issues/1723#issuecomment-648887040","issue_url":"https://api.github.com/repos/apache/hudi/issues/1723","id":648887040,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODg4NzA0MA==","user":{"login":"bobgalvao","id":56259791,"node_id":"MDQ6VXNlcjU2MjU5Nzkx","avatar_url":"https://avatars.githubusercontent.com/u/56259791?v=4","gravatar_id":"","url":"https://api.github.com/users/bobgalvao","html_url":"https://github.com/bobgalvao","followers_url":"https://api.github.com/users/bobgalvao/followers","following_url":"https://api.github.com/users/bobgalvao/following{/other_user}","gists_url":"https://api.github.com/users/bobgalvao/gists{/gist_id}","starred_url":"https://api.github.com/users/bobgalvao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bobgalvao/subscriptions","organizations_url":"https://api.github.com/users/bobgalvao/orgs","repos_url":"https://api.github.com/users/bobgalvao/repos","events_url":"https://api.github.com/users/bobgalvao/events{/privacy}","received_events_url":"https://api.github.com/users/bobgalvao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T15:20:29Z","updated_at":"2020-06-24T15:20:29Z","author_association":"NONE","body":"Hi,\r\nI performed the migration to version 0.5.2 and no longer got the errors.\r\nThanks for the support.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648887040/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648888320","html_url":"https://github.com/apache/hudi/issues/1723#issuecomment-648888320","issue_url":"https://api.github.com/repos/apache/hudi/issues/1723","id":648888320,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODg4ODMyMA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T15:22:40Z","updated_at":"2020-06-24T15:22:40Z","author_association":"MEMBER","body":"@bobgalvao we also have a 0.5.3 out, with a bunch of perf fixes.. Might be going there directly as we cook 0.6.0 :)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648888320/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648916677","html_url":"https://github.com/apache/hudi/issues/1763#issuecomment-648916677","issue_url":"https://api.github.com/repos/apache/hudi/issues/1763","id":648916677,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODkxNjY3Nw==","user":{"login":"venkee14","id":12746240,"node_id":"MDQ6VXNlcjEyNzQ2MjQw","avatar_url":"https://avatars.githubusercontent.com/u/12746240?v=4","gravatar_id":"","url":"https://api.github.com/users/venkee14","html_url":"https://github.com/venkee14","followers_url":"https://api.github.com/users/venkee14/followers","following_url":"https://api.github.com/users/venkee14/following{/other_user}","gists_url":"https://api.github.com/users/venkee14/gists{/gist_id}","starred_url":"https://api.github.com/users/venkee14/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/venkee14/subscriptions","organizations_url":"https://api.github.com/users/venkee14/orgs","repos_url":"https://api.github.com/users/venkee14/repos","events_url":"https://api.github.com/users/venkee14/events{/privacy}","received_events_url":"https://api.github.com/users/venkee14/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T16:10:45Z","updated_at":"2020-06-24T16:10:45Z","author_association":"NONE","body":"@vinothchandar : Thanks will try that and report back","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648916677/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648921677","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-648921677","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":648921677,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODkyMTY3Nw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T16:19:40Z","updated_at":"2020-06-24T16:19:40Z","author_association":"CONTRIBUTOR","body":"Thanks @zuyanton for reporting the issue. Regarding failed compaction jobs getting retried - As async compaction is the usual compaction mode run by users, we did not notice this earlier. Have created a patch to retry failed compactions first in inline compaction mode against 0.5.3 release.\r\n\r\nhttps://github.com/apache/hudi/pull/1765\r\n\r\n We will also fix this in 0.6.0.  Can you give this a try ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648921677/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648966026","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-648966026","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":648966026,"node_id":"MDEyOklzc3VlQ29tbWVudDY0ODk2NjAyNg==","user":{"login":"zuyanton","id":67354813,"node_id":"MDQ6VXNlcjY3MzU0ODEz","avatar_url":"https://avatars.githubusercontent.com/u/67354813?v=4","gravatar_id":"","url":"https://api.github.com/users/zuyanton","html_url":"https://github.com/zuyanton","followers_url":"https://api.github.com/users/zuyanton/followers","following_url":"https://api.github.com/users/zuyanton/following{/other_user}","gists_url":"https://api.github.com/users/zuyanton/gists{/gist_id}","starred_url":"https://api.github.com/users/zuyanton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zuyanton/subscriptions","organizations_url":"https://api.github.com/users/zuyanton/orgs","repos_url":"https://api.github.com/users/zuyanton/repos","events_url":"https://api.github.com/users/zuyanton/events{/privacy}","received_events_url":"https://api.github.com/users/zuyanton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T17:41:45Z","updated_at":"2020-06-24T17:41:45Z","author_association":"NONE","body":"Thank you for quick response.\r\n\r\n@vinothchandar  posting hoodie.properties file zipped. However when I open file on my end with sublime I only see bunch of hex numbers, not sure if thats how it supposed to be or its due to S3 encryption, let me know if you can make sense out of it.\r\n[hoodie.zip](https://github.com/apache/hudi/files/4826981/hoodie.zip) \r\n\r\nIn regards to increasing wait time for consistency checks - I dont think thats the issue. I think files are either never were there or they got deleted prior to compaction finalizing step. I created a bug report few days before [here](https://issues.apache.org/jira/browse/HUDI-1030) (I probably should have asked support first though). The same exception appears almost always when we try to bulk_import large amount of data. I was checking s3 location 10-20-40 minutes after failed import and files that Hudi tried to delete but failed never appeared in S3. So I strongly believe its not S3 taking too long to show up files.  \r\n\r\nto the second issue: let me test @bvaradar patch \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/648966026/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649085031","html_url":"https://github.com/apache/hudi/pull/1732#issuecomment-649085031","issue_url":"https://api.github.com/repos/apache/hudi/issues/1732","id":649085031,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTA4NTAzMQ==","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-24T21:33:55Z","updated_at":"2020-06-24T21:33:55Z","author_association":"MEMBER","body":"@shenh062326 would be nice to have this tested out in real setup..ignore if you already did it. thanks","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649085031/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649156492","html_url":"https://github.com/apache/hudi/pull/1484#issuecomment-649156492","issue_url":"https://api.github.com/repos/apache/hudi/issues/1484","id":649156492,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTE1NjQ5Mg==","user":{"login":"v3nkatesh","id":33071342,"node_id":"MDQ6VXNlcjMzMDcxMzQy","avatar_url":"https://avatars.githubusercontent.com/u/33071342?v=4","gravatar_id":"","url":"https://api.github.com/users/v3nkatesh","html_url":"https://github.com/v3nkatesh","followers_url":"https://api.github.com/users/v3nkatesh/followers","following_url":"https://api.github.com/users/v3nkatesh/following{/other_user}","gists_url":"https://api.github.com/users/v3nkatesh/gists{/gist_id}","starred_url":"https://api.github.com/users/v3nkatesh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/v3nkatesh/subscriptions","organizations_url":"https://api.github.com/users/v3nkatesh/orgs","repos_url":"https://api.github.com/users/v3nkatesh/repos","events_url":"https://api.github.com/users/v3nkatesh/events{/privacy}","received_events_url":"https://api.github.com/users/v3nkatesh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-25T01:16:35Z","updated_at":"2020-06-25T01:16:35Z","author_association":"CONTRIBUTOR","body":"> In any case, we need unit tests for the RateLimiter class..\r\n> Few alternatives ..\r\n> You can maintain the index outside Hudi (index classes are pluggable)\r\n> I can write the rate limiter for you and check it in..\r\n> \r\n> let's hash this out together :)\r\n\r\nThanks @vinothchandar. Reg. restrictions around guava makes sense. Would be great if you can check in a Rate limiter equivalent. Let me know if you don't have time for that in the near future.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649156492/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649189110","html_url":"https://github.com/apache/hudi/pull/1732#issuecomment-649189110","issue_url":"https://api.github.com/repos/apache/hudi/issues/1732","id":649189110,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTE4OTExMA==","user":{"login":"shenh062326","id":9527867,"node_id":"MDQ6VXNlcjk1Mjc4Njc=","avatar_url":"https://avatars.githubusercontent.com/u/9527867?v=4","gravatar_id":"","url":"https://api.github.com/users/shenh062326","html_url":"https://github.com/shenh062326","followers_url":"https://api.github.com/users/shenh062326/followers","following_url":"https://api.github.com/users/shenh062326/following{/other_user}","gists_url":"https://api.github.com/users/shenh062326/gists{/gist_id}","starred_url":"https://api.github.com/users/shenh062326/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shenh062326/subscriptions","organizations_url":"https://api.github.com/users/shenh062326/orgs","repos_url":"https://api.github.com/users/shenh062326/repos","events_url":"https://api.github.com/users/shenh062326/events{/privacy}","received_events_url":"https://api.github.com/users/shenh062326/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-25T03:15:18Z","updated_at":"2020-06-25T03:15:18Z","author_association":"CONTRIBUTOR","body":"> @shenh062326 would be nice to have this tested out in real setup..ignore if you already did it. thanks\r\n\r\nI have test it and it works.\r\n\r\n![image](https://user-images.githubusercontent.com/9527867/85649204-17189e00-b6d5-11ea-977e-e66dc615e64a.png)\r\n\r\n![image](https://user-images.githubusercontent.com/9527867/85649213-1bdd5200-b6d5-11ea-81ee-38c6ad0ee3f1.png)\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649189110/reactions","total_count":2,"+1":0,"-1":0,"laugh":0,"hooray":2,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649235630","html_url":"https://github.com/apache/hudi/pull/1722#issuecomment-649235630","issue_url":"https://api.github.com/repos/apache/hudi/issues/1722","id":649235630,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTIzNTYzMA==","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-25T05:53:54Z","updated_at":"2020-06-25T05:53:54Z","author_association":"MEMBER","body":"@vinothchandar Thanks for reviewing! I created tickets for the follow-up work. All the file listing and globing can be improved after @umehrot2 's PR merged. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649235630/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649509707","html_url":"https://github.com/apache/hudi/issues/1747#issuecomment-649509707","issue_url":"https://api.github.com/repos/apache/hudi/issues/1747","id":649509707,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTUwOTcwNw==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-25T12:27:06Z","updated_at":"2020-06-25T12:27:06Z","author_association":"CONTRIBUTOR","body":"Agreed @bvaradar .\r\n\r\n@masterlemmi  closing this task in favor of the Jira issue created here - https://issues.apache.org/jira/browse/HUDI-1053. Lets continue there. Feel free to add to that issue. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649509707/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649692074","html_url":"https://github.com/apache/hudi/pull/1704#issuecomment-649692074","issue_url":"https://api.github.com/repos/apache/hudi/issues/1704","id":649692074,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTY5MjA3NA==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-25T16:49:11Z","updated_at":"2020-06-25T16:49:11Z","author_association":"CONTRIBUTOR","body":"@n3nash  could you PTAL when you can ?\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649692074/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649754943","html_url":"https://github.com/apache/hudi/pull/1687#issuecomment-649754943","issue_url":"https://api.github.com/repos/apache/hudi/issues/1687","id":649754943,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTc1NDk0Mw==","user":{"login":"prashantwason","id":58448203,"node_id":"MDQ6VXNlcjU4NDQ4MjAz","avatar_url":"https://avatars.githubusercontent.com/u/58448203?v=4","gravatar_id":"","url":"https://api.github.com/users/prashantwason","html_url":"https://github.com/prashantwason","followers_url":"https://api.github.com/users/prashantwason/followers","following_url":"https://api.github.com/users/prashantwason/following{/other_user}","gists_url":"https://api.github.com/users/prashantwason/gists{/gist_id}","starred_url":"https://api.github.com/users/prashantwason/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashantwason/subscriptions","organizations_url":"https://api.github.com/users/prashantwason/orgs","repos_url":"https://api.github.com/users/prashantwason/repos","events_url":"https://api.github.com/users/prashantwason/events{/privacy}","received_events_url":"https://api.github.com/users/prashantwason/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-25T18:47:11Z","updated_at":"2020-06-25T18:47:11Z","author_association":"MEMBER","body":"> @prashantwason :  Can you confirm if all occurrences (including tests) are taken care of ?\r\n\r\nI have removed all hardcoded \".parquet\" references that I found from src code. I have not removed them from all the tests though as that will be another major task. We need to talk about parameterize the tests as required beforehand. \r\n\r\nWe can handle that in another issue?  \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649754943/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649914448","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-649914448","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":649914448,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTkxNDQ0OA==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T02:24:53Z","updated_at":"2020-06-26T02:24:53Z","author_association":"CONTRIBUTOR","body":"@vinothchandar @bvaradar looking at the logic we are forming the list of invalid data file paths to be deleted from the marker file paths. One possible reason that seems to me can be that marker file got created but corresponding data file was never written by spark because failure happened before the file was written. Now we are expecting that file to appear, but it was never created in the first place. Do you guys think its possible ? I will also dive more into the marker file code to understand.\r\n\r\nOn a similar note regarding handling of marker files, I have narrowed down some performance issues with S3 in the marker files clean up code. https://issues.apache.org/jira/browse/HUDI-1054 @zuyanton might be of interest to you.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649914448/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649925956","html_url":"https://github.com/apache/hudi/issues/1694#issuecomment-649925956","issue_url":"https://api.github.com/repos/apache/hudi/issues/1694","id":649925956,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTkyNTk1Ng==","user":{"login":"Raghvendradubey","id":16387812,"node_id":"MDQ6VXNlcjE2Mzg3ODEy","avatar_url":"https://avatars.githubusercontent.com/u/16387812?v=4","gravatar_id":"","url":"https://api.github.com/users/Raghvendradubey","html_url":"https://github.com/Raghvendradubey","followers_url":"https://api.github.com/users/Raghvendradubey/followers","following_url":"https://api.github.com/users/Raghvendradubey/following{/other_user}","gists_url":"https://api.github.com/users/Raghvendradubey/gists{/gist_id}","starred_url":"https://api.github.com/users/Raghvendradubey/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Raghvendradubey/subscriptions","organizations_url":"https://api.github.com/users/Raghvendradubey/orgs","repos_url":"https://api.github.com/users/Raghvendradubey/repos","events_url":"https://api.github.com/users/Raghvendradubey/events{/privacy}","received_events_url":"https://api.github.com/users/Raghvendradubey/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T02:57:30Z","updated_at":"2020-07-02T23:18:15Z","author_association":"NONE","body":"@vinothchandar I run the job with 5 min batch interval using MOR, now I can see commit duration are 5 min and compaction is also 5 min, and updated records are only 10% of total records written but now job is running with huge lag.\r\nsample commit are as below - \r\n\r\n```\r\n\r\n CommitTime      Total Bytes Written  Total Files Added  Total Files Updated  Total Partitions Written  Total Records Written  Total Update Records Written  Total Errors \r\n\r\n 20200625112117  178.0 MB             1                  3                    2                         193777                 18939                         0            \r\n\r\n 20200625111810  104.0 MB             0                  1                    1                         149946                 12619                         0            \r\n\r\n 20200625111610  211.7 MB             0                  3                    2                         259500                 14721                         0            \r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649925956/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649928569","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-649928569","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":649928569,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTkyODU2OQ==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T03:03:59Z","updated_at":"2020-06-26T03:03:59Z","author_association":"CONTRIBUTOR","body":"Wow, I just started running into this same issue as I was running performance tests for RFC-12 bootstrap implementation. cc @bvaradar \r\n```\r\norg.apache.hudi.exception.HoodieCommitException: Failed to complete commit 00000000000001 due to finalize errors.\r\n  at org.apache.hudi.table.action.commit.BaseCommitActionExecutor.finalizeWrite(BaseCommitActionExecutor.java:255)\r\n  at org.apache.hudi.table.action.commit.BaseCommitActionExecutor.commit(BaseCommitActionExecutor.java:216)\r\n  at org.apache.hudi.table.action.bootstrap.BootstrapCommitActionExecutor.commit(BootstrapCommitActionExecutor.java:205)\r\n  at org.apache.hudi.table.action.commit.BaseCommitActionExecutor.commitOnAutoCommit(BaseCommitActionExecutor.java:178)\r\n  at org.apache.hudi.table.action.commit.BaseCommitActionExecutor.updateIndexAndCommitIfNeeded(BaseCommitActionExecutor.java:172)\r\n  at org.apache.hudi.table.action.bootstrap.BootstrapCommitActionExecutor.metadataBootstrap(BootstrapCommitActionExecutor.java:178)\r\n  at org.apache.hudi.table.action.bootstrap.BootstrapCommitActionExecutor.execute(BootstrapCommitActionExecutor.java:136)\r\n  at org.apache.hudi.table.HoodieCopyOnWriteTable.bootstrap(HoodieCopyOnWriteTable.java:143)\r\n  at org.apache.hudi.client.HoodieWriteClient.bootstrap(HoodieWriteClient.java:158)\r\n  at org.apache.hudi.HoodieSparkSqlWriter$.bootstrap(HoodieSparkSqlWriter.scala:203)\r\n  at org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:139)\r\n  at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\r\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\r\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\r\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\r\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:173)\r\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:169)\r\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:197)\r\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:194)\r\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:169)\r\n  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:114)\r\n  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:112)\r\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\r\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\r\n  at org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$executeQuery$1(SQLExecution.scala:83)\r\n  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1$$anonfun$apply$1.apply(SQLExecution.scala:94)\r\n  at org.apache.spark.sql.execution.QueryExecutionMetrics$.withMetrics(QueryExecutionMetrics.scala:141)\r\n  at org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$withMetrics(SQLExecution.scala:178)\r\n  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:93)\r\n  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:200)\r\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:92)\r\n  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\r\n  at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\r\n  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\r\n  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\r\n  ... 49 elided\r\nCaused by: org.apache.hudi.exception.HoodieIOException: Consistency check failed to ensure all files APPEAR\r\n  at org.apache.hudi.table.HoodieTable.waitForAllFiles(HoodieTable.java:553)\r\n  at org.apache.hudi.table.HoodieTable.cleanFailedWrites(HoodieTable.java:495)\r\n  at org.apache.hudi.table.HoodieTable.finalizeWrite(HoodieTable.java:398)\r\n  at org.apache.hudi.table.action.commit.BaseCommitActionExecutor.finalizeWrite(BaseCommitActionExecutor.java:252)\r\n  ... 84 more\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649928569/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649930927","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-649930927","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":649930927,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTkzMDkyNw==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T03:10:30Z","updated_at":"2020-06-26T03:10:30Z","author_association":"CONTRIBUTOR","body":"I think my assumption is right. The root cause is S3 throttling that causes intermittent tasks to be failed and retried while writing the parquet files.\r\n\r\n```\r\n20/06/26 02:19:06 WARN TaskSetManager: Lost task 539.0 in stage 1.0 (TID 9300, ip-172-30-0-24.ec2.internal, executor 74): com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: FAE1300E894176E8; S3 Extended Request ID: y4HlnhS5ClPb+DlERbIYW4kGOa2EqP1Ghio0krjgu+dBhlgPzwhNRnN5OL8h9vCCLfaiv8/0HTk=), S3 Extended Request ID: y4HlnhS5ClPb+DlERbIYW4kGOa2EqP1Ghio0krjgu+dBhlgPzwhNRnN5OL8h9vCCLfaiv8/0HTk=\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1742)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleServiceErrorResponse(AmazonHttpClient.java:1371)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1347)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1127)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:784)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:752)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:726)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:686)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:668)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:532)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:512)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5052)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4998)\r\n\tat com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1335)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:22)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:8)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3.lite.executor.GlobalS3Executor.execute(GlobalS3Executor.java:114)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.invoke(AmazonS3LiteClient.java:189)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.invoke(AmazonS3LiteClient.java:184)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.getObjectMetadata(AmazonS3LiteClient.java:96)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3.lite.AbstractAmazonS3Lite.getObjectMetadata(AbstractAmazonS3Lite.java:43)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3n.Jets3tNativeFileSystemStore.getFileMetadataFromCacheOrS3(Jets3tNativeFileSystemStore.java:497)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3n.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:223)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.getFileStatus(S3NativeFileSystem.java:597)\r\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1440)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3.upload.plan.RegularUploadPlanner.checkExistenceIfNotOverwriting(RegularUploadPlanner.java:35)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3.upload.plan.RegularUploadPlanner.plan(RegularUploadPlanner.java:30)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3.upload.plan.UploadPlannerChain.plan(UploadPlannerChain.java:37)\r\n\tat com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.create(S3NativeFileSystem.java:433)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:932)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:913)\r\n\tat com.amazon.ws.emr.hadoop.fs.EmrFileSystem.create(EmrFileSystem.java:252)\r\n\tat org.apache.hudi.common.fs.HoodieWrapperFileSystem.create(HoodieWrapperFileSystem.java:221)\r\n\tat org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:74)\r\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:248)\r\n\tat org.apache.parquet.hadoop.ParquetWriter.<init>(ParquetWriter.java:280)\r\n\tat org.apache.parquet.hadoop.ParquetWriter.<init>(ParquetWriter.java:227)\r\n\tat org.apache.hudi.io.storage.HoodieParquetWriter.<init>(HoodieParquetWriter.java:59)\r\n\tat org.apache.hudi.io.storage.HoodieStorageWriterFactory.newParquetStorageWriter(HoodieStorageWriterFactory.java:67)\r\n\tat org.apache.hudi.io.storage.HoodieStorageWriterFactory.getStorageWriter(HoodieStorageWriterFactory.java:48)\r\n\tat org.apache.hudi.io.HoodieCreateHandle.<init>(HoodieCreateHandle.java:83)\r\n\tat org.apache.hudi.io.HoodieBootstrapHandle.<init>(HoodieBootstrapHandle.java:33)\r\n\tat org.apache.hudi.table.action.bootstrap.BootstrapCommitActionExecutor.handleMetadataBootstrap(BootstrapCommitActionExecutor.java:246)\r\n\tat org.apache.hudi.table.action.bootstrap.BootstrapCommitActionExecutor.lambda$runMetadataBootstrap$237db4ee$1(BootstrapCommitActionExecutor.java:345)\r\n\tat org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040)\r\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\r\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\r\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)\r\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1181)\r\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1155)\r\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1090)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1155)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:881)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:308)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nAs we can see that S3 throttled while trying to create the output parquet file, and hence it was not created in the first place. Later on when the same task was retried it succeeded. But from the previous retry we have a lingering `marker file` with no corresponding `parquet file`\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649930927/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649932495","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-649932495","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":649932495,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTkzMjQ5NQ==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T03:15:00Z","updated_at":"2020-06-26T03:15:19Z","author_association":"CONTRIBUTOR","body":"So this seems like a bug in Hudi. The simplest and reasonable solution seems to me to move `createMarkerFile` call after the `storageWriter` is instantiated so that we never create lingering marker files.\r\nhttps://github.com/apache/hudi/blob/master/hudi-client/src/main/java/org/apache/hudi/io/HoodieCreateHandle.java#L70\r\n\r\nI will make this change and test for my failing workload, and put up a PR if this seems fine. cc @vinothchandar","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649932495/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649994437","html_url":"https://github.com/apache/hudi/issues/1766#issuecomment-649994437","issue_url":"https://api.github.com/repos/apache/hudi/issues/1766","id":649994437,"node_id":"MDEyOklzc3VlQ29tbWVudDY0OTk5NDQzNw==","user":{"login":"RajasekarSribalan","id":22605603,"node_id":"MDQ6VXNlcjIyNjA1NjAz","avatar_url":"https://avatars.githubusercontent.com/u/22605603?v=4","gravatar_id":"","url":"https://api.github.com/users/RajasekarSribalan","html_url":"https://github.com/RajasekarSribalan","followers_url":"https://api.github.com/users/RajasekarSribalan/followers","following_url":"https://api.github.com/users/RajasekarSribalan/following{/other_user}","gists_url":"https://api.github.com/users/RajasekarSribalan/gists{/gist_id}","starred_url":"https://api.github.com/users/RajasekarSribalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RajasekarSribalan/subscriptions","organizations_url":"https://api.github.com/users/RajasekarSribalan/orgs","repos_url":"https://api.github.com/users/RajasekarSribalan/repos","events_url":"https://api.github.com/users/RajasekarSribalan/events{/privacy}","received_events_url":"https://api.github.com/users/RajasekarSribalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T06:15:12Z","updated_at":"2020-06-26T09:53:34Z","author_association":"NONE","body":"@vinothchandar @bvaradar  could you please help!\r\n\r\n\r\nAnd I am getting below error when querying from hive beeline.\r\n\r\n1) In below scenario\r\n\r\nset hive.input.format=org.apache.hudi.hadoop.hive.HoodieCombineHiveInputFormat;\r\n\r\n\r\nError: org.apache.hudi.hadoop.hive.HoodieCombineHiveInputFormat.pushProjectionsAndFilters(Lorg/apache/hadoop/mapred/JobConf;Ljava/lang/Class;Lorg/apache/hadoop/fs/Path;)V\r\n\r\n2) In below scenario\r\n\r\nset hive.input.format=org.apache.hudi.hadoop.HoodieParquetInputFormat;\r\n\r\nError :\r\n\r\n2020-06-26 09:50:19,231 FATAL [IPC Server handler 4 on 36657] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1592820090013_257670_m_000000_0 - exited : java.lang.IndexOutOfBoundsException: Index: 1, Size: 1\r\n\tat java.util.ArrayList.rangeCheck(ArrayList.java:653)\r\n\tat java.util.ArrayList.get(ArrayList.java:429)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.getProjectedGroupFields(DataWritableReadSupport.java:116)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.getSchemaByName(DataWritableReadSupport.java:176)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.init(DataWritableReadSupport.java:242)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.getSplit(ParquetRecordReaderWrapper.java:256)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.<init>(ParquetRecordReaderWrapper.java:95)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.<init>(ParquetRecordReaderWrapper.java:81)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat.getRecordReader(MapredParquetInputFormat.java:72)\r\n\tat org.apache.hudi.hadoop.HoodieParquetInputFormat.getRecordReader(HoodieParquetInputFormat.java:297)\r\n\tat org.apache.hadoop.mapred.MapTask$TrackedRecordReader.<init>(MapTask.java:169)\r\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:438)\r\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\r\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)\r\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\r\n\r\n2020-06-26 09:50:19,231 INFO [IPC Server handler 4 on 36657] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1592820090013_257670_m_000000_0: Error: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1\r\n\tat java.util.ArrayList.rangeCheck(ArrayList.java:653)\r\n\tat java.util.ArrayList.get(ArrayList.java:429)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.getProjectedGroupFields(DataWritableReadSupport.java:116)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.getSchemaByName(DataWritableReadSupport.java:176)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.init(DataWritableReadSupport.java:242)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.getSplit(ParquetRecordReaderWrapper.java:256)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.<init>(ParquetRecordReaderWrapper.java:95)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.<init>(ParquetRecordReaderWrapper.java:81)\r\n\tat org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat.getRecordReader(MapredParquetInputFormat.java:72)\r\n\tat org.apache.hudi.hadoop.HoodieParquetInputFormat.getRecordReader(HoodieParquetInputFormat.java:297)\r\n\tat org.apache.hadoop.mapred.MapTask$TrackedRecordReader.<init>(MapTask.java:169)\r\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:438)\r\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\r\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)\r\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/649994437/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650096565","html_url":"https://github.com/apache/hudi/pull/1756#issuecomment-650096565","issue_url":"https://api.github.com/repos/apache/hudi/issues/1756","id":650096565,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDA5NjU2NQ==","user":{"login":"lw309637554","id":8501994,"node_id":"MDQ6VXNlcjg1MDE5OTQ=","avatar_url":"https://avatars.githubusercontent.com/u/8501994?v=4","gravatar_id":"","url":"https://api.github.com/users/lw309637554","html_url":"https://github.com/lw309637554","followers_url":"https://api.github.com/users/lw309637554/followers","following_url":"https://api.github.com/users/lw309637554/following{/other_user}","gists_url":"https://api.github.com/users/lw309637554/gists{/gist_id}","starred_url":"https://api.github.com/users/lw309637554/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lw309637554/subscriptions","organizations_url":"https://api.github.com/users/lw309637554/orgs","repos_url":"https://api.github.com/users/lw309637554/repos","events_url":"https://api.github.com/users/lw309637554/events{/privacy}","received_events_url":"https://api.github.com/users/lw309637554/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T09:58:40Z","updated_at":"2020-06-28T03:30:09Z","author_association":"CONTRIBUTOR","body":"> Took a quick pass at the three test classes you have added.. LGTM .\r\n> Will do a detailed pass once you confirm PR is indeed ready..\r\n\r\n@vinothchandar helloi  have add more test for  end to end rollback. And the all hudi unit test passed.\r\nThere are a few questions to discuss with you:\r\n1.  for rollback successful commit, in HoodieWriteClient.java i remove the deleteMarkerDir() in postcommit when is in usingmarkers mode.   But it will double the file numbers in dfs. \r\n2. if the markers file retain, if we should clean it when the datafile is cleaned, also if we should archive the markers file when archiveCommitsWith\r\n\r\nif  these two question clear and solved, i think the patch will be ok .","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650096565/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650238181","html_url":"https://github.com/apache/hudi/issues/1586#issuecomment-650238181","issue_url":"https://api.github.com/repos/apache/hudi/issues/1586","id":650238181,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDIzODE4MQ==","user":{"login":"nandurj","id":67474555,"node_id":"MDQ6VXNlcjY3NDc0NTU1","avatar_url":"https://avatars.githubusercontent.com/u/67474555?v=4","gravatar_id":"","url":"https://api.github.com/users/nandurj","html_url":"https://github.com/nandurj","followers_url":"https://api.github.com/users/nandurj/followers","following_url":"https://api.github.com/users/nandurj/following{/other_user}","gists_url":"https://api.github.com/users/nandurj/gists{/gist_id}","starred_url":"https://api.github.com/users/nandurj/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nandurj/subscriptions","organizations_url":"https://api.github.com/users/nandurj/orgs","repos_url":"https://api.github.com/users/nandurj/repos","events_url":"https://api.github.com/users/nandurj/events{/privacy}","received_events_url":"https://api.github.com/users/nandurj/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T15:22:10Z","updated_at":"2020-06-26T15:22:10Z","author_association":"NONE","body":"We are still facing this issue after setting the hoodie.datasource.write.keygenerator.class=org.apache.hudi.keygen.ComplexKeyGenerator\r\nhoodie.datasource.write.recordkey.field=comma_seperated_list_of_primary_keys\r\n\r\nThe fist key is only considered as a recordkey.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650238181/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650243029","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-650243029","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":650243029,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDI0MzAyOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T15:30:58Z","updated_at":"2020-06-26T15:30:58Z","author_association":"MEMBER","body":"@umehrot2 if we reverse the order, then it might violate guarantee that if there was a file created in storage, then there is a marker file involved... the task can open a parquet file, and crash without writing a marker right?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650243029/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650338788","html_url":"https://github.com/apache/hudi/issues/1586#issuecomment-650338788","issue_url":"https://api.github.com/repos/apache/hudi/issues/1586","id":650338788,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDMzODc4OA==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T18:48:28Z","updated_at":"2020-06-26T18:48:28Z","author_association":"NONE","body":"@bvaradar pls reopen","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650338788/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650344638","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-650344638","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":650344638,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDM0NDYzOA==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T19:00:21Z","updated_at":"2020-06-26T19:00:21Z","author_association":"CONTRIBUTOR","body":"@vinothchandar Agreed, I realized this soon after so didn't proceed with this approach. I am just thinking if we really need to wait for all files to appear here, or even if we need to wait, if at the end of the wait period the file is not present it should be safe to assume that file never got created.\r\n\r\nAtleast for S3 I can say that it is eventually consistent in the order of few 100 milliseconds. If after waiting so much (7 consistency checks by default) the file is not present, we can assume that it was never created.\r\n\r\nAnother, approach can be that if parquet file didn't get created then we try to delete the marker file. But then again it can potentially fail to delete the marker as well.\r\n\r\nWe can possibly do a combination of both.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650344638/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650366410","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-650366410","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":650366410,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDM2NjQxMA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-26T19:48:00Z","updated_at":"2020-06-26T19:48:00Z","author_association":"MEMBER","body":">I am just thinking if we really need to wait for all files to appear here, or even if we need to wait, if at the end of the wait period the file is not present it should be safe to assume that file never got created.\r\n\r\nthe marker file being like a write ahead log for parquet file is probably a better design to keep.. In the case, that happy path of checking after 2000ms \r\n\r\n```\r\n  // time between successive attempts to ensure written data's metadata is consistent on storage\r\n  private static final String INITIAL_CONSISTENCY_CHECK_INTERVAL_MS_PROP =\r\n      \"hoodie.consistency.check.initial_interval_ms\";\r\n  private static long DEFAULT_INITIAL_CONSISTENCY_CHECK_INTERVAL_MS = 2000L;\r\n```\r\n\r\nshould succeed most of the time right - in just one attempt right? are you suggesting we don't even do this check to overcome the throttling issue","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650366410/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650472516","html_url":"https://github.com/apache/hudi/issues/1766#issuecomment-650472516","issue_url":"https://api.github.com/repos/apache/hudi/issues/1766","id":650472516,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDQ3MjUxNg==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-27T01:55:53Z","updated_at":"2020-06-27T01:55:53Z","author_association":"MEMBER","body":"@RajasekarSribalan  as you may have guessed the issue seems like the right input format not getting invoked. Hudi input formats filler for the latest parquet files after each commit. So when this is not happening query ends up reading all the files resulting in duplicates. \r\n\r\nWhats the version of hive you are trying to use? First error with combine input format seems like a jar mismatch issue \r\n\r\nThe second exception does seem to be coming from actual reading? Ie it called hoodieParquetInputFormat.getSplits properly and errors out trying to read parquet \r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650472516/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650472589","html_url":"https://github.com/apache/hudi/issues/1766#issuecomment-650472589","issue_url":"https://api.github.com/repos/apache/hudi/issues/1766","id":650472589,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDQ3MjU4OQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-27T01:56:49Z","updated_at":"2020-06-27T01:56:49Z","author_association":"MEMBER","body":"Are you getting this error consistently","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650472589/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650478776","html_url":"https://github.com/apache/hudi/issues/1764#issuecomment-650478776","issue_url":"https://api.github.com/repos/apache/hudi/issues/1764","id":650478776,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDQ3ODc3Ng==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-27T03:03:50Z","updated_at":"2020-06-27T03:03:50Z","author_association":"CONTRIBUTOR","body":"Actually this is not just a problem with `Throttling`. AWS S3 can throw intermittent `Throttling` and well as `Internal Errors` which can potentially succeed upon retrying.\r\n\r\nI wish we were able to use https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-s3-optimized-committer.html which solved a lot of the S3 related commit problems. The EMR file system will not commit the file until the spark task commit succeeds, essentially making this file commit atomic. Unfortunately, Hudi does not depend on sparks commit mechanisms to be able to leverage this.\r\n\r\nYes, I think waiting for 1 attempt and if it does not appear, just skipping (**and not failing the job**) it should work better as an interim solution given the current design of using marker files. @bvaradar also has some thoughts of improving this in the long run.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650478776/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650479862","html_url":"https://github.com/apache/hudi/pull/1768#issuecomment-650479862","issue_url":"https://api.github.com/repos/apache/hudi/issues/1768","id":650479862,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDQ3OTg2Mg==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-27T03:13:14Z","updated_at":"2020-06-27T03:13:14Z","author_association":"CONTRIBUTOR","body":"@bvaradar fyi","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650479862/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650487308","html_url":"https://github.com/apache/hudi/issues/1766#issuecomment-650487308","issue_url":"https://api.github.com/repos/apache/hudi/issues/1766","id":650487308,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDQ4NzMwOA==","user":{"login":"RajasekarSribalan","id":22605603,"node_id":"MDQ6VXNlcjIyNjA1NjAz","avatar_url":"https://avatars.githubusercontent.com/u/22605603?v=4","gravatar_id":"","url":"https://api.github.com/users/RajasekarSribalan","html_url":"https://github.com/RajasekarSribalan","followers_url":"https://api.github.com/users/RajasekarSribalan/followers","following_url":"https://api.github.com/users/RajasekarSribalan/following{/other_user}","gists_url":"https://api.github.com/users/RajasekarSribalan/gists{/gist_id}","starred_url":"https://api.github.com/users/RajasekarSribalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RajasekarSribalan/subscriptions","organizations_url":"https://api.github.com/users/RajasekarSribalan/orgs","repos_url":"https://api.github.com/users/RajasekarSribalan/repos","events_url":"https://api.github.com/users/RajasekarSribalan/events{/privacy}","received_events_url":"https://api.github.com/users/RajasekarSribalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-27T04:15:05Z","updated_at":"2020-06-27T04:15:05Z","author_association":"NONE","body":"@vinothchandar  Thanks for the quick response. Much appreciated.\r\n\r\nVersion details :\r\n\r\nHudi : 0.5.2\r\nHive version : hive-1.1.0+cdh5.12.2+1218\r\n\r\nI get these error consistently and even for non-Hudi hive tables I get these errors. \r\n\r\nI have the list of parquets correctly in the DFS and able to read via spark.\r\n\r\n\r\n ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650487308/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650524267","html_url":"https://github.com/apache/hudi/pull/1767#issuecomment-650524267","issue_url":"https://api.github.com/repos/apache/hudi/issues/1767","id":650524267,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDUyNDI2Nw==","user":{"login":"leesf","id":10128888,"node_id":"MDQ6VXNlcjEwMTI4ODg4","avatar_url":"https://avatars.githubusercontent.com/u/10128888?v=4","gravatar_id":"","url":"https://api.github.com/users/leesf","html_url":"https://github.com/leesf","followers_url":"https://api.github.com/users/leesf/followers","following_url":"https://api.github.com/users/leesf/following{/other_user}","gists_url":"https://api.github.com/users/leesf/gists{/gist_id}","starred_url":"https://api.github.com/users/leesf/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leesf/subscriptions","organizations_url":"https://api.github.com/users/leesf/orgs","repos_url":"https://api.github.com/users/leesf/repos","events_url":"https://api.github.com/users/leesf/events{/privacy}","received_events_url":"https://api.github.com/users/leesf/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-27T08:39:52Z","updated_at":"2020-06-27T08:39:52Z","author_association":"CONTRIBUTOR","body":"@xushiyan Could you please review this PR since you did the related work before.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650524267/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650534678","html_url":"https://github.com/apache/hudi/pull/1732#issuecomment-650534678","issue_url":"https://api.github.com/repos/apache/hudi/issues/1732","id":650534678,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDUzNDY3OA==","user":{"login":"shenh062326","id":9527867,"node_id":"MDQ6VXNlcjk1Mjc4Njc=","avatar_url":"https://avatars.githubusercontent.com/u/9527867?v=4","gravatar_id":"","url":"https://api.github.com/users/shenh062326","html_url":"https://github.com/shenh062326","followers_url":"https://api.github.com/users/shenh062326/followers","following_url":"https://api.github.com/users/shenh062326/following{/other_user}","gists_url":"https://api.github.com/users/shenh062326/gists{/gist_id}","starred_url":"https://api.github.com/users/shenh062326/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shenh062326/subscriptions","organizations_url":"https://api.github.com/users/shenh062326/orgs","repos_url":"https://api.github.com/users/shenh062326/repos","events_url":"https://api.github.com/users/shenh062326/events{/privacy}","received_events_url":"https://api.github.com/users/shenh062326/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-27T09:58:40Z","updated_at":"2020-06-27T09:58:40Z","author_association":"CONTRIBUTOR","body":"> @leesf Given the limited scope of the pr, can we try and avoid copying code from other places\r\n\r\nDone.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650534678/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650630601","html_url":"https://github.com/apache/hudi/pull/1558#issuecomment-650630601","issue_url":"https://api.github.com/repos/apache/hudi/issues/1558","id":650630601,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDYzMDYwMQ==","user":{"login":"pratyakshsharma","id":30863489,"node_id":"MDQ6VXNlcjMwODYzNDg5","avatar_url":"https://avatars.githubusercontent.com/u/30863489?v=4","gravatar_id":"","url":"https://api.github.com/users/pratyakshsharma","html_url":"https://github.com/pratyakshsharma","followers_url":"https://api.github.com/users/pratyakshsharma/followers","following_url":"https://api.github.com/users/pratyakshsharma/following{/other_user}","gists_url":"https://api.github.com/users/pratyakshsharma/gists{/gist_id}","starred_url":"https://api.github.com/users/pratyakshsharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pratyakshsharma/subscriptions","organizations_url":"https://api.github.com/users/pratyakshsharma/orgs","repos_url":"https://api.github.com/users/pratyakshsharma/repos","events_url":"https://api.github.com/users/pratyakshsharma/events{/privacy}","received_events_url":"https://api.github.com/users/pratyakshsharma/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-27T21:20:46Z","updated_at":"2020-06-27T21:20:46Z","author_association":"CONTRIBUTOR","body":"@yanghua Can we merge this now? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650630601/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650631076","html_url":"https://github.com/apache/hudi/pull/1433#issuecomment-650631076","issue_url":"https://api.github.com/repos/apache/hudi/issues/1433","id":650631076,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDYzMTA3Ng==","user":{"login":"pratyakshsharma","id":30863489,"node_id":"MDQ6VXNlcjMwODYzNDg5","avatar_url":"https://avatars.githubusercontent.com/u/30863489?v=4","gravatar_id":"","url":"https://api.github.com/users/pratyakshsharma","html_url":"https://github.com/pratyakshsharma","followers_url":"https://api.github.com/users/pratyakshsharma/followers","following_url":"https://api.github.com/users/pratyakshsharma/following{/other_user}","gists_url":"https://api.github.com/users/pratyakshsharma/gists{/gist_id}","starred_url":"https://api.github.com/users/pratyakshsharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pratyakshsharma/subscriptions","organizations_url":"https://api.github.com/users/pratyakshsharma/orgs","repos_url":"https://api.github.com/users/pratyakshsharma/repos","events_url":"https://api.github.com/users/pratyakshsharma/events{/privacy}","received_events_url":"https://api.github.com/users/pratyakshsharma/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-27T21:23:47Z","updated_at":"2020-06-27T21:23:47Z","author_association":"CONTRIBUTOR","body":"@nsivabalan can we merge this now? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650631076/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650631442","html_url":"https://github.com/apache/hudi/pull/1562#issuecomment-650631442","issue_url":"https://api.github.com/repos/apache/hudi/issues/1562","id":650631442,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDYzMTQ0Mg==","user":{"login":"pratyakshsharma","id":30863489,"node_id":"MDQ6VXNlcjMwODYzNDg5","avatar_url":"https://avatars.githubusercontent.com/u/30863489?v=4","gravatar_id":"","url":"https://api.github.com/users/pratyakshsharma","html_url":"https://github.com/pratyakshsharma","followers_url":"https://api.github.com/users/pratyakshsharma/followers","following_url":"https://api.github.com/users/pratyakshsharma/following{/other_user}","gists_url":"https://api.github.com/users/pratyakshsharma/gists{/gist_id}","starred_url":"https://api.github.com/users/pratyakshsharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pratyakshsharma/subscriptions","organizations_url":"https://api.github.com/users/pratyakshsharma/orgs","repos_url":"https://api.github.com/users/pratyakshsharma/repos","events_url":"https://api.github.com/users/pratyakshsharma/events{/privacy}","received_events_url":"https://api.github.com/users/pratyakshsharma/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-27T21:26:34Z","updated_at":"2020-06-27T21:26:34Z","author_association":"CONTRIBUTOR","body":"@n3nash @vinothchandar I guess we can merge this? :) ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650631442/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650673354","html_url":"https://github.com/apache/hudi/pull/1558#issuecomment-650673354","issue_url":"https://api.github.com/repos/apache/hudi/issues/1558","id":650673354,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDY3MzM1NA==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T02:20:41Z","updated_at":"2020-06-28T02:20:41Z","author_association":"CONTRIBUTOR","body":"> @yanghua Can we merge this now?\r\n\r\nWill review soon.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650673354/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650698829","html_url":"https://github.com/apache/hudi/pull/1767#issuecomment-650698829","issue_url":"https://api.github.com/repos/apache/hudi/issues/1767","id":650698829,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDY5ODgyOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T05:19:31Z","updated_at":"2020-06-28T05:19:31Z","author_association":"MEMBER","body":"@nsivabalan this is more than the 50 lines we agreed on for MINOR prefix. can you please file a JIRA and let me know if you think this quallifies for the MINOR prefix.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650698829/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650699549","html_url":"https://github.com/apache/hudi/pull/1512#issuecomment-650699549","issue_url":"https://api.github.com/repos/apache/hudi/issues/1512","id":650699549,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDY5OTU0OQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T05:28:37Z","updated_at":"2020-06-28T05:28:37Z","author_association":"MEMBER","body":"@prashantwason @bvaradar IIUC some of this PR overlaps with the changes you are making as well. can you both clarify so we can close or revive this as needed..  ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650699549/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650699629","html_url":"https://github.com/apache/hudi/pull/1100#issuecomment-650699629","issue_url":"https://api.github.com/repos/apache/hudi/issues/1100","id":650699629,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDY5OTYyOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T05:29:27Z","updated_at":"2020-06-28T05:29:27Z","author_association":"MEMBER","body":"@n3nash @yanghua do you mind me pushing some changes to this and land this?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650699629/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650699704","html_url":"https://github.com/apache/hudi/pull/1593#issuecomment-650699704","issue_url":"https://api.github.com/repos/apache/hudi/issues/1593","id":650699704,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDY5OTcwNA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T05:30:25Z","updated_at":"2020-06-28T05:30:25Z","author_association":"MEMBER","body":"Closing in favor of #1756 ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650699704/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650702037","html_url":"https://github.com/apache/hudi/pull/1100#issuecomment-650702037","issue_url":"https://api.github.com/repos/apache/hudi/issues/1100","id":650702037,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDcwMjAzNw==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T06:00:15Z","updated_at":"2020-06-28T06:00:15Z","author_association":"CONTRIBUTOR","body":"> @n3nash @yanghua do you mind me pushing some changes to this and land this?\r\n\r\nOf course No, please feel free to improve it.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650702037/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650703651","html_url":"https://github.com/apache/hudi/pull/1746#issuecomment-650703651","issue_url":"https://api.github.com/repos/apache/hudi/issues/1746","id":650703651,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDcwMzY1MQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T06:17:38Z","updated_at":"2020-06-28T06:17:38Z","author_association":"MEMBER","body":"I will take another pass at this once you rebase.. merged #1753 ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650703651/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650708997","html_url":"https://github.com/apache/hudi/issues/1766#issuecomment-650708997","issue_url":"https://api.github.com/repos/apache/hudi/issues/1766","id":650708997,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDcwODk5Nw==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T07:12:11Z","updated_at":"2020-06-28T07:12:11Z","author_association":"CONTRIBUTOR","body":"It is strange you are seeing this for Hudi and non Hudi tables. Could you try setting this config when querying Hive\r\n\r\n```set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat``` and check once?\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650708997/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650710398","html_url":"https://github.com/apache/hudi/pull/1512#issuecomment-650710398","issue_url":"https://api.github.com/repos/apache/hudi/issues/1512","id":650710398,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDcxMDM5OA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T07:24:30Z","updated_at":"2020-06-28T07:24:30Z","author_association":"CONTRIBUTOR","body":"yes @vinothchandar , this overlaps with PR-1687 which got merged. PR-1687 exposes setting base-file format through deltastreamer and spark data-source writer. \r\n\r\n @lamber-ken : Can you check current master branch and see if you still need any other functionality?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650710398/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650712662","html_url":"https://github.com/apache/hudi/issues/1766#issuecomment-650712662","issue_url":"https://api.github.com/repos/apache/hudi/issues/1766","id":650712662,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDcxMjY2Mg==","user":{"login":"RajasekarSribalan","id":22605603,"node_id":"MDQ6VXNlcjIyNjA1NjAz","avatar_url":"https://avatars.githubusercontent.com/u/22605603?v=4","gravatar_id":"","url":"https://api.github.com/users/RajasekarSribalan","html_url":"https://github.com/RajasekarSribalan","followers_url":"https://api.github.com/users/RajasekarSribalan/followers","following_url":"https://api.github.com/users/RajasekarSribalan/following{/other_user}","gists_url":"https://api.github.com/users/RajasekarSribalan/gists{/gist_id}","starred_url":"https://api.github.com/users/RajasekarSribalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RajasekarSribalan/subscriptions","organizations_url":"https://api.github.com/users/RajasekarSribalan/orgs","repos_url":"https://api.github.com/users/RajasekarSribalan/repos","events_url":"https://api.github.com/users/RajasekarSribalan/events{/privacy}","received_events_url":"https://api.github.com/users/RajasekarSribalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T07:45:38Z","updated_at":"2020-06-29T05:21:04Z","author_association":"NONE","body":"Thanks for your reply @bhasudha @vinothchandar \r\n\r\nI tried this setting as well but I get duplicate records when querying hudi\r\ntables... ideally it has to pick up only latest commit but it fetches all\r\nparquet and returns duplicate records.\r\n\r\nBut for non-hudi tables, below setting works fine.\r\n\r\nset hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat\r\n\r\nOn Sun, 28 Jun 2020, 12:42 pm Bhavani Sudha Saktheeswaran, <\r\nnotifications@github.com> wrote:\r\n\r\n> It is strange you are seeing this for Hudi and non Hudi tables. Could you\r\n> try setting this config when querying Hive\r\n>\r\n> set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat and\r\n> check once?\r\n>\r\n> \r\n> You are receiving this because you were mentioned.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/apache/hudi/issues/1766#issuecomment-650708997>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AFMO6I42ZJHBA4T2WLQF6NTRY3UNPANCNFSM4OIRVWCA>\r\n> .\r\n>\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650712662/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650728664","html_url":"https://github.com/apache/hudi/pull/1756#issuecomment-650728664","issue_url":"https://api.github.com/repos/apache/hudi/issues/1756","id":650728664,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDcyODY2NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T10:07:43Z","updated_at":"2020-06-28T10:07:43Z","author_association":"MEMBER","body":">for rollback successful commit, in HoodieWriteClient.java i remove the deleteMarkerDir() in postcommit when is in usingmarkers mode. But it will double the file numbers in dfs.\r\n\r\nI think delaying marker deletion till cleaning is probably ok. but the reconcilation with data files i.e the deletion of extraeneous data files written due to spark stage retries must be handled pre-commit.. \r\n\r\n>if the markers file retain, if we should clean it when the datafile is cleaned, also if we should archive the markers file when archiveCommitsWith\r\n\r\nthere is no need to archive teh marker files in my opinion.. the contract in Hudi is that once an instant leaves the active timeline, its effects are permanent on the table ... so if a rollback needs to happen based on marker files, then it needs to be within the retained commits for active timeline.. I think this is a practical approach.. \r\n\r\nthink of active timeline as the transaction log with pending actions/inflight/completed actions..","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650728664/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650732218","html_url":"https://github.com/apache/hudi/pull/1752#issuecomment-650732218","issue_url":"https://api.github.com/repos/apache/hudi/issues/1752","id":650732218,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDczMjIxOA==","user":{"login":"codecov-commenter","id":65553080,"node_id":"MDQ6VXNlcjY1NTUzMDgw","avatar_url":"https://avatars.githubusercontent.com/u/65553080?v=4","gravatar_id":"","url":"https://api.github.com/users/codecov-commenter","html_url":"https://github.com/codecov-commenter","followers_url":"https://api.github.com/users/codecov-commenter/followers","following_url":"https://api.github.com/users/codecov-commenter/following{/other_user}","gists_url":"https://api.github.com/users/codecov-commenter/gists{/gist_id}","starred_url":"https://api.github.com/users/codecov-commenter/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/codecov-commenter/subscriptions","organizations_url":"https://api.github.com/users/codecov-commenter/orgs","repos_url":"https://api.github.com/users/codecov-commenter/repos","events_url":"https://api.github.com/users/codecov-commenter/events{/privacy}","received_events_url":"https://api.github.com/users/codecov-commenter/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T10:39:57Z","updated_at":"2020-06-28T10:39:57Z","author_association":"NONE","body":"# [Codecov](https://codecov.io/gh/apache/hudi/pull/1752?src=pr&el=h1) Report\n> Merging [#1752](https://codecov.io/gh/apache/hudi/pull/1752?src=pr&el=desc) into [master](https://codecov.io/gh/apache/hudi/commit/8919be6a5d8038db7265bfd7459d72fbd545f133&el=desc) will **decrease** coverage by `2.86%`.\n> The diff coverage is `14.68%`.\n\n[![Impacted file tree graph](https://codecov.io/gh/apache/hudi/pull/1752/graphs/tree.svg?width=650&height=150&src=pr&token=VTTXabwbs2)](https://codecov.io/gh/apache/hudi/pull/1752?src=pr&el=tree)\n\n```diff\n@@             Coverage Diff              @@\n##             master    #1752      +/-   ##\n============================================\n- Coverage     62.82%   59.95%   -2.87%     \n- Complexity     3437     3609     +172     \n============================================\n  Files           401      439      +38     \n  Lines         17091    19088    +1997     \n  Branches       1698     1943     +245     \n============================================\n+ Hits          10737    11445     +708     \n- Misses         5623     6850    +1227     \n- Partials        731      793      +62     \n```\n\n| Flag | Coverage  | Complexity  | |\n|---|---|---|---|\n| #hudicli | `67.89% <0.00%> (?)` | `1430.00 <0.00> (?)` | |\n| #hudiclient | `78.35% <0.00%> (-0.89%)` | `1258.00 <0.00> ()` | |\n| #hudicommon | `54.29% <> (+0.04%)` | `1486.00 <> (+1.00)` | |\n| #hudihadoopmr | `39.36% <> ()` | `163.00 <> ()` | |\n| #hudihivesync | `72.25% <> ()` | `121.00 <> ()` | |\n| #hudispark | `41.54% <18.89%> (-2.69%)` | `78.00 <2.00> (+2.00)` | :arrow_down: |\n| #huditimelineservice | `63.47% <> ()` | `47.00 <> ()` | |\n| #hudiutilities | `73.49% <100.00%> (-0.27%)` | `284.00 <0.00> (-3.00)` | |\n\n| [Impacted Files](https://codecov.io/gh/apache/hudi/pull/1752?src=pr&el=tree) | Coverage  | Complexity  | |\n|---|---|---|---|\n| [...va/org/apache/hudi/async/AbstractAsyncService.java](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree#diff-aHVkaS1jbGllbnQvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvYXN5bmMvQWJzdHJhY3RBc3luY1NlcnZpY2UuamF2YQ==) | `2.17% <0.00%> (+0.04%)` | `1.00 <0.00> ()` | |\n| [...ava/org/apache/hudi/async/AsyncCompactService.java](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree#diff-aHVkaS1jbGllbnQvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvYXN5bmMvQXN5bmNDb21wYWN0U2VydmljZS5qYXZh) | `0.00% <0.00%> ()` | `0.00 <0.00> (?)` | |\n| [...rc/main/java/org/apache/hudi/client/Compactor.java](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree#diff-aHVkaS1jbGllbnQvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvY2xpZW50L0NvbXBhY3Rvci5qYXZh) | `0.00% <> ()` | `0.00 <0.00> (?)` | |\n| [.../hudi/async/SparkStreamingAsyncCompactService.java](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9hc3luYy9TcGFya1N0cmVhbWluZ0FzeW5jQ29tcGFjdFNlcnZpY2UuamF2YQ==) | `0.00% <0.00%> ()` | `0.00 <0.00> (?)` | |\n| [...di/async/SparkStreamingWriterActivityDetector.java](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9hc3luYy9TcGFya1N0cmVhbWluZ1dyaXRlckFjdGl2aXR5RGV0ZWN0b3IuamF2YQ==) | `0.00% <0.00%> ()` | `0.00 <0.00> (?)` | |\n| [...in/scala/org/apache/hudi/HoodieStreamingSink.scala](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay9zcmMvbWFpbi9zY2FsYS9vcmcvYXBhY2hlL2h1ZGkvSG9vZGllU3RyZWFtaW5nU2luay5zY2FsYQ==) | `0.00% <0.00%> ()` | `0.00 <0.00> ()` | |\n| [...tilities/deltastreamer/SchedulerConfGenerator.java](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree#diff-aHVkaS11dGlsaXRpZXMvc3JjL21haW4vamF2YS9vcmcvYXBhY2hlL2h1ZGkvdXRpbGl0aWVzL2RlbHRhc3RyZWFtZXIvU2NoZWR1bGVyQ29uZkdlbmVyYXRvci5qYXZh) | `90.90% <> ()` | `8.00 <0.00> ()` | |\n| [...n/scala/org/apache/hudi/HoodieSparkSqlWriter.scala](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay9zcmMvbWFpbi9zY2FsYS9vcmcvYXBhY2hlL2h1ZGkvSG9vZGllU3BhcmtTcWxXcml0ZXIuc2NhbGE=) | `53.60% <50.00%> (-1.16%)` | `0.00 <0.00> ()` | |\n| [...src/main/java/org/apache/hudi/DataSourceUtils.java](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay9zcmMvbWFpbi9qYXZhL29yZy9hcGFjaGUvaHVkaS9EYXRhU291cmNlVXRpbHMuamF2YQ==) | `54.90% <66.66%> (-0.10%)` | `27.00 <2.00> (+2.00)` | :arrow_down: |\n| [...main/scala/org/apache/hudi/DataSourceOptions.scala](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree#diff-aHVkaS1zcGFyay9zcmMvbWFpbi9zY2FsYS9vcmcvYXBhY2hlL2h1ZGkvRGF0YVNvdXJjZU9wdGlvbnMuc2NhbGE=) | `93.81% <100.00%> (+0.26%)` | `0.00 <0.00> ()` | |\n| ... and [41 more](https://codecov.io/gh/apache/hudi/pull/1752/diff?src=pr&el=tree-more) | |\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650732218/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650740750","html_url":"https://github.com/apache/hudi/pull/1650#issuecomment-650740750","issue_url":"https://api.github.com/repos/apache/hudi/issues/1650","id":650740750,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDc0MDc1MA==","user":{"login":"pratyakshsharma","id":30863489,"node_id":"MDQ6VXNlcjMwODYzNDg5","avatar_url":"https://avatars.githubusercontent.com/u/30863489?v=4","gravatar_id":"","url":"https://api.github.com/users/pratyakshsharma","html_url":"https://github.com/pratyakshsharma","followers_url":"https://api.github.com/users/pratyakshsharma/followers","following_url":"https://api.github.com/users/pratyakshsharma/following{/other_user}","gists_url":"https://api.github.com/users/pratyakshsharma/gists{/gist_id}","starred_url":"https://api.github.com/users/pratyakshsharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pratyakshsharma/subscriptions","organizations_url":"https://api.github.com/users/pratyakshsharma/orgs","repos_url":"https://api.github.com/users/pratyakshsharma/repos","events_url":"https://api.github.com/users/pratyakshsharma/events{/privacy}","received_events_url":"https://api.github.com/users/pratyakshsharma/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T11:53:28Z","updated_at":"2020-06-28T11:53:28Z","author_association":"CONTRIBUTOR","body":"@bvaradar please take a pass. I have added aliases in avro schema.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650740750/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650793135","html_url":"https://github.com/apache/hudi/pull/1767#issuecomment-650793135","issue_url":"https://api.github.com/repos/apache/hudi/issues/1767","id":650793135,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDc5MzEzNQ==","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T16:54:46Z","updated_at":"2020-06-28T16:54:46Z","author_association":"MEMBER","body":"> @xushiyan Could you please review this PR since you did the related work before.\r\n\r\n@leesf Yes I can look into this soon.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650793135/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650807492","html_url":"https://github.com/apache/hudi/pull/1746#issuecomment-650807492","issue_url":"https://api.github.com/repos/apache/hudi/issues/1746","id":650807492,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MDgwNzQ5Mg==","user":{"login":"xushiyan","id":2701446,"node_id":"MDQ6VXNlcjI3MDE0NDY=","avatar_url":"https://avatars.githubusercontent.com/u/2701446?v=4","gravatar_id":"","url":"https://api.github.com/users/xushiyan","html_url":"https://github.com/xushiyan","followers_url":"https://api.github.com/users/xushiyan/followers","following_url":"https://api.github.com/users/xushiyan/following{/other_user}","gists_url":"https://api.github.com/users/xushiyan/gists{/gist_id}","starred_url":"https://api.github.com/users/xushiyan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xushiyan/subscriptions","organizations_url":"https://api.github.com/users/xushiyan/orgs","repos_url":"https://api.github.com/users/xushiyan/repos","events_url":"https://api.github.com/users/xushiyan/events{/privacy}","received_events_url":"https://api.github.com/users/xushiyan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-28T18:59:34Z","updated_at":"2020-06-28T18:59:34Z","author_association":"MEMBER","body":"> I will take another pass at this once you rebase.. merged #1753\r\n\r\n@vinothchandar ok update the branch","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/650807492/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651199789","html_url":"https://github.com/apache/hudi/pull/1765#issuecomment-651199789","issue_url":"https://api.github.com/repos/apache/hudi/issues/1765","id":651199789,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTE5OTc4OQ==","user":{"login":"zuyanton","id":67354813,"node_id":"MDQ6VXNlcjY3MzU0ODEz","avatar_url":"https://avatars.githubusercontent.com/u/67354813?v=4","gravatar_id":"","url":"https://api.github.com/users/zuyanton","html_url":"https://github.com/zuyanton","followers_url":"https://api.github.com/users/zuyanton/followers","following_url":"https://api.github.com/users/zuyanton/following{/other_user}","gists_url":"https://api.github.com/users/zuyanton/gists{/gist_id}","starred_url":"https://api.github.com/users/zuyanton/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zuyanton/subscriptions","organizations_url":"https://api.github.com/users/zuyanton/orgs","repos_url":"https://api.github.com/users/zuyanton/repos","events_url":"https://api.github.com/users/zuyanton/events{/privacy}","received_events_url":"https://api.github.com/users/zuyanton/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-29T15:38:43Z","updated_at":"2020-06-29T15:38:43Z","author_association":"NONE","body":"I was running this bug fix on two large tables updated every 10 minutes for 3 days. I don't see any lingering  compactions that are INFLIGHT mode. also ran this code change on old table that already had several compactions stuck INFLIGHT, verified that lingering INFLIGHT compaction were restarted successfully ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651199789/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651281125","html_url":"https://github.com/apache/hudi/issues/1243#issuecomment-651281125","issue_url":"https://api.github.com/repos/apache/hudi/issues/1243","id":651281125,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTI4MTEyNQ==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-29T18:17:25Z","updated_at":"2020-06-29T18:38:32Z","author_association":"NONE","body":"i face this issue in 0.5.3, for my custom jar importing hudi-client it is bringing in hbase-client/hadoop* and then old avro 1.7\r\n\r\n\r\n\r\n[INFO] +- org.apache.hudi:hudi-client:jar:0.5.3:compile\r\n[INFO] |  +- (org.apache.hudi:hudi-common:jar:0.5.3:compile - omitted for duplicate)\r\n[INFO] |  +- org.apache.hudi:hudi-timeline-service:jar:0.5.3:compile\r\n[INFO] |  |  +- (org.apache.hudi:hudi-common:jar:0.5.3:compile - omitted for duplicate)\r\n[INFO] |  |  +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate)\r\n[INFO] |  |  +- (com.fasterxml.jackson.core:jackson-annotations:jar:2.6.7:compile - omitted for duplicate)\r\n[INFO] |  |  +- (com.fasterxml.jackson.core:jackson-core:jar:2.6.7:compile - omitted for duplicate)\r\n[INFO] |  |  +- (com.fasterxml.jackson.core:jackson-databind:jar:2.6.7.1:compile - omitted for conflict with 2.6.7.3)\r\n[INFO] |  |  +- (org.apache.httpcomponents:fluent-hc:jar:4.3.2:compile - omitted for duplicate)\r\n[INFO] |  |  +- io.javalin:javalin:jar:2.8.0:compile\r\n[INFO] |  |  |  +- org.jetbrains.kotlin:kotlin-stdlib-jdk8:jar:1.2.71:compile\r\n[INFO] |  |  |  |  +- org.jetbrains.kotlin:kotlin-stdlib:jar:1.2.71:compile\r\n[INFO] |  |  |  |  |  +- org.jetbrains.kotlin:kotlin-stdlib-common:jar:1.2.71:compile\r\n[INFO] |  |  |  |  |  \\- org.jetbrains:annotations:jar:13.0:compile\r\n[INFO] |  |  |  |  \\- org.jetbrains.kotlin:kotlin-stdlib-jdk7:jar:1.2.71:compile\r\n[INFO] |  |  |  |     \\- (org.jetbrains.kotlin:kotlin-stdlib:jar:1.2.71:compile - omitted for duplicate)\r\n[INFO] |  |  |  +- (org.slf4j:slf4j-api:jar:1.7.26:compile - omitted for conflict with 1.7.28)\r\n[INFO] |  |  |  +- org.eclipse.jetty:jetty-server:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |  |  +- javax.servlet:javax.servlet-api:jar:3.1.0:compile\r\n[INFO] |  |  |  |  +- org.eclipse.jetty:jetty-http:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |  |  |  +- org.eclipse.jetty:jetty-util:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |  |  |  \\- (org.eclipse.jetty:jetty-io:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |  |  \\- org.eclipse.jetty:jetty-io:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |  |     \\- (org.eclipse.jetty:jetty-util:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |  +- org.eclipse.jetty:jetty-webapp:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |  |  +- org.eclipse.jetty:jetty-xml:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |  |  |  \\- (org.eclipse.jetty:jetty-util:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |  |  \\- org.eclipse.jetty:jetty-servlet:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |  |     \\- org.eclipse.jetty:jetty-security:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |  |        \\- (org.eclipse.jetty:jetty-server:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |  \\- org.eclipse.jetty.websocket:websocket-server:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |     +- org.eclipse.jetty.websocket:websocket-common:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |     |  +- org.eclipse.jetty.websocket:websocket-api:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |     |  +- (org.eclipse.jetty:jetty-util:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |     |  \\- (org.eclipse.jetty:jetty-io:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |     +- org.eclipse.jetty.websocket:websocket-client:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |     |  +- org.eclipse.jetty:jetty-client:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |     |  |  +- (org.eclipse.jetty:jetty-http:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |     |  |  \\- (org.eclipse.jetty:jetty-io:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |     |  +- (org.eclipse.jetty:jetty-xml:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |     |  +- (org.eclipse.jetty:jetty-util:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |     |  +- (org.eclipse.jetty:jetty-io:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |     |  \\- (org.eclipse.jetty.websocket:websocket-common:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |     +- org.eclipse.jetty.websocket:websocket-servlet:jar:9.4.15.v20190215:compile\r\n[INFO] |  |  |     |  +- (org.eclipse.jetty.websocket:websocket-api:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |     |  \\- (javax.servlet:javax.servlet-api:jar:3.1.0:compile - omitted for duplicate)\r\n[INFO] |  |  |     +- (org.eclipse.jetty:jetty-servlet:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  |     \\- (org.eclipse.jetty:jetty-http:jar:9.4.15.v20190215:compile - omitted for duplicate)\r\n[INFO] |  |  +- (com.beust:jcommander:jar:1.72:compile - omitted for duplicate)\r\n[INFO] |  |  +- (org.rocksdb:rocksdbjni:jar:5.17.2:compile - omitted for duplicate)\r\n[INFO] |  |  \\- (org.apache.hadoop:hadoop-common:jar:tests:2.7.3:compile - omitted for duplicate)\r\n[INFO] |  +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate)\r\n[INFO] |  +- io.dropwizard.metrics:metrics-graphite:jar:4.1.1:compile\r\n[INFO] |  |  +- (io.dropwizard.metrics:metrics-core:jar:4.1.1:compile - omitted for duplicate)\r\n[INFO] |  |  \\- (org.slf4j:slf4j-api:jar:1.7.28:compile - omitted for conflict with 1.7.7)\r\n[INFO] |  +- io.dropwizard.metrics:metrics-core:jar:4.1.1:compile\r\n[INFO] |  |  \\- (org.slf4j:slf4j-api:jar:1.7.28:compile - omitted for duplicate)\r\n[INFO] |  +- org.apache.hadoop:hadoop-hdfs:jar:tests:2.7.3:compile\r\n[INFO] |  |  +- (com.google.guava:guava:jar:11.0.2:compile - omitted for duplicate)\r\n[INFO] |  |  +- (com.sun.jersey:jersey-core:jar:1.9:compile - omitted for duplicate)\r\n[INFO] |  |  +- (com.sun.jersey:jersey-server:jar:1.9:compile - omitted for duplicate)\r\n[INFO] |  |  +- (commons-cli:commons-cli:jar:1.2:compile - omitted for duplicate)\r\n[INFO] |  |  +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6)\r\n[INFO] |  |  +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate)\r\n[INFO] |  |  +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate)\r\n[INFO] |  |  +- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate)\r\n[INFO] |  |  +- (commons-daemon:commons-daemon:jar:1.0.13:compile - omitted for duplicate)\r\n[INFO] |  |  +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate)\r\n[INFO] |  |  +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate)\r\n[INFO] |  |  +- (org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile - omitted for duplicate)\r\n[INFO] |  |  +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile - omitted for duplicate)\r\n[INFO] |  |  +- (xmlenc:xmlenc:jar:0.52:compile - omitted for duplicate)\r\n[INFO] |  |  +- (io.netty:netty:jar:3.6.2.Final:compile - omitted for duplicate)\r\n[INFO] |  |  +- (io.netty:netty-all:jar:4.0.23.Final:compile - omitted for duplicate)\r\n[INFO] |  |  +- (xerces:xercesImpl:jar:2.9.1:compile - omitted for duplicate)\r\n[INFO] |  |  +- (org.apache.htrace:htrace-core:jar:3.1.0-incubating:compile - omitted for duplicate)\r\n[INFO] |  |  \\- (org.fusesource.leveldbjni:leveldbjni-all:jar:1.8:compile - omitted for duplicate)\r\n[INFO] |  +- org.apache.hadoop:hadoop-common:jar:tests:2.7.3:compile\r\n[INFO] |  |  +- org.apache.hadoop:hadoop-annotations:jar:2.7.3:compile\r\n[INFO] |  |  |  \\- jdk.tools:jdk.tools:jar:1.8:system\r\n[INFO] |  |  +- (com.google.guava:guava:jar:11.0.2:compile - omitted for duplicate)\r\n[INFO] |  |  +- (commons-cli:commons-cli:jar:1.2:compile - omitted for duplicate)\r\n[INFO] |  |  +- org.apache.commons:commons-math3:jar:3.1.1:compile\r\n[INFO] |  |  +- (xmlenc:xmlenc:jar:0.52:compile - omitted for duplicate)\r\n[INFO] |  |  +- commons-httpclient:commons-httpclient:jar:3.1:compile\r\n[INFO] |  |  |  +- (commons-logging:commons-logging:jar:1.0.4:compile - omitted for conflict with 1.1.3)\r\n[INFO] |  |  |  \\- (commons-codec:commons-codec:jar:1.2:compile - omitted for conflict with 1.6)\r\n[INFO] |  |  +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6)\r\n[INFO] |  |  +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate)\r\n[INFO] |  |  +- commons-net:commons-net:jar:3.1:compile\r\n[INFO] |  |  +- commons-collections:commons-collections:jar:3.2.2:compile\r\n[INFO] |  |  +- (com.sun.jersey:jersey-core:jar:1.9:compile - omitted for duplicate)\r\n[INFO] |  |  +- com.sun.jersey:jersey-json:jar:1.9:compile\r\n[INFO] |  |  |  +- org.codehaus.jettison:jettison:jar:1.1:compile\r\n[INFO] |  |  |  +- com.sun.xml.bind:jaxb-impl:jar:2.2.3-1:compile\r\n[INFO] |  |  |  |  \\- javax.xml.bind:jaxb-api:jar:2.2.2:compile\r\n[INFO] |  |  |  |     +- javax.xml.stream:stax-api:jar:1.0-2:compile\r\n[INFO] |  |  |  |     \\- (javax.activation:activation:jar:1.1:compile - omitted for duplicate)\r\n[INFO] |  |  |  +- (org.codehaus.jackson:jackson-core-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13)\r\n[INFO] |  |  |  +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13)\r\n[INFO] |  |  |  +- org.codehaus.jackson:jackson-jaxrs:jar:1.8.3:compile\r\n[INFO] |  |  |  |  +- (org.codehaus.jackson:jackson-core-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13)\r\n[INFO] |  |  |  |  \\- (org.codehaus.jackson:jackson-mapper-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13)\r\n[INFO] |  |  |  +- org.codehaus.jackson:jackson-xc:jar:1.8.3:compile\r\n[INFO] |  |  |  |  +- (org.codehaus.jackson:jackson-core-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13)\r\n[INFO] |  |  |  |  \\- (org.codehaus.jackson:jackson-mapper-asl:jar:1.8.3:compile - omitted for conflict with 1.9.13)\r\n[INFO] |  |  |  \\- (com.sun.jersey:jersey-core:jar:1.9:compile - omitted for duplicate)\r\n[INFO] |  |  +- (com.sun.jersey:jersey-server:jar:1.9:compile - omitted for duplicate)\r\n[INFO] |  |  +- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate)\r\n[INFO] |  |  +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate)\r\n[INFO] |  |  +- net.java.dev.jets3t:jets3t:jar:0.9.0:compile\r\n[INFO] |  |  |  +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6)\r\n[INFO] |  |  |  +- (commons-logging:commons-logging:jar:1.1.1:compile - omitted for conflict with 1.1.3)\r\n[INFO] |  |  |  +- (org.apache.httpcomponents:httpclient:jar:4.1.2:compile - omitted for conflict with 4.3.6)\r\n[INFO] |  |  |  +- (org.apache.httpcomponents:httpcore:jar:4.1.2:compile - omitted for conflict with 4.3.3)\r\n[INFO] |  |  |  \\- com.jamesmurty.utils:java-xmlbuilder:jar:0.4:compile\r\n[INFO] |  |  +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate)\r\n[INFO] |  |  +- commons-configuration:commons-configuration:jar:1.6:compile\r\n[INFO] |  |  |  +- (commons-collections:commons-collections:jar:3.2.1:compile - omitted for conflict with 3.2.2)\r\n[INFO] |  |  |  +- (commons-lang:commons-lang:jar:2.4:compile - omitted for conflict with 2.6)\r\n[INFO] |  |  |  +- (commons-logging:commons-logging:jar:1.1.1:compile - omitted for conflict with 1.1.3)\r\n[INFO] |  |  |  +- commons-digester:commons-digester:jar:1.8:compile\r\n[INFO] |  |  |  |  +- commons-beanutils:commons-beanutils:jar:1.7.0:compile\r\n[INFO] |  |  |  |  |  \\- (commons-logging:commons-logging:jar:1.0.3:compile - omitted for conflict with 1.1.3)\r\n[INFO] |  |  |  |  \\- (commons-logging:commons-logging:jar:1.1:compile - omitted for conflict with 1.1.3)\r\n[INFO] |  |  |  \\- commons-beanutils:commons-beanutils-core:jar:1.8.0:compile\r\n[INFO] |  |  |     \\- (commons-logging:commons-logging:jar:1.1.1:compile - omitted for conflict with 1.1.3)\r\n[INFO] |  |  +- (org.slf4j:slf4j-api:jar:1.7.10:compile - omitted for conflict with 1.7.28)\r\n[INFO] |  |  +- (org.slf4j:slf4j-log4j12:jar:1.7.10:compile - scope updated from runtime; omitted for duplicate)\r\n[INFO] |  |  +- (org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile - omitted for duplicate)\r\n[INFO] |  |  +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile - omitted for duplicate)\r\n[INFO] |  |  +- (org.apache.avro:avro:jar:1.7.4:compile - omitted for conflict with 1.8.2)\r\n[INFO] |  |  +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate)\r\n[INFO] |  |  +- com.google.code.gson:gson:jar:2.2.4:compile\r\n[INFO] |  |  +- org.apache.hadoop:hadoop-auth:jar:2.7.3:compile\r\n[INFO] |  |  |  +- (org.slf4j:slf4j-api:jar:1.7.10:compile - omitted for conflict with 1.7.28)\r\n[INFO] |  |  |  +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6)\r\n[INFO] |  |  |  +- (log4j:log4j:jar:1.2.17:runtime - omitted for duplicate)\r\n[INFO] |  |  |  +- (org.slf4j:slf4j-log4j12:jar:1.7.10:runtime - omitted for duplicate)\r\n[INFO] |  |  |  +- (org.apache.httpcomponents:httpclient:jar:4.2.5:compile - omitted for conflict with 4.3.6)\r\n[INFO] |  |  |  +- org.apache.directory.server:apacheds-kerberos-codec:jar:2.0.0-M15:compile\r\n[INFO] |  |  |  |  +- org.apache.directory.server:apacheds-i18n:jar:2.0.0-M15:compile\r\n[INFO] |  |  |  |  |  \\- (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28)\r\n[INFO] |  |  |  |  +- org.apache.directory.api:api-asn1-api:jar:1.0.0-M20:compile\r\n[INFO] |  |  |  |  |  \\- (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28)\r\n[INFO] |  |  |  |  +- org.apache.directory.api:api-util:jar:1.0.0-M20:compile\r\n[INFO] |  |  |  |  |  \\- (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28)\r\n[INFO] |  |  |  |  \\- (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28)\r\n[INFO] |  |  |  +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate)\r\n[INFO] |  |  |  \\- org.apache.curator:curator-framework:jar:2.7.1:compile\r\n[INFO] |  |  |     +- (org.apache.curator:curator-client:jar:2.7.1:compile - omitted for duplicate)\r\n[INFO] |  |  |     +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate)\r\n[INFO] |  |  |     \\- (com.google.guava:guava:jar:16.0.1:compile - omitted for conflict with 11.0.2)\r\n[INFO] |  |  +- com.jcraft:jsch:jar:0.1.42:compile\r\n[INFO] |  |  +- org.apache.curator:curator-client:jar:2.7.1:compile\r\n[INFO] |  |  |  +- (org.slf4j:slf4j-api:jar:1.7.6:compile - omitted for conflict with 1.7.28)\r\n[INFO] |  |  |  +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate)\r\n[INFO] |  |  |  \\- (com.google.guava:guava:jar:16.0.1:compile - omitted for conflict with 11.0.2)\r\n[INFO] |  |  +- org.apache.curator:curator-recipes:jar:2.7.1:compile\r\n[INFO] |  |  |  +- (org.apache.curator:curator-framework:jar:2.7.1:compile - omitted for duplicate)\r\n[INFO] |  |  |  +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate)\r\n[INFO] |  |  |  \\- (com.google.guava:guava:jar:16.0.1:compile - omitted for conflict with 11.0.2)\r\n[INFO] |  |  +- com.google.code.findbugs:jsr305:jar:3.0.0:compile\r\n[INFO] |  |  +- (org.apache.htrace:htrace-core:jar:3.1.0-incubating:compile - omitted for duplicate)\r\n[INFO] |  |  +- org.apache.zookeeper:zookeeper:jar:3.4.6:compile\r\n[INFO] |  |  |  +- (org.slf4j:slf4j-api:jar:1.6.1:compile - omitted for conflict with 1.7.28)\r\n[INFO] |  |  |  +- org.slf4j:slf4j-log4j12:jar:1.6.1:compile\r\n[INFO] |  |  |  |  +- (org.slf4j:slf4j-api:jar:1.6.1:compile - omitted for conflict with 1.7.28)\r\n[INFO] |  |  |  |  \\- (log4j:log4j:jar:1.2.16:compile - omitted for conflict with 1.2.17)\r\n[INFO] |  |  |  +- (log4j:log4j:jar:1.2.16:compile - omitted for conflict with 1.2.17)\r\n[INFO] |  |  |  \\- (io.netty:netty:jar:3.7.0.Final:compile - omitted for conflict with 3.6.2.Final)\r\n[INFO] |  |  \\- (org.apache.commons:commons-compress:jar:1.4.1:compile - omitted for conflict with 1.9)\r\n[INFO] |  \\- org.apache.hbase:hbase-client:jar:1.2.3:compile\r\n[INFO] |     +- org.apache.hbase:hbase-annotations:jar:1.2.3:compile\r\n[INFO] |     |  +- com.github.stephenc.findbugs:findbugs-annotations:jar:1.3.9-1:compile\r\n[INFO] |     |  +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate)\r\n[INFO] |     |  \\- (junit:junit:jar:4.12:compile - omitted for duplicate)\r\n[INFO] |     +- org.apache.hbase:hbase-common:jar:1.2.3:compile\r\n[INFO] |     |  +- (org.apache.hbase:hbase-protocol:jar:1.2.3:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.apache.hbase:hbase-annotations:jar:1.2.3:compile - omitted for duplicate)\r\n[INFO] |     |  +- (com.google.guava:guava:jar:12.0.1:compile - omitted for conflict with 11.0.2)\r\n[INFO] |     |  +- (commons-logging:commons-logging:jar:1.2:compile - omitted for conflict with 1.1.3)\r\n[INFO] |     |  +- (commons-codec:commons-codec:jar:1.9:compile - omitted for conflict with 1.6)\r\n[INFO] |     |  +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-collections:commons-collections:jar:3.2.2:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate)\r\n[INFO] |     |  +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.mortbay.jetty:jetty-util:jar:6.1.26:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.apache.htrace:htrace-core:jar:3.1.0-incubating:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.apache.hadoop:hadoop-common:jar:2.5.1:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.apache.hadoop:hadoop-mapreduce-client-core:jar:2.5.1:compile - omitted for duplicate)\r\n[INFO] |     |  +- (com.github.stephenc.findbugs:findbugs-annotations:jar:1.3.9-1:compile - omitted for duplicate)\r\n[INFO] |     |  +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate)\r\n[INFO] |     |  \\- (junit:junit:jar:4.12:compile - omitted for duplicate)\r\n[INFO] |     +- org.apache.hbase:hbase-protocol:jar:1.2.3:compile\r\n[INFO] |     |  +- (org.apache.hbase:hbase-annotations:jar:1.2.3:compile - omitted for duplicate)\r\n[INFO] |     |  +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-logging:commons-logging:jar:1.2:compile - omitted for conflict with 1.1.3)\r\n[INFO] |     |  +- (com.github.stephenc.findbugs:findbugs-annotations:jar:1.3.9-1:compile - omitted for duplicate)\r\n[INFO] |     |  +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate)\r\n[INFO] |     |  \\- (junit:junit:jar:4.12:compile - omitted for duplicate)\r\n[INFO] |     +- (commons-codec:commons-codec:jar:1.9:compile - omitted for conflict with 1.6)\r\n[INFO] |     +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate)\r\n[INFO] |     +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate)\r\n[INFO] |     +- (commons-logging:commons-logging:jar:1.2:compile - omitted for conflict with 1.1.3)\r\n[INFO] |     +- (com.google.guava:guava:jar:12.0.1:compile - omitted for conflict with 11.0.2)\r\n[INFO] |     +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate)\r\n[INFO] |     +- (io.netty:netty-all:jar:4.0.23.Final:compile - omitted for duplicate)\r\n[INFO] |     +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate)\r\n[INFO] |     +- (org.apache.htrace:htrace-core:jar:3.1.0-incubating:compile - omitted for duplicate)\r\n[INFO] |     +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile - omitted for duplicate)\r\n[INFO] |     +- org.jruby.jcodings:jcodings:jar:1.0.8:compile\r\n[INFO] |     +- org.jruby.joni:joni:jar:2.1.2:compile\r\n[INFO] |     |  \\- (org.jruby.jcodings:jcodings:jar:1.0.8:compile - omitted for duplicate)\r\n[INFO] |     +- com.yammer.metrics:metrics-core:jar:2.2.0:compile\r\n[INFO] |     |  \\- (org.slf4j:slf4j-api:jar:1.7.2:compile - omitted for conflict with 1.7.28)\r\n[INFO] |     +- (org.apache.hadoop:hadoop-auth:jar:2.5.1:compile - omitted for conflict with 2.7.3)\r\n[INFO] |     +- org.apache.hadoop:hadoop-common:jar:2.5.1:compile\r\n[INFO] |     |  +- (org.apache.hadoop:hadoop-annotations:jar:2.5.1:compile - omitted for conflict with 2.7.3)\r\n[INFO] |     |  +- (com.google.guava:guava:jar:11.0.2:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-cli:commons-cli:jar:1.2:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.apache.commons:commons-math3:jar:3.1.1:compile - omitted for duplicate)\r\n[INFO] |     |  +- (xmlenc:xmlenc:jar:0.52:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-httpclient:commons-httpclient:jar:3.1:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6)\r\n[INFO] |     |  +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-net:commons-net:jar:3.1:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-collections:commons-collections:jar:3.2.1:compile - omitted for conflict with 3.2.2)\r\n[INFO] |     |  +- (org.mortbay.jetty:jetty-util:jar:6.1.26:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-el:commons-el:jar:1.0:compile - scope updated from runtime; omitted for duplicate)\r\n[INFO] |     |  +- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate)\r\n[INFO] |     |  +- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate)\r\n[INFO] |     |  +- (commons-configuration:commons-configuration:jar:1.6:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28)\r\n[INFO] |     |  +- (org.slf4j:slf4j-log4j12:jar:1.7.5:runtime - omitted for conflict with 1.6.1)\r\n[INFO] |     |  +- (org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.apache.avro:avro:jar:1.7.4:compile - omitted for duplicate)\r\n[INFO] |     |  +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.apache.hadoop:hadoop-auth:jar:2.5.1:compile - omitted for conflict with 2.7.3)\r\n[INFO] |     |  +- (com.jcraft:jsch:jar:0.1.42:compile - omitted for duplicate)\r\n[INFO] |     |  +- (com.google.code.findbugs:jsr305:jar:1.3.9:compile - omitted for conflict with 3.0.0)\r\n[INFO] |     |  +- (org.apache.zookeeper:zookeeper:jar:3.4.6:compile - omitted for duplicate)\r\n[INFO] |     |  \\- (org.apache.commons:commons-compress:jar:1.4.1:compile - omitted for duplicate)\r\n[INFO] |     +- org.apache.hadoop:hadoop-mapreduce-client-core:jar:2.5.1:compile\r\n[INFO] |     |  +- org.apache.hadoop:hadoop-yarn-common:jar:2.5.1:compile\r\n[INFO] |     |  |  +- org.apache.hadoop:hadoop-yarn-api:jar:2.5.1:compile\r\n[INFO] |     |  |  |  +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate)\r\n[INFO] |     |  |  |  +- (com.google.guava:guava:jar:11.0.2:compile - omitted for duplicate)\r\n[INFO] |     |  |  |  +- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate)\r\n[INFO] |     |  |  |  +- (org.apache.hadoop:hadoop-annotations:jar:2.5.1:compile - omitted for conflict with 2.7.3)\r\n[INFO] |     |  |  |  \\- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate)\r\n[INFO] |     |  |  +- (javax.xml.bind:jaxb-api:jar:2.2.2:compile - omitted for duplicate)\r\n[INFO] |     |  |  +- (org.apache.commons:commons-compress:jar:1.4.1:compile - omitted for duplicate)\r\n[INFO] |     |  |  +- (commons-lang:commons-lang:jar:2.6:compile - omitted for duplicate)\r\n[INFO] |     |  |  +- (commons-codec:commons-codec:jar:1.4:compile - omitted for conflict with 1.6)\r\n[INFO] |     |  |  +- (org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile - omitted for duplicate)\r\n[INFO] |     |  |  +- (org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile - omitted for duplicate)\r\n[INFO] |     |  |  +- (com.google.guava:guava:jar:11.0.2:compile - omitted for duplicate)\r\n[INFO] |     |  |  +- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate)\r\n[INFO] |     |  |  +- (commons-cli:commons-cli:jar:1.2:compile - omitted for duplicate)\r\n[INFO] |     |  |  +- (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28)\r\n[INFO] |     |  |  +- (org.apache.hadoop:hadoop-annotations:jar:2.5.1:compile - omitted for conflict with 2.7.3)\r\n[INFO] |     |  |  +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate)\r\n[INFO] |     |  |  +- (commons-io:commons-io:jar:2.4:compile - omitted for duplicate)\r\n[INFO] |     |  |  \\- (log4j:log4j:jar:1.2.17:compile - omitted for duplicate)\r\n[INFO] |     |  +- (com.google.protobuf:protobuf-java:jar:2.5.0:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.apache.avro:avro:jar:1.7.4:compile - omitted for duplicate)\r\n[INFO] |     |  +- (org.slf4j:slf4j-api:jar:1.7.5:compile - omitted for conflict with 1.7.28)\r\n[INFO] |     |  +- (org.slf4j:slf4j-log4j12:jar:1.7.5:compile - omitted for conflict with 1.6.1)\r\n[INFO] |     |  +- (org.apache.hadoop:hadoop-annotations:jar:2.5.1:compile - omitted for conflict with 2.7.3)\r\n[INFO] |     |  \\- (io.netty:netty:jar:3.6.2.Final:compile - omitted for duplicate)\r\n[INFO] |     \\- (junit:junit:jar:4.12:compile - omitted for duplicate)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651281125/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651401043","html_url":"https://github.com/apache/hudi/pull/1702#issuecomment-651401043","issue_url":"https://api.github.com/repos/apache/hudi/issues/1702","id":651401043,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTQwMTA0Mw==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-29T22:22:20Z","updated_at":"2020-06-29T22:22:20Z","author_association":"CONTRIBUTOR","body":"> @umehrot2 does this PR some of @bvaradar 's changes included?\r\n\r\n@vinothchandar yes it does. I had put some stuff in just for ease of reviewing becuase this utilizes some of the core changes that @bvaradar has done. If that is creating confusion I can get rid of it.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651401043/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651401659","html_url":"https://github.com/apache/hudi/pull/1702#issuecomment-651401659","issue_url":"https://api.github.com/repos/apache/hudi/issues/1702","id":651401659,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTQwMTY1OQ==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-29T22:24:11Z","updated_at":"2020-06-29T22:24:11Z","author_association":"CONTRIBUTOR","body":"@garyli1019 thank you for your inputs. Sorry, I had been busy with oncall and other projects. Let me try to catch up and process your comments.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651401659/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651535976","html_url":"https://github.com/apache/hudi/issues/1773#issuecomment-651535976","issue_url":"https://api.github.com/repos/apache/hudi/issues/1773","id":651535976,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTUzNTk3Ng==","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-30T04:59:50Z","updated_at":"2020-06-30T04:59:50Z","author_association":"MEMBER","body":"Hi, would you share more info about this issue? Stack tracing and your Hudi config will help.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651535976/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651537179","html_url":"https://github.com/apache/hudi/issues/1771#issuecomment-651537179","issue_url":"https://api.github.com/repos/apache/hudi/issues/1771","id":651537179,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTUzNzE3OQ==","user":{"login":"garyli1019","id":23007841,"node_id":"MDQ6VXNlcjIzMDA3ODQx","avatar_url":"https://avatars.githubusercontent.com/u/23007841?v=4","gravatar_id":"","url":"https://api.github.com/users/garyli1019","html_url":"https://github.com/garyli1019","followers_url":"https://api.github.com/users/garyli1019/followers","following_url":"https://api.github.com/users/garyli1019/following{/other_user}","gists_url":"https://api.github.com/users/garyli1019/gists{/gist_id}","starred_url":"https://api.github.com/users/garyli1019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/garyli1019/subscriptions","organizations_url":"https://api.github.com/users/garyli1019/orgs","repos_url":"https://api.github.com/users/garyli1019/repos","events_url":"https://api.github.com/users/garyli1019/events{/privacy}","received_events_url":"https://api.github.com/users/garyli1019/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-30T05:03:18Z","updated_at":"2020-06-30T05:03:18Z","author_association":"MEMBER","body":"this answer prob help. https://github.com/apache/hudi/issues/1745#issuecomment-646581422","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651537179/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651716297","html_url":"https://github.com/apache/hudi/pull/1702#issuecomment-651716297","issue_url":"https://api.github.com/repos/apache/hudi/issues/1702","id":651716297,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTcxNjI5Nw==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-30T10:46:59Z","updated_at":"2020-06-30T10:46:59Z","author_association":"CONTRIBUTOR","body":"> Hi @umehrot2 , very clean work  ! I walked through this PR and found some common places we can share.\r\n> \r\n>     * Path filtering.\r\n> \r\n>     * User input paths handling and blob pattern.\r\n> \r\n>     * Schema provider.\r\n> \r\n> \r\n> I have a few questions.\r\n> \r\n> How should we define the user interface?\r\n> Soon, we will have Bootstrap view, read optimized view, snapshot(realtime) view, incremental view. I am wondering we should unified the query interface and handle all the file formats internally. How about this:\r\n> Snapshot view: Bootstrap files + non-hudi files + hudi files + hudi log\r\n> Read optimized: Bootstrap files + non-hudi files + hudi files\r\n> Incremental: incremental view on top of snapshot\r\n> \r\n> How should we split the filegroups?\r\n> Right now we already have 4 different filegroups. Once we add ORC support, there will be more. One of the cleanest ways I could find is to read each filegroup into RDD independently then union them together. In the current version of this PR, we handle regular parquet in `HudiBootstrapRDD`. The two disadvantages I could see:\r\n> \r\n>     * After we add ORC support, the complexity of this RDD would increase if we handle the ORC reading here too.\r\n> \r\n>     * IIUC, we didn't take the full advantage of the vectorized reader by using `ColumnBatch` directly. Merging probably requires reading row by row, but for regular parquet files, we can use the default parquet reader.\r\n> \r\n> \r\n> If we can find a way to efficiently listing files in the driver, I think we can separate the bootstrap files from regular parquet and only use the `BootstrapRDD` to handle the files that need to be merged. Happy to discuss more here.\r\n\r\nThanks @garyli1019 for your review and bringing some interesting points.\r\n\r\nYes, I think the pieces you mentioned can be used by you later for the MOR datasource work.\r\n\r\nRegarding the user interface for the query your proposal makes sense to me in general. We can may be have it flushed out in more detail once our PRs are merged and happy to collaborate on that.\r\n\r\nRegarding your suggestion about using `sparks regular parquet reader` for regular hudi files and doing a `union` with bootstrapped files:\r\n- Complexity after ORC comes in: The current implementation is not very tightly coupled with parquet. IIUC for this implementation it should just be matter of initializing the readers with OrcFileFormat instead of ParquetFileFormat which shouldn't make life difficult. Happy to hear your thoughts.\r\n\r\n- Full advantage of Vectorized Reader: I think I answered this in another comment you posted. At this point I need to do more research and gather datapoints if it is not utilizing `100%` of the advantages of `vectorized reading`. What I know for sure that the data from the file is read in a batch. Now, if I am loosing some performance in doing a row iteration over that batch I am not sure. But I believe spark regular readers, must be doing the batch to row conversion at some point of time. If you have more details on how spark does this, do let me know as it will be of great help. I will do some more research on this as well.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651716297/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651718529","html_url":"https://github.com/apache/hudi/issues/1243#issuecomment-651718529","issue_url":"https://api.github.com/repos/apache/hudi/issues/1243","id":651718529,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTcxODUyOQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-30T10:52:46Z","updated_at":"2020-06-30T10:52:46Z","author_association":"MEMBER","body":"@tooptoop4 trying to understand .. can you give us a set of reproducible steps? for e.g on the docker demo setup or somewhere we can repro and try? Guess hbase is being brought in due to HBaseIndex? @n3nash any pointers here, given you deal with `hudi-client` dependency on a daily basis as well?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651718529/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651719069","html_url":"https://github.com/apache/hudi/pull/1765#issuecomment-651719069","issue_url":"https://api.github.com/repos/apache/hudi/issues/1765","id":651719069,"node_id":"MDEyOklzc3VlQ29tbWVudDY1MTcxOTA2OQ==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-06-30T10:54:05Z","updated_at":"2020-06-30T10:54:05Z","author_association":"MEMBER","body":"@zuyanton This is great.. Thanks for testing it out.. We will work on getting this landed onto master first.. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/651719069/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]