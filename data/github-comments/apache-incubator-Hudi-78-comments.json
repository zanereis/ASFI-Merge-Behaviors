[{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679264433","html_url":"https://github.com/apache/hudi/issues/2001#issuecomment-679264433","issue_url":"https://api.github.com/repos/apache/hudi/issues/2001","id":679264433,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTI2NDQzMw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T17:30:51Z","updated_at":"2020-08-24T17:30:51Z","author_association":"CONTRIBUTOR","body":"Can you turn on INFO level logs and attach the logs to debug this ?\r\n\r\nThanks,\r\nBalaji.V","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679264433/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679264539","html_url":"https://github.com/apache/hudi/issues/2007#issuecomment-679264539","issue_url":"https://api.github.com/repos/apache/hudi/issues/2007","id":679264539,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTI2NDUzOQ==","user":{"login":"ashishmgofficial","id":40498599,"node_id":"MDQ6VXNlcjQwNDk4NTk5","avatar_url":"https://avatars.githubusercontent.com/u/40498599?v=4","gravatar_id":"","url":"https://api.github.com/users/ashishmgofficial","html_url":"https://github.com/ashishmgofficial","followers_url":"https://api.github.com/users/ashishmgofficial/followers","following_url":"https://api.github.com/users/ashishmgofficial/following{/other_user}","gists_url":"https://api.github.com/users/ashishmgofficial/gists{/gist_id}","starred_url":"https://api.github.com/users/ashishmgofficial/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ashishmgofficial/subscriptions","organizations_url":"https://api.github.com/users/ashishmgofficial/orgs","repos_url":"https://api.github.com/users/ashishmgofficial/repos","events_url":"https://api.github.com/users/ashishmgofficial/events{/privacy}","received_events_url":"https://api.github.com/users/ashishmgofficial/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T17:31:06Z","updated_at":"2020-08-24T17:31:06Z","author_association":"NONE","body":"Our exact process is that, \n\n-  We have a Kafka Topic producing data\n-  Target is Ceph object store\n\nSo, we need timeline data like\n\n-  Source Topic\n-  Target Hudi Table on Ceph\n-  Other details like timestamp related, size etc\n\nAnother Query is that , does hudi currently support, exporting this data from Hive CLI to some other database or as Files?\n\nAlso, other than CLI , is any sorts of APIs are exposed for retrieving these data programattically?\n ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679264539/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679275414","html_url":"https://github.com/apache/hudi/issues/2002#issuecomment-679275414","issue_url":"https://api.github.com/repos/apache/hudi/issues/2002","id":679275414,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTI3NTQxNA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T17:53:34Z","updated_at":"2020-08-24T17:53:34Z","author_association":"CONTRIBUTOR","body":"@jpugliesi : It looks like 2nd and 3rd upsert updated the same set of records (generateUpdates()). In this case, all those records will be updated with latest commit time and incremental query will only show the commit time of 3rd upsert. Hope, this is clear. Please reopen if this does not make sense to you.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679275414/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679276189","html_url":"https://github.com/apache/hudi/issues/1947#issuecomment-679276189","issue_url":"https://api.github.com/repos/apache/hudi/issues/1947","id":679276189,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTI3NjE4OQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T17:55:12Z","updated_at":"2020-08-24T17:55:12Z","author_association":"CONTRIBUTOR","body":"@cun123 : Please reopen if the suggestion @xushiyan  did not work.\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679276189/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679298263","html_url":"https://github.com/apache/hudi/pull/1964#issuecomment-679298263","issue_url":"https://api.github.com/repos/apache/hudi/issues/1964","id":679298263,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTI5ODI2Mw==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T18:41:22Z","updated_at":"2020-08-24T18:41:22Z","author_association":"CONTRIBUTOR","body":"Could we structure this as a \"BaseTableMetaClient\", \"HoodieTableMetaClient\" and \"HoodieTableIncrementalMetaClient\" ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679298263/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679298548","html_url":"https://github.com/apache/hudi/issues/2002#issuecomment-679298548","issue_url":"https://api.github.com/repos/apache/hudi/issues/2002","id":679298548,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTI5ODU0OA==","user":{"login":"jpugliesi","id":2141170,"node_id":"MDQ6VXNlcjIxNDExNzA=","avatar_url":"https://avatars.githubusercontent.com/u/2141170?v=4","gravatar_id":"","url":"https://api.github.com/users/jpugliesi","html_url":"https://github.com/jpugliesi","followers_url":"https://api.github.com/users/jpugliesi/followers","following_url":"https://api.github.com/users/jpugliesi/following{/other_user}","gists_url":"https://api.github.com/users/jpugliesi/gists{/gist_id}","starred_url":"https://api.github.com/users/jpugliesi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jpugliesi/subscriptions","organizations_url":"https://api.github.com/users/jpugliesi/orgs","repos_url":"https://api.github.com/users/jpugliesi/repos","events_url":"https://api.github.com/users/jpugliesi/events{/privacy}","received_events_url":"https://api.github.com/users/jpugliesi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T18:41:57Z","updated_at":"2020-08-24T18:44:14Z","author_association":"NONE","body":"@bvaradar I suspected this may have been the case, but I was not able to find any documentation anywhere that states that a commit tracks the timestamp of when a _specific subset of records is changed_, as opposed to the timestamp of when a write operation was executed. Does such documentation exist, and if so, can you please point me to it?\r\n\r\nSince incremental query does not necessarily contain the full set of table commits, is there an alternative way to get the full tabe commit history via the Spark or some other API _besides the CLI_? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679298548/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679305798","html_url":"https://github.com/apache/hudi/issues/1954#issuecomment-679305798","issue_url":"https://api.github.com/repos/apache/hudi/issues/1954","id":679305798,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTMwNTc5OA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T18:57:34Z","updated_at":"2020-08-24T18:57:34Z","author_association":"CONTRIBUTOR","body":"@tooptoop4 : IIUC, Are you effectively changing a table from non-partitioned to partitioned ? The exception you added to the last comment was about a missing file which does not tie up with your comments. Can you elaborate on the steps to reproduce this. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679305798/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679316776","html_url":"https://github.com/apache/hudi/issues/1962#issuecomment-679316776","issue_url":"https://api.github.com/repos/apache/hudi/issues/1962","id":679316776,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTMxNjc3Ng==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T19:19:42Z","updated_at":"2020-08-24T19:19:42Z","author_association":"CONTRIBUTOR","body":"For the second case, Hive Metastore would be filtering out partitions and only return specific paths. I think there is some inconsistency between the path used in the filesystem and the one that is present in meta-store. \r\n\r\n@sassai : Sorry for the delay, Can you recursively list your hoodie data set and attach the output. Also please add the file contents of latest .commit or .deltacommit file .\r\n\r\nAlso, add the output for one of the partition with location: \r\ndescribe formatted table_name partition (year=xxx,month=xxx,day=xxx,hour=xxx,minute=xxx);\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679316776/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679352339","html_url":"https://github.com/apache/hudi/issues/1955#issuecomment-679352339","issue_url":"https://api.github.com/repos/apache/hudi/issues/1955","id":679352339,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTM1MjMzOQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T20:36:17Z","updated_at":"2020-08-24T20:36:17Z","author_association":"CONTRIBUTOR","body":"@tooptoop4 : can you clarify what you mean by this.\r\n```\r\nie for each version_no,group_company combo, i want to get the latest row by TimeCreated (ie the source-ordering-field) and then partition on whatever sys_user that latest row has.\r\n```\r\nBut in general, yes, if you use global index with the update partition path set, you should not see any duplicates in your entire hoodie dataset. \r\n\r\nI can try to illustrate with an eg. Lets say each row consists only 4 vals, v_no(version no), cmp (group_company), time_cr, sys_user.\r\nIncase of regular index, combination of record keys and partition path forms unique keys. \r\n\r\nIf you are using regular index and ingest \r\nv_1, c_1, t_1, u_1\r\nv_2, c_1, t_1, u_1\r\nv_1, c_1, t_1, u_2\r\nv_1, c_1, t_1, u_3\r\n\r\nThis will result in 2 rows going to partition u_1, 1 row to partition u_2, and one row to u_3. \r\n\r\nIn 2nd batch of updates, lets say you ingest few more rows. \r\nv_1, c_1, t_2, u_1\r\nv_3, c_1, t_2, u_1\r\nv_1, c_2, t_2, u_2\r\nv_1, c_3, t_2, u_3\r\n\r\nHere is the result\r\nu_1:\r\nv_1, c_1, t_2, u_1 (updated with latest value)\r\nv_2, c_1, t_1, u_1\r\nv_3, c_1, t_2, u_1 (insert from 2nd batch)\r\nu_2:\r\nv_1, c_2, t_2, u_2 (updated with latest value)\r\nu_3:\r\nv_1, c_1, t_1, u_3\r\nv_1, c_3, t_2, u_3(insert from 2nd batch)\r\n\r\nIncase of global index, only record keys are unique. \r\nLets see an example with global bloom, but with the update partition path config not set.\r\n\r\nIf 1st batch of ingest contains\r\nv_1, c_1, t_1, u_1\r\nv_1, c_2, t_1, u_1\r\nv_2, c_1, t_1, u_2\r\nv_3, c_1, t_1, u_3\r\n\r\nresult will be. \r\n\r\nv_1, c_1, t_1, u_1 \r\nv_1, c_2, t_1, u_1\r\nv_2, c_1, t_1, u_2 \r\nv_3, c_1, t_1, u_3\r\n\r\nAnd 2nd batch of ingest contains \r\nv_1, c_1, t_2, u_1 (updating with latest time)\r\nv_1, c_2, t_2, u_2 (moving v1,c2 from u_1 to u_2). expectation is that, this will update U_1 only, since the config is not set. and hence new partition path i.e. u_2 will be ignored. \r\nv_2, c_2, t_2, u_2 (new insert)\r\nv_1, c_3, t_2, u_3 (new insert)\r\n\r\nSo, the result will be\r\nv_1, c_1, t_2, u_1 (updated with latest time)\r\nv_1, c_2, t_2, u_1 (updated with latest time even though incoming record was sent to u_2)\r\nv_2, c_1, t_1, u_2 \r\nv_2, c_2, t_2, u_2 (new insert)\r\nv_3, c_1, t_1, u_3\r\nv_1, c_3, t_2, u_3 (new insert)\r\n\r\nWe can go the same with the config value set. \r\n\r\nresult from first batch:\r\nv_1, c_1, t_1, u_1 \r\nv_1, c_2, t_1, u_1\r\nv_2, c_1, t_1, u_2 \r\nv_3, c_1, t_1, u_3\r\n\r\nAnd 2nd batch of ingest contains \r\nv_1, c_1, t_2, u_1 (updating with latest time)\r\nv_1, c_2, t_2, u_2 (moving v1,c2 from u_1 to u_2). expectation is that, this will insert a new record to u_2 and will delete corres record from u_1, since the config is set.\r\nv_2, c_2, t_2, u_2 (new insert)\r\nv_1, c_3, t_2, u_3 (new insert)\r\n\r\nSo, the result will be\r\nv_1, c_1, t_2, u_1 (updated with latest time)\r\nv_1, c_2, t_2, u_2 (updated with latest time and old record is deleted)\r\nv_2, c_1, t_1, u_2 \r\nv_2, c_2, t_2, u_2 (new insert)\r\nv_3, c_1, t_1, u_3\r\nv_1, c_3, t_2, u_3 (new insert)\r\n\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679352339/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679353671","html_url":"https://github.com/apache/hudi/issues/1954#issuecomment-679353671","issue_url":"https://api.github.com/repos/apache/hudi/issues/1954","id":679353671,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTM1MzY3MQ==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T20:39:12Z","updated_at":"2020-08-24T20:39:12Z","author_association":"NONE","body":"@bvaradar in each comment I am trying brand new tables with different spark submits. So not changing an existing table.\r\n\r\ntry to reproduce with\r\n\r\n/home/ec2-user/spark_home/bin/spark-submit --conf \"spark.hadoop.fs.s3a.proxy.host=redact\" --conf \"spark.hadoop.fs.s3a.proxy.port=redact\" --conf \"spark.driver.extraClassPath=/home/ec2-user/json-20090211.jar\" --conf \"spark.executor.extraClassPath=/home/ec2-user/json-20090211.jar\" --class org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer --jars \"/home/ec2-user/spark-avro_2.11-2.4.6.jar\" --master spark://redact:7077 --deploy-mode client /home/ec2-user/hudi-utilities-bundle_2.11-0.5.3-1.jar --table-type COPY_ON_WRITE --source-ordering-field TimeCreated --source-class org.apache.hudi.utilities.sources.ParquetDFSSource --enable-hive-sync --hoodie-conf hoodie.datasource.hive_sync.database=redact --hoodie-conf hoodie.datasource.hive_sync.table=dmstest_multpk7 --hoodie-conf hoodie.datasource.hive_sync.partition_extractor_class=org.apache.hudi.hive.NonPartitionedExtractor --hoodie-conf  hoodie.datasource.hive_sync.use_jdbc=false --target-base-path s3a://redact/my2/multpk7 --target-table dmstest_multpk7 --transformer-class org.apache.hudi.utilities.transform.AWSDmsTransformer --payload-class org.apache.hudi.payload.AWSDmsAvroPayload --hoodie-conf hoodie.datasource.write.keygenerator.class=org.apache.hudi.keygen.ComplexKeyGenerator --hoodie-conf hoodie.datasource.write.recordkey.field=version_no,group_company --hoodie-conf \"hoodie.datasource.write.partitionpath.field=\" --hoodie-conf hoodie.deltastreamer.source.dfs.root=s3a://redact/dbo/tbl\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679353671/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679356547","html_url":"https://github.com/apache/hudi/issues/1955#issuecomment-679356547","issue_url":"https://api.github.com/repos/apache/hudi/issues/1955","id":679356547,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTM1NjU0Nw==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T20:45:25Z","updated_at":"2020-08-24T20:45:40Z","author_association":"NONE","body":"@nsivabalan  perfect, that is how I expect. perhaps the default should be global index? or documentation should be updated?\r\n\r\nFrom coming from RDBMS background the PK is unique at table level not at partition level but reading below configs it is not clear that hudi default is different and I'm sure will trip up many newcomers to hudi:\r\n\r\n\"RECORDKEY_FIELD_OPT_KEY (Required): **Primary key** field(s). Nested fields can be specified using the dot notation eg: a.b.c. When using multiple columns as primary key use comma separated notation, eg: \"col1,col2,col3,etc\". Single or multiple columns as primary key specified by KEYGENERATOR_CLASS_OPT_KEY property.\r\nDefault value: \"uuid\"\r\n\r\nPARTITIONPATH_FIELD_OPT_KEY (Required): Columns to be used for **partitioning** the table. To prevent partitioning, provide empty string as value eg: \"\". Specify partitioning/no partitioning using KEYGENERATOR_CLASS_OPT_KEY. If synchronizing to hive, also specify using HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY.\r\nDefault value: \"partitionpath\"\"\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679356547/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679383433","html_url":"https://github.com/apache/hudi/pull/2016#issuecomment-679383433","issue_url":"https://api.github.com/repos/apache/hudi/issues/2016","id":679383433,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTM4MzQzMw==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T21:47:12Z","updated_at":"2020-08-24T21:47:12Z","author_association":"CONTRIBUTOR","body":"closing this in favor of https://github.com/apache/hudi/pull/2028 . Capture the comment there. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679383433/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679398095","html_url":"https://github.com/apache/hudi/issues/1980#issuecomment-679398095","issue_url":"https://api.github.com/repos/apache/hudi/issues/1980","id":679398095,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTM5ODA5NQ==","user":{"login":"jiegzhan","id":10664626,"node_id":"MDQ6VXNlcjEwNjY0NjI2","avatar_url":"https://avatars.githubusercontent.com/u/10664626?v=4","gravatar_id":"","url":"https://api.github.com/users/jiegzhan","html_url":"https://github.com/jiegzhan","followers_url":"https://api.github.com/users/jiegzhan/followers","following_url":"https://api.github.com/users/jiegzhan/following{/other_user}","gists_url":"https://api.github.com/users/jiegzhan/gists{/gist_id}","starred_url":"https://api.github.com/users/jiegzhan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jiegzhan/subscriptions","organizations_url":"https://api.github.com/users/jiegzhan/orgs","repos_url":"https://api.github.com/users/jiegzhan/repos","events_url":"https://api.github.com/users/jiegzhan/events{/privacy}","received_events_url":"https://api.github.com/users/jiegzhan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T22:28:02Z","updated_at":"2020-08-24T22:28:02Z","author_association":"NONE","body":"@bvaradar, before re-clustering is available, I tested [hoodie.cleaner.commits.retained](https://hudi.apache.org/docs/configurations.html#retainCommits). \r\nI set option(\"hoodie.cleaner.commits.retained\", 1), then issued a few delete queries. For each parquet file in S3, the latest version and 1 older version (sometimes, not always) got kept in S3, all other versions are gone from S3. Is this how it works?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679398095/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679401505","html_url":"https://github.com/apache/hudi/pull/2026#issuecomment-679401505","issue_url":"https://api.github.com/repos/apache/hudi/issues/2026","id":679401505,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTQwMTUwNQ==","user":{"login":"prashantwason","id":58448203,"node_id":"MDQ6VXNlcjU4NDQ4MjAz","avatar_url":"https://avatars.githubusercontent.com/u/58448203?v=4","gravatar_id":"","url":"https://api.github.com/users/prashantwason","html_url":"https://github.com/prashantwason","followers_url":"https://api.github.com/users/prashantwason/followers","following_url":"https://api.github.com/users/prashantwason/following{/other_user}","gists_url":"https://api.github.com/users/prashantwason/gists{/gist_id}","starred_url":"https://api.github.com/users/prashantwason/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashantwason/subscriptions","organizations_url":"https://api.github.com/users/prashantwason/orgs","repos_url":"https://api.github.com/users/prashantwason/repos","events_url":"https://api.github.com/users/prashantwason/events{/privacy}","received_events_url":"https://api.github.com/users/prashantwason/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T22:37:49Z","updated_at":"2020-08-24T22:37:49Z","author_association":"MEMBER","body":"@n3nash corrected the errors.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679401505/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679403428","html_url":"https://github.com/apache/hudi/issues/1980#issuecomment-679403428","issue_url":"https://api.github.com/repos/apache/hudi/issues/1980","id":679403428,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTQwMzQyOA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T22:43:58Z","updated_at":"2020-08-24T22:43:58Z","author_association":"CONTRIBUTOR","body":"Yes, this is expected. We retain the penultimate version of the file to prevent a running query from failing. In this case, you might see only one version  of some file which did not see any deletes. That is expected.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679403428/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679406205","html_url":"https://github.com/apache/hudi/issues/1895#issuecomment-679406205","issue_url":"https://api.github.com/repos/apache/hudi/issues/1895","id":679406205,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTQwNjIwNQ==","user":{"login":"s-sanjay","id":7111850,"node_id":"MDQ6VXNlcjcxMTE4NTA=","avatar_url":"https://avatars.githubusercontent.com/u/7111850?v=4","gravatar_id":"","url":"https://api.github.com/users/s-sanjay","html_url":"https://github.com/s-sanjay","followers_url":"https://api.github.com/users/s-sanjay/followers","following_url":"https://api.github.com/users/s-sanjay/following{/other_user}","gists_url":"https://api.github.com/users/s-sanjay/gists{/gist_id}","starred_url":"https://api.github.com/users/s-sanjay/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/s-sanjay/subscriptions","organizations_url":"https://api.github.com/users/s-sanjay/orgs","repos_url":"https://api.github.com/users/s-sanjay/repos","events_url":"https://api.github.com/users/s-sanjay/events{/privacy}","received_events_url":"https://api.github.com/users/s-sanjay/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T22:53:32Z","updated_at":"2020-08-24T22:53:32Z","author_association":"CONTRIBUTOR","body":"@FelixKJose I have raised a [PR](https://github.com/prestodb/presto/pull/15074)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679406205/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679408763","html_url":"https://github.com/apache/hudi/issues/1981#issuecomment-679408763","issue_url":"https://api.github.com/repos/apache/hudi/issues/1981","id":679408763,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTQwODc2Mw==","user":{"login":"umehrot2","id":8647012,"node_id":"MDQ6VXNlcjg2NDcwMTI=","avatar_url":"https://avatars.githubusercontent.com/u/8647012?v=4","gravatar_id":"","url":"https://api.github.com/users/umehrot2","html_url":"https://github.com/umehrot2","followers_url":"https://api.github.com/users/umehrot2/followers","following_url":"https://api.github.com/users/umehrot2/following{/other_user}","gists_url":"https://api.github.com/users/umehrot2/gists{/gist_id}","starred_url":"https://api.github.com/users/umehrot2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/umehrot2/subscriptions","organizations_url":"https://api.github.com/users/umehrot2/orgs","repos_url":"https://api.github.com/users/umehrot2/repos","events_url":"https://api.github.com/users/umehrot2/events{/privacy}","received_events_url":"https://api.github.com/users/umehrot2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T23:02:13Z","updated_at":"2020-08-24T23:02:13Z","author_association":"CONTRIBUTOR","body":"@rubenssoto yes currently EMR presto is on 0.232, but in upcoming releases you will see later versions of presto where you will be able to use this patch.\r\n\r\nIf you want to manually give it a shot on current emr version..you can try to build presto 0.233 and replace presto-hive jar I believe on all nodes of the cluster and restart presto-server on all nodes.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679408763/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679411848","html_url":"https://github.com/apache/hudi/pull/2030#issuecomment-679411848","issue_url":"https://api.github.com/repos/apache/hudi/issues/2030","id":679411848,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTQxMTg0OA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-24T23:12:31Z","updated_at":"2020-08-24T23:12:31Z","author_association":"MEMBER","body":"can we first make the test-suite tests work on master and run in CI, before we merge more features? cc @n3nash ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679411848/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679429416","html_url":"https://github.com/apache/hudi/pull/2030#issuecomment-679429416","issue_url":"https://api.github.com/repos/apache/hudi/issues/2030","id":679429416,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTQyOTQxNg==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T00:15:23Z","updated_at":"2020-08-25T00:15:23Z","author_association":"CONTRIBUTOR","body":"@vinothchandar Yes, that PR is following later today by @modi95. We will merge this after that.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679429416/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679481632","html_url":"https://github.com/apache/hudi/issues/2020#issuecomment-679481632","issue_url":"https://api.github.com/repos/apache/hudi/issues/2020","id":679481632,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTQ4MTYzMg==","user":{"login":"dm-tran","id":7153721,"node_id":"MDQ6VXNlcjcxNTM3MjE=","avatar_url":"https://avatars.githubusercontent.com/u/7153721?v=4","gravatar_id":"","url":"https://api.github.com/users/dm-tran","html_url":"https://github.com/dm-tran","followers_url":"https://api.github.com/users/dm-tran/followers","following_url":"https://api.github.com/users/dm-tran/following{/other_user}","gists_url":"https://api.github.com/users/dm-tran/gists{/gist_id}","starred_url":"https://api.github.com/users/dm-tran/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dm-tran/subscriptions","organizations_url":"https://api.github.com/users/dm-tran/orgs","repos_url":"https://api.github.com/users/dm-tran/repos","events_url":"https://api.github.com/users/dm-tran/events{/privacy}","received_events_url":"https://api.github.com/users/dm-tran/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T03:01:51Z","updated_at":"2020-08-25T03:01:51Z","author_association":"NONE","body":"Thank you for your answer @bvaradar !\r\n\r\n> Can you please add the details of \"commit showfiles --commit 20200821153748\"\r\n\r\n```\r\n╔═══════════════════╤════════════════════════════════════════╤═════════════════╤═══════════════════════╤═══════════════════════╤═════════════════════╤══════════════╤═══════════╗\r\n║ Partition Path    │ File ID                                │ Previous Commit │ Total Records Updated │ Total Records Written │ Total Bytes Written │ Total Errors │ File Size ║\r\n╠═══════════════════╪════════════════════════════════════════╪═════════════════╪═══════════════════════╪═══════════════════════╪═════════════════════╪══════════════╪═══════════╣\r\n║ daas_date=2020-04 │ 63bacea1-d6af-4ce0-8dc8-6ce9db8df332-0 │ 20200821152906  │ 212                   │ 534115                │ 22998619            │ 0            │ 22998619  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-04 │ 9c5e022c-feda-4059-84f6-752344cea4a9-0 │ 20200821152906  │ 89                    │ 460341                │ 18755115            │ 0            │ 18755115  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-04 │ 80be527b-eda7-42f3-8565-c15e9447d731-0 │ 20200821152906  │ 39                    │ 192455                │ 9112346             │ 0            │ 9112346   ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-04 │ 569b2555-5cd6-416a-b7d7-11897603a1e3-0 │ 20200821152906  │ 3                     │ 483483                │ 19114286            │ 0            │ 19114286  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-05 │ 80be527b-eda7-42f3-8565-c15e9447d731-1 │ 20200821152906  │ 106                   │ 302728                │ 13385764            │ 0            │ 13385764  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-05 │ 27da8cb6-e4b7-4c29-904b-25d3ba321d0a-0 │ 20200821152906  │ 84                    │ 482538                │ 19568311            │ 0            │ 19568311  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-05 │ 0c376059-0279-4967-8002-70c3cd9c6b8e-0 │ 20200821152906  │ 84                    │ 498131                │ 21751990            │ 0            │ 21751990  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-05 │ 9730fe61-5584-4156-b25c-8c8ef41583f4-0 │ 20200821152906  │ 76                    │ 500352                │ 19812831            │ 0            │ 19812831  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-05 │ c2c3fb95-3e58-4021-80c4-7e48aace8dda-0 │ 20200821152906  │ 72                    │ 484533                │ 21001957            │ 0            │ 21001957  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-05 │ ec2ba5dc-7dd7-4cc7-93cd-1358476a124f-0 │ 20200821152906  │ 61                    │ 509569                │ 21960018            │ 0            │ 21960018  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-05 │ bd54d7bb-2fb7-475f-8ca2-47594a1c3206-0 │ 20200821152906  │ 46                    │ 342451                │ 14678548            │ 0            │ 14678548  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-05 │ a0d89a7a-0621-469a-8359-c4c4b8948ff5-1 │ 20200821152906  │ 3                     │ 445248                │ 16992382            │ 0            │ 16992382  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-05 │ bc6f9f87-f16d-410b-b6fa-57abfb666920-0 │ 20200821152207  │ 1                     │ 456187                │ 17399230            │ 0            │ 17399230  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-02 │ 8f6cdcc9-a0e6-4cb5-91b2-510b5498728f-0 │ 20200821145253  │ 3                     │ 500228                │ 20060642            │ 0            │ 20060642  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-02 │ b14d49d0-5a5a-4f39-826c-24492428798a-0 │ 20200821145904  │ 2                     │ 318078                │ 12939981            │ 0            │ 12939981  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-02 │ ddc1d386-4362-4b05-af7e-8bb4de0eecd2-0 │ 20200821152906  │ 2                     │ 485278                │ 19727682            │ 0            │ 19727682  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-02 │ 48bce3e8-07b1-4122-ba68-7850a63bffaa-0 │ 20200821150425  │ 1                     │ 499951                │ 20217825            │ 0            │ 20217825  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-06 │ 508cb5db-343d-4469-a563-b1718f5c6573-0 │ 20200821152207  │ 1                     │ 472946                │ 17554600            │ 0            │ 17554600  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-06 │ 8ee8be98-3ffc-42de-8256-cf27d721f42f-1 │ 20200821143533  │ 1                     │ 218185                │ 8371612             │ 0            │ 8371612   ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-03 │ aa8afa91-df8a-4ffb-8631-bb2a89d02f08-0 │ 20200821144125  │ 2                     │ 457587                │ 18147009            │ 0            │ 18147009  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-03 │ 97d32e96-fb5c-440f-9852-a1575079215c-0 │ 20200821152906  │ 1                     │ 498822                │ 19592479            │ 0            │ 19592479  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-03 │ c558aa0c-a124-4bf7-b9dd-d567e4ee8113-0 │ 20200821152207  │ 1                     │ 520347                │ 20337019            │ 0            │ 20337019  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-11 │ 5b286fd4-9ff2-4153-89f8-4fb7fc7ef02d-0 │ 20200821151547  │ 1                     │ 520080                │ 20243264            │ 0            │ 20243264  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-11 │ 20256a1b-958d-449c-b3a1-f0ab0c453bde-0 │ 20200821152207  │ 1                     │ 467601                │ 18393947            │ 0            │ 18393947  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-12 │ 762a64e7-21e3-4c8a-8e97-8cfb442e70a2-0 │ 20200821144717  │ 1                     │ 494207                │ 19713725            │ 0            │ 19713725  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-12 │ 61561c4a-59b3-4f34-9cab-4c9aeb6f8bdb-0 │ 20200821152207  │ 1                     │ 496330                │ 20137687            │ 0            │ 20137687  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-12 │ e3946c85-4ac3-4b4b-b43a-b2371a4b552a-0 │ 20200821151014  │ 1                     │ 469533                │ 18865890            │ 0            │ 18865890  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-12 │ aaea130f-affc-40dc-b25d-bd0e6b269401-0 │ 20200821145904  │ 1                     │ 498338                │ 20196834            │ 0            │ 20196834  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-10 │ 9eadc3a2-37bd-4f57-90c8-fcd33350c121-0 │ 20200821151014  │ 1                     │ 487381                │ 19804823            │ 0            │ 19804823  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-10 │ 12c2581f-17b8-478f-82d0-d66f042a2846-0 │ 20200821152906  │ 1                     │ 497778                │ 19899349            │ 0            │ 19899349  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-10 │ cf786b7b-863d-4bb5-b36b-9a7459d5da3e-0 │ 20200821152906  │ 1                     │ 482072                │ 19234653            │ 0            │ 19234653  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-08 │ c50c0657-50bd-4d3e-9c4e-14f6b83f4a47-0 │ 20200821152906  │ 89                    │ 587055                │ 24543135            │ 0            │ 24543135  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-08 │ 1aeadbe6-c52b-4e96-ade6-c5b692c7b6be-0 │ 20200821152906  │ 78                    │ 575952                │ 24546899            │ 0            │ 24546899  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-08 │ 62d133ed-0231-44c3-966b-eb30b39a4dee-1 │ 20200821152906  │ 62                    │ 585495                │ 24545575            │ 0            │ 24545575  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-08 │ 19c055e0-6601-4be2-abaa-f1c937cd4fa8-0 │ 20200821152814  │ 57                    │ 588315                │ 24562628            │ 0            │ 24562628  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-06 │ 9db9dd32-0b88-49d3-9620-a13d25d1a7a6-0 │ 20200821152906  │ 93                    │ 500121                │ 20943670            │ 0            │ 20943670  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-06 │ c48e8b31-5e78-4314-9ad6-74b38b471912-0 │ 20200821152906  │ 78                    │ 483713                │ 20575447            │ 0            │ 20575447  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-06 │ cb058aae-0e88-4bbc-adf3-1a481e876200-0 │ 20200821152906  │ 74                    │ 511153                │ 21077515            │ 0            │ 21077515  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-06 │ 5e3f4be1-e7d6-4608-8622-7a9284d2dd0e-0 │ 20200821152906  │ 62                    │ 472906                │ 19983800            │ 0            │ 19983800  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-06 │ 26ace4dc-4e9c-4d3d-94be-d01964462fca-0 │ 20200821152906  │ 53                    │ 500369                │ 20743099            │ 0            │ 20743099  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-06 │ 06046bb8-dc24-44a5-95cd-3a5c0aa9a904-0 │ 20200821152906  │ 43                    │ 237650                │ 10979197            │ 0            │ 10979197  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-06 │ bd54d7bb-2fb7-475f-8ca2-47594a1c3206-1 │ 20200821152906  │ 13                    │ 133180                │ 6523322             │ 0            │ 6523322   ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ b1d0acc3-0e72-4798-8b26-1c93d9a8a3a9-0 │ 20200821152906  │ 60                    │ 499450                │ 21280641            │ 0            │ 21280641  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ 96e33f65-8ed9-4198-8141-fd6b4211c58e-0 │ 20200821152906  │ 58                    │ 505448                │ 21342125            │ 0            │ 21342125  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ 541ef666-271d-4b34-ac84-a023fae33338-0 │ 20200821152906  │ 56                    │ 500421                │ 21352889            │ 0            │ 21352889  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ 372c42b0-612c-4644-8ebe-baec3ce18192-0 │ 20200821152906  │ 49                    │ 487464                │ 20588883            │ 0            │ 20588883  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ f1f2c008-4d29-48e9-a6af-ecbe42f1753e-0 │ 20200821152906  │ 48                    │ 500438                │ 21573335            │ 0            │ 21573335  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ f1d99d5c-6f2f-446b-9389-5be5987896c8-0 │ 20200821152906  │ 47                    │ 494778                │ 20824372            │ 0            │ 20824372  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ 6e89f5b2-e3c6-4bdf-9bee-fc2f08f38624-0 │ 20200821152906  │ 47                    │ 493837                │ 20219635            │ 0            │ 20219635  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ 37b67db6-d444-45b4-948d-ffc3d96a122f-0 │ 20200821152906  │ 46                    │ 487084                │ 20394802            │ 0            │ 20394802  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ afb52cc2-5a34-4db0-854f-292fda6fc8da-0 │ 20200821152906  │ 37                    │ 495374                │ 21544700            │ 0            │ 21544700  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ e22586c6-0890-4f01-9862-81b0f59d1195-0 │ 20200821152906  │ 34                    │ 476130                │ 20039658            │ 0            │ 20039658  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ 06046bb8-dc24-44a5-95cd-3a5c0aa9a904-1 │ 20200821152906  │ 12                    │ 252056                │ 11086635            │ 0            │ 11086635  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2020-07 │ 62d133ed-0231-44c3-966b-eb30b39a4dee-0 │ 20200821152906  │ 5                     │ 33545                 │ 1932342             │ 0            │ 1932342   ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-09 │ 8721bc6c-1eef-497b-ad3f-a6f9b1a1656c-0 │ 20200821142335  │ 2                     │ 529694                │ 20268183            │ 0            │ 20268183  ║\r\n╟───────────────────┼────────────────────────────────────────┼─────────────────┼───────────────────────┼───────────────────────┼─────────────────────┼──────────────┼───────────╢\r\n║ daas_date=2019-09 │ d4f2c861-6493-4185-9c1c-5f41b60abf15-1 │ 20200821142335  │ 1                     │ 256409                │ 10268763            │ 0            │ 10268763  ║\r\n╚═══════════════════╧════════════════════════════════════════╧═════════════════╧═══════════════════════╧═══════════════════════╧═════════════════════╧══════════════╧═══════════╝\r\n```\r\n\r\n> Are you running with consistency check enabled ?\r\n\r\nNo, `hoodie.consistency.check.enabled` wasn't set. I will try to run the structured streaming job with `hoodie.consistency.check.enabled = true`.\r\n\r\n> Can you also check if the file is actually absent by listing the folder s3://myBucket/absolute_path_to/daas_date=2020-05/\r\n\r\nYes, the file is actually absent.\r\n\r\n> Also, paste the output of listing in this issue.\r\n\r\nParquet files with fileId \"0c376059-0279-4967-8002-70c3cd9c6b8e-0\":\r\n```\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_10-3360-221478_20200821152906.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_11-2909-192474_20200821142335.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_13-3032-200435_20200821144125.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_2-3073-203081_20200821144717.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_3-2581-171166_20200821133908.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_3-3114-205741_20200821145253.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_4-2950-195120_20200821142949.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_4-3155-208347_20200821145904.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_4-3237-213604_20200821151014.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_5-2786-184435_20200821140554.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_5-2827-187104_20200821141202.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_5-2991-197774_20200821143533.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_6-3196-210983_20200821150425.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_6-3278-216229_20200821151547.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_6-39-2575_20200821153748.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_7-2745-181775_20200821140025.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_7-39-2576_20200821154520.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_7-39-2578_20200821154520.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_7-39-2580_20200821154520.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_7-39-2582_20200821154520.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_8-3319-218872_20200821152207.parquet\r\ns3://myBucket/absolute_path_to/daas_date=2020-05/0c376059-0279-4967-8002-70c3cd9c6b8e-0_9-2540-168511_20200821133319.parquet\r\n```\r\n\r\nThere are around 5000 files, so I attached a text file, which contains the result of `s4cmd ls s3://myBucket/absolute_path_to/daas_date=2020-05` (this folder is actually a copy of the original s3 folder, so the date and time of each file are not the original ones).\r\n\r\n[2020-05_files.txt](https://github.com/apache/hudi/files/5121126/2020-05_files.txt)\r\n\r\nThere are lots of files, because of the following process:\r\n1. the structured streaming job reads messages from Kafka and saves log files to s3\r\n2. the compaction which previously failed is retried but fails, and the structured streaming job fails\r\n3. the structured streaming job is re-launched by an external process: steps 1 and 2 are repeated (step 1 keeps adding log files)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679481632/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679497286","html_url":"https://github.com/apache/hudi/issues/2007#issuecomment-679497286","issue_url":"https://api.github.com/repos/apache/hudi/issues/2007","id":679497286,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTQ5NzI4Ng==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T03:13:56Z","updated_at":"2020-08-25T03:13:56Z","author_association":"CONTRIBUTOR","body":"@ashishmgofficial : If you use DeltaStreamer, it comes with kafka integration and manages checkpoints internally. So, there is no need to query timeline metadata separately. Do you have any specific requirement where you need to look at timeline ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679497286/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679522323","html_url":"https://github.com/apache/hudi/issues/1979#issuecomment-679522323","issue_url":"https://api.github.com/repos/apache/hudi/issues/1979","id":679522323,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTUyMjMyMw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T03:32:56Z","updated_at":"2020-08-25T03:32:56Z","author_association":"CONTRIBUTOR","body":"@hughfdjackson : In general getting incremental read to discard duplicates is not possible for MOR table types as we defer the merging of records to compaction.\r\n\r\nI was thinking about alternate ways to achieve your use-case for COW table by using an application level boolean flag. Let me know if this makes sense:\r\n\r\n1. Introduce additional  boolean column \"changed\". Default Value is false.\r\n2. Have your own implementation of HoodieRecordPayload plugged-in.\r\n3a In HoodieRecordPayload.getInsertValue(), return an avro record with changed = true. This function is called first time  when the new record is inserted.\r\n3(b) In HoodieRecordPayload.combineAndGetUpdateValue(), if you determine, there is no material change, set changed = false else set it to true.\r\n\r\nIn your incremental query,  add the filter changed = true to filter out those without material changes ? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679522323/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679866696","html_url":"https://github.com/apache/hudi/issues/2020#issuecomment-679866696","issue_url":"https://api.github.com/repos/apache/hudi/issues/2020","id":679866696,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTg2NjY5Ng==","user":{"login":"dm-tran","id":7153721,"node_id":"MDQ6VXNlcjcxNTM3MjE=","avatar_url":"https://avatars.githubusercontent.com/u/7153721?v=4","gravatar_id":"","url":"https://api.github.com/users/dm-tran","html_url":"https://github.com/dm-tran","followers_url":"https://api.github.com/users/dm-tran/followers","following_url":"https://api.github.com/users/dm-tran/following{/other_user}","gists_url":"https://api.github.com/users/dm-tran/gists{/gist_id}","starred_url":"https://api.github.com/users/dm-tran/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dm-tran/subscriptions","organizations_url":"https://api.github.com/users/dm-tran/orgs","repos_url":"https://api.github.com/users/dm-tran/repos","events_url":"https://api.github.com/users/dm-tran/events{/privacy}","received_events_url":"https://api.github.com/users/dm-tran/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T07:54:17Z","updated_at":"2020-08-25T07:54:45Z","author_association":"NONE","body":"@bvaradar I ran the structured streaming job with `hoodie.consistency.check.enabled = true`, starting from the earliest offsets in Kafka, and got the same error: a `java.io.FileNotFoundException` when the compaction is retried.\r\n\r\n**Summary**\r\n\r\nThe structured streaming job ran during 3 hours:\r\n- at some point, some executors were lost because of an OutOfMemory error.\r\n- then the spark driver failed because the consistency check failed.\r\n\r\nThe spark application was then retried by YARN, and the 2nd attempt failed with `Caused by: java.io.FileNotFoundException: No such file or directory` when the compaction was retried.\r\n\r\n**Stacktraces**\r\n\r\nStracktrace of the first attempt:\r\n```\r\n20/08/25 06:51:39 WARN HiveConf: HiveConf of name hive.server2.thrift.url does not exist\r\n20/08/25 06:51:40 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 300000 milliseconds, but spent 800229 milliseconds\r\n20/08/25 06:56:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_1775_40 !\r\n20/08/25 06:56:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_1785_53 !\r\n[...]\r\n20/08/25 06:56:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_1785_35 !\r\n20/08/25 06:56:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_1785_50 !\r\n20/08/25 06:56:24 WARN YarnAllocator: Container from a bad node: container_1594796531644_1833_01_000002 on host: ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal. Exit status: 143. Diagnostics: [2020-08-25 06:56:24.636]Container killed on request. Exit code is 143\r\n[2020-08-25 06:56:24.636]Container exited with a non-zero exit code 143. \r\n[2020-08-25 06:56:24.637]Killed by external signal\r\n.\r\n20/08/25 06:56:24 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container from a bad node: container_1594796531644_1833_01_000002 on host: ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal. Exit status: 143. Diagnostics: [2020-08-25 06:56:24.636]Container killed on request. Exit code is 143\r\n[2020-08-25 06:56:24.636]Container exited with a non-zero exit code 143. \r\n[2020-08-25 06:56:24.637]Killed by external signal\r\n.\r\n20/08/25 06:56:24 ERROR YarnClusterScheduler: Lost executor 1 on ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal: Container from a bad node: container_1594796531644_1833_01_000002 on host: ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal. Exit status: 143. Diagnostics: [2020-08-25 06:56:24.636]Container killed on request. Exit code is 143\r\n[2020-08-25 06:56:24.636]Container exited with a non-zero exit code 143. \r\n[2020-08-25 06:56:24.637]Killed by external signal\r\n.\r\n20/08/25 06:56:24 WARN TaskSetManager: Lost task 1.0 in stage 816.0 (TID 50626, ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1594796531644_1833_01_000002 on host: ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal. Exit status: 143. Diagnostics: [2020-08-25 06:56:24.636]Container killed on request. Exit code is 143\r\n[2020-08-25 06:56:24.636]Container exited with a non-zero exit code 143. \r\n[2020-08-25 06:56:24.637]Killed by external signal\r\n.\r\n20/08/25 06:56:24 WARN TaskSetManager: Lost task 0.0 in stage 816.0 (TID 50625, ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1594796531644_1833_01_000002 on host: ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal. Exit status: 143. Diagnostics: [2020-08-25 06:56:24.636]Container killed on request. Exit code is 143\r\n[2020-08-25 06:56:24.636]Container exited with a non-zero exit code 143. \r\n[2020-08-25 06:56:24.637]Killed by external signal\r\n.\r\n20/08/25 06:56:24 WARN ExecutorAllocationManager: Attempted to mark unknown executor 1 idle\r\n20/08/25 07:07:51 ERROR MicroBatchExecution: Query [id = 6ea738ee-0886-4014-a2b2-f51efd693c45, runId = 97c16ef4-d610-4d44-a0e9-a9d24ed5e0cf] terminated with error\r\norg.apache.hudi.exception.HoodieCommitException: Failed to complete commit 20200825065331 due to finalize errors.\r\n    at org.apache.hudi.client.AbstractHoodieWriteClient.finalizeWrite(AbstractHoodieWriteClient.java:204)\r\n    at org.apache.hudi.client.HoodieWriteClient.doCompactionCommit(HoodieWriteClient.java:1142)\r\n    at org.apache.hudi.client.HoodieWriteClient.commitCompaction(HoodieWriteClient.java:1102)\r\n    at org.apache.hudi.client.HoodieWriteClient.runCompaction(HoodieWriteClient.java:1085)\r\n    at org.apache.hudi.client.HoodieWriteClient.compact(HoodieWriteClient.java:1056)\r\n    at org.apache.hudi.client.HoodieWriteClient.lambda$forceCompact$13(HoodieWriteClient.java:1171)\r\n    at org.apache.hudi.common.util.Option.ifPresent(Option.java:96)\r\n    at org.apache.hudi.client.HoodieWriteClient.forceCompact(HoodieWriteClient.java:1168)\r\n    at org.apache.hudi.client.HoodieWriteClient.postCommit(HoodieWriteClient.java:503)\r\n    at org.apache.hudi.client.AbstractHoodieWriteClient.commit(AbstractHoodieWriteClient.java:157)\r\n    at org.apache.hudi.client.AbstractHoodieWriteClient.commit(AbstractHoodieWriteClient.java:101)\r\n    at org.apache.hudi.client.AbstractHoodieWriteClient.commit(AbstractHoodieWriteClient.java:92)\r\n    at org.apache.hudi.HoodieSparkSqlWriter$.checkWriteStatus(HoodieSparkSqlWriter.scala:268)\r\n    at org.apache.hudi.HoodieSparkSqlWriter$.write(HoodieSparkSqlWriter.scala:188)\r\n    at org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:108)\r\n    at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:46)\r\n    at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\r\n    at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\r\n    at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\r\n    at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:131)\r\n    at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:156)\r\n    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n    at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n    at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n    at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:83)\r\n    at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:83)\r\n    at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:676)\r\n    at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:84)\r\n    at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:165)\r\n    at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:74)\r\n    at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\r\n    at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:290)\r\n    at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\r\n    at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\r\n    at aaa.dataprocessor.writer.EventsWriter$.saveToHudiTable(EventsWriter.scala:145)\r\n    at aaa.dataprocessor.MainProcessor$.processBatch(MainProcessor.scala:162)\r\n    at aaa.dataprocessor.MainProcessor$.$anonfun$main$4(MainProcessor.scala:90)\r\n    at aaa.dataprocessor.MainProcessor$.$anonfun$main$4$adapted(MainProcessor.scala:82)\r\n    at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:35)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$15(MicroBatchExecution.scala:537)\r\n    at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:84)\r\n    at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:165)\r\n    at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:74)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$14(MicroBatchExecution.scala:536)\r\n    at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:351)\r\n    at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:349)\r\n    at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:535)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:198)\r\n    at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n    at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:351)\r\n    at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:349)\r\n    at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:166)\r\n    at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:160)\r\n    at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:281)\r\n    at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:193)\r\nCaused by: org.apache.hudi.exception.HoodieIOException: Consistency check failed to ensure all files APPEAR\r\n    at org.apache.hudi.table.HoodieTable.waitForAllFiles(HoodieTable.java:431)\r\n    at org.apache.hudi.table.HoodieTable.cleanFailedWrites(HoodieTable.java:379)\r\n    at org.apache.hudi.table.HoodieTable.finalizeWrite(HoodieTable.java:315)\r\n    at org.apache.hudi.table.HoodieMergeOnReadTable.finalizeWrite(HoodieMergeOnReadTable.java:319)\r\n    at org.apache.hudi.client.AbstractHoodieWriteClient.finalizeWrite(AbstractHoodieWriteClient.java:195)\r\n    ... 57 more\r\n```\r\n\r\nStracktrace of the second attempt:\r\n```\r\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\r\n20/08/25 07:07:56 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!\r\n20/08/25 07:10:02 ERROR HoodieMergeOnReadTable: Rolling back instant [==>20200825065331__compaction__INFLIGHT]\r\n20/08/25 07:10:07 WARN HoodieCopyOnWriteTable: Rollback finished without deleting inflight instant file. Instant=[==>20200825065331__compaction__INFLIGHT]\r\n20/08/25 07:17:12 WARN TaskSetManager: Lost task 2.0 in stage 41.0 (TID 2539, ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal, executor 1): org.apache.hudi.exception.HoodieException: java.io.FileNotFoundException: No such file or directory 's3://myBucket/absolute_path_to/daas_date=2020/ff707f6d-0e41-405e-9623-f7302600765b-0_2-816-50629_20200825065331.parquet'\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdateInternal(HoodieCopyOnWriteTable.java:207)\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdate(HoodieCopyOnWriteTable.java:190)\r\n    at org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor.compact(HoodieMergeOnReadTableCompactor.java:139)\r\n    at org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor.lambda$compact$644ebad7$1(HoodieMergeOnReadTableCompactor.java:98)\r\n    at org.apache.spark.api.java.JavaPairRDD$.$anonfun$toScalaFunction$1(JavaPairRDD.scala:1040)\r\n    at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\r\n    at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\r\n    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\r\n    at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\r\n    at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)\r\n    at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1182)\r\n    at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n    at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n    at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n    at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n    at org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n    at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\r\n    at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n    at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.FileNotFoundException: No such file or directory 's3://myBucket/absolute_path_to/daas_date=2020/ff707f6d-0e41-405e-9623-f7302600765b-0_2-816-50629_20200825065331.parquet'\r\n    at com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.getFileStatus(S3NativeFileSystem.java:617)\r\n    at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.getFileStatus(EmrFileSystem.java:553)\r\n    at org.apache.parquet.hadoop.ParquetReader$Builder.build(ParquetReader.java:300)\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdateInternal(HoodieCopyOnWriteTable.java:202)\r\n    ... 26 more\r\n\r\n20/08/25 07:17:13 WARN TaskSetManager: Lost task 3.0 in stage 41.0 (TID 2540, ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal, executor 1): org.apache.hudi.exception.HoodieException: java.io.FileNotFoundException: No such file or directory 's3://myBucket/absolute_path_to/daas_date=2020/56be5da5-f5f3-4675-8dec-433f3656f839-0_3-816-50630_20200825065331.parquet'\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdateInternal(HoodieCopyOnWriteTable.java:207)\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdate(HoodieCopyOnWriteTable.java:190)\r\n    at org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor.compact(HoodieMergeOnReadTableCompactor.java:139)\r\n    at org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor.lambda$compact$644ebad7$1(HoodieMergeOnReadTableCompactor.java:98)\r\n    at org.apache.spark.api.java.JavaPairRDD$.$anonfun$toScalaFunction$1(JavaPairRDD.scala:1040)\r\n    at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\r\n    at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\r\n    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\r\n    at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\r\n    at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)\r\n    at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1182)\r\n    at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n    at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n    at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n    at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n    at org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n    at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\r\n    at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n    at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.FileNotFoundException: No such file or directory 's3://myBucket/absolute_path_to/daas_date=2020/56be5da5-f5f3-4675-8dec-433f3656f839-0_3-816-50630_20200825065331.parquet'\r\n    at com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.getFileStatus(S3NativeFileSystem.java:617)\r\n    at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.getFileStatus(EmrFileSystem.java:553)\r\n    at org.apache.parquet.hadoop.ParquetReader$Builder.build(ParquetReader.java:300)\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdateInternal(HoodieCopyOnWriteTable.java:202)\r\n    ... 26 more\r\n\r\n20/08/25 07:17:18 ERROR TaskSetManager: Task 2 in stage 41.0 failed 4 times; aborting job\r\n20/08/25 07:17:18 ERROR MicroBatchExecution: Query [id = 6ea738ee-0886-4014-a2b2-f51efd693c45, runId = 9afd92cc-2ced-47e9-a34b-9574dd82c229] terminated with error\r\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 41.0 failed 4 times, most recent failure: Lost task 2.3 in stage 41.0 (TID 2546, ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal, executor 1): org.apache.hudi.exception.HoodieException: java.io.FileNotFoundException: No such file or directory 's3://myBucket/absolute_path_to/daas_date=2020/ff707f6d-0e41-405e-9623-f7302600765b-0_2-816-50629_20200825065331.parquet'\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdateInternal(HoodieCopyOnWriteTable.java:207)\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdate(HoodieCopyOnWriteTable.java:190)\r\n    at org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor.compact(HoodieMergeOnReadTableCompactor.java:139)\r\n    at org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor.lambda$compact$644ebad7$1(HoodieMergeOnReadTableCompactor.java:98)\r\n    at org.apache.spark.api.java.JavaPairRDD$.$anonfun$toScalaFunction$1(JavaPairRDD.scala:1040)\r\n    at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\r\n    at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\r\n    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\r\n    at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\r\n    at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)\r\n    at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1182)\r\n    at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n    at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n    at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n    at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n    at org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n    at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\r\n    at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n    at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.FileNotFoundException: No such file or directory 's3://myBucket/absolute_path_to/daas_date=2020/ff707f6d-0e41-405e-9623-f7302600765b-0_2-816-50629_20200825065331.parquet'\r\n    at com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.getFileStatus(S3NativeFileSystem.java:617)\r\n    at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.getFileStatus(EmrFileSystem.java:553)\r\n    at org.apache.parquet.hadoop.ParquetReader$Builder.build(ParquetReader.java:300)\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdateInternal(HoodieCopyOnWriteTable.java:202)\r\n    ... 26 more\r\n\r\nDriver stacktrace:\r\n    at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2041)\r\n    at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2029)\r\n    at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2028)\r\n    at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n    at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n    at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2028)\r\n    at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:966)\r\n    at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:966)\r\n    at scala.Option.foreach(Option.scala:407)\r\n    at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966)\r\n    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2262)\r\n    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2211)\r\n    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2200)\r\n    at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n    at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)\r\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n    at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:945)\r\n    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n    at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n    at org.apache.spark.rdd.RDD.collect(RDD.scala:944)\r\n    at org.apache.spark.api.java.JavaRDDLike.collect(JavaRDDLike.scala:361)\r\n    at org.apache.spark.api.java.JavaRDDLike.collect$(JavaRDDLike.scala:360)\r\n    at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)\r\n    at org.apache.hudi.client.HoodieWriteClient.doCompactionCommit(HoodieWriteClient.java:1134)\r\n    at org.apache.hudi.client.HoodieWriteClient.commitCompaction(HoodieWriteClient.java:1102)\r\n    at org.apache.hudi.client.HoodieWriteClient.runCompaction(HoodieWriteClient.java:1085)\r\n    at org.apache.hudi.client.HoodieWriteClient.compact(HoodieWriteClient.java:1056)\r\n    at org.apache.hudi.client.HoodieWriteClient.lambda$forceCompact$13(HoodieWriteClient.java:1171)\r\n    at org.apache.hudi.common.util.Option.ifPresent(Option.java:96)\r\n    at org.apache.hudi.client.HoodieWriteClient.forceCompact(HoodieWriteClient.java:1168)\r\n    at org.apache.hudi.client.HoodieWriteClient.postCommit(HoodieWriteClient.java:503)\r\n    at org.apache.hudi.client.AbstractHoodieWriteClient.commit(AbstractHoodieWriteClient.java:157)\r\n    at org.apache.hudi.client.AbstractHoodieWriteClient.commit(AbstractHoodieWriteClient.java:101)\r\n    at org.apache.hudi.client.AbstractHoodieWriteClient.commit(AbstractHoodieWriteClient.java:92)\r\n    at org.apache.hudi.HoodieSparkSqlWriter$.checkWriteStatus(HoodieSparkSqlWriter.scala:268)\r\n    at org.apache.hudi.HoodieSparkSqlWriter$.write(HoodieSparkSqlWriter.scala:188)\r\n    at org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:108)\r\n    at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:46)\r\n    at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\r\n    at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\r\n    at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\r\n    at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:131)\r\n    at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:156)\r\n    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n    at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n    at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n    at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:83)\r\n    at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:83)\r\n    at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:676)\r\n    at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:84)\r\n    at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:165)\r\n    at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:74)\r\n    at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\r\n    at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:290)\r\n    at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\r\n    at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\r\n    at aaa.dataprocessor.writer.EventsWriter$.saveToHudiTable(EventsWriter.scala:145)\r\n    at aaa.dataprocessor.MainProcessor$.processBatch(MainProcessor.scala:162)\r\n    at aaa.dataprocessor.MainProcessor$.$anonfun$main$4(MainProcessor.scala:90)\r\n    at aaa.dataprocessor.MainProcessor$.$anonfun$main$4$adapted(MainProcessor.scala:82)\r\n    at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:35)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$15(MicroBatchExecution.scala:537)\r\n    at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:84)\r\n    at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:165)\r\n    at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:74)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$14(MicroBatchExecution.scala:536)\r\n    at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:351)\r\n    at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:349)\r\n    at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:535)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:198)\r\n    at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n    at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:351)\r\n    at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:349)\r\n    at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:166)\r\n    at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)\r\n    at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:160)\r\n    at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:281)\r\n    at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:193)\r\nCaused by: org.apache.hudi.exception.HoodieException: java.io.FileNotFoundException: No such file or directory 's3://myBucket/absolute_path_to/daas_date=2020/ff707f6d-0e41-405e-9623-f7302600765b-0_2-816-50629_20200825065331.parquet'\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdateInternal(HoodieCopyOnWriteTable.java:207)\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdate(HoodieCopyOnWriteTable.java:190)\r\n    at org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor.compact(HoodieMergeOnReadTableCompactor.java:139)\r\n    at org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor.lambda$compact$644ebad7$1(HoodieMergeOnReadTableCompactor.java:98)\r\n    at org.apache.spark.api.java.JavaPairRDD$.$anonfun$toScalaFunction$1(JavaPairRDD.scala:1040)\r\n    at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\r\n    at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\r\n    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\r\n    at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\r\n    at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)\r\n    at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1182)\r\n    at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n    at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n    at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n    at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n    at org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n    at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\r\n    at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n    at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.FileNotFoundException: No such file or directory 's3://myBucket/absolute_path_to/daas_date=2020/ff707f6d-0e41-405e-9623-f7302600765b-0_2-816-50629_20200825065331.parquet'\r\n    at com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.getFileStatus(S3NativeFileSystem.java:617)\r\n    at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.getFileStatus(EmrFileSystem.java:553)\r\n    at org.apache.parquet.hadoop.ParquetReader$Builder.build(ParquetReader.java:300)\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdateInternal(HoodieCopyOnWriteTable.java:202)\r\n    ... 26 more\r\n20/08/25 07:17:18 WARN TaskSetManager: Lost task 3.3 in stage 41.0 (TID 2547, ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal, executor 1): TaskKilled (Stage cancelled)\r\n20/08/25 07:17:18 ERROR ApplicationMaster: User class threw exception: org.apache.spark.sql.streaming.StreamingQueryException: Job aborted due to stage failure: Task 2 in stage 41.0 failed 4 times, most recent failure: Lost task 2.3 in stage 41.0 (TID 2546, ip-xxx-xxx-xxx-xxx.ap-northeast-1.compute.internal, executor 1): org.apache.hudi.exception.HoodieException: java.io.FileNotFoundException: No such file or directory 's3://myBucket/absolute_path_to/daas_date=2020/ff707f6d-0e41-405e-9623-f7302600765b-0_2-816-50629_20200825065331.parquet'\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdateInternal(HoodieCopyOnWriteTable.java:207)\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdate(HoodieCopyOnWriteTable.java:190)\r\n    at org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor.compact(HoodieMergeOnReadTableCompactor.java:139)\r\n    at org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor.lambda$compact$644ebad7$1(HoodieMergeOnReadTableCompactor.java:98)\r\n    at org.apache.spark.api.java.JavaPairRDD$.$anonfun$toScalaFunction$1(JavaPairRDD.scala:1040)\r\n    at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\r\n    at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\r\n    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\r\n    at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\r\n    at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)\r\n    at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1182)\r\n    at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\r\n    at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\r\n    at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\r\n    at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\r\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\r\n    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n    at org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n    at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\r\n    at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n    at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.FileNotFoundException: No such file or directory 's3://myBucket/absolute_path_to/daas_date=2020/ff707f6d-0e41-405e-9623-f7302600765b-0_2-816-50629_20200825065331.parquet'\r\n    at com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.getFileStatus(S3NativeFileSystem.java:617)\r\n    at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.getFileStatus(EmrFileSystem.java:553)\r\n    at org.apache.parquet.hadoop.ParquetReader$Builder.build(ParquetReader.java:300)\r\n    at org.apache.hudi.table.HoodieCopyOnWriteTable.handleUpdateInternal(HoodieCopyOnWriteTable.java:202)\r\n    ... 26 more\r\n\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679866696/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679873398","html_url":"https://github.com/apache/hudi/issues/2020#issuecomment-679873398","issue_url":"https://api.github.com/repos/apache/hudi/issues/2020","id":679873398,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTg3MzM5OA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T08:07:46Z","updated_at":"2020-08-25T08:07:46Z","author_association":"CONTRIBUTOR","body":"@dm-tran : COmpaction would retry compacting the same file again till it succeeds. As the file is not there already, it would not help. can you re-bootstrap and then start ingesting  the data but this time enable consistency guard right from the begining.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679873398/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679875396","html_url":"https://github.com/apache/hudi/issues/2020#issuecomment-679875396","issue_url":"https://api.github.com/repos/apache/hudi/issues/2020","id":679875396,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTg3NTM5Ng==","user":{"login":"dm-tran","id":7153721,"node_id":"MDQ6VXNlcjcxNTM3MjE=","avatar_url":"https://avatars.githubusercontent.com/u/7153721?v=4","gravatar_id":"","url":"https://api.github.com/users/dm-tran","html_url":"https://github.com/dm-tran","followers_url":"https://api.github.com/users/dm-tran/followers","following_url":"https://api.github.com/users/dm-tran/following{/other_user}","gists_url":"https://api.github.com/users/dm-tran/gists{/gist_id}","starred_url":"https://api.github.com/users/dm-tran/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dm-tran/subscriptions","organizations_url":"https://api.github.com/users/dm-tran/orgs","repos_url":"https://api.github.com/users/dm-tran/repos","events_url":"https://api.github.com/users/dm-tran/events{/privacy}","received_events_url":"https://api.github.com/users/dm-tran/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T08:11:51Z","updated_at":"2020-08-25T08:12:03Z","author_association":"NONE","body":"> can you re-bootstrap and then start ingesting the data but this time enable consistency guard right from the begining.\r\n\r\n@bvaradar Actually, this is what I did. I deleted the hudi table in s3, added the consistency check property and started ingesting the data from the beginning.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679875396/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679905218","html_url":"https://github.com/apache/hudi/issues/2020#issuecomment-679905218","issue_url":"https://api.github.com/repos/apache/hudi/issues/2020","id":679905218,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTkwNTIxOA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T09:10:47Z","updated_at":"2020-08-25T09:10:47Z","author_association":"CONTRIBUTOR","body":"@dm-tran : Thanks for the details. The only possible explanation that I can think of is more than 1 writers are concurrently running that can cause this. Can you check if more than 1 writers are concurrently happening. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679905218/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679910464","html_url":"https://github.com/apache/hudi/pull/2012#issuecomment-679910464","issue_url":"https://api.github.com/repos/apache/hudi/issues/2012","id":679910464,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTkxMDQ2NA==","user":{"login":"sbernauer","id":29303194,"node_id":"MDQ6VXNlcjI5MzAzMTk0","avatar_url":"https://avatars.githubusercontent.com/u/29303194?v=4","gravatar_id":"","url":"https://api.github.com/users/sbernauer","html_url":"https://github.com/sbernauer","followers_url":"https://api.github.com/users/sbernauer/followers","following_url":"https://api.github.com/users/sbernauer/following{/other_user}","gists_url":"https://api.github.com/users/sbernauer/gists{/gist_id}","starred_url":"https://api.github.com/users/sbernauer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sbernauer/subscriptions","organizations_url":"https://api.github.com/users/sbernauer/orgs","repos_url":"https://api.github.com/users/sbernauer/repos","events_url":"https://api.github.com/users/sbernauer/events{/privacy}","received_events_url":"https://api.github.com/users/sbernauer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T09:20:37Z","updated_at":"2020-08-25T09:20:37Z","author_association":"CONTRIBUTOR","body":"Hi @sathyaprakashg, thanks for your work!\r\n\r\nWhen i move the new field `evoluted_optional_union_field` to a place not at the end of the schema (somewhere in the middle) i get the following exception:\r\n`java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.lang.Iterable.`\r\nThis makes sense, since now the ids of the fields dont line up any more. So reducing the length to the minimum is not sufficient here.\r\n\r\nI suggest using the field names instead of the ids (which dont match up any more after a new field in the middle). See https://github.com/sbernauer/hudi/commit/1adbc7bddac431bb060880efab2d3979840765da#diff-3c046573a91f36ba0f12dad0e3395dc9R139\r\n\r\nShould i open a PR for this change or do you want to modify yours?\r\n\r\nCheers,\r\nSebastian","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679910464/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679911709","html_url":"https://github.com/apache/hudi/issues/2020#issuecomment-679911709","issue_url":"https://api.github.com/repos/apache/hudi/issues/2020","id":679911709,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTkxMTcwOQ==","user":{"login":"dm-tran","id":7153721,"node_id":"MDQ6VXNlcjcxNTM3MjE=","avatar_url":"https://avatars.githubusercontent.com/u/7153721?v=4","gravatar_id":"","url":"https://api.github.com/users/dm-tran","html_url":"https://github.com/dm-tran","followers_url":"https://api.github.com/users/dm-tran/followers","following_url":"https://api.github.com/users/dm-tran/following{/other_user}","gists_url":"https://api.github.com/users/dm-tran/gists{/gist_id}","starred_url":"https://api.github.com/users/dm-tran/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dm-tran/subscriptions","organizations_url":"https://api.github.com/users/dm-tran/orgs","repos_url":"https://api.github.com/users/dm-tran/repos","events_url":"https://api.github.com/users/dm-tran/events{/privacy}","received_events_url":"https://api.github.com/users/dm-tran/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T09:22:59Z","updated_at":"2020-08-25T09:22:59Z","author_association":"NONE","body":"Thank you @bvaradar \r\n\r\n> Can you check if more than 1 writers are concurrently happening.\r\n\r\nOnly the structured streaming application writes to the Hudi table, so there is only one writer.\r\n\r\nTasks that failed are automatically retried by Spark. Could the retries lead to this kind of error?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679911709/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679927681","html_url":"https://github.com/apache/hudi/pull/2032#issuecomment-679927681","issue_url":"https://api.github.com/repos/apache/hudi/issues/2032","id":679927681,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTkyNzY4MQ==","user":{"login":"wangxianghu","id":49835526,"node_id":"MDQ6VXNlcjQ5ODM1NTI2","avatar_url":"https://avatars.githubusercontent.com/u/49835526?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxianghu","html_url":"https://github.com/wangxianghu","followers_url":"https://api.github.com/users/wangxianghu/followers","following_url":"https://api.github.com/users/wangxianghu/following{/other_user}","gists_url":"https://api.github.com/users/wangxianghu/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxianghu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxianghu/subscriptions","organizations_url":"https://api.github.com/users/wangxianghu/orgs","repos_url":"https://api.github.com/users/wangxianghu/repos","events_url":"https://api.github.com/users/wangxianghu/events{/privacy}","received_events_url":"https://api.github.com/users/wangxianghu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T09:56:14Z","updated_at":"2020-08-25T09:56:14Z","author_association":"CONTRIBUTOR","body":"@yanghua please take a look when free","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679927681/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679927856","html_url":"https://github.com/apache/hudi/pull/2033#issuecomment-679927856","issue_url":"https://api.github.com/repos/apache/hudi/issues/2033","id":679927856,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTkyNzg1Ng==","user":{"login":"wangxianghu","id":49835526,"node_id":"MDQ6VXNlcjQ5ODM1NTI2","avatar_url":"https://avatars.githubusercontent.com/u/49835526?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxianghu","html_url":"https://github.com/wangxianghu","followers_url":"https://api.github.com/users/wangxianghu/followers","following_url":"https://api.github.com/users/wangxianghu/following{/other_user}","gists_url":"https://api.github.com/users/wangxianghu/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxianghu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxianghu/subscriptions","organizations_url":"https://api.github.com/users/wangxianghu/orgs","repos_url":"https://api.github.com/users/wangxianghu/repos","events_url":"https://api.github.com/users/wangxianghu/events{/privacy}","received_events_url":"https://api.github.com/users/wangxianghu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T09:56:34Z","updated_at":"2020-08-25T09:56:34Z","author_association":"CONTRIBUTOR","body":"@yanghua  please take a look when free","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679927856/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679962745","html_url":"https://github.com/apache/hudi/pull/1946#issuecomment-679962745","issue_url":"https://api.github.com/repos/apache/hudi/issues/1946","id":679962745,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTk2Mjc0NQ==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T11:16:09Z","updated_at":"2020-08-25T11:16:09Z","author_association":"CONTRIBUTOR","body":"@wangxianghu Can you help to verify and review this PR?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679962745/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679963589","html_url":"https://github.com/apache/hudi/pull/2022#issuecomment-679963589","issue_url":"https://api.github.com/repos/apache/hudi/issues/2022","id":679963589,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTk2MzU4OQ==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T11:18:11Z","updated_at":"2020-08-25T11:18:11Z","author_association":"CONTRIBUTOR","body":"@Trevor-zhang Please follow the contributing guidelines, e.g. the title of the PR.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679963589/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679965694","html_url":"https://github.com/apache/hudi/pull/2033#issuecomment-679965694","issue_url":"https://api.github.com/repos/apache/hudi/issues/2033","id":679965694,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTk2NTY5NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T11:22:57Z","updated_at":"2020-08-25T11:22:57Z","author_association":"MEMBER","body":"for such a helper struct like class, it makes sense to be inline right? can you please help me understand the reason behind this refactor. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679965694/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679967819","html_url":"https://github.com/apache/hudi/issues/2017#issuecomment-679967819","issue_url":"https://api.github.com/repos/apache/hudi/issues/2017","id":679967819,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTk2NzgxOQ==","user":{"login":"Yogashri12","id":37909597,"node_id":"MDQ6VXNlcjM3OTA5NTk3","avatar_url":"https://avatars.githubusercontent.com/u/37909597?v=4","gravatar_id":"","url":"https://api.github.com/users/Yogashri12","html_url":"https://github.com/Yogashri12","followers_url":"https://api.github.com/users/Yogashri12/followers","following_url":"https://api.github.com/users/Yogashri12/following{/other_user}","gists_url":"https://api.github.com/users/Yogashri12/gists{/gist_id}","starred_url":"https://api.github.com/users/Yogashri12/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Yogashri12/subscriptions","organizations_url":"https://api.github.com/users/Yogashri12/orgs","repos_url":"https://api.github.com/users/Yogashri12/repos","events_url":"https://api.github.com/users/Yogashri12/events{/privacy}","received_events_url":"https://api.github.com/users/Yogashri12/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T11:27:52Z","updated_at":"2020-08-25T11:27:52Z","author_association":"NONE","body":"how to use ComplexKeyGenerator in pyspark.\r\nhudi_options = {\r\n'hoodie.table.name': tableName,\r\n'hoodie.datasource.write.recordkey.field': 'ID',\r\n'hoodie.datasource.write.table.name': tableName,\r\n'hoodie.datasource.write.operation': 'upsert',\r\n'hoodie.datasource.write.precombine.field': 'ID',\r\n'hoodie.upsert.shuffle.parallelism': 2,\r\n'hoodie.insert.shuffle.parallelism': 2,\r\n'hoodie.datasource.write.keygenerator.class': 'org.apache.hudi.ComplexKeyGenerator',\r\n'hoodie.datasource.write.partitionpath.field':'year/month'\r\n}\r\nthrows an error\r\npy4j.protocol.Py4JJavaError: An error occurred while calling o48.save.\r\n: java.io.IOException: Could not load key generator class org.apache.hudi.ComplexKeyGenerator\r\n\r\nsry i am new to apache hudi,so can you help me out without any hesitation.\r\n\r\nthanks in advance. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679967819/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679987475","html_url":"https://github.com/apache/hudi/pull/2033#issuecomment-679987475","issue_url":"https://api.github.com/repos/apache/hudi/issues/2033","id":679987475,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTk4NzQ3NQ==","user":{"login":"wangxianghu","id":49835526,"node_id":"MDQ6VXNlcjQ5ODM1NTI2","avatar_url":"https://avatars.githubusercontent.com/u/49835526?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxianghu","html_url":"https://github.com/wangxianghu","followers_url":"https://api.github.com/users/wangxianghu/followers","following_url":"https://api.github.com/users/wangxianghu/following{/other_user}","gists_url":"https://api.github.com/users/wangxianghu/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxianghu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxianghu/subscriptions","organizations_url":"https://api.github.com/users/wangxianghu/orgs","repos_url":"https://api.github.com/users/wangxianghu/repos","events_url":"https://api.github.com/users/wangxianghu/events{/privacy}","received_events_url":"https://api.github.com/users/wangxianghu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T12:13:58Z","updated_at":"2020-08-25T12:13:58Z","author_association":"CONTRIBUTOR","body":"> for such a helper struct like class, it makes sense to be inline right? can you please help me understand the reason behind this refactor.\r\n\r\n@vinothchandar thanks for the reply\r\nThis is prepared for the multi-engine support abstraction. In the abstraction, MergerHelper can be abstract to an abstract class, its inner class UpdateHandler referenced HoodieMergeHandle, which is related to spark. so I think maybe we can make it an independent class, convenient to expand.\r\n\r\nDoing these little adjusts before rebase(or refactor) can reduce the review work of HUDI-1089, that`s my thought, WDYT?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679987475/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679987859","html_url":"https://github.com/apache/hudi/pull/1946#issuecomment-679987859","issue_url":"https://api.github.com/repos/apache/hudi/issues/1946","id":679987859,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTk4Nzg1OQ==","user":{"login":"wangxianghu","id":49835526,"node_id":"MDQ6VXNlcjQ5ODM1NTI2","avatar_url":"https://avatars.githubusercontent.com/u/49835526?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxianghu","html_url":"https://github.com/wangxianghu","followers_url":"https://api.github.com/users/wangxianghu/followers","following_url":"https://api.github.com/users/wangxianghu/following{/other_user}","gists_url":"https://api.github.com/users/wangxianghu/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxianghu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxianghu/subscriptions","organizations_url":"https://api.github.com/users/wangxianghu/orgs","repos_url":"https://api.github.com/users/wangxianghu/repos","events_url":"https://api.github.com/users/wangxianghu/events{/privacy}","received_events_url":"https://api.github.com/users/wangxianghu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T12:14:49Z","updated_at":"2020-08-25T12:14:49Z","author_association":"CONTRIBUTOR","body":"> @wangxianghu Can you help to verify and review this PR?\r\n\r\nsure, will do","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/679987859/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680017703","html_url":"https://github.com/apache/hudi/pull/1804#issuecomment-680017703","issue_url":"https://api.github.com/repos/apache/hudi/issues/1804","id":680017703,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDAxNzcwMw==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T13:14:57Z","updated_at":"2020-08-25T13:14:57Z","author_association":"MEMBER","body":"```\r\n[ERROR] Failures: \r\n[ERROR]   ITTestHoodieDemo.testParquetDemo:115->testHiveAfterSecondBatchAfterCompaction:360->ITTestBase.assertStdOutContains:287->ITTestBase.saveUpLogs:255->ITTestBase.executeCommandStringInDocker:206->ITTestBase.executeCommandInDocker:185 Command ([cat, /tmp/root/hive.log, |, grep, -i, exception, -A, 10, -B, 5]) expected to succeed. Exit (1) ==> expected: <0> but was: <1>\r\n[INFO] \r\n```\r\n\r\nLooks like this command failed, probably because there were no exceptions here?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680017703/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680083731","html_url":"https://github.com/apache/hudi/pull/2035#issuecomment-680083731","issue_url":"https://api.github.com/repos/apache/hudi/issues/2035","id":680083731,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDA4MzczMQ==","user":{"login":"wangxianghu","id":49835526,"node_id":"MDQ6VXNlcjQ5ODM1NTI2","avatar_url":"https://avatars.githubusercontent.com/u/49835526?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxianghu","html_url":"https://github.com/wangxianghu","followers_url":"https://api.github.com/users/wangxianghu/followers","following_url":"https://api.github.com/users/wangxianghu/following{/other_user}","gists_url":"https://api.github.com/users/wangxianghu/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxianghu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxianghu/subscriptions","organizations_url":"https://api.github.com/users/wangxianghu/orgs","repos_url":"https://api.github.com/users/wangxianghu/repos","events_url":"https://api.github.com/users/wangxianghu/events{/privacy}","received_events_url":"https://api.github.com/users/wangxianghu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T15:07:33Z","updated_at":"2020-08-25T15:07:33Z","author_association":"CONTRIBUTOR","body":"@yanghu please take a look when free","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680083731/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680115497","html_url":"https://github.com/apache/hudi/issues/2029#issuecomment-680115497","issue_url":"https://api.github.com/repos/apache/hudi/issues/2029","id":680115497,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDExNTQ5Nw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T15:59:39Z","updated_at":"2020-08-25T15:59:39Z","author_association":"CONTRIBUTOR","body":"@nsivabalan : Please take a look. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680115497/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680118462","html_url":"https://github.com/apache/hudi/issues/2031#issuecomment-680118462","issue_url":"https://api.github.com/repos/apache/hudi/issues/2031","id":680118462,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDExODQ2Mg==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T16:04:31Z","updated_at":"2020-08-25T16:04:31Z","author_association":"CONTRIBUTOR","body":"@vinothsiva1989 : This is likely due to scala compiler version. I see that you are using 2.12 but most/all of spark 2.x versions comes prepackaged with 2.11 only. Can you check if you are using the right version of spark compiled against scala 2.12  ?\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680118462/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680144291","html_url":"https://github.com/apache/hudi/issues/2001#issuecomment-680144291","issue_url":"https://api.github.com/repos/apache/hudi/issues/2001","id":680144291,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDE0NDI5MQ==","user":{"login":"kpurella","id":67808897,"node_id":"MDQ6VXNlcjY3ODA4ODk3","avatar_url":"https://avatars.githubusercontent.com/u/67808897?v=4","gravatar_id":"","url":"https://api.github.com/users/kpurella","html_url":"https://github.com/kpurella","followers_url":"https://api.github.com/users/kpurella/followers","following_url":"https://api.github.com/users/kpurella/following{/other_user}","gists_url":"https://api.github.com/users/kpurella/gists{/gist_id}","starred_url":"https://api.github.com/users/kpurella/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kpurella/subscriptions","organizations_url":"https://api.github.com/users/kpurella/orgs","repos_url":"https://api.github.com/users/kpurella/repos","events_url":"https://api.github.com/users/kpurella/events{/privacy}","received_events_url":"https://api.github.com/users/kpurella/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T16:49:49Z","updated_at":"2020-08-25T16:49:49Z","author_association":"NONE","body":"@bvaradar  Thank you for your response. I was able to resolve this issue.\r\nI am building invalid partitionpath which is causing the issue. - Thank you.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680144291/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680144616","html_url":"https://github.com/apache/hudi/issues/2001#issuecomment-680144616","issue_url":"https://api.github.com/repos/apache/hudi/issues/2001","id":680144616,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDE0NDYxNg==","user":{"login":"kpurella","id":67808897,"node_id":"MDQ6VXNlcjY3ODA4ODk3","avatar_url":"https://avatars.githubusercontent.com/u/67808897?v=4","gravatar_id":"","url":"https://api.github.com/users/kpurella","html_url":"https://github.com/kpurella","followers_url":"https://api.github.com/users/kpurella/followers","following_url":"https://api.github.com/users/kpurella/following{/other_user}","gists_url":"https://api.github.com/users/kpurella/gists{/gist_id}","starred_url":"https://api.github.com/users/kpurella/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kpurella/subscriptions","organizations_url":"https://api.github.com/users/kpurella/orgs","repos_url":"https://api.github.com/users/kpurella/repos","events_url":"https://api.github.com/users/kpurella/events{/privacy}","received_events_url":"https://api.github.com/users/kpurella/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T16:50:26Z","updated_at":"2020-08-25T16:50:26Z","author_association":"NONE","body":"Resolved after addressing partitionpath issue.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680144616/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680168375","html_url":"https://github.com/apache/hudi/issues/1954#issuecomment-680168375","issue_url":"https://api.github.com/repos/apache/hudi/issues/1954","id":680168375,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDE2ODM3NQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T17:32:47Z","updated_at":"2020-08-25T17:32:47Z","author_association":"CONTRIBUTOR","body":"@satishkotha : Would you be able to help reproduce this  ? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680168375/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680174568","html_url":"https://github.com/apache/hudi/issues/2005#issuecomment-680174568","issue_url":"https://api.github.com/repos/apache/hudi/issues/2005","id":680174568,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDE3NDU2OA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T17:45:07Z","updated_at":"2020-08-25T17:45:07Z","author_association":"CONTRIBUTOR","body":"@cdmikechen : The integration test actually brings up a dockerized environment and runs spark-submit command. So, the dependencies specified in hudi-integ-test/pom.xml should not be part of the deltastreamer run. As you can look from my spark-submit command in my previous comment, only HUDI_UTILITIES_BUNDLE is passed. otherwise, it is only spark runtime environment. \r\n\r\nThe ParquetInputFormatClass is part of parquer-hadoop-bundle.\r\nroot@adhoc-2:/opt# grep -r 'parquet.hadoop.ParquetInputFormat' $SPARK_HOME/jars/*\r\nBinary file /opt/spark/jars/parquet-hadoop-1.10.1.jar matches\r\nBinary file /opt/spark/jars/parquet-hadoop-bundle-1.6.0.jar matches\r\nroot@adhoc-2:/opt# \r\n\r\nroot@adhoc-2:/opt# jar tf /opt/spark/jars/parquet-hadoop-bundle-1.6.0.jar | grep ParquetInputFormat.class\r\nparquet/hadoop/mapred/DeprecatedParquetInputFormat.class\r\nparquet/hadoop/ParquetInputFormat.class\r\n\r\nAre you using the spark distribution prebuilt with hadoop ? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680174568/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680216583","html_url":"https://github.com/apache/hudi/issues/1751#issuecomment-680216583","issue_url":"https://api.github.com/repos/apache/hudi/issues/1751","id":680216583,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDIxNjU4Mw==","user":{"login":"shashwatsrivastava94","id":6412006,"node_id":"MDQ6VXNlcjY0MTIwMDY=","avatar_url":"https://avatars.githubusercontent.com/u/6412006?v=4","gravatar_id":"","url":"https://api.github.com/users/shashwatsrivastava94","html_url":"https://github.com/shashwatsrivastava94","followers_url":"https://api.github.com/users/shashwatsrivastava94/followers","following_url":"https://api.github.com/users/shashwatsrivastava94/following{/other_user}","gists_url":"https://api.github.com/users/shashwatsrivastava94/gists{/gist_id}","starred_url":"https://api.github.com/users/shashwatsrivastava94/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shashwatsrivastava94/subscriptions","organizations_url":"https://api.github.com/users/shashwatsrivastava94/orgs","repos_url":"https://api.github.com/users/shashwatsrivastava94/repos","events_url":"https://api.github.com/users/shashwatsrivastava94/events{/privacy}","received_events_url":"https://api.github.com/users/shashwatsrivastava94/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T19:08:52Z","updated_at":"2020-08-25T19:08:52Z","author_association":"NONE","body":"Was wondering if there is an update here! Running a PoC and would love to use Hudi + Spark 3 if possible.\r\nThanks!","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680216583/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680230551","html_url":"https://github.com/apache/hudi/issues/2034#issuecomment-680230551","issue_url":"https://api.github.com/repos/apache/hudi/issues/2034","id":680230551,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDIzMDU1MQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T19:39:13Z","updated_at":"2020-08-25T19:39:13Z","author_association":"CONTRIBUTOR","body":"Looking at the constructor of java.sql.Date, \r\n\r\nDate(long date) :Constructs a Date object using the given milliseconds time value.\r\nIt expects time resolution in milliseconds. \r\n\r\nBut from debezium and Avro specification page, it looks like INT for DATE logical type represents the number of days since epoch. \r\n\r\nFiled a Jira : https://issues.apache.org/jira/browse/HUDI-1225\r\n\r\ncc @shenh062326  \r\n\r\n@cdmikechen : Can you send a PR to fix it ? \r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680230551/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680231795","html_url":"https://github.com/apache/hudi/issues/1751#issuecomment-680231795","issue_url":"https://api.github.com/repos/apache/hudi/issues/1751","id":680231795,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDIzMTc5NQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T19:42:13Z","updated_at":"2020-08-25T19:42:13Z","author_association":"CONTRIBUTOR","body":"@nsivabalan : Can you reply when you get a chance ?\r\n\r\nThanks,\r\nBalaji.V","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680231795/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680233990","html_url":"https://github.com/apache/hudi/issues/2007#issuecomment-680233990","issue_url":"https://api.github.com/repos/apache/hudi/issues/2007","id":680233990,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDIzMzk5MA==","user":{"login":"ashishmgofficial","id":40498599,"node_id":"MDQ6VXNlcjQwNDk4NTk5","avatar_url":"https://avatars.githubusercontent.com/u/40498599?v=4","gravatar_id":"","url":"https://api.github.com/users/ashishmgofficial","html_url":"https://github.com/ashishmgofficial","followers_url":"https://api.github.com/users/ashishmgofficial/followers","following_url":"https://api.github.com/users/ashishmgofficial/following{/other_user}","gists_url":"https://api.github.com/users/ashishmgofficial/gists{/gist_id}","starred_url":"https://api.github.com/users/ashishmgofficial/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ashishmgofficial/subscriptions","organizations_url":"https://api.github.com/users/ashishmgofficial/orgs","repos_url":"https://api.github.com/users/ashishmgofficial/repos","events_url":"https://api.github.com/users/ashishmgofficial/events{/privacy}","received_events_url":"https://api.github.com/users/ashishmgofficial/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T19:47:09Z","updated_at":"2020-08-25T19:48:07Z","author_association":"NONE","body":"@bvaradar Yes, we want to keep the metadata details and if possible store it somewhere for other analytical purposes and for audit","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680233990/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680259178","html_url":"https://github.com/apache/hudi/issues/1954#issuecomment-680259178","issue_url":"https://api.github.com/repos/apache/hudi/issues/1954","id":680259178,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDI1OTE3OA==","user":{"login":"satishkotha","id":2992755,"node_id":"MDQ6VXNlcjI5OTI3NTU=","avatar_url":"https://avatars.githubusercontent.com/u/2992755?v=4","gravatar_id":"","url":"https://api.github.com/users/satishkotha","html_url":"https://github.com/satishkotha","followers_url":"https://api.github.com/users/satishkotha/followers","following_url":"https://api.github.com/users/satishkotha/following{/other_user}","gists_url":"https://api.github.com/users/satishkotha/gists{/gist_id}","starred_url":"https://api.github.com/users/satishkotha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/satishkotha/subscriptions","organizations_url":"https://api.github.com/users/satishkotha/orgs","repos_url":"https://api.github.com/users/satishkotha/repos","events_url":"https://api.github.com/users/satishkotha/events{/privacy}","received_events_url":"https://api.github.com/users/satishkotha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T20:41:58Z","updated_at":"2020-08-25T20:41:58Z","author_association":"MEMBER","body":"@tooptoop4  \r\nFor non-partitioned tables, data is typically stored in base directory (s3://redact/my2/multpk7/). Looks like partitionpath field you specified is getting interpreted incorrectly, so the data is being stored under 'default' partition. You also specified 'NonPartitionedExtractor' for hive sync. So 'default' partition is not registered with hive.\r\n\r\n ComplexKeyGenerator doesn't seem to work well with non-partitioned tables. I tried making it work by making this code change https://github.com/apache/hudi/pull/2037. Can you apply this patch and let me know if it works?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680259178/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680262762","html_url":"https://github.com/apache/hudi/issues/1954#issuecomment-680262762","issue_url":"https://api.github.com/repos/apache/hudi/issues/1954","id":680262762,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDI2Mjc2Mg==","user":{"login":"satishkotha","id":2992755,"node_id":"MDQ6VXNlcjI5OTI3NTU=","avatar_url":"https://avatars.githubusercontent.com/u/2992755?v=4","gravatar_id":"","url":"https://api.github.com/users/satishkotha","html_url":"https://github.com/satishkotha","followers_url":"https://api.github.com/users/satishkotha/followers","following_url":"https://api.github.com/users/satishkotha/following{/other_user}","gists_url":"https://api.github.com/users/satishkotha/gists{/gist_id}","starred_url":"https://api.github.com/users/satishkotha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/satishkotha/subscriptions","organizations_url":"https://api.github.com/users/satishkotha/orgs","repos_url":"https://api.github.com/users/satishkotha/repos","events_url":"https://api.github.com/users/satishkotha/events{/privacy}","received_events_url":"https://api.github.com/users/satishkotha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T20:50:04Z","updated_at":"2020-08-25T20:50:04Z","author_association":"MEMBER","body":"If a single column as key works for you, you can also try\r\n\r\nhoodie.datasource.write.keygenerator.class=com.uber.hoodie.NonpartitionedKeyGenerator\r\nhoodie.datasource.hive_sync.partition_extractor_class=com.uber.hoodie.hive.NonPartitionedExtractor\r\nhoodie.datasource.write.recordkey.field=(new column that is unique)\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680262762/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680279264","html_url":"https://github.com/apache/hudi/pull/2037#issuecomment-680279264","issue_url":"https://api.github.com/repos/apache/hudi/issues/2037","id":680279264,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDI3OTI2NA==","user":{"login":"satishkotha","id":2992755,"node_id":"MDQ6VXNlcjI5OTI3NTU=","avatar_url":"https://avatars.githubusercontent.com/u/2992755?v=4","gravatar_id":"","url":"https://api.github.com/users/satishkotha","html_url":"https://github.com/satishkotha","followers_url":"https://api.github.com/users/satishkotha/followers","following_url":"https://api.github.com/users/satishkotha/following{/other_user}","gists_url":"https://api.github.com/users/satishkotha/gists{/gist_id}","starred_url":"https://api.github.com/users/satishkotha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/satishkotha/subscriptions","organizations_url":"https://api.github.com/users/satishkotha/orgs","repos_url":"https://api.github.com/users/satishkotha/repos","events_url":"https://api.github.com/users/satishkotha/events{/privacy}","received_events_url":"https://api.github.com/users/satishkotha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T21:29:01Z","updated_at":"2020-08-25T21:29:01Z","author_association":"MEMBER","body":"> @satishkotha was it throwing an exception before this change ?\r\n\r\nFrom https://issues.apache.org/jira/browse/HUDI-1226, \r\n1) If we pass empty string(-hoodie-conf hoodie.datasource.write.partitionpath.field=), generator returns 'default' as partitionpath\r\n2) if we pass delimiter alone (-hoodie-conf hoodie.datasource.write.partitionpath.field=,), it throws\r\njava.lang.StringIndexOutOfBoundsException: String index out of range: -1\r\n\r\nat java.lang.AbstractStringBuilder.deleteCharAt(AbstractStringBuilder.java:824)\r\nat java.lang.StringBuilder.deleteCharAt(StringBuilder.java:253)\r\nat org.apache.hudi.keygen.KeyGenUtils.getRecordPartitionPath(KeyGenUtils.java:80)\r\nat org.apache.hudi.keygen.ComplexKeyGenerator.getPartitionPath(ComplexKeyGenerator.java:52)\r\nat org.apache.hudi.keygen.BuiltinKeyGenerator.getKey(BuiltinKeyGenerator.java:75)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680279264/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680284122","html_url":"https://github.com/apache/hudi/issues/1981#issuecomment-680284122","issue_url":"https://api.github.com/repos/apache/hudi/issues/1981","id":680284122,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDI4NDEyMg==","user":{"login":"rubenssoto","id":36298331,"node_id":"MDQ6VXNlcjM2Mjk4MzMx","avatar_url":"https://avatars.githubusercontent.com/u/36298331?v=4","gravatar_id":"","url":"https://api.github.com/users/rubenssoto","html_url":"https://github.com/rubenssoto","followers_url":"https://api.github.com/users/rubenssoto/followers","following_url":"https://api.github.com/users/rubenssoto/following{/other_user}","gists_url":"https://api.github.com/users/rubenssoto/gists{/gist_id}","starred_url":"https://api.github.com/users/rubenssoto/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rubenssoto/subscriptions","organizations_url":"https://api.github.com/users/rubenssoto/orgs","repos_url":"https://api.github.com/users/rubenssoto/repos","events_url":"https://api.github.com/users/rubenssoto/events{/privacy}","received_events_url":"https://api.github.com/users/rubenssoto/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T21:42:18Z","updated_at":"2020-08-25T21:42:18Z","author_association":"NONE","body":"@bvaradar is this problem was solved in 0.6 because I read that rfc 15 is in experimental.\r\nAnd Athena already support? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680284122/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680284508","html_url":"https://github.com/apache/hudi/issues/1981#issuecomment-680284508","issue_url":"https://api.github.com/repos/apache/hudi/issues/1981","id":680284508,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDI4NDUwOA==","user":{"login":"rubenssoto","id":36298331,"node_id":"MDQ6VXNlcjM2Mjk4MzMx","avatar_url":"https://avatars.githubusercontent.com/u/36298331?v=4","gravatar_id":"","url":"https://api.github.com/users/rubenssoto","html_url":"https://github.com/rubenssoto","followers_url":"https://api.github.com/users/rubenssoto/followers","following_url":"https://api.github.com/users/rubenssoto/following{/other_user}","gists_url":"https://api.github.com/users/rubenssoto/gists{/gist_id}","starred_url":"https://api.github.com/users/rubenssoto/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rubenssoto/subscriptions","organizations_url":"https://api.github.com/users/rubenssoto/orgs","repos_url":"https://api.github.com/users/rubenssoto/repos","events_url":"https://api.github.com/users/rubenssoto/events{/privacy}","received_events_url":"https://api.github.com/users/rubenssoto/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T21:43:14Z","updated_at":"2020-08-25T21:43:14Z","author_association":"NONE","body":"@umehrot2 ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680284508/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680287507","html_url":"https://github.com/apache/hudi/pull/2037#issuecomment-680287507","issue_url":"https://api.github.com/repos/apache/hudi/issues/2037","id":680287507,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDI4NzUwNw==","user":{"login":"satishkotha","id":2992755,"node_id":"MDQ6VXNlcjI5OTI3NTU=","avatar_url":"https://avatars.githubusercontent.com/u/2992755?v=4","gravatar_id":"","url":"https://api.github.com/users/satishkotha","html_url":"https://github.com/satishkotha","followers_url":"https://api.github.com/users/satishkotha/followers","following_url":"https://api.github.com/users/satishkotha/following{/other_user}","gists_url":"https://api.github.com/users/satishkotha/gists{/gist_id}","starred_url":"https://api.github.com/users/satishkotha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/satishkotha/subscriptions","organizations_url":"https://api.github.com/users/satishkotha/orgs","repos_url":"https://api.github.com/users/satishkotha/repos","events_url":"https://api.github.com/users/satishkotha/events{/privacy}","received_events_url":"https://api.github.com/users/satishkotha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T21:51:31Z","updated_at":"2020-08-25T21:51:31Z","author_association":"MEMBER","body":"> > @satishkotha was it throwing an exception before this change ?\r\n> \r\n> From https://issues.apache.org/jira/browse/HUDI-1226,\r\n> \r\n> 1. If we pass empty string(-hoodie-conf hoodie.datasource.write.partitionpath.field=), generator returns 'default' as partitionpath\r\n> 2. if we pass delimiter alone (-hoodie-conf hoodie.datasource.write.partitionpath.field=,), it throws\r\n>    java.lang.StringIndexOutOfBoundsException: String index out of range: -1\r\n> \r\n> at java.lang.AbstractStringBuilder.deleteCharAt(AbstractStringBuilder.java:824)\r\n> at java.lang.StringBuilder.deleteCharAt(StringBuilder.java:253)\r\n> at org.apache.hudi.keygen.KeyGenUtils.getRecordPartitionPath(KeyGenUtils.java:80)\r\n> at org.apache.hudi.keygen.ComplexKeyGenerator.getPartitionPath(ComplexKeyGenerator.java:52)\r\n> at org.apache.hudi.keygen.BuiltinKeyGenerator.getKey(BuiltinKeyGenerator.java:75)\r\n\r\n@n3nash ^","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680287507/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680303027","html_url":"https://github.com/apache/hudi/issues/1980#issuecomment-680303027","issue_url":"https://api.github.com/repos/apache/hudi/issues/1980","id":680303027,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDMwMzAyNw==","user":{"login":"jiegzhan","id":10664626,"node_id":"MDQ6VXNlcjEwNjY0NjI2","avatar_url":"https://avatars.githubusercontent.com/u/10664626?v=4","gravatar_id":"","url":"https://api.github.com/users/jiegzhan","html_url":"https://github.com/jiegzhan","followers_url":"https://api.github.com/users/jiegzhan/followers","following_url":"https://api.github.com/users/jiegzhan/following{/other_user}","gists_url":"https://api.github.com/users/jiegzhan/gists{/gist_id}","starred_url":"https://api.github.com/users/jiegzhan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jiegzhan/subscriptions","organizations_url":"https://api.github.com/users/jiegzhan/orgs","repos_url":"https://api.github.com/users/jiegzhan/repos","events_url":"https://api.github.com/users/jiegzhan/events{/privacy}","received_events_url":"https://api.github.com/users/jiegzhan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-25T22:35:47Z","updated_at":"2020-08-25T22:35:47Z","author_association":"NONE","body":"Thanks for your explanation, @bvaradar. Closed this ticket. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680303027/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680351956","html_url":"https://github.com/apache/hudi/issues/2005#issuecomment-680351956","issue_url":"https://api.github.com/repos/apache/hudi/issues/2005","id":680351956,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDM1MTk1Ng==","user":{"login":"cdmikechen","id":12069428,"node_id":"MDQ6VXNlcjEyMDY5NDI4","avatar_url":"https://avatars.githubusercontent.com/u/12069428?v=4","gravatar_id":"","url":"https://api.github.com/users/cdmikechen","html_url":"https://github.com/cdmikechen","followers_url":"https://api.github.com/users/cdmikechen/followers","following_url":"https://api.github.com/users/cdmikechen/following{/other_user}","gists_url":"https://api.github.com/users/cdmikechen/gists{/gist_id}","starred_url":"https://api.github.com/users/cdmikechen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cdmikechen/subscriptions","organizations_url":"https://api.github.com/users/cdmikechen/orgs","repos_url":"https://api.github.com/users/cdmikechen/repos","events_url":"https://api.github.com/users/cdmikechen/events{/privacy}","received_events_url":"https://api.github.com/users/cdmikechen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T00:25:42Z","updated_at":"2020-08-26T00:26:11Z","author_association":"CONTRIBUTOR","body":"@bvaradar \r\nThanks for your reminder, I finally found my mistake: \r\nI use hudi in a maven project with spark dependencies. I noticed that hudi remove `com.twitter:parquet-hadoop-bundle`, so that I also removed this dependency in my project.\r\n```\r\n<exclusions>\r\n    <exclusion>\r\n        <groupId>com.twitter</groupId>\r\n        <artifactId>parquet-hadoop-bundle</artifactId>\r\n    </exclusion>\r\n</exclusions>\r\n```\r\nTherefore, when starting a spark task in this maven project, hudi can not find `parquet-hadoop-bundle-1.6.0.jar` and `parquet.hadoop.ParquetInputFormat` class. If I add this dependency, it should not report this error .\r\n\r\nMeanwhile, I think my another suggestion which we should avoid new `FileInputFormat` to just get class name should be fixed.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680351956/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680364028","html_url":"https://github.com/apache/hudi/issues/2034#issuecomment-680364028","issue_url":"https://api.github.com/repos/apache/hudi/issues/2034","id":680364028,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDM2NDAyOA==","user":{"login":"cdmikechen","id":12069428,"node_id":"MDQ6VXNlcjEyMDY5NDI4","avatar_url":"https://avatars.githubusercontent.com/u/12069428?v=4","gravatar_id":"","url":"https://api.github.com/users/cdmikechen","html_url":"https://github.com/cdmikechen","followers_url":"https://api.github.com/users/cdmikechen/followers","following_url":"https://api.github.com/users/cdmikechen/following{/other_user}","gists_url":"https://api.github.com/users/cdmikechen/gists{/gist_id}","starred_url":"https://api.github.com/users/cdmikechen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cdmikechen/subscriptions","organizations_url":"https://api.github.com/users/cdmikechen/orgs","repos_url":"https://api.github.com/users/cdmikechen/repos","events_url":"https://api.github.com/users/cdmikechen/events{/privacy}","received_events_url":"https://api.github.com/users/cdmikechen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T00:35:28Z","updated_at":"2020-08-26T00:35:28Z","author_association":"CONTRIBUTOR","body":"@bvaradar \r\nYes, of course. I will deal with it recently.\r\nI've test a case in hive, I found hive may also parse date type as int and display it as `yyyy-mm-dd`, according to day offsets from `1970-01-01`. \r\n ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680364028/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680376811","html_url":"https://github.com/apache/hudi/pull/2032#issuecomment-680376811","issue_url":"https://api.github.com/repos/apache/hudi/issues/2032","id":680376811,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDM3NjgxMQ==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T00:46:01Z","updated_at":"2020-08-26T00:46:01Z","author_association":"CONTRIBUTOR","body":"> ## _Tips_\r\n> * _Thank you very much for contributing to Apache Hudi._\r\n> * _Please review https://hudi.apache.org/contributing.html before opening a pull request._\r\n> \r\n> ## What is the purpose of the pull request\r\n> _(For example: This pull request adds quick-start document.)_\r\n> \r\n> ## Brief change log\r\n> _(for example:)_\r\n> \r\n> * _Modify AnnotationLocation checkstyle rule in checkstyle.xml_\r\n> \r\n> ## Verify this pull request\r\n> _(Please pick either of the following options)_\r\n> \r\n> This pull request is a trivial rework / code cleanup without any test coverage.\r\n> \r\n> _(or)_\r\n> \r\n> This pull request is already covered by existing tests, such as _(please describe tests)_.\r\n> \r\n> (or)\r\n> \r\n> This change added tests and can be verified as follows:\r\n> \r\n> _(example:)_\r\n> \r\n> * _Added integration tests for end-to-end._\r\n> * _Added HoodieClientWriteTest to verify the change._\r\n> * _Manually verified the change by running a job locally._\r\n> \r\n> ## Committer checklist\r\n> * [ ]  Has a corresponding JIRA in PR title & commit\r\n> * [ ]  Commit message is descriptive of the change\r\n> * [ ]  CI is green\r\n> * [ ]  Necessary doc changes done or have another open PR\r\n> * [ ]  For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.\r\n\r\nIMO, it would be better to write correct description of each PR.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680376811/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680381474","html_url":"https://github.com/apache/hudi/pull/1804#issuecomment-680381474","issue_url":"https://api.github.com/repos/apache/hudi/issues/1804","id":680381474,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDM4MTQ3NA==","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T00:49:54Z","updated_at":"2020-08-26T00:49:54Z","author_association":"MEMBER","body":"actually compaction is failing. \r\n\r\n```\r\nINFO: 20/08/25 01:10:42 ERROR HoodieCompactor: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, 172.18.0.13, executor 0): java.io.InvalidClassException: org.apache.hudi.config.HoodieWriteConfig; local class incompatible: stream classdesc serialVersionUID = 5557714552053876810, local class serialVersionUID = 2074255769914985087\r\nAug 25, 2020 1:10:42 AM org.apache.hudi.cli.utils.InputStreamConsumer run\r\nINFO: \tat java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:699)\r\n```\r\n\r\nthats the real issue. looking ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680381474/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680390778","html_url":"https://github.com/apache/hudi/pull/1772#issuecomment-680390778","issue_url":"https://api.github.com/repos/apache/hudi/issues/1772","id":680390778,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDM5MDc3OA==","user":{"login":"yanghua","id":2283778,"node_id":"MDQ6VXNlcjIyODM3Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2283778?v=4","gravatar_id":"","url":"https://api.github.com/users/yanghua","html_url":"https://github.com/yanghua","followers_url":"https://api.github.com/users/yanghua/followers","following_url":"https://api.github.com/users/yanghua/following{/other_user}","gists_url":"https://api.github.com/users/yanghua/gists{/gist_id}","starred_url":"https://api.github.com/users/yanghua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yanghua/subscriptions","organizations_url":"https://api.github.com/users/yanghua/orgs","repos_url":"https://api.github.com/users/yanghua/repos","events_url":"https://api.github.com/users/yanghua/events{/privacy}","received_events_url":"https://api.github.com/users/yanghua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T00:57:38Z","updated_at":"2020-08-26T00:57:38Z","author_association":"CONTRIBUTOR","body":"@Trevor-zhang Can you help to review this PR? 3ks.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680390778/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680424479","html_url":"https://github.com/apache/hudi/issues/2038#issuecomment-680424479","issue_url":"https://api.github.com/repos/apache/hudi/issues/2038","id":680424479,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDQyNDQ3OQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T02:35:13Z","updated_at":"2020-08-26T02:35:13Z","author_association":"CONTRIBUTOR","body":"Yes, Hudi is compiled with hive 2.x ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680424479/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680432778","html_url":"https://github.com/apache/hudi/issues/2005#issuecomment-680432778","issue_url":"https://api.github.com/repos/apache/hudi/issues/2005","id":680432778,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDQzMjc3OA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T02:41:15Z","updated_at":"2020-08-26T02:41:15Z","author_association":"CONTRIBUTOR","body":"Thanks @cdmikechen  for clarifying. Agree on not having to instantiate the input format. @garyli1019  has a PR for this : https://github.com/apache/hudi/pull/2008\r\n\r\nClosing this ticket !!","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680432778/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680443395","html_url":"https://github.com/apache/hudi/issues/2017#issuecomment-680443395","issue_url":"https://api.github.com/repos/apache/hudi/issues/2017","id":680443395,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDQ0MzM5NQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T02:48:29Z","updated_at":"2020-08-26T02:48:29Z","author_association":"CONTRIBUTOR","body":"@Yogashri12 : \r\n\r\nhoodie.datasource.write.keygenerator.class \r\n should be set to  org.apache.hudi.keygen.ComplexKeyGenerator\r\nand not org.apache.hudi.ComplexKeyGenerator\r\n\r\nCan you let me know where you found this reference toComplexKeyGenerator. We might need to fix the document accordingly ? \r\n\r\nAlso, set hoodie.datasource.write.partitionpath.field to \"year,month\"\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680443395/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680450091","html_url":"https://github.com/apache/hudi/issues/2020#issuecomment-680450091","issue_url":"https://api.github.com/repos/apache/hudi/issues/2020","id":680450091,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDQ1MDA5MQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T02:53:16Z","updated_at":"2020-08-26T02:53:16Z","author_association":"CONTRIBUTOR","body":"@dm-tran : No, that should be fine. Hudi logic takes care of Spark retries. So, that should not be the issue. Given, that you are able to reproduce very easily and I have not seen this issue reported by anyone, Would you be able to provide us a self-contained code to reproduce this. I can set up S3 and try.  If not, can you turn on INFO level logging and catch the logs till you hit the exception and attach them. I am not sure how else to debug this. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680450091/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680502038","html_url":"https://github.com/apache/hudi/pull/2012#issuecomment-680502038","issue_url":"https://api.github.com/repos/apache/hudi/issues/2012","id":680502038,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDUwMjAzOA==","user":{"login":"sathyaprakashg","id":15080820,"node_id":"MDQ6VXNlcjE1MDgwODIw","avatar_url":"https://avatars.githubusercontent.com/u/15080820?v=4","gravatar_id":"","url":"https://api.github.com/users/sathyaprakashg","html_url":"https://github.com/sathyaprakashg","followers_url":"https://api.github.com/users/sathyaprakashg/followers","following_url":"https://api.github.com/users/sathyaprakashg/following{/other_user}","gists_url":"https://api.github.com/users/sathyaprakashg/gists{/gist_id}","starred_url":"https://api.github.com/users/sathyaprakashg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sathyaprakashg/subscriptions","organizations_url":"https://api.github.com/users/sathyaprakashg/orgs","repos_url":"https://api.github.com/users/sathyaprakashg/repos","events_url":"https://api.github.com/users/sathyaprakashg/events{/privacy}","received_events_url":"https://api.github.com/users/sathyaprakashg/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T03:29:53Z","updated_at":"2020-08-26T03:29:53Z","author_association":"CONTRIBUTOR","body":"Thanks @sbernauer for the code example. I fixed it now","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680502038/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680653572","html_url":"https://github.com/apache/hudi/issues/2041#issuecomment-680653572","issue_url":"https://api.github.com/repos/apache/hudi/issues/2041","id":680653572,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDY1MzU3Mg==","user":{"login":"zherenyu831","id":52404525,"node_id":"MDQ6VXNlcjUyNDA0NTI1","avatar_url":"https://avatars.githubusercontent.com/u/52404525?v=4","gravatar_id":"","url":"https://api.github.com/users/zherenyu831","html_url":"https://github.com/zherenyu831","followers_url":"https://api.github.com/users/zherenyu831/followers","following_url":"https://api.github.com/users/zherenyu831/following{/other_user}","gists_url":"https://api.github.com/users/zherenyu831/gists{/gist_id}","starred_url":"https://api.github.com/users/zherenyu831/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zherenyu831/subscriptions","organizations_url":"https://api.github.com/users/zherenyu831/orgs","repos_url":"https://api.github.com/users/zherenyu831/repos","events_url":"https://api.github.com/users/zherenyu831/events{/privacy}","received_events_url":"https://api.github.com/users/zherenyu831/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T05:16:11Z","updated_at":"2020-08-26T05:16:24Z","author_association":"CONTRIBUTOR","body":"Fixed second problem by adding hive-exec into pom\r\n```\r\n\"org.apache.hive\" % \"hive-exec\" % \"3.1.2\" % Provided,\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680653572/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680656042","html_url":"https://github.com/apache/hudi/issues/2041#issuecomment-680656042","issue_url":"https://api.github.com/repos/apache/hudi/issues/2041","id":680656042,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDY1NjA0Mg==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T05:17:52Z","updated_at":"2020-08-26T05:17:52Z","author_association":"CONTRIBUTOR","body":"@zherenyu831 : I have seen this kind of issue (first problem) if you use prebuilt version of spark. Spark 2.x is prebuilt with scala 2.11 and you are using Hudi built with scala 2.12. Can you confirm if this is the case ?\r\n\r\nLooking into the second issue.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680656042/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680661912","html_url":"https://github.com/apache/hudi/issues/2041#issuecomment-680661912","issue_url":"https://api.github.com/repos/apache/hudi/issues/2041","id":680661912,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDY2MTkxMg==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T05:21:56Z","updated_at":"2020-08-26T05:21:56Z","author_association":"CONTRIBUTOR","body":"Regarding second problem, can you use Hive 2.x (e.g: 2.3.3) version. This is what hudi is compiled with.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680661912/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680663016","html_url":"https://github.com/apache/hudi/issues/2041#issuecomment-680663016","issue_url":"https://api.github.com/repos/apache/hudi/issues/2041","id":680663016,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDY2MzAxNg==","user":{"login":"zherenyu831","id":52404525,"node_id":"MDQ6VXNlcjUyNDA0NTI1","avatar_url":"https://avatars.githubusercontent.com/u/52404525?v=4","gravatar_id":"","url":"https://api.github.com/users/zherenyu831","html_url":"https://github.com/zherenyu831","followers_url":"https://api.github.com/users/zherenyu831/followers","following_url":"https://api.github.com/users/zherenyu831/following{/other_user}","gists_url":"https://api.github.com/users/zherenyu831/gists{/gist_id}","starred_url":"https://api.github.com/users/zherenyu831/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zherenyu831/subscriptions","organizations_url":"https://api.github.com/users/zherenyu831/orgs","repos_url":"https://api.github.com/users/zherenyu831/repos","events_url":"https://api.github.com/users/zherenyu831/events{/privacy}","received_events_url":"https://api.github.com/users/zherenyu831/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T05:24:10Z","updated_at":"2020-08-26T05:24:10Z","author_association":"CONTRIBUTOR","body":"@bvaradar \r\nThank you for quick response\r\n\r\n> I have seen this kind of issue (first problem) if you use prebuilt version of spark. Spark 2.x is prebuilt with scala 2.11 and you are using Hudi built with scala 2.12. Can you confirm if this is the case ?\r\n\r\nYes, we are using scala 2.12.11","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680663016/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680685136","html_url":"https://github.com/apache/hudi/issues/1979#issuecomment-680685136","issue_url":"https://api.github.com/repos/apache/hudi/issues/1979","id":680685136,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDY4NTEzNg==","user":{"login":"hughfdjackson","id":545689,"node_id":"MDQ6VXNlcjU0NTY4OQ==","avatar_url":"https://avatars.githubusercontent.com/u/545689?v=4","gravatar_id":"","url":"https://api.github.com/users/hughfdjackson","html_url":"https://github.com/hughfdjackson","followers_url":"https://api.github.com/users/hughfdjackson/followers","following_url":"https://api.github.com/users/hughfdjackson/following{/other_user}","gists_url":"https://api.github.com/users/hughfdjackson/gists{/gist_id}","starred_url":"https://api.github.com/users/hughfdjackson/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hughfdjackson/subscriptions","organizations_url":"https://api.github.com/users/hughfdjackson/orgs","repos_url":"https://api.github.com/users/hughfdjackson/repos","events_url":"https://api.github.com/users/hughfdjackson/events{/privacy}","received_events_url":"https://api.github.com/users/hughfdjackson/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T06:26:22Z","updated_at":"2020-08-26T06:27:39Z","author_association":"NONE","body":"Hi @bvaradar -  \r\n\r\n> In general getting incremental read to discard duplicates is not possible for MOR table types as we defer the merging of records to compaction.\r\n\r\nThat's interesting - as your comment suggests, I've only looked at CoW tables in any depth.  I look forward to delving into MoR's design in a bit more detail so I can get my head around what the implications of such a feature would be there + understand your comment better. \r\n\r\n> I was thinking about alternate ways to achieve your use-case for COW table by using an application level boolean flag. Let me know if this makes sense:\r\n> \r\n>     Introduce additional boolean column \"changed\". Default Value is false.\r\n>     Have your own implementation of HoodieRecordPayload plugged-in.\r\n>     3a In HoodieRecordPayload.getInsertValue(), return an avro record with changed = true. This function is called first time when the new record is inserted.\r\n>     3(b) In HoodieRecordPayload.combineAndGetUpdateValue(), if you determine, there is no material change, set changed = false else set it to true.\r\n> \r\n> In your incremental query, add the filter changed = true to filter out those without material changes ?\r\n\r\nThat does make sense, although I think a boolean column may lead to missing changes if the incremental read spans two or more commits to the same row.  I'm spiking a variation on that suggesting with my team, wherein: \r\n\r\n1. Introduce a 'last_updated_timestamp', default to null (i.e. the update was in this commit)\r\n2. Have your own implementation of HoodieRecordPayload plugged-in.\r\n3. a. In HoodieRecordPayload.getInsertValue(), return an avro record with last_updated_timestamp = null.*\r\n3. b. In HoodieRecordPayload.combineAndGetUpdateValue(), if you determine, there is no material change, set last_updated_timestamp to that of the old record (if it exists) _or_ to the old record's commit_time. \r\n\r\nIn the incremental query, we're filtering for `null` (which indicates that one of the commits within the timeline last updated the record) or for `last_updated_timestamp` within the beginInstant and endInstant bounds. \r\n\r\nWe've not tested it extensively, but it looks like a promising workaround so far. \r\n\r\n---\r\n\r\n\\* It'd be 'cleaner' to set this equal to the commit time of the write, but in our HoodieRecordPayload class, that's not available unfortunately.  The 'null means insert' + special case handling in HoodieRecordPayload.combineAndGetUpdateValue() is a work-around for that.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680685136/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680697513","html_url":"https://github.com/apache/hudi/issues/2017#issuecomment-680697513","issue_url":"https://api.github.com/repos/apache/hudi/issues/2017","id":680697513,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDY5NzUxMw==","user":{"login":"Yogashri12","id":37909597,"node_id":"MDQ6VXNlcjM3OTA5NTk3","avatar_url":"https://avatars.githubusercontent.com/u/37909597?v=4","gravatar_id":"","url":"https://api.github.com/users/Yogashri12","html_url":"https://github.com/Yogashri12","followers_url":"https://api.github.com/users/Yogashri12/followers","following_url":"https://api.github.com/users/Yogashri12/following{/other_user}","gists_url":"https://api.github.com/users/Yogashri12/gists{/gist_id}","starred_url":"https://api.github.com/users/Yogashri12/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Yogashri12/subscriptions","organizations_url":"https://api.github.com/users/Yogashri12/orgs","repos_url":"https://api.github.com/users/Yogashri12/repos","events_url":"https://api.github.com/users/Yogashri12/events{/privacy}","received_events_url":"https://api.github.com/users/Yogashri12/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T06:58:20Z","updated_at":"2020-08-26T06:58:20Z","author_association":"NONE","body":"thank you,\r\nthe partition is working totally fine.\r\n\r\nIn configuration page,\r\n\r\nKEYGENERATOR_CLASS_OPT_KEY\r\nProperty: hoodie.datasource.write.keygenerator.class, Default: org.apache.hudi.SimpleKeyGenerator\r\nKey generator class, that implements will extract the key out of incoming Row object\r\n\r\ni just modified it into org.apache.hudi.ComplexKeyGenerator","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680697513/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680699277","html_url":"https://github.com/apache/hudi/issues/2017#issuecomment-680699277","issue_url":"https://api.github.com/repos/apache/hudi/issues/2017","id":680699277,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDY5OTI3Nw==","user":{"login":"Yogashri12","id":37909597,"node_id":"MDQ6VXNlcjM3OTA5NTk3","avatar_url":"https://avatars.githubusercontent.com/u/37909597?v=4","gravatar_id":"","url":"https://api.github.com/users/Yogashri12","html_url":"https://github.com/Yogashri12","followers_url":"https://api.github.com/users/Yogashri12/followers","following_url":"https://api.github.com/users/Yogashri12/following{/other_user}","gists_url":"https://api.github.com/users/Yogashri12/gists{/gist_id}","starred_url":"https://api.github.com/users/Yogashri12/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Yogashri12/subscriptions","organizations_url":"https://api.github.com/users/Yogashri12/orgs","repos_url":"https://api.github.com/users/Yogashri12/repos","events_url":"https://api.github.com/users/Yogashri12/events{/privacy}","received_events_url":"https://api.github.com/users/Yogashri12/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T07:02:40Z","updated_at":"2020-08-26T07:02:40Z","author_association":"NONE","body":"I have another issue in compression technique.\r\n\r\neven after including snappy as compression technique my file size is not compressed.\r\n\r\nhudi_options = {\r\n'hoodie.table.name': tableName,\r\n'hoodie.datasource.write.recordkey.field': 'ID',\r\n'hoodie.datasource.write.table.name': tableName,\r\n'hoodie.datasource.write.operation': 'upsert',\r\n'hoodie.datasource.write.precombine.field': 'ID',\r\n'hoodie.upsert.shuffle.parallelism': 2,\r\n'hoodie.insert.shuffle.parallelism': 2,\r\n'hoodie.datasource.write.keygenerator.class': 'org.apache.hudi.keygen.ComplexKeyGenerator',\r\n'hoodie.datasource.write.partitionpath.field':'year,month',\r\n'hoodie.parquet.compression.codec':'SNAPPY',\r\n}","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680699277/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680706372","html_url":"https://github.com/apache/hudi/issues/2041#issuecomment-680706372","issue_url":"https://api.github.com/repos/apache/hudi/issues/2041","id":680706372,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDcwNjM3Mg==","user":{"login":"zherenyu831","id":52404525,"node_id":"MDQ6VXNlcjUyNDA0NTI1","avatar_url":"https://avatars.githubusercontent.com/u/52404525?v=4","gravatar_id":"","url":"https://api.github.com/users/zherenyu831","html_url":"https://github.com/zherenyu831","followers_url":"https://api.github.com/users/zherenyu831/followers","following_url":"https://api.github.com/users/zherenyu831/following{/other_user}","gists_url":"https://api.github.com/users/zherenyu831/gists{/gist_id}","starred_url":"https://api.github.com/users/zherenyu831/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zherenyu831/subscriptions","organizations_url":"https://api.github.com/users/zherenyu831/orgs","repos_url":"https://api.github.com/users/zherenyu831/repos","events_url":"https://api.github.com/users/zherenyu831/events{/privacy}","received_events_url":"https://api.github.com/users/zherenyu831/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T07:20:03Z","updated_at":"2020-08-26T07:20:03Z","author_association":"CONTRIBUTOR","body":"@bvaradar \r\n\r\n> Regarding second problem, can you use Hive 2.x (e.g: 2.3.3) version. This is what hudi is compiled with.\r\n\r\nWorks fine with on local, will check on EMR, since on emr, hive-exec version is 3.1.2\r\n```\r\n\"org.apache.hive\" % \"hive-exec\" % \"2.3.3\" % Provided,\r\n\"com.fasterxml.jackson.core\" % \"jackson-databind\" % \"2.6.7.3\" % Test\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680706372/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680768292","html_url":"https://github.com/apache/hudi/pull/1772#issuecomment-680768292","issue_url":"https://api.github.com/repos/apache/hudi/issues/1772","id":680768292,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDc2ODI5Mg==","user":{"login":"Trevor-zhang","id":33487819,"node_id":"MDQ6VXNlcjMzNDg3ODE5","avatar_url":"https://avatars.githubusercontent.com/u/33487819?v=4","gravatar_id":"","url":"https://api.github.com/users/Trevor-zhang","html_url":"https://github.com/Trevor-zhang","followers_url":"https://api.github.com/users/Trevor-zhang/followers","following_url":"https://api.github.com/users/Trevor-zhang/following{/other_user}","gists_url":"https://api.github.com/users/Trevor-zhang/gists{/gist_id}","starred_url":"https://api.github.com/users/Trevor-zhang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Trevor-zhang/subscriptions","organizations_url":"https://api.github.com/users/Trevor-zhang/orgs","repos_url":"https://api.github.com/users/Trevor-zhang/repos","events_url":"https://api.github.com/users/Trevor-zhang/events{/privacy}","received_events_url":"https://api.github.com/users/Trevor-zhang/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T09:27:50Z","updated_at":"2020-08-26T09:27:50Z","author_association":"CONTRIBUTOR","body":"ok, @yanghua .\r\nhi, @hddong ,how are the changes you made different from before? Version information has been specified before.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680768292/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680780943","html_url":"https://github.com/apache/hudi/pull/1772#issuecomment-680780943","issue_url":"https://api.github.com/repos/apache/hudi/issues/1772","id":680780943,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDc4MDk0Mw==","user":{"login":"hddong","id":17537134,"node_id":"MDQ6VXNlcjE3NTM3MTM0","avatar_url":"https://avatars.githubusercontent.com/u/17537134?v=4","gravatar_id":"","url":"https://api.github.com/users/hddong","html_url":"https://github.com/hddong","followers_url":"https://api.github.com/users/hddong/followers","following_url":"https://api.github.com/users/hddong/following{/other_user}","gists_url":"https://api.github.com/users/hddong/gists{/gist_id}","starred_url":"https://api.github.com/users/hddong/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hddong/subscriptions","organizations_url":"https://api.github.com/users/hddong/orgs","repos_url":"https://api.github.com/users/hddong/repos","events_url":"https://api.github.com/users/hddong/events{/privacy}","received_events_url":"https://api.github.com/users/hddong/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T09:53:39Z","updated_at":"2020-08-26T09:53:39Z","author_association":"CONTRIBUTOR","body":"@Trevor-zhang : My mistake, before, when we only want specify version for hive, we need specify all components(hadoop hive spark).After ,just need specify hive.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680780943/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680789158","html_url":"https://github.com/apache/hudi/issues/2020#issuecomment-680789158","issue_url":"https://api.github.com/repos/apache/hudi/issues/2020","id":680789158,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDc4OTE1OA==","user":{"login":"dm-tran","id":7153721,"node_id":"MDQ6VXNlcjcxNTM3MjE=","avatar_url":"https://avatars.githubusercontent.com/u/7153721?v=4","gravatar_id":"","url":"https://api.github.com/users/dm-tran","html_url":"https://github.com/dm-tran","followers_url":"https://api.github.com/users/dm-tran/followers","following_url":"https://api.github.com/users/dm-tran/following{/other_user}","gists_url":"https://api.github.com/users/dm-tran/gists{/gist_id}","starred_url":"https://api.github.com/users/dm-tran/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dm-tran/subscriptions","organizations_url":"https://api.github.com/users/dm-tran/orgs","repos_url":"https://api.github.com/users/dm-tran/repos","events_url":"https://api.github.com/users/dm-tran/events{/privacy}","received_events_url":"https://api.github.com/users/dm-tran/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T10:10:42Z","updated_at":"2020-08-26T10:10:42Z","author_association":"NONE","body":"@bvaradar \r\n\r\nThe workflow of my applications is the following one:\r\n1. Initialize a Hudi table using a spark batch and \"bulk insert\".\r\n2. Launch a spark structured streaming application that consumes messages from Kafka and saves them to Hudi, using \"upsert\".\r\n\r\nYesterday, I used property \"hoodie.consistency.check.enabled=true\" for step 2, but I forgot to use it for step 1. Sorry about that. I used this property for both steps today.\r\n\r\n\r\n> Given, that you are able to reproduce very easily and I have not seen this issue reported by anyone, Would you be able to provide us a self-contained code to reproduce this. \r\n\r\nActually, I have been successfully running a dozen of structured streaming applications for several weeks. \r\n\r\nI got this \"java.io.FileNotFoundException\" for the first time a few days ago, when launching a structured streaming application for a new data source. Providing a self-contained code to reproduce this error isn't easy. It might be related to the input data or workload.\r\n\r\n> If not, can you turn on INFO level logging and catch the logs till you hit the exception and attach them. \r\n\r\nSure, I have been running the structured streaming application from the start for several hours, with INFO level logging. So far, it works fine. I will attach the logs if the exception is raised.\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680789158/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680816712","html_url":"https://github.com/apache/hudi/pull/1772#issuecomment-680816712","issue_url":"https://api.github.com/repos/apache/hudi/issues/1772","id":680816712,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDgxNjcxMg==","user":{"login":"Trevor-zhang","id":33487819,"node_id":"MDQ6VXNlcjMzNDg3ODE5","avatar_url":"https://avatars.githubusercontent.com/u/33487819?v=4","gravatar_id":"","url":"https://api.github.com/users/Trevor-zhang","html_url":"https://github.com/Trevor-zhang","followers_url":"https://api.github.com/users/Trevor-zhang/followers","following_url":"https://api.github.com/users/Trevor-zhang/following{/other_user}","gists_url":"https://api.github.com/users/Trevor-zhang/gists{/gist_id}","starred_url":"https://api.github.com/users/Trevor-zhang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Trevor-zhang/subscriptions","organizations_url":"https://api.github.com/users/Trevor-zhang/orgs","repos_url":"https://api.github.com/users/Trevor-zhang/repos","events_url":"https://api.github.com/users/Trevor-zhang/events{/privacy}","received_events_url":"https://api.github.com/users/Trevor-zhang/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T11:15:55Z","updated_at":"2020-08-26T11:15:55Z","author_association":"CONTRIBUTOR","body":"@hddong I think this pr is ok.By the way,you can add the explanation in README.md. Cc @yanghua \r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680816712/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680998998","html_url":"https://github.com/apache/hudi/issues/1979#issuecomment-680998998","issue_url":"https://api.github.com/repos/apache/hudi/issues/1979","id":680998998,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDk5ODk5OA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T16:50:38Z","updated_at":"2020-08-26T16:50:38Z","author_association":"CONTRIBUTOR","body":"@hughfdjackson : Good point about incrementally reading multiple commits. The variation you suggested seems to make sense. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/680998998/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/681051908","html_url":"https://github.com/apache/hudi/issues/1955#issuecomment-681051908","issue_url":"https://api.github.com/repos/apache/hudi/issues/1955","id":681051908,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MTA1MTkwOA==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T18:34:38Z","updated_at":"2020-08-26T18:34:38Z","author_association":"CONTRIBUTOR","body":"@tooptoop4 : hudi is more of synonymous to hive/presto where partitioning is by default enabled. But we will see how to fix the phrasing. btw, can you point me to the page where you saw this? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/681051908/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/681054525","html_url":"https://github.com/apache/hudi/issues/2029#issuecomment-681054525","issue_url":"https://api.github.com/repos/apache/hudi/issues/2029","id":681054525,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MTA1NDUyNQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T18:39:55Z","updated_at":"2020-08-26T18:39:55Z","author_association":"CONTRIBUTOR","body":"@prashanthvg89 : may I know which hudi version are you using? I tried in latest master, and I don't see this. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/681054525/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/681106051","html_url":"https://github.com/apache/hudi/issues/1955#issuecomment-681106051","issue_url":"https://api.github.com/repos/apache/hudi/issues/1955","id":681106051,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MTEwNjA1MQ==","user":{"login":"tooptoop4","id":33283496,"node_id":"MDQ6VXNlcjMzMjgzNDk2","avatar_url":"https://avatars.githubusercontent.com/u/33283496?v=4","gravatar_id":"","url":"https://api.github.com/users/tooptoop4","html_url":"https://github.com/tooptoop4","followers_url":"https://api.github.com/users/tooptoop4/followers","following_url":"https://api.github.com/users/tooptoop4/following{/other_user}","gists_url":"https://api.github.com/users/tooptoop4/gists{/gist_id}","starred_url":"https://api.github.com/users/tooptoop4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tooptoop4/subscriptions","organizations_url":"https://api.github.com/users/tooptoop4/orgs","repos_url":"https://api.github.com/users/tooptoop4/repos","events_url":"https://api.github.com/users/tooptoop4/events{/privacy}","received_events_url":"https://api.github.com/users/tooptoop4/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T20:27:35Z","updated_at":"2020-08-26T20:27:35Z","author_association":"NONE","body":"@nsivabalan https://hudi.apache.org/docs/writing_data.html","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/681106051/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/681176230","html_url":"https://github.com/apache/hudi/pull/2044#issuecomment-681176230","issue_url":"https://api.github.com/repos/apache/hudi/issues/2044","id":681176230,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MTE3NjIzMA==","user":{"login":"n3nash","id":2722167,"node_id":"MDQ6VXNlcjI3MjIxNjc=","avatar_url":"https://avatars.githubusercontent.com/u/2722167?v=4","gravatar_id":"","url":"https://api.github.com/users/n3nash","html_url":"https://github.com/n3nash","followers_url":"https://api.github.com/users/n3nash/followers","following_url":"https://api.github.com/users/n3nash/following{/other_user}","gists_url":"https://api.github.com/users/n3nash/gists{/gist_id}","starred_url":"https://api.github.com/users/n3nash/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n3nash/subscriptions","organizations_url":"https://api.github.com/users/n3nash/orgs","repos_url":"https://api.github.com/users/n3nash/repos","events_url":"https://api.github.com/users/n3nash/events{/privacy}","received_events_url":"https://api.github.com/users/n3nash/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T23:31:29Z","updated_at":"2020-08-26T23:31:29Z","author_association":"CONTRIBUTOR","body":"@satishkotha it looks like the build failed, could you take a look ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/681176230/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/681179722","html_url":"https://github.com/apache/hudi/pull/2044#issuecomment-681179722","issue_url":"https://api.github.com/repos/apache/hudi/issues/2044","id":681179722,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MTE3OTcyMg==","user":{"login":"satishkotha","id":2992755,"node_id":"MDQ6VXNlcjI5OTI3NTU=","avatar_url":"https://avatars.githubusercontent.com/u/2992755?v=4","gravatar_id":"","url":"https://api.github.com/users/satishkotha","html_url":"https://github.com/satishkotha","followers_url":"https://api.github.com/users/satishkotha/followers","following_url":"https://api.github.com/users/satishkotha/following{/other_user}","gists_url":"https://api.github.com/users/satishkotha/gists{/gist_id}","starred_url":"https://api.github.com/users/satishkotha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/satishkotha/subscriptions","organizations_url":"https://api.github.com/users/satishkotha/orgs","repos_url":"https://api.github.com/users/satishkotha/repos","events_url":"https://api.github.com/users/satishkotha/events{/privacy}","received_events_url":"https://api.github.com/users/satishkotha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-26T23:44:32Z","updated_at":"2020-08-26T23:44:32Z","author_association":"MEMBER","body":"> @satishkotha it looks like the build failed, could you take a look ?\r\n\r\n@n3nash There were checkstyle errors related to use java.util.Optional. I fixed them. PTAL after build runs.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/681179722/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682045840","html_url":"https://github.com/apache/hudi/issues/2029#issuecomment-682045840","issue_url":"https://api.github.com/repos/apache/hudi/issues/2029","id":682045840,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjA0NTg0MA==","user":{"login":"prashanthvg89","id":8704802,"node_id":"MDQ6VXNlcjg3MDQ4MDI=","avatar_url":"https://avatars.githubusercontent.com/u/8704802?v=4","gravatar_id":"","url":"https://api.github.com/users/prashanthvg89","html_url":"https://github.com/prashanthvg89","followers_url":"https://api.github.com/users/prashanthvg89/followers","following_url":"https://api.github.com/users/prashanthvg89/following{/other_user}","gists_url":"https://api.github.com/users/prashanthvg89/gists{/gist_id}","starred_url":"https://api.github.com/users/prashanthvg89/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashanthvg89/subscriptions","organizations_url":"https://api.github.com/users/prashanthvg89/orgs","repos_url":"https://api.github.com/users/prashanthvg89/repos","events_url":"https://api.github.com/users/prashanthvg89/events{/privacy}","received_events_url":"https://api.github.com/users/prashanthvg89/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T16:11:15Z","updated_at":"2020-08-27T16:11:15Z","author_association":"NONE","body":"I am using 0.5.2. Master is 0.6.1 right? What is the latest version this is fixed?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682045840/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682061419","html_url":"https://github.com/apache/hudi/issues/1979#issuecomment-682061419","issue_url":"https://api.github.com/repos/apache/hudi/issues/1979","id":682061419,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjA2MTQxOQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T16:39:24Z","updated_at":"2020-08-27T16:39:24Z","author_association":"CONTRIBUTOR","body":"Will close the ticket for now. Please reopen if we need to discuss more on this topic.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682061419/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682062239","html_url":"https://github.com/apache/hudi/issues/2034#issuecomment-682062239","issue_url":"https://api.github.com/repos/apache/hudi/issues/2034","id":682062239,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjA2MjIzOQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T16:41:00Z","updated_at":"2020-08-27T16:41:00Z","author_association":"CONTRIBUTOR","body":"Thanks. Closing this issue as it is tracked in Jira","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682062239/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682062820","html_url":"https://github.com/apache/hudi/issues/2031#issuecomment-682062820","issue_url":"https://api.github.com/repos/apache/hudi/issues/2031","id":682062820,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjA2MjgyMA==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T16:42:00Z","updated_at":"2020-08-27T16:42:00Z","author_association":"CONTRIBUTOR","body":"@vinothsiva1989  : I am assuming this issue is resolved with scala version. Please reopen if this is a different issue. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682062820/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682063177","html_url":"https://github.com/apache/hudi/issues/2019#issuecomment-682063177","issue_url":"https://api.github.com/repos/apache/hudi/issues/2019","id":682063177,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjA2MzE3Nw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T16:42:41Z","updated_at":"2020-08-27T16:42:41Z","author_association":"CONTRIBUTOR","body":"Closing this issue as we have a jira to track.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682063177/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682087937","html_url":"https://github.com/apache/hudi/pull/1597#issuecomment-682087937","issue_url":"https://api.github.com/repos/apache/hudi/issues/1597","id":682087937,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjA4NzkzNw==","user":{"login":"bhasudha","id":2179254,"node_id":"MDQ6VXNlcjIxNzkyNTQ=","avatar_url":"https://avatars.githubusercontent.com/u/2179254?v=4","gravatar_id":"","url":"https://api.github.com/users/bhasudha","html_url":"https://github.com/bhasudha","followers_url":"https://api.github.com/users/bhasudha/followers","following_url":"https://api.github.com/users/bhasudha/following{/other_user}","gists_url":"https://api.github.com/users/bhasudha/gists{/gist_id}","starred_url":"https://api.github.com/users/bhasudha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bhasudha/subscriptions","organizations_url":"https://api.github.com/users/bhasudha/orgs","repos_url":"https://api.github.com/users/bhasudha/repos","events_url":"https://api.github.com/users/bhasudha/events{/privacy}","received_events_url":"https://api.github.com/users/bhasudha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T17:29:25Z","updated_at":"2020-08-27T17:29:25Z","author_association":"CONTRIBUTOR","body":"closing this PR in favor of https://github.com/apache/hudi/pull/1433","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682087937/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682100271","html_url":"https://github.com/apache/hudi/issues/2043#issuecomment-682100271","issue_url":"https://api.github.com/repos/apache/hudi/issues/2043","id":682100271,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjEwMDI3MQ==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T17:53:43Z","updated_at":"2020-08-27T17:53:43Z","author_association":"CONTRIBUTOR","body":"@zherenyu831 : Can you model your query using pure structured streaming APIs and avoid foreachBatch. It looks like foreachBatch is triggering batch sink and not streaming sink APIs. We will have a blog shortly on the usage but you can reference the PR : https://github.com/apache/hudi/pull/1996/files#diff-cb5b78d0c2deafe117b643f5de250a17R50\r\n\r\nAlso, please note that we have discovered an issue related to batch writes https://issues.apache.org/jira/browse/HUDI-1230\r\nI have sent an email to dev@ and users@ Mailing list on the config change to workaround. \r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682100271/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682102033","html_url":"https://github.com/apache/hudi/issues/2042#issuecomment-682102033","issue_url":"https://api.github.com/repos/apache/hudi/issues/2042","id":682102033,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjEwMjAzMw==","user":{"login":"bvaradar","id":3021376,"node_id":"MDQ6VXNlcjMwMjEzNzY=","avatar_url":"https://avatars.githubusercontent.com/u/3021376?v=4","gravatar_id":"","url":"https://api.github.com/users/bvaradar","html_url":"https://github.com/bvaradar","followers_url":"https://api.github.com/users/bvaradar/followers","following_url":"https://api.github.com/users/bvaradar/following{/other_user}","gists_url":"https://api.github.com/users/bvaradar/gists{/gist_id}","starred_url":"https://api.github.com/users/bvaradar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bvaradar/subscriptions","organizations_url":"https://api.github.com/users/bvaradar/orgs","repos_url":"https://api.github.com/users/bvaradar/repos","events_url":"https://api.github.com/users/bvaradar/events{/privacy}","received_events_url":"https://api.github.com/users/bvaradar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T17:57:08Z","updated_at":"2020-08-27T17:57:08Z","author_association":"CONTRIBUTOR","body":"@n3nash : Can you help take a look at this ?\r\n\r\n@sam-wmt : Can you please provide the full stack track of the corrupted log file exception ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682102033/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682107789","html_url":"https://github.com/apache/hudi/issues/2029#issuecomment-682107789","issue_url":"https://api.github.com/repos/apache/hudi/issues/2029","id":682107789,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjEwNzc4OQ==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T18:08:36Z","updated_at":"2020-08-27T18:09:23Z","author_association":"CONTRIBUTOR","body":"can you try 0.6.0. we had a release recently and you should be able to use mvn artifacts.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682107789/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682213033","html_url":"https://github.com/apache/hudi/pull/1804#issuecomment-682213033","issue_url":"https://api.github.com/repos/apache/hudi/issues/1804","id":682213033,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjIxMzAzMw==","user":{"login":"prashantwason","id":58448203,"node_id":"MDQ6VXNlcjU4NDQ4MjAz","avatar_url":"https://avatars.githubusercontent.com/u/58448203?v=4","gravatar_id":"","url":"https://api.github.com/users/prashantwason","html_url":"https://github.com/prashantwason","followers_url":"https://api.github.com/users/prashantwason/followers","following_url":"https://api.github.com/users/prashantwason/following{/other_user}","gists_url":"https://api.github.com/users/prashantwason/gists{/gist_id}","starred_url":"https://api.github.com/users/prashantwason/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prashantwason/subscriptions","organizations_url":"https://api.github.com/users/prashantwason/orgs","repos_url":"https://api.github.com/users/prashantwason/repos","events_url":"https://api.github.com/users/prashantwason/events{/privacy}","received_events_url":"https://api.github.com/users/prashantwason/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T22:01:20Z","updated_at":"2020-08-27T22:01:57Z","author_association":"MEMBER","body":"> @prashantwason if you broadly agree, I will make the change and land this, so you can focus on rfc-15 more :)\r\nSure @vinothchandar . Thanks for all the help. Lets get this rolling soon.\r\n\r\nI will look into the comments too but you can do the needful.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682213033/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682247412","html_url":"https://github.com/apache/hudi/pull/2048#issuecomment-682247412","issue_url":"https://api.github.com/repos/apache/hudi/issues/2048","id":682247412,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjI0NzQxMg==","user":{"login":"satishkotha","id":2992755,"node_id":"MDQ6VXNlcjI5OTI3NTU=","avatar_url":"https://avatars.githubusercontent.com/u/2992755?v=4","gravatar_id":"","url":"https://api.github.com/users/satishkotha","html_url":"https://github.com/satishkotha","followers_url":"https://api.github.com/users/satishkotha/followers","following_url":"https://api.github.com/users/satishkotha/following{/other_user}","gists_url":"https://api.github.com/users/satishkotha/gists{/gist_id}","starred_url":"https://api.github.com/users/satishkotha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/satishkotha/subscriptions","organizations_url":"https://api.github.com/users/satishkotha/orgs","repos_url":"https://api.github.com/users/satishkotha/repos","events_url":"https://api.github.com/users/satishkotha/events{/privacy}","received_events_url":"https://api.github.com/users/satishkotha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-27T23:50:35Z","updated_at":"2020-08-27T23:50:35Z","author_association":"MEMBER","body":"@vinothchandar @bvaradar FYI. There are few things that I'm not fully happy with. But would like to get initial feedback and get agreement on high level approach.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682247412/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682301333","html_url":"https://github.com/apache/hudi/issues/1751#issuecomment-682301333","issue_url":"https://api.github.com/repos/apache/hudi/issues/1751","id":682301333,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjMwMTMzMw==","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-28T03:14:16Z","updated_at":"2020-08-28T03:14:16Z","author_association":"CONTRIBUTOR","body":"@bschell is driving this. Ref PR: https://github.com/apache/hudi/pull/1760. @bschell : any rough timelines ? \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682301333/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682303627","html_url":"https://github.com/apache/hudi/pull/2033#issuecomment-682303627","issue_url":"https://api.github.com/repos/apache/hudi/issues/2033","id":682303627,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjMwMzYyNw==","user":{"login":"wangxianghu","id":49835526,"node_id":"MDQ6VXNlcjQ5ODM1NTI2","avatar_url":"https://avatars.githubusercontent.com/u/49835526?v=4","gravatar_id":"","url":"https://api.github.com/users/wangxianghu","html_url":"https://github.com/wangxianghu","followers_url":"https://api.github.com/users/wangxianghu/followers","following_url":"https://api.github.com/users/wangxianghu/following{/other_user}","gists_url":"https://api.github.com/users/wangxianghu/gists{/gist_id}","starred_url":"https://api.github.com/users/wangxianghu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangxianghu/subscriptions","organizations_url":"https://api.github.com/users/wangxianghu/orgs","repos_url":"https://api.github.com/users/wangxianghu/repos","events_url":"https://api.github.com/users/wangxianghu/events{/privacy}","received_events_url":"https://api.github.com/users/wangxianghu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-28T03:23:26Z","updated_at":"2020-08-28T03:23:26Z","author_association":"CONTRIBUTOR","body":"let`s keep it in HUDI-1089\r\nclosing now","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682303627/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682305478","html_url":"https://github.com/apache/hudi/issues/2043#issuecomment-682305478","issue_url":"https://api.github.com/repos/apache/hudi/issues/2043","id":682305478,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjMwNTQ3OA==","user":{"login":"zherenyu831","id":52404525,"node_id":"MDQ6VXNlcjUyNDA0NTI1","avatar_url":"https://avatars.githubusercontent.com/u/52404525?v=4","gravatar_id":"","url":"https://api.github.com/users/zherenyu831","html_url":"https://github.com/zherenyu831","followers_url":"https://api.github.com/users/zherenyu831/followers","following_url":"https://api.github.com/users/zherenyu831/following{/other_user}","gists_url":"https://api.github.com/users/zherenyu831/gists{/gist_id}","starred_url":"https://api.github.com/users/zherenyu831/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zherenyu831/subscriptions","organizations_url":"https://api.github.com/users/zherenyu831/orgs","repos_url":"https://api.github.com/users/zherenyu831/repos","events_url":"https://api.github.com/users/zherenyu831/events{/privacy}","received_events_url":"https://api.github.com/users/zherenyu831/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-28T03:31:43Z","updated_at":"2020-08-28T03:31:43Z","author_association":"CONTRIBUTOR","body":"@bvaradar \r\nThank you for reply, I also saw your blog pr before, and it work with pure structured streaming api\r\nMarked, will try to avoid this issue when batch writing","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682305478/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682311268","html_url":"https://github.com/apache/hudi/issues/2020#issuecomment-682311268","issue_url":"https://api.github.com/repos/apache/hudi/issues/2020","id":682311268,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjMxMTI2OA==","user":{"login":"dm-tran","id":7153721,"node_id":"MDQ6VXNlcjcxNTM3MjE=","avatar_url":"https://avatars.githubusercontent.com/u/7153721?v=4","gravatar_id":"","url":"https://api.github.com/users/dm-tran","html_url":"https://github.com/dm-tran","followers_url":"https://api.github.com/users/dm-tran/followers","following_url":"https://api.github.com/users/dm-tran/following{/other_user}","gists_url":"https://api.github.com/users/dm-tran/gists{/gist_id}","starred_url":"https://api.github.com/users/dm-tran/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dm-tran/subscriptions","organizations_url":"https://api.github.com/users/dm-tran/orgs","repos_url":"https://api.github.com/users/dm-tran/repos","events_url":"https://api.github.com/users/dm-tran/events{/privacy}","received_events_url":"https://api.github.com/users/dm-tran/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-28T03:58:36Z","updated_at":"2020-08-28T03:58:49Z","author_association":"NONE","body":"@bvaradar The exception was raised, after running the structured streaming job for a while.\r\n\r\nPlease find attached the driver logs with INFO level logging.\r\n\r\n[stderr_01.log](https://github.com/apache/hudi/files/5139921/stderr_01.log) : the structured streaming job fails with error `org.apache.hudi.exception.HoodieIOException: Consistency check failed to ensure all files APPEAR`\r\n[stderr_02.log](https://github.com/apache/hudi/files/5139922/stderr_02.log) : the structured streaming job is retried by YARN and compaction fails with a `java.io.FileNotFoundException`\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682311268/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682314989","html_url":"https://github.com/apache/hudi/issues/2020#issuecomment-682314989","issue_url":"https://api.github.com/repos/apache/hudi/issues/2020","id":682314989,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjMxNDk4OQ==","user":{"login":"dm-tran","id":7153721,"node_id":"MDQ6VXNlcjcxNTM3MjE=","avatar_url":"https://avatars.githubusercontent.com/u/7153721?v=4","gravatar_id":"","url":"https://api.github.com/users/dm-tran","html_url":"https://github.com/dm-tran","followers_url":"https://api.github.com/users/dm-tran/followers","following_url":"https://api.github.com/users/dm-tran/following{/other_user}","gists_url":"https://api.github.com/users/dm-tran/gists{/gist_id}","starred_url":"https://api.github.com/users/dm-tran/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dm-tran/subscriptions","organizations_url":"https://api.github.com/users/dm-tran/orgs","repos_url":"https://api.github.com/users/dm-tran/repos","events_url":"https://api.github.com/users/dm-tran/events{/privacy}","received_events_url":"https://api.github.com/users/dm-tran/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-28T04:15:34Z","updated_at":"2020-08-28T04:21:39Z","author_association":"NONE","body":"The file that isn't found is `'s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4957-299294_20200827155539.parquet'`.\r\n\r\nThe available files in s3 that start with \"9dee1248-c972-4ed3-80f5-15545ac4c534-0_2\" are: \r\n```\r\n2020-08-27 10:26 33525767 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-3850-231917_20200827102526.parquet\r\n2020-08-27 10:33 33526574 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-3891-234401_20200827103318.parquet\r\n2020-08-27 16:17 33545224 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-39-2458_20200827155539.parquet\r\n2020-08-27 11:13 33530132 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4096-246791_20200827111254.parquet\r\n2020-08-27 11:22 33530880 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4137-249295_20200827112139.parquet\r\n2020-08-27 12:00 33533333 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4301-259277_20200827115949.parquet\r\n2020-08-27 12:20 33534377 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4383-264271_20200827121947.parquet\r\n2020-08-27 12:42 33535631 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4465-269277_20200827124204.parquet\r\n2020-08-27 12:54 33536084 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4506-271786_20200827125338.parquet\r\n2020-08-27 13:07 33536635 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4547-274289_20200827130640.parquet\r\n2020-08-27 13:20 33537444 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4588-276783_20200827131919.parquet\r\n2020-08-27 13:32 33538151 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4629-279284_20200827133143.parquet\r\n2020-08-27 13:46 33539531 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4670-281782_20200827134536.parquet\r\n2020-08-27 14:14 33541130 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4752-286756_20200827141258.parquet\r\n2020-08-27 14:30 33541913 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4793-289269_20200827142922.parquet\r\n2020-08-27 14:49 33542820 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4834-291776_20200827144807.parquet\r\n2020-08-27 15:08 33543459 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4875-294286_20200827150653.parquet\r\n2020-08-27 15:30 33544369 s3://my-bucket/my-table/daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4916-296786_20200827152840.parquet\r\n```\r\n\r\nContents of s3://my-bucket/my-table/.hoodie/20200827155539.commit\r\n\r\n```\r\n \"9dee1248-c972-4ed3-80f5-15545ac4c534-0\" : \"daas_date=2020/9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-39-2458_20200827155539.parquet\",\r\n```\r\n\r\nContents of s3://my-bucket/my-table/.hoodie/20200827155539.compaction.requested\r\n\r\n```\r\n[20200827152840, [.9dee1248-c972-4ed3-80f5-15545ac4c534-0_20200827152840.log.1_32-4949-299212], 9dee1248-c972-4ed3-80f5-15545ac4c534-0_2-4916-296786_20200827152840.parquet, 9dee1248-c972-4ed3-80f5-15545ac4c534-0, daas_date=2020, [TOTAL_LOG_FILES -> 1.0, TOTAL_IO_READ_MB -> 32.0, TOTAL_LOG_FILES_SIZE -> 121966.0, TOTAL_IO_WRITE_MB -> 31.0, TOTAL_IO_MB -> 63.0, TOTAL_LOG_FILE_SIZE -> 121966.0]],\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682314989/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682378314","html_url":"https://github.com/apache/hudi/issues/2041#issuecomment-682378314","issue_url":"https://api.github.com/repos/apache/hudi/issues/2041","id":682378314,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MjM3ODMxNA==","user":{"login":"zherenyu831","id":52404525,"node_id":"MDQ6VXNlcjUyNDA0NTI1","avatar_url":"https://avatars.githubusercontent.com/u/52404525?v=4","gravatar_id":"","url":"https://api.github.com/users/zherenyu831","html_url":"https://github.com/zherenyu831","followers_url":"https://api.github.com/users/zherenyu831/followers","following_url":"https://api.github.com/users/zherenyu831/following{/other_user}","gists_url":"https://api.github.com/users/zherenyu831/gists{/gist_id}","starred_url":"https://api.github.com/users/zherenyu831/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zherenyu831/subscriptions","organizations_url":"https://api.github.com/users/zherenyu831/orgs","repos_url":"https://api.github.com/users/zherenyu831/repos","events_url":"https://api.github.com/users/zherenyu831/events{/privacy}","received_events_url":"https://api.github.com/users/zherenyu831/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-08-28T07:38:12Z","updated_at":"2020-08-28T10:03:23Z","author_association":"CONTRIBUTOR","body":"@bvaradar \r\nAny solution for Spark 2.4.4 and scala 2.12?\r\nAlso tried rebuild hudi with scala 2.12, still same problem","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/682378314/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]