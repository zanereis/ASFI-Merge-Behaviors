[{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925159","html_url":"https://github.com/apache/storm/issues/5741#issuecomment-2612925159","issue_url":"https://api.github.com/repos/apache/storm/issues/5741","id":2612925159,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUxNTk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T15:58:50Z","updated_at":"2025-01-24T16:27:32Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user asfgit closed the pull request at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1551\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1551</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925159/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925162","html_url":"https://github.com/apache/storm/issues/5741#issuecomment-2612925162","issue_url":"https://api.github.com/repos/apache/storm/issues/5741","id":2612925162,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUxNjI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T16:00:06Z","updated_at":"2025-01-24T16:27:32Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=revans2\">revans2</a>:</i>\n<p>Thanks <a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\" class=\"user-hover\" rel=\"kabhwan\">Jungtaek Lim</a></p>\n\n<p>I merged this into master and 1.x-branch.</p>\n\n<p>Thanks again for the quick turn around time on this.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925162/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612923614","html_url":"https://github.com/apache/storm/issues/5731#issuecomment-2612923614","issue_url":"https://api.github.com/repos/apache/storm/issues/5731","id":2612923614,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjM2MTQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T16:02:24Z","updated_at":"2025-01-24T16:26:43Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.agarwal\">abhishek.agarwal</a>:</i>\n<p>ok. my understanding was that spout will continue emitting new tuples even if consumer is not consuming fast enough. But that won't happen because spout doesn't emit further if transfer queue is full - <br/>\n<a href=\"https://github.com/apache/storm/blob/1.x-branch/storm-core/src/clj/org/apache/storm/daemon/executor.clj#L647\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/blob/1.x-branch/storm-core/src/clj/org/apache/storm/daemon/executor.clj#L647</a><br/>\n<a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\" class=\"user-hover\" rel=\"kabhwan\">Jungtaek Lim</a> doesn't this address your concern? </p>\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612923614/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612923617","html_url":"https://github.com/apache/storm/issues/5731#issuecomment-2612923617","issue_url":"https://api.github.com/repos/apache/storm/issues/5731","id":2612923617,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjM2MTc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T16:17:25Z","updated_at":"2025-01-24T16:26:43Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sriharsha\">sriharsha</a>:</i>\n<p><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=knusbaum\" class=\"user-hover\" rel=\"knusbaum\">Kyle Nusbaum</a> another issue that we've seen is erratic toggling between back pressure on/off. IMO adding a time duration before turning the back pressure on/off might yield a better experience here. Currently we toggle as soon as we hit the higher watermark , how about we observe the pattern for configurable amount of time before we turn on the back pressure. Does this makes sense.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612923617/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925238","html_url":"https://github.com/apache/storm/issues/5742#issuecomment-2612925238","issue_url":"https://api.github.com/repos/apache/storm/issues/5742","id":2612925238,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUyMzg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T16:28:09Z","updated_at":"2025-01-24T16:27:34Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user harshach opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1552\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1552</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1960\" title=\"Add CORS support to STORM UI Rest api\" class=\"issue-link\" data-issue-key=\"STORM-1960\"><del>STORM-1960</del></a>. Add CORS support to STORM UI Rest api.</p>\n\n\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/harshach/incubator-storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/harshach/incubator-storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-1960\" title=\"Add CORS support to STORM UI Rest api\" class=\"issue-link\" data-issue-key=\"STORM-1960\"><del>STORM-1960</del></a></p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1552.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1552.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1552</p>\n\n<hr />\n<p>commit 8ee3eeec54e6d75eb7e20a30b4efffa8e8f6aa54<br/>\nAuthor: Sriharsha Chintalapani <harsha@hortonworks.com><br/>\nDate:   2016-07-11T16:24:48Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1960\" title=\"Add CORS support to STORM UI Rest api\" class=\"issue-link\" data-issue-key=\"STORM-1960\"><del>STORM-1960</del></a>. Add CORS support to STORM UI Rest api.</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925238/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231787767","html_url":"https://github.com/apache/storm/pull/1552#issuecomment-231787767","issue_url":"https://api.github.com/repos/apache/storm/issues/1552","id":231787767,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTc4Nzc2Nw==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T16:28:20Z","updated_at":"2016-07-11T16:28:20Z","author_association":"CONTRIBUTOR","body":"@HeartSaVioR @arunmahadevan pinging for a review\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231787767/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925243","html_url":"https://github.com/apache/storm/issues/5742#issuecomment-2612925243","issue_url":"https://api.github.com/repos/apache/storm/issues/5742","id":2612925243,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUyNDM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T16:28:22Z","updated_at":"2025-01-24T16:27:34Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1552\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1552</a></p>\n\n<p>    @HeartSaVioR @arunmahadevan pinging for a review</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925243/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231812562","html_url":"https://github.com/apache/storm/pull/1482#issuecomment-231812562","issue_url":"https://api.github.com/repos/apache/storm/issues/1482","id":231812562,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTgxMjU2Mg==","user":{"login":"ptgoetz","id":260896,"node_id":"MDQ6VXNlcjI2MDg5Ng==","avatar_url":"https://avatars.githubusercontent.com/u/260896?v=4","gravatar_id":"","url":"https://api.github.com/users/ptgoetz","html_url":"https://github.com/ptgoetz","followers_url":"https://api.github.com/users/ptgoetz/followers","following_url":"https://api.github.com/users/ptgoetz/following{/other_user}","gists_url":"https://api.github.com/users/ptgoetz/gists{/gist_id}","starred_url":"https://api.github.com/users/ptgoetz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ptgoetz/subscriptions","organizations_url":"https://api.github.com/users/ptgoetz/orgs","repos_url":"https://api.github.com/users/ptgoetz/repos","events_url":"https://api.github.com/users/ptgoetz/events{/privacy}","received_events_url":"https://api.github.com/users/ptgoetz/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T17:54:52Z","updated_at":"2016-07-11T17:54:52Z","author_association":"MEMBER","body":"The README needs to be updated for this change with instructions on how to use different Kafka client and scala versions.\n\nI'm okay with either leaving or removing the `provided` scope for the Kafka dependency. It was originally there in order to force the user to make a choice of scala version (mainly directed at users using Scala in their topology code). Without it, users have to explicitly exclude the Kafka dependency and include the one they want. It's kind of a 6 vs. one-half dozen tradeoff.\n\nI'd be +1 once the documentation is updated to reflect this change.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231812562/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612913066","html_url":"https://github.com/apache/storm/issues/5659#issuecomment-2612913066","issue_url":"https://api.github.com/repos/apache/storm/issues/5659","id":2612913066,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTMwNjY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T17:54:54Z","updated_at":"2025-01-24T16:21:25Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user ptgoetz commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1482\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1482</a></p>\n\n<p>    The README needs to be updated for this change with instructions on how to use different Kafka client and scala versions.</p>\n\n<p>    I'm okay with either leaving or removing the `provided` scope for the Kafka dependency. It was originally there in order to force the user to make a choice of scala version (mainly directed at users using Scala in their topology code). Without it, users have to explicitly exclude the Kafka dependency and include the one they want. It's kind of a 6 vs. one-half dozen tradeoff.</p>\n\n<p>    I'd be +1 once the documentation is updated to reflect this change.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612913066/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901013","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901013","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901013,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwMTM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T18:11:53Z","updated_at":"2025-01-24T16:15:28Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hmclouro\">hmclouro</a>:</i>\n<p><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\" class=\"user-hover\" rel=\"kabhwan\">Jungtaek Lim</a> as of release 0.10.0 the @InterfaceStability.Unstable annotation was removed from the Consumer interface.</p>\n\n<p>I am working on this now. I will a PR by EOD</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901013/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925509","html_url":"https://github.com/apache/storm/issues/5743#issuecomment-2612925509","issue_url":"https://api.github.com/repos/apache/storm/issues/5743","id":2612925509,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjU1MDk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T18:15:00Z","updated_at":"2025-01-24T16:27:42Z","author_association":"COLLABORATOR","body":"Subtask of parent task STORM-1843","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925509/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918464","html_url":"https://github.com/apache/storm/issues/5695#issuecomment-2612918464","issue_url":"https://api.github.com/repos/apache/storm/issues/5695","id":2612918464,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTg0NjQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T18:18:10Z","updated_at":"2025-01-24T16:24:08Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user asfgit closed the pull request at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1500\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1500</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918464/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231820689","html_url":"https://github.com/apache/storm/pull/1507#issuecomment-231820689","issue_url":"https://api.github.com/repos/apache/storm/issues/1507","id":231820689,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTgyMDY4OQ==","user":{"login":"knusbaum","id":1819836,"node_id":"MDQ6VXNlcjE4MTk4MzY=","avatar_url":"https://avatars.githubusercontent.com/u/1819836?v=4","gravatar_id":"","url":"https://api.github.com/users/knusbaum","html_url":"https://github.com/knusbaum","followers_url":"https://api.github.com/users/knusbaum/followers","following_url":"https://api.github.com/users/knusbaum/following{/other_user}","gists_url":"https://api.github.com/users/knusbaum/gists{/gist_id}","starred_url":"https://api.github.com/users/knusbaum/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/knusbaum/subscriptions","organizations_url":"https://api.github.com/users/knusbaum/orgs","repos_url":"https://api.github.com/users/knusbaum/repos","events_url":"https://api.github.com/users/knusbaum/events{/privacy}","received_events_url":"https://api.github.com/users/knusbaum/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T18:23:21Z","updated_at":"2016-07-11T18:23:21Z","author_association":"CONTRIBUTOR","body":"@d2r Sorry about missing that. Ready for a check.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231820689/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919051","html_url":"https://github.com/apache/storm/issues/5698#issuecomment-2612919051","issue_url":"https://api.github.com/repos/apache/storm/issues/5698","id":2612919051,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTkwNTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T18:23:22Z","updated_at":"2025-01-24T16:24:24Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user knusbaum commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1507\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1507</a></p>\n\n<p>    @d2r Sorry about missing that. Ready for a check.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919051/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901016","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901016","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901016,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwMTY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T18:28:13Z","updated_at":"2025-01-24T16:15:28Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sriharsha\">sriharsha</a>:</i>\n<p><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\" class=\"user-hover\" rel=\"kabhwan\">Jungtaek Lim</a> anyone using storm-kafka-client that built with 0.9 binaries will not  be able to use 0.10 release. Yes we don't need to follow kafka releases but in this case we should take the advantage of api stability that came in 0.10 release and fix the broken compatibility .</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901016/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231830066","html_url":"https://github.com/apache/storm/pull/1552#issuecomment-231830066","issue_url":"https://api.github.com/repos/apache/storm/issues/1552","id":231830066,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTgzMDA2Ng==","user":{"login":"arunmahadevan","id":6792890,"node_id":"MDQ6VXNlcjY3OTI4OTA=","avatar_url":"https://avatars.githubusercontent.com/u/6792890?v=4","gravatar_id":"","url":"https://api.github.com/users/arunmahadevan","html_url":"https://github.com/arunmahadevan","followers_url":"https://api.github.com/users/arunmahadevan/followers","following_url":"https://api.github.com/users/arunmahadevan/following{/other_user}","gists_url":"https://api.github.com/users/arunmahadevan/gists{/gist_id}","starred_url":"https://api.github.com/users/arunmahadevan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arunmahadevan/subscriptions","organizations_url":"https://api.github.com/users/arunmahadevan/orgs","repos_url":"https://api.github.com/users/arunmahadevan/repos","events_url":"https://api.github.com/users/arunmahadevan/events{/privacy}","received_events_url":"https://api.github.com/users/arunmahadevan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T18:55:27Z","updated_at":"2016-07-11T18:55:27Z","author_association":"CONTRIBUTOR","body":"@harshach the changes look good. May be you could also add a note about this feature in the storm rest api docs. Since CORS is going to be on by default, if it makes sense we could take a storm config option where by users can optionally turn it off. \n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231830066/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925246","html_url":"https://github.com/apache/storm/issues/5742#issuecomment-2612925246","issue_url":"https://api.github.com/repos/apache/storm/issues/5742","id":2612925246,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUyNDY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T18:55:29Z","updated_at":"2025-01-24T16:27:34Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user arunmahadevan commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1552\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1552</a></p>\n\n<p>    @harshach the changes look good. May be you could also add a note about this feature in the storm rest api docs. Since CORS is going to be on by default, if it makes sense we could take a storm config option where by users can optionally turn it off. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925246/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925605","html_url":"https://github.com/apache/storm/issues/5744#issuecomment-2612925605","issue_url":"https://api.github.com/repos/apache/storm/issues/5744","id":2612925605,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjU2MDU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T19:21:42Z","updated_at":"2025-01-24T16:27:45Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user revans2 opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1553\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1553</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1962\" title=\"python storm integration does not run on python 3\" class=\"issue-link\" data-issue-key=\"STORM-1962\"><del>STORM-1962</del></a>: support python 3 and 2 in multilang</p>\n\n\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/revans2/incubator-storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/revans2/incubator-storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-1962\" title=\"python storm integration does not run on python 3\" class=\"issue-link\" data-issue-key=\"STORM-1962\"><del>STORM-1962</del></a></p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1553.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1553.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1553</p>\n\n<hr />\n<p>commit 01be0d4171189ed0ff26b67e9a43da821f81e3b2<br/>\nAuthor: Robert (Bobby) Evans <evans@yahoo-inc.com><br/>\nDate:   2016-07-11T19:19:35Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1962\" title=\"python storm integration does not run on python 3\" class=\"issue-link\" data-issue-key=\"STORM-1962\"><del>STORM-1962</del></a>: support python 3/2 in multilang</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925605/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919055","html_url":"https://github.com/apache/storm/issues/5698#issuecomment-2612919055","issue_url":"https://api.github.com/repos/apache/storm/issues/5698","id":2612919055,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTkwNTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T21:13:33Z","updated_at":"2025-01-24T16:24:24Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user d2r commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1507#discussion_r70338254\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1507#discussion_r70338254</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/Config.java &#8212;<br/>\n    @@ -1835,6 +1835,21 @@<br/>\n public static final String TOPOLOGY_CLASSPATH=\"topology.classpath\";</p>\n\n<p> /**<br/>\n    +     * Topology-specific classpath for the worker child process. This will be <b>prepended</b> to<br/>\n    +     * the usual classpath, meaning it can override the Storm classpath. This is for debugging<br/>\n    +     * purposes, and is disabled by default. To allow topologies to be submitted with user-first<br/>\n    +     * classpaths, set the user.classpath.first.enabled config to true.<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    comment rename</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919055/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919060","html_url":"https://github.com/apache/storm/issues/5698#issuecomment-2612919060","issue_url":"https://api.github.com/repos/apache/storm/issues/5698","id":2612919060,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTkwNjA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T21:13:38Z","updated_at":"2025-01-24T16:24:24Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user d2r commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1507#discussion_r70338269\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1507#discussion_r70338269</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/Config.java &#8212;<br/>\n    @@ -1835,6 +1835,21 @@<br/>\n public static final String TOPOLOGY_CLASSPATH=\"topology.classpath\";</p>\n\n<p> /**<br/>\n    +     * Topology-specific classpath for the worker child process. This will be <b>prepended</b> to<br/>\n    +     * the usual classpath, meaning it can override the Storm classpath. This is for debugging<br/>\n    +     * purposes, and is disabled by default. To allow topologies to be submitted with user-first<br/>\n    +     * classpaths, set the user.classpath.first.enabled config to true.<br/>\n    +     */<br/>\n    +    @isStringOrStringList<br/>\n    +    public static final String TOPOLOGY_CLASSPATH_BEGINNING=\"topology.classpath.beginning\";<br/>\n    +<br/>\n    +    /**<br/>\n    +     * Enables user-first classpath. See topology.classpath.first<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    comment rename</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919060/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919064","html_url":"https://github.com/apache/storm/issues/5698#issuecomment-2612919064","issue_url":"https://api.github.com/repos/apache/storm/issues/5698","id":2612919064,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTkwNjQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T21:14:11Z","updated_at":"2025-01-24T16:24:24Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user d2r commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1507#discussion_r70338370\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1507#discussion_r70338370</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/utils/Utils.java &#8212;<br/>\n    @@ -2092,6 +2092,11 @@ public static String addToClasspath(String classpath,<br/>\n     return _instance.addToClasspathImpl(classpath, paths);<br/>\n }</p>\n\n<p>    +    public static String addToClasspath(Collection<String> classpaths,<br/>\n    +Collection<String> paths) </p>\n{\n    +return _instance.addToClasspathImpl(classpaths, paths);\n    +    }\n<p>    +<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Looks good.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919064/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612924421","html_url":"https://github.com/apache/storm/issues/5736#issuecomment-2612924421","issue_url":"https://api.github.com/repos/apache/storm/issues/5736","id":2612924421,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjQ0MjE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T21:22:51Z","updated_at":"2025-01-24T16:27:06Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user asfgit closed the pull request at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1547\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1547</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612924421/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231869555","html_url":"https://github.com/apache/storm/pull/1287#issuecomment-231869555","issue_url":"https://api.github.com/repos/apache/storm/issues/1287","id":231869555,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTg2OTU1NQ==","user":{"login":"moesol","id":5385733,"node_id":"MDQ6VXNlcjUzODU3MzM=","avatar_url":"https://avatars.githubusercontent.com/u/5385733?v=4","gravatar_id":"","url":"https://api.github.com/users/moesol","html_url":"https://github.com/moesol","followers_url":"https://api.github.com/users/moesol/followers","following_url":"https://api.github.com/users/moesol/following{/other_user}","gists_url":"https://api.github.com/users/moesol/gists{/gist_id}","starred_url":"https://api.github.com/users/moesol/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/moesol/subscriptions","organizations_url":"https://api.github.com/users/moesol/orgs","repos_url":"https://api.github.com/users/moesol/repos","events_url":"https://api.github.com/users/moesol/events{/privacy}","received_events_url":"https://api.github.com/users/moesol/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T21:23:20Z","updated_at":"2016-07-11T21:23:20Z","author_association":"CONTRIBUTOR","body":"Merged via different PR. Closing this PR.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231869555/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612891910","html_url":"https://github.com/apache/storm/issues/5509#issuecomment-2612891910","issue_url":"https://api.github.com/repos/apache/storm/issues/5509","id":2612891910,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI4OTE5MTA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T21:23:22Z","updated_at":"2025-01-24T16:11:10Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user moesol commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1287\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1287</a></p>\n\n<p>    Merged via different PR. Closing this PR.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612891910/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612891915","html_url":"https://github.com/apache/storm/issues/5509#issuecomment-2612891915","issue_url":"https://api.github.com/repos/apache/storm/issues/5509","id":2612891915,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI4OTE5MTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T21:23:22Z","updated_at":"2025-01-24T16:11:10Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user moesol closed the pull request at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1287\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1287</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612891915/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231870734","html_url":"https://github.com/apache/storm/pull/1507#issuecomment-231870734","issue_url":"https://api.github.com/repos/apache/storm/issues/1507","id":231870734,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTg3MDczNA==","user":{"login":"d2r","id":905298,"node_id":"MDQ6VXNlcjkwNTI5OA==","avatar_url":"https://avatars.githubusercontent.com/u/905298?v=4","gravatar_id":"","url":"https://api.github.com/users/d2r","html_url":"https://github.com/d2r","followers_url":"https://api.github.com/users/d2r/followers","following_url":"https://api.github.com/users/d2r/following{/other_user}","gists_url":"https://api.github.com/users/d2r/gists{/gist_id}","starred_url":"https://api.github.com/users/d2r/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/d2r/subscriptions","organizations_url":"https://api.github.com/users/d2r/orgs","repos_url":"https://api.github.com/users/d2r/repos","events_url":"https://api.github.com/users/d2r/events{/privacy}","received_events_url":"https://api.github.com/users/d2r/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T21:27:29Z","updated_at":"2016-07-11T21:27:29Z","author_association":"NONE","body":"+1 after we fix the javadoc.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231870734/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919069","html_url":"https://github.com/apache/storm/issues/5698#issuecomment-2612919069","issue_url":"https://api.github.com/repos/apache/storm/issues/5698","id":2612919069,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTkwNjk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T21:27:31Z","updated_at":"2025-01-24T16:24:25Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user d2r commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1507\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1507</a></p>\n\n<p>    +1 after we fix the javadoc.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919069/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919073","html_url":"https://github.com/apache/storm/issues/5698#issuecomment-2612919073","issue_url":"https://api.github.com/repos/apache/storm/issues/5698","id":2612919073,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTkwNzM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-11T21:32:41Z","updated_at":"2025-01-24T16:24:25Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user asfgit closed the pull request at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1507\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1507</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919073/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231917805","html_url":"https://github.com/apache/storm/pull/1552#issuecomment-231917805","issue_url":"https://api.github.com/repos/apache/storm/issues/1552","id":231917805,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTkxNzgwNQ==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T02:02:12Z","updated_at":"2016-07-12T02:02:12Z","author_association":"CONTRIBUTOR","body":"Same as @arunmahadevan. I'm wondering that we need to open detailed configurations for these, but we can add it later when someone claims he/she needs that.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231917805/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925252","html_url":"https://github.com/apache/storm/issues/5742#issuecomment-2612925252","issue_url":"https://api.github.com/repos/apache/storm/issues/5742","id":2612925252,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUyNTI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T02:02:15Z","updated_at":"2025-01-24T16:27:35Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1552\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1552</a></p>\n\n<p>    Same as @arunmahadevan. I'm wondering that we need to open detailed configurations for these, but we can add it later when someone claims he/she needs that.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925252/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231933283","html_url":"https://github.com/apache/storm/pull/1536#issuecomment-231933283","issue_url":"https://api.github.com/repos/apache/storm/issues/1536","id":231933283,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTkzMzI4Mw==","user":{"login":"abellina","id":1901059,"node_id":"MDQ6VXNlcjE5MDEwNTk=","avatar_url":"https://avatars.githubusercontent.com/u/1901059?v=4","gravatar_id":"","url":"https://api.github.com/users/abellina","html_url":"https://github.com/abellina","followers_url":"https://api.github.com/users/abellina/followers","following_url":"https://api.github.com/users/abellina/following{/other_user}","gists_url":"https://api.github.com/users/abellina/gists{/gist_id}","starred_url":"https://api.github.com/users/abellina/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abellina/subscriptions","organizations_url":"https://api.github.com/users/abellina/orgs","repos_url":"https://api.github.com/users/abellina/repos","events_url":"https://api.github.com/users/abellina/events{/privacy}","received_events_url":"https://api.github.com/users/abellina/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T04:17:00Z","updated_at":"2016-07-12T04:17:00Z","author_association":"CONTRIBUTOR","body":"ping\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231933283/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231937578","html_url":"https://github.com/apache/storm/pull/1507#issuecomment-231937578","issue_url":"https://api.github.com/repos/apache/storm/issues/1507","id":231937578,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTkzNzU3OA==","user":{"login":"abhishekagarwal87","id":1477457,"node_id":"MDQ6VXNlcjE0Nzc0NTc=","avatar_url":"https://avatars.githubusercontent.com/u/1477457?v=4","gravatar_id":"","url":"https://api.github.com/users/abhishekagarwal87","html_url":"https://github.com/abhishekagarwal87","followers_url":"https://api.github.com/users/abhishekagarwal87/followers","following_url":"https://api.github.com/users/abhishekagarwal87/following{/other_user}","gists_url":"https://api.github.com/users/abhishekagarwal87/gists{/gist_id}","starred_url":"https://api.github.com/users/abhishekagarwal87/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abhishekagarwal87/subscriptions","organizations_url":"https://api.github.com/users/abhishekagarwal87/orgs","repos_url":"https://api.github.com/users/abhishekagarwal87/repos","events_url":"https://api.github.com/users/abhishekagarwal87/events{/privacy}","received_events_url":"https://api.github.com/users/abhishekagarwal87/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T04:58:55Z","updated_at":"2016-07-12T04:58:55Z","author_association":"CONTRIBUTOR","body":"Let's make sure that we squash the commits before merging. \n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231937578/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919075","html_url":"https://github.com/apache/storm/issues/5698#issuecomment-2612919075","issue_url":"https://api.github.com/repos/apache/storm/issues/5698","id":2612919075,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTkwNzU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T04:58:56Z","updated_at":"2025-01-24T16:24:25Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user abhishekagarwal87 commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1507\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1507</a></p>\n\n<p>    Let's make sure that we squash the commits before merging. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612919075/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646010","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646010","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646010,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwMTA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T07:08:18Z","updated_at":"2025-01-24T14:20:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user vesense commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359#discussion_r70386736\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359#discussion_r70386736</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/scheduler/IsolationScheduler.java &#8212;<br/>\n    @@ -0,0 +1,417 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.scheduler;<br/>\n    +<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.Collections;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.HashSet;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Set;<br/>\n    +import java.util.TreeMap;<br/>\n    +<br/>\n    +import org.apache.commons.lang.Validate;<br/>\n    +import org.apache.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import org.apache.storm.Config;<br/>\n    +import org.apache.storm.scheduler.Cluster;<br/>\n    +import org.apache.storm.scheduler.ExecutorDetails;<br/>\n    +import org.apache.storm.scheduler.IScheduler;<br/>\n    +import org.apache.storm.scheduler.SchedulerAssignment;<br/>\n    +import org.apache.storm.scheduler.Topologies;<br/>\n    +import org.apache.storm.scheduler.TopologyDetails;<br/>\n    +import org.apache.storm.scheduler.WorkerSlot;<br/>\n    +<br/>\n    +// for each isolated topology:<br/>\n    +//   compute even distribution of executors -> workers on the number of workers specified for the topology<br/>\n    +//   compute distribution of workers to machines<br/>\n    +// determine host -> list of <span class=\"error\">&#91;slot, topology id, executors&#93;</span><br/>\n    +// iterate through hosts and: a machine is good if:<br/>\n    +//   1. only running workers from one isolated topology<br/>\n    +//   2. all workers running on it match one of the distributions of executors for that topology<br/>\n    +//   3. matches one of the # of workers<br/>\n    +// blacklist the good hosts and remove those workers from the list of need to be assigned workers<br/>\n    +// otherwise unassign all other workers for isolated topologies if assigned<br/>\n    +public class IsolationScheduler implements IScheduler {<br/>\n    +    private final static Logger LOG = LoggerFactory.getLogger(IsolationScheduler.class);<br/>\n    +<br/>\n    +    private Map<String, Number> isoMachines;<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public void prepare(Map conf) </p>\n{\n    +this.isoMachines = (Map<String, Number>) conf.get(Config.ISOLATION_SCHEDULER_MACHINES);\n    +Validate.notEmpty(isoMachines);\n    +    }\n<p>    +<br/>\n    +    // get host -> all assignable worker slots for non-blacklisted machines (assigned or not assigned)<br/>\n    +    // will then have a list of machines that need to be assigned (machine -> <span class=\"error\">&#91;topology, list of list of executors&#93;</span>)<br/>\n    +    // match each spec to a machine (who has the right number of workers), free everything else on that machine and assign those slots (do one topology at a time)<br/>\n    +    // blacklist all machines who had production slots defined<br/>\n    +    // log isolated topologies who weren't able to get enough slots / machines<br/>\n    +    // run default scheduler on isolated topologies that didn't have enough slots + non-isolated topologies on remaining machines<br/>\n    +    // set blacklist to what it was initially<br/>\n    +    @Override<br/>\n    +    public void schedule(Topologies topologies, Cluster cluster) {<br/>\n    +Set<String> origBlacklist = cluster.getBlacklistedHosts();<br/>\n    +List<TopologyDetails> isoTopologies = isolatedTopologies(topologies.getTopologies());<br/>\n    +Set<String> isoIds = isolatedTopoplogyIds(isoTopologies);<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs = topologyWorkerSpecs(isoTopologies);<br/>\n    +Map<String, Map<Integer, Integer>> topologyMachineDistributions = topologyMachineDistributions(isoTopologies);<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = hostAssignments(cluster);<br/>\n    +<br/>\n    +for (Map.Entry<String, List<AssignmentInfo>> entry : hostAssignments.entrySet()) {<br/>\n    +    List<AssignmentInfo> assignments = entry.getValue();<br/>\n    +    String topologyId = assignments.get(0).getTopologyId();<br/>\n    +    Map<Integer, Integer> distribution = topologyMachineDistributions.get(topologyId);<br/>\n    +    Set<Set<ExecutorDetails>> workerSpecs = topologyWorkerSpecs.get(topologyId);<br/>\n    +    int numWorkers = assignments.size();<br/>\n    +<br/>\n    +    if (isoIds.contains(topologyId)<br/>\n    +    && checkAssignmentTopology(assignments, topologyId)<br/>\n    +    && distribution.containsKey(numWorkers)<br/>\n    +    && checkAssignmentWorkerSpecs(assignments, workerSpecs)) {<br/>\n    +decrementDistribution(distribution, numWorkers);<br/>\n    +for (AssignmentInfo ass : assignments) </p>\n{\n    +    workerSpecs.remove(ass.getExecutors());\n    +}\n<p>    +cluster.blacklistHost(entry.getKey());<br/>\n    +    } else {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (isoIds.contains(ass.getTopologyId())) </p>\n{\n    +cluster.freeSlot(ass.getWorkerSlot());\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = hostUsedSlots(cluster);<br/>\n    +LinkedList<HostAssignableSlots> hss = hostAssignableSlots(cluster);<br/>\n    +List<String> failedTopologyIds = new ArrayList<String>();<br/>\n    +for (Map.Entry<String, Set<Set<ExecutorDetails>>> entry : topologyWorkerSpecs.entrySet()) {<br/>\n    +    String topologyId = entry.getKey();<br/>\n    +    Set<Set<ExecutorDetails>> executorSet = entry.getValue();<br/>\n    +    if (executorSet != null && executorSet.size() > 0) </p>\n{\n    +failedTopologyIds.add(topologyId);\n    +    }\n<p>    +    List<Integer> workerNum = distributionSortedAmts(topologyMachineDistributions.get(topologyId));<br/>\n    +    for (Integer num : workerNum) {<br/>\n    +HostAssignableSlots hostSlots = hss.peek();<br/>\n    +List<WorkerSlot> slot = hostSlots != null ? hostSlots.getWorkerSlots() : null;<br/>\n    +<br/>\n    +if (slot != null && slot.size() >= num.intValue()) {<br/>\n    +    hss.poll();<br/>\n    +    cluster.freeSlots(hostUsedSlots.get(hostSlots.getHostName()));<br/>\n    +    for (WorkerSlot tmpSlot : slot.subList(0, num)) </p>\n{\n    +Set<ExecutorDetails> executor = removeElemFromSet(executorSet);\n    +cluster.assign(tmpSlot, topologyId, executor);\n    +    }\n<p>    +    cluster.blacklistHost(hostSlots.getHostName());<br/>\n    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +if (failedTopologyIds.size() > 0) {<br/>\n    +    LOG.warn(\"Unable to isolate topologies \" + failedTopologyIds<br/>\n    +    + \". No machine had enough worker slots to run the remaining workers for these topologies. \"<br/>\n    +    + \"Clearing all other resources and will wait for enough resources for \"<br/>\n    +    + \"isolated topologies before allocating any other resources.\");<br/>\n    +    // clear workers off all hosts that are not blacklisted<br/>\n    +    Map<String, Set<WorkerSlot>> usedSlots = hostUsedSlots(cluster);<br/>\n    +    Set<Map.Entry<String, Set<WorkerSlot>>> entries = usedSlots.entrySet();<br/>\n    +    for (Map.Entry<String, Set<WorkerSlot>> entry : entries) {<br/>\n    +if (!cluster.isBlacklistedHost(entry.getKey())) </p>\n{\n    +    cluster.freeSlots(entry.getValue());\n    +}\n<p>    +    }<br/>\n    +} else </p>\n{\n    +    // run default scheduler on non-isolated topologies\n    +    Set<String> allocatedTopologies = allocatedTopologies(topologyWorkerSpecs);\n    +    Topologies leftOverTopologies = leftoverTopologies(topologies, allocatedTopologies);\n    +    DefaultScheduler.defaultSchedule(leftOverTopologies, cluster);\n    +}\n<p>    +cluster.setBlacklistedHosts(origBlacklist);<br/>\n    +    }<br/>\n    +<br/>\n    +    public Set<ExecutorDetails> removeElemFromSet(Set<Set<ExecutorDetails>> executorsSets) </p>\n{\n    +Set<ExecutorDetails> elem = executorsSets.iterator().next();\n    +executorsSets.remove(elem);\n    +return elem;\n    +    }\n<p>    +<br/>\n    +    private List<TopologyDetails> isolatedTopologies(Collection<TopologyDetails> topologies) {<br/>\n    +Set<String> topologyNames = isoMachines.keySet();<br/>\n    +List<TopologyDetails> isoTopologies = new ArrayList<TopologyDetails>();<br/>\n    +for (TopologyDetails topo : topologies) {<br/>\n    +    if (topologyNames.contains(topo.getName())) </p>\n{\n    +isoTopologies.add(topo);\n    +    }\n<p>    +}<br/>\n    +return isoTopologies;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<String> isolatedTopoplogyIds(List<TopologyDetails> topologies) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Good. Will fix.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646010/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646015","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646015","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646015,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwMTU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T07:52:44Z","updated_at":"2025-01-24T14:20:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359#discussion_r70391988\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359#discussion_r70391988</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/scheduler/IsolationScheduler.java &#8212;<br/>\n    @@ -0,0 +1,417 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.scheduler;<br/>\n    +<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.Collections;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.HashSet;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Set;<br/>\n    +import java.util.TreeMap;<br/>\n    +<br/>\n    +import org.apache.commons.lang.Validate;<br/>\n    +import org.apache.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import org.apache.storm.Config;<br/>\n    +import org.apache.storm.scheduler.Cluster;<br/>\n    +import org.apache.storm.scheduler.ExecutorDetails;<br/>\n    +import org.apache.storm.scheduler.IScheduler;<br/>\n    +import org.apache.storm.scheduler.SchedulerAssignment;<br/>\n    +import org.apache.storm.scheduler.Topologies;<br/>\n    +import org.apache.storm.scheduler.TopologyDetails;<br/>\n    +import org.apache.storm.scheduler.WorkerSlot;<br/>\n    +<br/>\n    +// for each isolated topology:<br/>\n    +//   compute even distribution of executors -> workers on the number of workers specified for the topology<br/>\n    +//   compute distribution of workers to machines<br/>\n    +// determine host -> list of <span class=\"error\">&#91;slot, topology id, executors&#93;</span><br/>\n    +// iterate through hosts and: a machine is good if:<br/>\n    +//   1. only running workers from one isolated topology<br/>\n    +//   2. all workers running on it match one of the distributions of executors for that topology<br/>\n    +//   3. matches one of the # of workers<br/>\n    +// blacklist the good hosts and remove those workers from the list of need to be assigned workers<br/>\n    +// otherwise unassign all other workers for isolated topologies if assigned<br/>\n    +public class IsolationScheduler implements IScheduler {<br/>\n    +    private final static Logger LOG = LoggerFactory.getLogger(IsolationScheduler.class);<br/>\n    +<br/>\n    +    private Map<String, Number> isoMachines;<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public void prepare(Map conf) </p>\n{\n    +this.isoMachines = (Map<String, Number>) conf.get(Config.ISOLATION_SCHEDULER_MACHINES);\n    +Validate.notEmpty(isoMachines);\n    +    }\n<p>    +<br/>\n    +    // get host -> all assignable worker slots for non-blacklisted machines (assigned or not assigned)<br/>\n    +    // will then have a list of machines that need to be assigned (machine -> <span class=\"error\">&#91;topology, list of list of executors&#93;</span>)<br/>\n    +    // match each spec to a machine (who has the right number of workers), free everything else on that machine and assign those slots (do one topology at a time)<br/>\n    +    // blacklist all machines who had production slots defined<br/>\n    +    // log isolated topologies who weren't able to get enough slots / machines<br/>\n    +    // run default scheduler on isolated topologies that didn't have enough slots + non-isolated topologies on remaining machines<br/>\n    +    // set blacklist to what it was initially<br/>\n    +    @Override<br/>\n    +    public void schedule(Topologies topologies, Cluster cluster) {<br/>\n    +Set<String> origBlacklist = cluster.getBlacklistedHosts();<br/>\n    +List<TopologyDetails> isoTopologies = isolatedTopologies(topologies.getTopologies());<br/>\n    +Set<String> isoIds = isolatedTopoplogyIds(isoTopologies);<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs = topologyWorkerSpecs(isoTopologies);<br/>\n    +Map<String, Map<Integer, Integer>> topologyMachineDistributions = topologyMachineDistributions(isoTopologies);<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = hostAssignments(cluster);<br/>\n    +<br/>\n    +for (Map.Entry<String, List<AssignmentInfo>> entry : hostAssignments.entrySet()) {<br/>\n    +    List<AssignmentInfo> assignments = entry.getValue();<br/>\n    +    String topologyId = assignments.get(0).getTopologyId();<br/>\n    +    Map<Integer, Integer> distribution = topologyMachineDistributions.get(topologyId);<br/>\n    +    Set<Set<ExecutorDetails>> workerSpecs = topologyWorkerSpecs.get(topologyId);<br/>\n    +    int numWorkers = assignments.size();<br/>\n    +<br/>\n    +    if (isoIds.contains(topologyId)<br/>\n    +    && checkAssignmentTopology(assignments, topologyId)<br/>\n    +    && distribution.containsKey(numWorkers)<br/>\n    +    && checkAssignmentWorkerSpecs(assignments, workerSpecs)) {<br/>\n    +decrementDistribution(distribution, numWorkers);<br/>\n    +for (AssignmentInfo ass : assignments) </p>\n{\n    +    workerSpecs.remove(ass.getExecutors());\n    +}\n<p>    +cluster.blacklistHost(entry.getKey());<br/>\n    +    } else {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (isoIds.contains(ass.getTopologyId())) </p>\n{\n    +cluster.freeSlot(ass.getWorkerSlot());\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = hostUsedSlots(cluster);<br/>\n    +LinkedList<HostAssignableSlots> hss = hostAssignableSlots(cluster);<br/>\n    +List<String> failedTopologyIds = new ArrayList<String>();<br/>\n    +for (Map.Entry<String, Set<Set<ExecutorDetails>>> entry : topologyWorkerSpecs.entrySet()) {<br/>\n    +    String topologyId = entry.getKey();<br/>\n    +    Set<Set<ExecutorDetails>> executorSet = entry.getValue();<br/>\n    +    if (executorSet != null && executorSet.size() > 0) </p>\n{\n    +failedTopologyIds.add(topologyId);\n    +    }\n<p>    +    List<Integer> workerNum = distributionSortedAmts(topologyMachineDistributions.get(topologyId));<br/>\n    +    for (Integer num : workerNum) {<br/>\n    +HostAssignableSlots hostSlots = hss.peek();<br/>\n    +List<WorkerSlot> slot = hostSlots != null ? hostSlots.getWorkerSlots() : null;<br/>\n    +<br/>\n    +if (slot != null && slot.size() >= num.intValue()) {<br/>\n    +    hss.poll();<br/>\n    +    cluster.freeSlots(hostUsedSlots.get(hostSlots.getHostName()));<br/>\n    +    for (WorkerSlot tmpSlot : slot.subList(0, num)) </p>\n{\n    +Set<ExecutorDetails> executor = removeElemFromSet(executorSet);\n    +cluster.assign(tmpSlot, topologyId, executor);\n    +    }\n<p>    +    cluster.blacklistHost(hostSlots.getHostName());<br/>\n    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +if (failedTopologyIds.size() > 0) {<br/>\n    +    LOG.warn(\"Unable to isolate topologies \" + failedTopologyIds<br/>\n    +    + \". No machine had enough worker slots to run the remaining workers for these topologies. \"<br/>\n    +    + \"Clearing all other resources and will wait for enough resources for \"<br/>\n    +    + \"isolated topologies before allocating any other resources.\");<br/>\n    +    // clear workers off all hosts that are not blacklisted<br/>\n    +    Map<String, Set<WorkerSlot>> usedSlots = hostUsedSlots(cluster);<br/>\n    +    Set<Map.Entry<String, Set<WorkerSlot>>> entries = usedSlots.entrySet();<br/>\n    +    for (Map.Entry<String, Set<WorkerSlot>> entry : entries) {<br/>\n    +if (!cluster.isBlacklistedHost(entry.getKey())) </p>\n{\n    +    cluster.freeSlots(entry.getValue());\n    +}\n<p>    +    }<br/>\n    +} else </p>\n{\n    +    // run default scheduler on non-isolated topologies\n    +    Set<String> allocatedTopologies = allocatedTopologies(topologyWorkerSpecs);\n    +    Topologies leftOverTopologies = leftoverTopologies(topologies, allocatedTopologies);\n    +    DefaultScheduler.defaultSchedule(leftOverTopologies, cluster);\n    +}\n<p>    +cluster.setBlacklistedHosts(origBlacklist);<br/>\n    +    }<br/>\n    +<br/>\n    +    public Set<ExecutorDetails> removeElemFromSet(Set<Set<ExecutorDetails>> executorsSets) </p>\n{\n    +Set<ExecutorDetails> elem = executorsSets.iterator().next();\n    +executorsSets.remove(elem);\n    +return elem;\n    +    }\n<p>    +<br/>\n    +    private List<TopologyDetails> isolatedTopologies(Collection<TopologyDetails> topologies) {<br/>\n    +Set<String> topologyNames = isoMachines.keySet();<br/>\n    +List<TopologyDetails> isoTopologies = new ArrayList<TopologyDetails>();<br/>\n    +for (TopologyDetails topo : topologies) {<br/>\n    +    if (topologyNames.contains(topo.getName())) </p>\n{\n    +isoTopologies.add(topo);\n    +    }\n<p>    +}<br/>\n    +return isoTopologies;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<String> isolatedTopoplogyIds(List<TopologyDetails> topologies) {<br/>\n    +Set<String> ids = new HashSet<String>();<br/>\n    +if (topologies != null && topologies.size() > 0) {<br/>\n    +    for (TopologyDetails topology : topologies) </p>\n{\n    +ids.add(topology.getId());\n    +    }\n<p>    +}<br/>\n    +return ids;<br/>\n    +    }<br/>\n    +<br/>\n    +    // map from topology id -> set of sets of executors<br/>\n    +    private Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs(List<TopologyDetails> topologies) {<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> workerSpecs = new HashMap<String, Set<Set<ExecutorDetails>>>();<br/>\n    +for (TopologyDetails topology : topologies) </p>\n{\n    +    workerSpecs.put(topology.getId(), computeWorkerSpecs(topology));\n    +}\n<p>    +return workerSpecs;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, List<AssignmentInfo>> hostAssignments(Cluster cluster) {<br/>\n    +Collection<SchedulerAssignment> assignmentValues =  cluster.getAssignments().values();<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = new HashMap<String, List<AssignmentInfo>>();<br/>\n    +<br/>\n    +for (SchedulerAssignment sa : assignmentValues) {<br/>\n    +    Map<WorkerSlot, List<ExecutorDetails>> slotExecutors = Utils.reverseMap(sa.getExecutorToSlot());<br/>\n    +    Set<Map.Entry<WorkerSlot, List<ExecutorDetails>>> entries = slotExecutors.entrySet();<br/>\n    +    for (Map.Entry<WorkerSlot, List<ExecutorDetails>> entry : entries) {<br/>\n    +WorkerSlot slot = entry.getKey();<br/>\n    +List<ExecutorDetails> executors = entry.getValue();<br/>\n    +<br/>\n    +String host = cluster.getHost(slot.getNodeId());<br/>\n    +AssignmentInfo ass = new AssignmentInfo(slot, sa.getTopologyId(), new HashSet<ExecutorDetails>(executors));<br/>\n    +List<AssignmentInfo> executorList = hostAssignments.get(host);<br/>\n    +if (executorList == null) </p>\n{\n    +    executorList = new ArrayList<AssignmentInfo>();\n    +    hostAssignments.put(host, executorList);\n    +}\n<p>    +executorList.add(ass);<br/>\n    +    }<br/>\n    +}<br/>\n    +return hostAssignments;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<Set<ExecutorDetails>> computeWorkerSpecs(TopologyDetails topology) {<br/>\n    +Map<String, List<ExecutorDetails>> compExecutors = Utils.reverseMap(topology.getExecutorToComponent());<br/>\n    +<br/>\n    +List<ExecutorDetails> allExecutors = new ArrayList<ExecutorDetails>();<br/>\n    +Collection<List<ExecutorDetails>> values = compExecutors.values();<br/>\n    +for (List<ExecutorDetails> eList : values) </p>\n{\n    +    allExecutors.addAll(eList);\n    +}\n<p>    +<br/>\n    +int numWorkers = topology.getNumWorkers();<br/>\n    +int bucketIndex = 0;<br/>\n    +Map<Integer, Set<ExecutorDetails>> bucketExecutors = new HashMap<Integer, Set<ExecutorDetails>>(numWorkers);<br/>\n    +for (ExecutorDetails executor : allExecutors) {<br/>\n    +    Set<ExecutorDetails> executors = bucketExecutors.get(bucketIndex);<br/>\n    +    if (executors == null) </p>\n{\n    +executors = new HashSet<ExecutorDetails>();\n    +bucketExecutors.put(bucketIndex, executors);\n    +    }\n<p>    +    executors.add(executor);<br/>\n    +    bucketIndex = (bucketIndex+1) % numWorkers;<br/>\n    +}<br/>\n    +<br/>\n    +return new HashSet<Set<ExecutorDetails>>(bucketExecutors.values());<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Map<Integer, Integer>> topologyMachineDistributions(List<TopologyDetails> isoTopologies) {<br/>\n    +Map<String, Map<Integer, Integer>> machineDistributions = new HashMap<String, Map<Integer, Integer>>();<br/>\n    +for (TopologyDetails topology : isoTopologies) </p>\n{\n    +    machineDistributions.put(topology.getId(), machineDistribution(topology));\n    +}\n<p>    +return machineDistributions;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Integer, Integer> machineDistribution(TopologyDetails topology) {<br/>\n    +int machineNum = isoMachines.get(topology.getName()).intValue();<br/>\n    +int workerNum = topology.getNumWorkers();<br/>\n    +TreeMap<Integer, Integer> distribution = Utils.integerDivided(workerNum, machineNum);<br/>\n    +<br/>\n    +if (distribution.containsKey(0)) </p>\n{\n    +    distribution.remove(0);\n    +}\n<p>    +return distribution;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentTopology(List<AssignmentInfo> assignments, String topologyId) {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (!topologyId.equals(ass.getTopologyId())) </p>\n{\n    +return false;\n    +    }<br/>\n    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentWorkerSpecs(List<AssignmentInfo> assigments, Set<Set<ExecutorDetails>> workerSpecs) {<br/>\n    +for (AssignmentInfo ass : assigments) {<br/>\n    +    if (!workerSpecs.contains(ass.getExecutors())) {    +return false;    +    }\n<p>    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void decrementDistribution(Map<Integer, Integer> distribution, int value) {<br/>\n    +Integer distValue = distribution.get(value);<br/>\n    +if (distValue != null) {<br/>\n    +    int newValue = distValue - 1;<br/>\n    +    if (newValue == 0) </p>\n{\n    +distribution.remove(value);\n    +    }\n<p> else </p>\n{\n    +distribution.put(value, newValue);\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Set<WorkerSlot>> hostUsedSlots(Cluster cluster) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    It should be `hostToUsedSlots` according to `Java Migration Guidelines`.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646015/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646020","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646020","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646020,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwMjA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T07:55:32Z","updated_at":"2025-01-24T14:20:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359#discussion_r70392274\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359#discussion_r70392274</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/scheduler/IsolationScheduler.java &#8212;<br/>\n    @@ -0,0 +1,417 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.scheduler;<br/>\n    +<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.Collections;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.HashSet;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Set;<br/>\n    +import java.util.TreeMap;<br/>\n    +<br/>\n    +import org.apache.commons.lang.Validate;<br/>\n    +import org.apache.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import org.apache.storm.Config;<br/>\n    +import org.apache.storm.scheduler.Cluster;<br/>\n    +import org.apache.storm.scheduler.ExecutorDetails;<br/>\n    +import org.apache.storm.scheduler.IScheduler;<br/>\n    +import org.apache.storm.scheduler.SchedulerAssignment;<br/>\n    +import org.apache.storm.scheduler.Topologies;<br/>\n    +import org.apache.storm.scheduler.TopologyDetails;<br/>\n    +import org.apache.storm.scheduler.WorkerSlot;<br/>\n    +<br/>\n    +// for each isolated topology:<br/>\n    +//   compute even distribution of executors -> workers on the number of workers specified for the topology<br/>\n    +//   compute distribution of workers to machines<br/>\n    +// determine host -> list of <span class=\"error\">&#91;slot, topology id, executors&#93;</span><br/>\n    +// iterate through hosts and: a machine is good if:<br/>\n    +//   1. only running workers from one isolated topology<br/>\n    +//   2. all workers running on it match one of the distributions of executors for that topology<br/>\n    +//   3. matches one of the # of workers<br/>\n    +// blacklist the good hosts and remove those workers from the list of need to be assigned workers<br/>\n    +// otherwise unassign all other workers for isolated topologies if assigned<br/>\n    +public class IsolationScheduler implements IScheduler {<br/>\n    +    private final static Logger LOG = LoggerFactory.getLogger(IsolationScheduler.class);<br/>\n    +<br/>\n    +    private Map<String, Number> isoMachines;<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public void prepare(Map conf) </p>\n{\n    +this.isoMachines = (Map<String, Number>) conf.get(Config.ISOLATION_SCHEDULER_MACHINES);\n    +Validate.notEmpty(isoMachines);\n    +    }\n<p>    +<br/>\n    +    // get host -> all assignable worker slots for non-blacklisted machines (assigned or not assigned)<br/>\n    +    // will then have a list of machines that need to be assigned (machine -> <span class=\"error\">&#91;topology, list of list of executors&#93;</span>)<br/>\n    +    // match each spec to a machine (who has the right number of workers), free everything else on that machine and assign those slots (do one topology at a time)<br/>\n    +    // blacklist all machines who had production slots defined<br/>\n    +    // log isolated topologies who weren't able to get enough slots / machines<br/>\n    +    // run default scheduler on isolated topologies that didn't have enough slots + non-isolated topologies on remaining machines<br/>\n    +    // set blacklist to what it was initially<br/>\n    +    @Override<br/>\n    +    public void schedule(Topologies topologies, Cluster cluster) {<br/>\n    +Set<String> origBlacklist = cluster.getBlacklistedHosts();<br/>\n    +List<TopologyDetails> isoTopologies = isolatedTopologies(topologies.getTopologies());<br/>\n    +Set<String> isoIds = isolatedTopoplogyIds(isoTopologies);<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs = topologyWorkerSpecs(isoTopologies);<br/>\n    +Map<String, Map<Integer, Integer>> topologyMachineDistributions = topologyMachineDistributions(isoTopologies);<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = hostAssignments(cluster);<br/>\n    +<br/>\n    +for (Map.Entry<String, List<AssignmentInfo>> entry : hostAssignments.entrySet()) {<br/>\n    +    List<AssignmentInfo> assignments = entry.getValue();<br/>\n    +    String topologyId = assignments.get(0).getTopologyId();<br/>\n    +    Map<Integer, Integer> distribution = topologyMachineDistributions.get(topologyId);<br/>\n    +    Set<Set<ExecutorDetails>> workerSpecs = topologyWorkerSpecs.get(topologyId);<br/>\n    +    int numWorkers = assignments.size();<br/>\n    +<br/>\n    +    if (isoIds.contains(topologyId)<br/>\n    +    && checkAssignmentTopology(assignments, topologyId)<br/>\n    +    && distribution.containsKey(numWorkers)<br/>\n    +    && checkAssignmentWorkerSpecs(assignments, workerSpecs)) {<br/>\n    +decrementDistribution(distribution, numWorkers);<br/>\n    +for (AssignmentInfo ass : assignments) </p>\n{\n    +    workerSpecs.remove(ass.getExecutors());\n    +}\n<p>    +cluster.blacklistHost(entry.getKey());<br/>\n    +    } else {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (isoIds.contains(ass.getTopologyId())) </p>\n{\n    +cluster.freeSlot(ass.getWorkerSlot());\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = hostUsedSlots(cluster);<br/>\n    +LinkedList<HostAssignableSlots> hss = hostAssignableSlots(cluster);<br/>\n    +List<String> failedTopologyIds = new ArrayList<String>();<br/>\n    +for (Map.Entry<String, Set<Set<ExecutorDetails>>> entry : topologyWorkerSpecs.entrySet()) {<br/>\n    +    String topologyId = entry.getKey();<br/>\n    +    Set<Set<ExecutorDetails>> executorSet = entry.getValue();<br/>\n    +    if (executorSet != null && executorSet.size() > 0) </p>\n{\n    +failedTopologyIds.add(topologyId);\n    +    }\n<p>    +    List<Integer> workerNum = distributionSortedAmts(topologyMachineDistributions.get(topologyId));<br/>\n    +    for (Integer num : workerNum) {<br/>\n    +HostAssignableSlots hostSlots = hss.peek();<br/>\n    +List<WorkerSlot> slot = hostSlots != null ? hostSlots.getWorkerSlots() : null;<br/>\n    +<br/>\n    +if (slot != null && slot.size() >= num.intValue()) {<br/>\n    +    hss.poll();<br/>\n    +    cluster.freeSlots(hostUsedSlots.get(hostSlots.getHostName()));<br/>\n    +    for (WorkerSlot tmpSlot : slot.subList(0, num)) </p>\n{\n    +Set<ExecutorDetails> executor = removeElemFromSet(executorSet);\n    +cluster.assign(tmpSlot, topologyId, executor);\n    +    }\n<p>    +    cluster.blacklistHost(hostSlots.getHostName());<br/>\n    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +if (failedTopologyIds.size() > 0) {<br/>\n    +    LOG.warn(\"Unable to isolate topologies \" + failedTopologyIds<br/>\n    +    + \". No machine had enough worker slots to run the remaining workers for these topologies. \"<br/>\n    +    + \"Clearing all other resources and will wait for enough resources for \"<br/>\n    +    + \"isolated topologies before allocating any other resources.\");<br/>\n    +    // clear workers off all hosts that are not blacklisted<br/>\n    +    Map<String, Set<WorkerSlot>> usedSlots = hostUsedSlots(cluster);<br/>\n    +    Set<Map.Entry<String, Set<WorkerSlot>>> entries = usedSlots.entrySet();<br/>\n    +    for (Map.Entry<String, Set<WorkerSlot>> entry : entries) {<br/>\n    +if (!cluster.isBlacklistedHost(entry.getKey())) </p>\n{\n    +    cluster.freeSlots(entry.getValue());\n    +}\n<p>    +    }<br/>\n    +} else </p>\n{\n    +    // run default scheduler on non-isolated topologies\n    +    Set<String> allocatedTopologies = allocatedTopologies(topologyWorkerSpecs);\n    +    Topologies leftOverTopologies = leftoverTopologies(topologies, allocatedTopologies);\n    +    DefaultScheduler.defaultSchedule(leftOverTopologies, cluster);\n    +}\n<p>    +cluster.setBlacklistedHosts(origBlacklist);<br/>\n    +    }<br/>\n    +<br/>\n    +    public Set<ExecutorDetails> removeElemFromSet(Set<Set<ExecutorDetails>> executorsSets) </p>\n{\n    +Set<ExecutorDetails> elem = executorsSets.iterator().next();\n    +executorsSets.remove(elem);\n    +return elem;\n    +    }\n<p>    +<br/>\n    +    private List<TopologyDetails> isolatedTopologies(Collection<TopologyDetails> topologies) {<br/>\n    +Set<String> topologyNames = isoMachines.keySet();<br/>\n    +List<TopologyDetails> isoTopologies = new ArrayList<TopologyDetails>();<br/>\n    +for (TopologyDetails topo : topologies) {<br/>\n    +    if (topologyNames.contains(topo.getName())) </p>\n{\n    +isoTopologies.add(topo);\n    +    }\n<p>    +}<br/>\n    +return isoTopologies;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<String> isolatedTopoplogyIds(List<TopologyDetails> topologies) {<br/>\n    +Set<String> ids = new HashSet<String>();<br/>\n    +if (topologies != null && topologies.size() > 0) {<br/>\n    +    for (TopologyDetails topology : topologies) </p>\n{\n    +ids.add(topology.getId());\n    +    }\n<p>    +}<br/>\n    +return ids;<br/>\n    +    }<br/>\n    +<br/>\n    +    // map from topology id -> set of sets of executors<br/>\n    +    private Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs(List<TopologyDetails> topologies) {<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> workerSpecs = new HashMap<String, Set<Set<ExecutorDetails>>>();<br/>\n    +for (TopologyDetails topology : topologies) </p>\n{\n    +    workerSpecs.put(topology.getId(), computeWorkerSpecs(topology));\n    +}\n<p>    +return workerSpecs;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, List<AssignmentInfo>> hostAssignments(Cluster cluster) {<br/>\n    +Collection<SchedulerAssignment> assignmentValues =  cluster.getAssignments().values();<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = new HashMap<String, List<AssignmentInfo>>();<br/>\n    +<br/>\n    +for (SchedulerAssignment sa : assignmentValues) {<br/>\n    +    Map<WorkerSlot, List<ExecutorDetails>> slotExecutors = Utils.reverseMap(sa.getExecutorToSlot());<br/>\n    +    Set<Map.Entry<WorkerSlot, List<ExecutorDetails>>> entries = slotExecutors.entrySet();<br/>\n    +    for (Map.Entry<WorkerSlot, List<ExecutorDetails>> entry : entries) {<br/>\n    +WorkerSlot slot = entry.getKey();<br/>\n    +List<ExecutorDetails> executors = entry.getValue();<br/>\n    +<br/>\n    +String host = cluster.getHost(slot.getNodeId());<br/>\n    +AssignmentInfo ass = new AssignmentInfo(slot, sa.getTopologyId(), new HashSet<ExecutorDetails>(executors));<br/>\n    +List<AssignmentInfo> executorList = hostAssignments.get(host);<br/>\n    +if (executorList == null) </p>\n{\n    +    executorList = new ArrayList<AssignmentInfo>();\n    +    hostAssignments.put(host, executorList);\n    +}\n<p>    +executorList.add(ass);<br/>\n    +    }<br/>\n    +}<br/>\n    +return hostAssignments;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<Set<ExecutorDetails>> computeWorkerSpecs(TopologyDetails topology) {<br/>\n    +Map<String, List<ExecutorDetails>> compExecutors = Utils.reverseMap(topology.getExecutorToComponent());<br/>\n    +<br/>\n    +List<ExecutorDetails> allExecutors = new ArrayList<ExecutorDetails>();<br/>\n    +Collection<List<ExecutorDetails>> values = compExecutors.values();<br/>\n    +for (List<ExecutorDetails> eList : values) </p>\n{\n    +    allExecutors.addAll(eList);\n    +}\n<p>    +<br/>\n    +int numWorkers = topology.getNumWorkers();<br/>\n    +int bucketIndex = 0;<br/>\n    +Map<Integer, Set<ExecutorDetails>> bucketExecutors = new HashMap<Integer, Set<ExecutorDetails>>(numWorkers);<br/>\n    +for (ExecutorDetails executor : allExecutors) {<br/>\n    +    Set<ExecutorDetails> executors = bucketExecutors.get(bucketIndex);<br/>\n    +    if (executors == null) </p>\n{\n    +executors = new HashSet<ExecutorDetails>();\n    +bucketExecutors.put(bucketIndex, executors);\n    +    }\n<p>    +    executors.add(executor);<br/>\n    +    bucketIndex = (bucketIndex+1) % numWorkers;<br/>\n    +}<br/>\n    +<br/>\n    +return new HashSet<Set<ExecutorDetails>>(bucketExecutors.values());<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Map<Integer, Integer>> topologyMachineDistributions(List<TopologyDetails> isoTopologies) {<br/>\n    +Map<String, Map<Integer, Integer>> machineDistributions = new HashMap<String, Map<Integer, Integer>>();<br/>\n    +for (TopologyDetails topology : isoTopologies) </p>\n{\n    +    machineDistributions.put(topology.getId(), machineDistribution(topology));\n    +}\n<p>    +return machineDistributions;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Integer, Integer> machineDistribution(TopologyDetails topology) {<br/>\n    +int machineNum = isoMachines.get(topology.getName()).intValue();<br/>\n    +int workerNum = topology.getNumWorkers();<br/>\n    +TreeMap<Integer, Integer> distribution = Utils.integerDivided(workerNum, machineNum);<br/>\n    +<br/>\n    +if (distribution.containsKey(0)) </p>\n{\n    +    distribution.remove(0);\n    +}\n<p>    +return distribution;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentTopology(List<AssignmentInfo> assignments, String topologyId) {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (!topologyId.equals(ass.getTopologyId())) </p>\n{\n    +return false;\n    +    }<br/>\n    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentWorkerSpecs(List<AssignmentInfo> assigments, Set<Set<ExecutorDetails>> workerSpecs) {<br/>\n    +for (AssignmentInfo ass : assigments) {<br/>\n    +    if (!workerSpecs.contains(ass.getExecutors())) {    +return false;    +    }\n<p>    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void decrementDistribution(Map<Integer, Integer> distribution, int value) {<br/>\n    +Integer distValue = distribution.get(value);<br/>\n    +if (distValue != null) {<br/>\n    +    int newValue = distValue - 1;<br/>\n    +    if (newValue == 0) </p>\n{\n    +distribution.remove(value);\n    +    }\n<p> else </p>\n{\n    +distribution.put(value, newValue);\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Set<WorkerSlot>> hostUsedSlots(Cluster cluster) {<br/>\n    +Collection<WorkerSlot> usedSlots = cluster.getUsedSlots();<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = new HashMap<String, Set<WorkerSlot>>();<br/>\n    +for (WorkerSlot slot : usedSlots) {<br/>\n    +    String host = cluster.getHost(slot.getNodeId());<br/>\n    +    Set<WorkerSlot> slots = hostUsedSlots.get(host);<br/>\n    +    if (slots == null) </p>\n{\n    +slots = new HashSet<WorkerSlot>();\n    +hostUsedSlots.put(host, slots);\n    +    }\n<p>    +    slots.add(slot);<br/>\n    +}<br/>\n    +return hostUsedSlots;<br/>\n    +    }<br/>\n    +<br/>\n    +    // returns list of list of slots, reverse sorted by number of slots<br/>\n    +    private LinkedList<HostAssignableSlots> hostAssignableSlots(Cluster cluster) {<br/>\n    +List<WorkerSlot> assignableSlots = cluster.getAssignableSlots();<br/>\n    +Map<String, List<WorkerSlot>> hostAssignableSlots = new HashMap<String, List<WorkerSlot>>();<br/>\n    +for (WorkerSlot slot : assignableSlots) {<br/>\n    +    String host = cluster.getHost(slot.getNodeId());<br/>\n    +    List<WorkerSlot> slots = hostAssignableSlots.get(host);<br/>\n    +    if (slots == null) </p>\n{\n    +slots = new ArrayList<WorkerSlot>();\n    +hostAssignableSlots.put(host, slots);\n    +    }\n<p>    +    slots.add(slot);<br/>\n    +}<br/>\n    +List<HostAssignableSlots> sortHostAssignSlots = new ArrayList<HostAssignableSlots>();<br/>\n    +for (Map.Entry<String, List<WorkerSlot>> entry : hostAssignableSlots.entrySet()) </p>\n{\n    +    sortHostAssignSlots.add(new HostAssignableSlots(entry.getKey(), entry.getValue()));\n    +}\n<p>    +Collections.sort(sortHostAssignSlots, new Comparator<HostAssignableSlots>() {<br/>\n    +    @Override<br/>\n    +    public int compare(HostAssignableSlots o1, HostAssignableSlots o2) </p>\n{\n    +return o2.getWorkerSlots().size() - o1.getWorkerSlots().size();\n    +    }\n<p>    +});<br/>\n    +Collections.shuffle(sortHostAssignSlots);<br/>\n    +<br/>\n    +return new LinkedList<HostAssignableSlots>(sortHostAssignSlots);<br/>\n    +    }<br/>\n    +<br/>\n    +    private List<Integer> distributionSortedAmts(Map<Integer, Integer> distributions) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    `distributionToSortedAmts` or `distributionToSortedAmounts`</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646020/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646022","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646022","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646022,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwMjI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T08:06:48Z","updated_at":"2025-01-24T14:20:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359#discussion_r70393611\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359#discussion_r70393611</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/scheduler/IsolationScheduler.java &#8212;<br/>\n    @@ -0,0 +1,417 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.scheduler;<br/>\n    +<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.Collections;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.HashSet;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Set;<br/>\n    +import java.util.TreeMap;<br/>\n    +<br/>\n    +import org.apache.commons.lang.Validate;<br/>\n    +import org.apache.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import org.apache.storm.Config;<br/>\n    +import org.apache.storm.scheduler.Cluster;<br/>\n    +import org.apache.storm.scheduler.ExecutorDetails;<br/>\n    +import org.apache.storm.scheduler.IScheduler;<br/>\n    +import org.apache.storm.scheduler.SchedulerAssignment;<br/>\n    +import org.apache.storm.scheduler.Topologies;<br/>\n    +import org.apache.storm.scheduler.TopologyDetails;<br/>\n    +import org.apache.storm.scheduler.WorkerSlot;<br/>\n    +<br/>\n    +// for each isolated topology:<br/>\n    +//   compute even distribution of executors -> workers on the number of workers specified for the topology<br/>\n    +//   compute distribution of workers to machines<br/>\n    +// determine host -> list of <span class=\"error\">&#91;slot, topology id, executors&#93;</span><br/>\n    +// iterate through hosts and: a machine is good if:<br/>\n    +//   1. only running workers from one isolated topology<br/>\n    +//   2. all workers running on it match one of the distributions of executors for that topology<br/>\n    +//   3. matches one of the # of workers<br/>\n    +// blacklist the good hosts and remove those workers from the list of need to be assigned workers<br/>\n    +// otherwise unassign all other workers for isolated topologies if assigned<br/>\n    +public class IsolationScheduler implements IScheduler {<br/>\n    +    private final static Logger LOG = LoggerFactory.getLogger(IsolationScheduler.class);<br/>\n    +<br/>\n    +    private Map<String, Number> isoMachines;<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public void prepare(Map conf) </p>\n{\n    +this.isoMachines = (Map<String, Number>) conf.get(Config.ISOLATION_SCHEDULER_MACHINES);\n    +Validate.notEmpty(isoMachines);\n    +    }\n<p>    +<br/>\n    +    // get host -> all assignable worker slots for non-blacklisted machines (assigned or not assigned)<br/>\n    +    // will then have a list of machines that need to be assigned (machine -> <span class=\"error\">&#91;topology, list of list of executors&#93;</span>)<br/>\n    +    // match each spec to a machine (who has the right number of workers), free everything else on that machine and assign those slots (do one topology at a time)<br/>\n    +    // blacklist all machines who had production slots defined<br/>\n    +    // log isolated topologies who weren't able to get enough slots / machines<br/>\n    +    // run default scheduler on isolated topologies that didn't have enough slots + non-isolated topologies on remaining machines<br/>\n    +    // set blacklist to what it was initially<br/>\n    +    @Override<br/>\n    +    public void schedule(Topologies topologies, Cluster cluster) {<br/>\n    +Set<String> origBlacklist = cluster.getBlacklistedHosts();<br/>\n    +List<TopologyDetails> isoTopologies = isolatedTopologies(topologies.getTopologies());<br/>\n    +Set<String> isoIds = isolatedTopoplogyIds(isoTopologies);<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs = topologyWorkerSpecs(isoTopologies);<br/>\n    +Map<String, Map<Integer, Integer>> topologyMachineDistributions = topologyMachineDistributions(isoTopologies);<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = hostAssignments(cluster);<br/>\n    +<br/>\n    +for (Map.Entry<String, List<AssignmentInfo>> entry : hostAssignments.entrySet()) {<br/>\n    +    List<AssignmentInfo> assignments = entry.getValue();<br/>\n    +    String topologyId = assignments.get(0).getTopologyId();<br/>\n    +    Map<Integer, Integer> distribution = topologyMachineDistributions.get(topologyId);<br/>\n    +    Set<Set<ExecutorDetails>> workerSpecs = topologyWorkerSpecs.get(topologyId);<br/>\n    +    int numWorkers = assignments.size();<br/>\n    +<br/>\n    +    if (isoIds.contains(topologyId)<br/>\n    +    && checkAssignmentTopology(assignments, topologyId)<br/>\n    +    && distribution.containsKey(numWorkers)<br/>\n    +    && checkAssignmentWorkerSpecs(assignments, workerSpecs)) {<br/>\n    +decrementDistribution(distribution, numWorkers);<br/>\n    +for (AssignmentInfo ass : assignments) </p>\n{\n    +    workerSpecs.remove(ass.getExecutors());\n    +}\n<p>    +cluster.blacklistHost(entry.getKey());<br/>\n    +    } else {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (isoIds.contains(ass.getTopologyId())) </p>\n{\n    +cluster.freeSlot(ass.getWorkerSlot());\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = hostUsedSlots(cluster);<br/>\n    +LinkedList<HostAssignableSlots> hss = hostAssignableSlots(cluster);<br/>\n    +List<String> failedTopologyIds = new ArrayList<String>();<br/>\n    +for (Map.Entry<String, Set<Set<ExecutorDetails>>> entry : topologyWorkerSpecs.entrySet()) {<br/>\n    +    String topologyId = entry.getKey();<br/>\n    +    Set<Set<ExecutorDetails>> executorSet = entry.getValue();<br/>\n    +    if (executorSet != null && executorSet.size() > 0) </p>\n{\n    +failedTopologyIds.add(topologyId);\n    +    }\n<p>    +    List<Integer> workerNum = distributionSortedAmts(topologyMachineDistributions.get(topologyId));<br/>\n    +    for (Integer num : workerNum) {<br/>\n    +HostAssignableSlots hostSlots = hss.peek();<br/>\n    +List<WorkerSlot> slot = hostSlots != null ? hostSlots.getWorkerSlots() : null;<br/>\n    +<br/>\n    +if (slot != null && slot.size() >= num.intValue()) {<br/>\n    +    hss.poll();<br/>\n    +    cluster.freeSlots(hostUsedSlots.get(hostSlots.getHostName()));<br/>\n    +    for (WorkerSlot tmpSlot : slot.subList(0, num)) </p>\n{\n    +Set<ExecutorDetails> executor = removeElemFromSet(executorSet);\n    +cluster.assign(tmpSlot, topologyId, executor);\n    +    }\n<p>    +    cluster.blacklistHost(hostSlots.getHostName());<br/>\n    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +if (failedTopologyIds.size() > 0) {<br/>\n    +    LOG.warn(\"Unable to isolate topologies \" + failedTopologyIds<br/>\n    +    + \". No machine had enough worker slots to run the remaining workers for these topologies. \"<br/>\n    +    + \"Clearing all other resources and will wait for enough resources for \"<br/>\n    +    + \"isolated topologies before allocating any other resources.\");<br/>\n    +    // clear workers off all hosts that are not blacklisted<br/>\n    +    Map<String, Set<WorkerSlot>> usedSlots = hostUsedSlots(cluster);<br/>\n    +    Set<Map.Entry<String, Set<WorkerSlot>>> entries = usedSlots.entrySet();<br/>\n    +    for (Map.Entry<String, Set<WorkerSlot>> entry : entries) {<br/>\n    +if (!cluster.isBlacklistedHost(entry.getKey())) </p>\n{\n    +    cluster.freeSlots(entry.getValue());\n    +}\n<p>    +    }<br/>\n    +} else </p>\n{\n    +    // run default scheduler on non-isolated topologies\n    +    Set<String> allocatedTopologies = allocatedTopologies(topologyWorkerSpecs);\n    +    Topologies leftOverTopologies = leftoverTopologies(topologies, allocatedTopologies);\n    +    DefaultScheduler.defaultSchedule(leftOverTopologies, cluster);\n    +}\n<p>    +cluster.setBlacklistedHosts(origBlacklist);<br/>\n    +    }<br/>\n    +<br/>\n    +    public Set<ExecutorDetails> removeElemFromSet(Set<Set<ExecutorDetails>> executorsSets) </p>\n{\n    +Set<ExecutorDetails> elem = executorsSets.iterator().next();\n    +executorsSets.remove(elem);\n    +return elem;\n    +    }\n<p>    +<br/>\n    +    private List<TopologyDetails> isolatedTopologies(Collection<TopologyDetails> topologies) {<br/>\n    +Set<String> topologyNames = isoMachines.keySet();<br/>\n    +List<TopologyDetails> isoTopologies = new ArrayList<TopologyDetails>();<br/>\n    +for (TopologyDetails topo : topologies) {<br/>\n    +    if (topologyNames.contains(topo.getName())) </p>\n{\n    +isoTopologies.add(topo);\n    +    }\n<p>    +}<br/>\n    +return isoTopologies;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<String> isolatedTopoplogyIds(List<TopologyDetails> topologies) {<br/>\n    +Set<String> ids = new HashSet<String>();<br/>\n    +if (topologies != null && topologies.size() > 0) {<br/>\n    +    for (TopologyDetails topology : topologies) </p>\n{\n    +ids.add(topology.getId());\n    +    }\n<p>    +}<br/>\n    +return ids;<br/>\n    +    }<br/>\n    +<br/>\n    +    // map from topology id -> set of sets of executors<br/>\n    +    private Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs(List<TopologyDetails> topologies) {<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> workerSpecs = new HashMap<String, Set<Set<ExecutorDetails>>>();<br/>\n    +for (TopologyDetails topology : topologies) </p>\n{\n    +    workerSpecs.put(topology.getId(), computeWorkerSpecs(topology));\n    +}\n<p>    +return workerSpecs;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, List<AssignmentInfo>> hostAssignments(Cluster cluster) {<br/>\n    +Collection<SchedulerAssignment> assignmentValues =  cluster.getAssignments().values();<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = new HashMap<String, List<AssignmentInfo>>();<br/>\n    +<br/>\n    +for (SchedulerAssignment sa : assignmentValues) {<br/>\n    +    Map<WorkerSlot, List<ExecutorDetails>> slotExecutors = Utils.reverseMap(sa.getExecutorToSlot());<br/>\n    +    Set<Map.Entry<WorkerSlot, List<ExecutorDetails>>> entries = slotExecutors.entrySet();<br/>\n    +    for (Map.Entry<WorkerSlot, List<ExecutorDetails>> entry : entries) {<br/>\n    +WorkerSlot slot = entry.getKey();<br/>\n    +List<ExecutorDetails> executors = entry.getValue();<br/>\n    +<br/>\n    +String host = cluster.getHost(slot.getNodeId());<br/>\n    +AssignmentInfo ass = new AssignmentInfo(slot, sa.getTopologyId(), new HashSet<ExecutorDetails>(executors));<br/>\n    +List<AssignmentInfo> executorList = hostAssignments.get(host);<br/>\n    +if (executorList == null) </p>\n{\n    +    executorList = new ArrayList<AssignmentInfo>();\n    +    hostAssignments.put(host, executorList);\n    +}\n<p>    +executorList.add(ass);<br/>\n    +    }<br/>\n    +}<br/>\n    +return hostAssignments;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<Set<ExecutorDetails>> computeWorkerSpecs(TopologyDetails topology) {<br/>\n    +Map<String, List<ExecutorDetails>> compExecutors = Utils.reverseMap(topology.getExecutorToComponent());<br/>\n    +<br/>\n    +List<ExecutorDetails> allExecutors = new ArrayList<ExecutorDetails>();<br/>\n    +Collection<List<ExecutorDetails>> values = compExecutors.values();<br/>\n    +for (List<ExecutorDetails> eList : values) </p>\n{\n    +    allExecutors.addAll(eList);\n    +}\n<p>    +<br/>\n    +int numWorkers = topology.getNumWorkers();<br/>\n    +int bucketIndex = 0;<br/>\n    +Map<Integer, Set<ExecutorDetails>> bucketExecutors = new HashMap<Integer, Set<ExecutorDetails>>(numWorkers);<br/>\n    +for (ExecutorDetails executor : allExecutors) {<br/>\n    +    Set<ExecutorDetails> executors = bucketExecutors.get(bucketIndex);<br/>\n    +    if (executors == null) </p>\n{\n    +executors = new HashSet<ExecutorDetails>();\n    +bucketExecutors.put(bucketIndex, executors);\n    +    }\n<p>    +    executors.add(executor);<br/>\n    +    bucketIndex = (bucketIndex+1) % numWorkers;<br/>\n    +}<br/>\n    +<br/>\n    +return new HashSet<Set<ExecutorDetails>>(bucketExecutors.values());<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Map<Integer, Integer>> topologyMachineDistributions(List<TopologyDetails> isoTopologies) {<br/>\n    +Map<String, Map<Integer, Integer>> machineDistributions = new HashMap<String, Map<Integer, Integer>>();<br/>\n    +for (TopologyDetails topology : isoTopologies) </p>\n{\n    +    machineDistributions.put(topology.getId(), machineDistribution(topology));\n    +}\n<p>    +return machineDistributions;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Integer, Integer> machineDistribution(TopologyDetails topology) {<br/>\n    +int machineNum = isoMachines.get(topology.getName()).intValue();<br/>\n    +int workerNum = topology.getNumWorkers();<br/>\n    +TreeMap<Integer, Integer> distribution = Utils.integerDivided(workerNum, machineNum);<br/>\n    +<br/>\n    +if (distribution.containsKey(0)) </p>\n{\n    +    distribution.remove(0);\n    +}\n<p>    +return distribution;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentTopology(List<AssignmentInfo> assignments, String topologyId) {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (!topologyId.equals(ass.getTopologyId())) </p>\n{\n    +return false;\n    +    }<br/>\n    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentWorkerSpecs(List<AssignmentInfo> assigments, Set<Set<ExecutorDetails>> workerSpecs) {<br/>\n    +for (AssignmentInfo ass : assigments) {<br/>\n    +    if (!workerSpecs.contains(ass.getExecutors())) {    +return false;    +    }\n<p>    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void decrementDistribution(Map<Integer, Integer> distribution, int value) {<br/>\n    +Integer distValue = distribution.get(value);<br/>\n    +if (distValue != null) {<br/>\n    +    int newValue = distValue - 1;<br/>\n    +    if (newValue == 0) </p>\n{\n    +distribution.remove(value);\n    +    }\n<p> else </p>\n{\n    +distribution.put(value, newValue);\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Set<WorkerSlot>> hostUsedSlots(Cluster cluster) {<br/>\n    +Collection<WorkerSlot> usedSlots = cluster.getUsedSlots();<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = new HashMap<String, Set<WorkerSlot>>();<br/>\n    +for (WorkerSlot slot : usedSlots) {<br/>\n    +    String host = cluster.getHost(slot.getNodeId());<br/>\n    +    Set<WorkerSlot> slots = hostUsedSlots.get(host);<br/>\n    +    if (slots == null) </p>\n{\n    +slots = new HashSet<WorkerSlot>();\n    +hostUsedSlots.put(host, slots);\n    +    }\n<p>    +    slots.add(slot);<br/>\n    +}<br/>\n    +return hostUsedSlots;<br/>\n    +    }<br/>\n    +<br/>\n    +    // returns list of list of slots, reverse sorted by number of slots<br/>\n    +    private LinkedList<HostAssignableSlots> hostAssignableSlots(Cluster cluster) {<br/>\n    +List<WorkerSlot> assignableSlots = cluster.getAssignableSlots();<br/>\n    +Map<String, List<WorkerSlot>> hostAssignableSlots = new HashMap<String, List<WorkerSlot>>();<br/>\n    +for (WorkerSlot slot : assignableSlots) {<br/>\n    +    String host = cluster.getHost(slot.getNodeId());<br/>\n    +    List<WorkerSlot> slots = hostAssignableSlots.get(host);<br/>\n    +    if (slots == null) </p>\n{\n    +slots = new ArrayList<WorkerSlot>();\n    +hostAssignableSlots.put(host, slots);\n    +    }\n<p>    +    slots.add(slot);<br/>\n    +}<br/>\n    +List<HostAssignableSlots> sortHostAssignSlots = new ArrayList<HostAssignableSlots>();<br/>\n    +for (Map.Entry<String, List<WorkerSlot>> entry : hostAssignableSlots.entrySet()) </p>\n{\n    +    sortHostAssignSlots.add(new HostAssignableSlots(entry.getKey(), entry.getValue()));\n    +}\n<p>    +Collections.sort(sortHostAssignSlots, new Comparator<HostAssignableSlots>() {<br/>\n    +    @Override<br/>\n    +    public int compare(HostAssignableSlots o1, HostAssignableSlots o2) </p>\n{\n    +return o2.getWorkerSlots().size() - o1.getWorkerSlots().size();\n    +    }\n<p>    +});<br/>\n    +Collections.shuffle(sortHostAssignSlots);<br/>\n    +<br/>\n    +return new LinkedList<HostAssignableSlots>(sortHostAssignSlots);<br/>\n    +    }<br/>\n    +<br/>\n    +    private List<Integer> distributionSortedAmts(Map<Integer, Integer> distributions) {<br/>\n    +List<Integer> sorts = new ArrayList<Integer>();<br/>\n    +for (Map.Entry<Integer, Integer> entry : distributions.entrySet()) {<br/>\n    +    int workers = entry.getKey();<br/>\n    +    int machines = entry.getValue();<br/>\n    +    for (int i = 0; i < machines; i++) </p>\n{\n    +sorts.add(workers);\n    +    }\n<p>    +}<br/>\n    +Collections.sort(sorts, new Comparator<Integer>() {<br/>\n    +    @Override<br/>\n    +    public int compare(Integer o1, Integer o2) {<br/>\n    +return o1.intValue() - o2.intValue();<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Order of sort should be reversed: `return o2.intValue() - o1.intValue()`</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646022/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646030","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646030","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646030,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwMzA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T08:10:05Z","updated_at":"2025-01-24T14:20:51Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user vesense commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359#discussion_r70394061\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359#discussion_r70394061</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/scheduler/IsolationScheduler.java &#8212;<br/>\n    @@ -0,0 +1,417 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.scheduler;<br/>\n    +<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.Collections;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.HashSet;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Set;<br/>\n    +import java.util.TreeMap;<br/>\n    +<br/>\n    +import org.apache.commons.lang.Validate;<br/>\n    +import org.apache.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import org.apache.storm.Config;<br/>\n    +import org.apache.storm.scheduler.Cluster;<br/>\n    +import org.apache.storm.scheduler.ExecutorDetails;<br/>\n    +import org.apache.storm.scheduler.IScheduler;<br/>\n    +import org.apache.storm.scheduler.SchedulerAssignment;<br/>\n    +import org.apache.storm.scheduler.Topologies;<br/>\n    +import org.apache.storm.scheduler.TopologyDetails;<br/>\n    +import org.apache.storm.scheduler.WorkerSlot;<br/>\n    +<br/>\n    +// for each isolated topology:<br/>\n    +//   compute even distribution of executors -> workers on the number of workers specified for the topology<br/>\n    +//   compute distribution of workers to machines<br/>\n    +// determine host -> list of <span class=\"error\">&#91;slot, topology id, executors&#93;</span><br/>\n    +// iterate through hosts and: a machine is good if:<br/>\n    +//   1. only running workers from one isolated topology<br/>\n    +//   2. all workers running on it match one of the distributions of executors for that topology<br/>\n    +//   3. matches one of the # of workers<br/>\n    +// blacklist the good hosts and remove those workers from the list of need to be assigned workers<br/>\n    +// otherwise unassign all other workers for isolated topologies if assigned<br/>\n    +public class IsolationScheduler implements IScheduler {<br/>\n    +    private final static Logger LOG = LoggerFactory.getLogger(IsolationScheduler.class);<br/>\n    +<br/>\n    +    private Map<String, Number> isoMachines;<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public void prepare(Map conf) </p>\n{\n    +this.isoMachines = (Map<String, Number>) conf.get(Config.ISOLATION_SCHEDULER_MACHINES);\n    +Validate.notEmpty(isoMachines);\n    +    }\n<p>    +<br/>\n    +    // get host -> all assignable worker slots for non-blacklisted machines (assigned or not assigned)<br/>\n    +    // will then have a list of machines that need to be assigned (machine -> <span class=\"error\">&#91;topology, list of list of executors&#93;</span>)<br/>\n    +    // match each spec to a machine (who has the right number of workers), free everything else on that machine and assign those slots (do one topology at a time)<br/>\n    +    // blacklist all machines who had production slots defined<br/>\n    +    // log isolated topologies who weren't able to get enough slots / machines<br/>\n    +    // run default scheduler on isolated topologies that didn't have enough slots + non-isolated topologies on remaining machines<br/>\n    +    // set blacklist to what it was initially<br/>\n    +    @Override<br/>\n    +    public void schedule(Topologies topologies, Cluster cluster) {<br/>\n    +Set<String> origBlacklist = cluster.getBlacklistedHosts();<br/>\n    +List<TopologyDetails> isoTopologies = isolatedTopologies(topologies.getTopologies());<br/>\n    +Set<String> isoIds = isolatedTopoplogyIds(isoTopologies);<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs = topologyWorkerSpecs(isoTopologies);<br/>\n    +Map<String, Map<Integer, Integer>> topologyMachineDistributions = topologyMachineDistributions(isoTopologies);<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = hostAssignments(cluster);<br/>\n    +<br/>\n    +for (Map.Entry<String, List<AssignmentInfo>> entry : hostAssignments.entrySet()) {<br/>\n    +    List<AssignmentInfo> assignments = entry.getValue();<br/>\n    +    String topologyId = assignments.get(0).getTopologyId();<br/>\n    +    Map<Integer, Integer> distribution = topologyMachineDistributions.get(topologyId);<br/>\n    +    Set<Set<ExecutorDetails>> workerSpecs = topologyWorkerSpecs.get(topologyId);<br/>\n    +    int numWorkers = assignments.size();<br/>\n    +<br/>\n    +    if (isoIds.contains(topologyId)<br/>\n    +    && checkAssignmentTopology(assignments, topologyId)<br/>\n    +    && distribution.containsKey(numWorkers)<br/>\n    +    && checkAssignmentWorkerSpecs(assignments, workerSpecs)) {<br/>\n    +decrementDistribution(distribution, numWorkers);<br/>\n    +for (AssignmentInfo ass : assignments) </p>\n{\n    +    workerSpecs.remove(ass.getExecutors());\n    +}\n<p>    +cluster.blacklistHost(entry.getKey());<br/>\n    +    } else {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (isoIds.contains(ass.getTopologyId())) </p>\n{\n    +cluster.freeSlot(ass.getWorkerSlot());\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = hostUsedSlots(cluster);<br/>\n    +LinkedList<HostAssignableSlots> hss = hostAssignableSlots(cluster);<br/>\n    +List<String> failedTopologyIds = new ArrayList<String>();<br/>\n    +for (Map.Entry<String, Set<Set<ExecutorDetails>>> entry : topologyWorkerSpecs.entrySet()) {<br/>\n    +    String topologyId = entry.getKey();<br/>\n    +    Set<Set<ExecutorDetails>> executorSet = entry.getValue();<br/>\n    +    if (executorSet != null && executorSet.size() > 0) </p>\n{\n    +failedTopologyIds.add(topologyId);\n    +    }\n<p>    +    List<Integer> workerNum = distributionSortedAmts(topologyMachineDistributions.get(topologyId));<br/>\n    +    for (Integer num : workerNum) {<br/>\n    +HostAssignableSlots hostSlots = hss.peek();<br/>\n    +List<WorkerSlot> slot = hostSlots != null ? hostSlots.getWorkerSlots() : null;<br/>\n    +<br/>\n    +if (slot != null && slot.size() >= num.intValue()) {<br/>\n    +    hss.poll();<br/>\n    +    cluster.freeSlots(hostUsedSlots.get(hostSlots.getHostName()));<br/>\n    +    for (WorkerSlot tmpSlot : slot.subList(0, num)) </p>\n{\n    +Set<ExecutorDetails> executor = removeElemFromSet(executorSet);\n    +cluster.assign(tmpSlot, topologyId, executor);\n    +    }\n<p>    +    cluster.blacklistHost(hostSlots.getHostName());<br/>\n    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +if (failedTopologyIds.size() > 0) {<br/>\n    +    LOG.warn(\"Unable to isolate topologies \" + failedTopologyIds<br/>\n    +    + \". No machine had enough worker slots to run the remaining workers for these topologies. \"<br/>\n    +    + \"Clearing all other resources and will wait for enough resources for \"<br/>\n    +    + \"isolated topologies before allocating any other resources.\");<br/>\n    +    // clear workers off all hosts that are not blacklisted<br/>\n    +    Map<String, Set<WorkerSlot>> usedSlots = hostUsedSlots(cluster);<br/>\n    +    Set<Map.Entry<String, Set<WorkerSlot>>> entries = usedSlots.entrySet();<br/>\n    +    for (Map.Entry<String, Set<WorkerSlot>> entry : entries) {<br/>\n    +if (!cluster.isBlacklistedHost(entry.getKey())) </p>\n{\n    +    cluster.freeSlots(entry.getValue());\n    +}\n<p>    +    }<br/>\n    +} else </p>\n{\n    +    // run default scheduler on non-isolated topologies\n    +    Set<String> allocatedTopologies = allocatedTopologies(topologyWorkerSpecs);\n    +    Topologies leftOverTopologies = leftoverTopologies(topologies, allocatedTopologies);\n    +    DefaultScheduler.defaultSchedule(leftOverTopologies, cluster);\n    +}\n<p>    +cluster.setBlacklistedHosts(origBlacklist);<br/>\n    +    }<br/>\n    +<br/>\n    +    public Set<ExecutorDetails> removeElemFromSet(Set<Set<ExecutorDetails>> executorsSets) </p>\n{\n    +Set<ExecutorDetails> elem = executorsSets.iterator().next();\n    +executorsSets.remove(elem);\n    +return elem;\n    +    }\n<p>    +<br/>\n    +    private List<TopologyDetails> isolatedTopologies(Collection<TopologyDetails> topologies) {<br/>\n    +Set<String> topologyNames = isoMachines.keySet();<br/>\n    +List<TopologyDetails> isoTopologies = new ArrayList<TopologyDetails>();<br/>\n    +for (TopologyDetails topo : topologies) {<br/>\n    +    if (topologyNames.contains(topo.getName())) </p>\n{\n    +isoTopologies.add(topo);\n    +    }\n<p>    +}<br/>\n    +return isoTopologies;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<String> isolatedTopoplogyIds(List<TopologyDetails> topologies) {<br/>\n    +Set<String> ids = new HashSet<String>();<br/>\n    +if (topologies != null && topologies.size() > 0) {<br/>\n    +    for (TopologyDetails topology : topologies) </p>\n{\n    +ids.add(topology.getId());\n    +    }\n<p>    +}<br/>\n    +return ids;<br/>\n    +    }<br/>\n    +<br/>\n    +    // map from topology id -> set of sets of executors<br/>\n    +    private Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs(List<TopologyDetails> topologies) {<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> workerSpecs = new HashMap<String, Set<Set<ExecutorDetails>>>();<br/>\n    +for (TopologyDetails topology : topologies) </p>\n{\n    +    workerSpecs.put(topology.getId(), computeWorkerSpecs(topology));\n    +}\n<p>    +return workerSpecs;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, List<AssignmentInfo>> hostAssignments(Cluster cluster) {<br/>\n    +Collection<SchedulerAssignment> assignmentValues =  cluster.getAssignments().values();<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = new HashMap<String, List<AssignmentInfo>>();<br/>\n    +<br/>\n    +for (SchedulerAssignment sa : assignmentValues) {<br/>\n    +    Map<WorkerSlot, List<ExecutorDetails>> slotExecutors = Utils.reverseMap(sa.getExecutorToSlot());<br/>\n    +    Set<Map.Entry<WorkerSlot, List<ExecutorDetails>>> entries = slotExecutors.entrySet();<br/>\n    +    for (Map.Entry<WorkerSlot, List<ExecutorDetails>> entry : entries) {<br/>\n    +WorkerSlot slot = entry.getKey();<br/>\n    +List<ExecutorDetails> executors = entry.getValue();<br/>\n    +<br/>\n    +String host = cluster.getHost(slot.getNodeId());<br/>\n    +AssignmentInfo ass = new AssignmentInfo(slot, sa.getTopologyId(), new HashSet<ExecutorDetails>(executors));<br/>\n    +List<AssignmentInfo> executorList = hostAssignments.get(host);<br/>\n    +if (executorList == null) </p>\n{\n    +    executorList = new ArrayList<AssignmentInfo>();\n    +    hostAssignments.put(host, executorList);\n    +}\n<p>    +executorList.add(ass);<br/>\n    +    }<br/>\n    +}<br/>\n    +return hostAssignments;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<Set<ExecutorDetails>> computeWorkerSpecs(TopologyDetails topology) {<br/>\n    +Map<String, List<ExecutorDetails>> compExecutors = Utils.reverseMap(topology.getExecutorToComponent());<br/>\n    +<br/>\n    +List<ExecutorDetails> allExecutors = new ArrayList<ExecutorDetails>();<br/>\n    +Collection<List<ExecutorDetails>> values = compExecutors.values();<br/>\n    +for (List<ExecutorDetails> eList : values) </p>\n{\n    +    allExecutors.addAll(eList);\n    +}\n<p>    +<br/>\n    +int numWorkers = topology.getNumWorkers();<br/>\n    +int bucketIndex = 0;<br/>\n    +Map<Integer, Set<ExecutorDetails>> bucketExecutors = new HashMap<Integer, Set<ExecutorDetails>>(numWorkers);<br/>\n    +for (ExecutorDetails executor : allExecutors) {<br/>\n    +    Set<ExecutorDetails> executors = bucketExecutors.get(bucketIndex);<br/>\n    +    if (executors == null) </p>\n{\n    +executors = new HashSet<ExecutorDetails>();\n    +bucketExecutors.put(bucketIndex, executors);\n    +    }\n<p>    +    executors.add(executor);<br/>\n    +    bucketIndex = (bucketIndex+1) % numWorkers;<br/>\n    +}<br/>\n    +<br/>\n    +return new HashSet<Set<ExecutorDetails>>(bucketExecutors.values());<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Map<Integer, Integer>> topologyMachineDistributions(List<TopologyDetails> isoTopologies) {<br/>\n    +Map<String, Map<Integer, Integer>> machineDistributions = new HashMap<String, Map<Integer, Integer>>();<br/>\n    +for (TopologyDetails topology : isoTopologies) </p>\n{\n    +    machineDistributions.put(topology.getId(), machineDistribution(topology));\n    +}\n<p>    +return machineDistributions;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Integer, Integer> machineDistribution(TopologyDetails topology) {<br/>\n    +int machineNum = isoMachines.get(topology.getName()).intValue();<br/>\n    +int workerNum = topology.getNumWorkers();<br/>\n    +TreeMap<Integer, Integer> distribution = Utils.integerDivided(workerNum, machineNum);<br/>\n    +<br/>\n    +if (distribution.containsKey(0)) </p>\n{\n    +    distribution.remove(0);\n    +}\n<p>    +return distribution;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentTopology(List<AssignmentInfo> assignments, String topologyId) {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (!topologyId.equals(ass.getTopologyId())) </p>\n{\n    +return false;\n    +    }<br/>\n    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentWorkerSpecs(List<AssignmentInfo> assigments, Set<Set<ExecutorDetails>> workerSpecs) {<br/>\n    +for (AssignmentInfo ass : assigments) {<br/>\n    +    if (!workerSpecs.contains(ass.getExecutors())) {    +return false;    +    }\n<p>    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void decrementDistribution(Map<Integer, Integer> distribution, int value) {<br/>\n    +Integer distValue = distribution.get(value);<br/>\n    +if (distValue != null) {<br/>\n    +    int newValue = distValue - 1;<br/>\n    +    if (newValue == 0) </p>\n{\n    +distribution.remove(value);\n    +    }\n<p> else </p>\n{\n    +distribution.put(value, newValue);\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Set<WorkerSlot>> hostUsedSlots(Cluster cluster) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Will fix.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646030/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646034","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646034","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646034,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwMzQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T08:10:26Z","updated_at":"2025-01-24T14:20:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user vesense commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359#discussion_r70394118\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359#discussion_r70394118</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/scheduler/IsolationScheduler.java &#8212;<br/>\n    @@ -0,0 +1,417 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.scheduler;<br/>\n    +<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.Collections;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.HashSet;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Set;<br/>\n    +import java.util.TreeMap;<br/>\n    +<br/>\n    +import org.apache.commons.lang.Validate;<br/>\n    +import org.apache.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import org.apache.storm.Config;<br/>\n    +import org.apache.storm.scheduler.Cluster;<br/>\n    +import org.apache.storm.scheduler.ExecutorDetails;<br/>\n    +import org.apache.storm.scheduler.IScheduler;<br/>\n    +import org.apache.storm.scheduler.SchedulerAssignment;<br/>\n    +import org.apache.storm.scheduler.Topologies;<br/>\n    +import org.apache.storm.scheduler.TopologyDetails;<br/>\n    +import org.apache.storm.scheduler.WorkerSlot;<br/>\n    +<br/>\n    +// for each isolated topology:<br/>\n    +//   compute even distribution of executors -> workers on the number of workers specified for the topology<br/>\n    +//   compute distribution of workers to machines<br/>\n    +// determine host -> list of <span class=\"error\">&#91;slot, topology id, executors&#93;</span><br/>\n    +// iterate through hosts and: a machine is good if:<br/>\n    +//   1. only running workers from one isolated topology<br/>\n    +//   2. all workers running on it match one of the distributions of executors for that topology<br/>\n    +//   3. matches one of the # of workers<br/>\n    +// blacklist the good hosts and remove those workers from the list of need to be assigned workers<br/>\n    +// otherwise unassign all other workers for isolated topologies if assigned<br/>\n    +public class IsolationScheduler implements IScheduler {<br/>\n    +    private final static Logger LOG = LoggerFactory.getLogger(IsolationScheduler.class);<br/>\n    +<br/>\n    +    private Map<String, Number> isoMachines;<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public void prepare(Map conf) </p>\n{\n    +this.isoMachines = (Map<String, Number>) conf.get(Config.ISOLATION_SCHEDULER_MACHINES);\n    +Validate.notEmpty(isoMachines);\n    +    }\n<p>    +<br/>\n    +    // get host -> all assignable worker slots for non-blacklisted machines (assigned or not assigned)<br/>\n    +    // will then have a list of machines that need to be assigned (machine -> <span class=\"error\">&#91;topology, list of list of executors&#93;</span>)<br/>\n    +    // match each spec to a machine (who has the right number of workers), free everything else on that machine and assign those slots (do one topology at a time)<br/>\n    +    // blacklist all machines who had production slots defined<br/>\n    +    // log isolated topologies who weren't able to get enough slots / machines<br/>\n    +    // run default scheduler on isolated topologies that didn't have enough slots + non-isolated topologies on remaining machines<br/>\n    +    // set blacklist to what it was initially<br/>\n    +    @Override<br/>\n    +    public void schedule(Topologies topologies, Cluster cluster) {<br/>\n    +Set<String> origBlacklist = cluster.getBlacklistedHosts();<br/>\n    +List<TopologyDetails> isoTopologies = isolatedTopologies(topologies.getTopologies());<br/>\n    +Set<String> isoIds = isolatedTopoplogyIds(isoTopologies);<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs = topologyWorkerSpecs(isoTopologies);<br/>\n    +Map<String, Map<Integer, Integer>> topologyMachineDistributions = topologyMachineDistributions(isoTopologies);<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = hostAssignments(cluster);<br/>\n    +<br/>\n    +for (Map.Entry<String, List<AssignmentInfo>> entry : hostAssignments.entrySet()) {<br/>\n    +    List<AssignmentInfo> assignments = entry.getValue();<br/>\n    +    String topologyId = assignments.get(0).getTopologyId();<br/>\n    +    Map<Integer, Integer> distribution = topologyMachineDistributions.get(topologyId);<br/>\n    +    Set<Set<ExecutorDetails>> workerSpecs = topologyWorkerSpecs.get(topologyId);<br/>\n    +    int numWorkers = assignments.size();<br/>\n    +<br/>\n    +    if (isoIds.contains(topologyId)<br/>\n    +    && checkAssignmentTopology(assignments, topologyId)<br/>\n    +    && distribution.containsKey(numWorkers)<br/>\n    +    && checkAssignmentWorkerSpecs(assignments, workerSpecs)) {<br/>\n    +decrementDistribution(distribution, numWorkers);<br/>\n    +for (AssignmentInfo ass : assignments) </p>\n{\n    +    workerSpecs.remove(ass.getExecutors());\n    +}\n<p>    +cluster.blacklistHost(entry.getKey());<br/>\n    +    } else {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (isoIds.contains(ass.getTopologyId())) </p>\n{\n    +cluster.freeSlot(ass.getWorkerSlot());\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = hostUsedSlots(cluster);<br/>\n    +LinkedList<HostAssignableSlots> hss = hostAssignableSlots(cluster);<br/>\n    +List<String> failedTopologyIds = new ArrayList<String>();<br/>\n    +for (Map.Entry<String, Set<Set<ExecutorDetails>>> entry : topologyWorkerSpecs.entrySet()) {<br/>\n    +    String topologyId = entry.getKey();<br/>\n    +    Set<Set<ExecutorDetails>> executorSet = entry.getValue();<br/>\n    +    if (executorSet != null && executorSet.size() > 0) </p>\n{\n    +failedTopologyIds.add(topologyId);\n    +    }\n<p>    +    List<Integer> workerNum = distributionSortedAmts(topologyMachineDistributions.get(topologyId));<br/>\n    +    for (Integer num : workerNum) {<br/>\n    +HostAssignableSlots hostSlots = hss.peek();<br/>\n    +List<WorkerSlot> slot = hostSlots != null ? hostSlots.getWorkerSlots() : null;<br/>\n    +<br/>\n    +if (slot != null && slot.size() >= num.intValue()) {<br/>\n    +    hss.poll();<br/>\n    +    cluster.freeSlots(hostUsedSlots.get(hostSlots.getHostName()));<br/>\n    +    for (WorkerSlot tmpSlot : slot.subList(0, num)) </p>\n{\n    +Set<ExecutorDetails> executor = removeElemFromSet(executorSet);\n    +cluster.assign(tmpSlot, topologyId, executor);\n    +    }\n<p>    +    cluster.blacklistHost(hostSlots.getHostName());<br/>\n    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +if (failedTopologyIds.size() > 0) {<br/>\n    +    LOG.warn(\"Unable to isolate topologies \" + failedTopologyIds<br/>\n    +    + \". No machine had enough worker slots to run the remaining workers for these topologies. \"<br/>\n    +    + \"Clearing all other resources and will wait for enough resources for \"<br/>\n    +    + \"isolated topologies before allocating any other resources.\");<br/>\n    +    // clear workers off all hosts that are not blacklisted<br/>\n    +    Map<String, Set<WorkerSlot>> usedSlots = hostUsedSlots(cluster);<br/>\n    +    Set<Map.Entry<String, Set<WorkerSlot>>> entries = usedSlots.entrySet();<br/>\n    +    for (Map.Entry<String, Set<WorkerSlot>> entry : entries) {<br/>\n    +if (!cluster.isBlacklistedHost(entry.getKey())) </p>\n{\n    +    cluster.freeSlots(entry.getValue());\n    +}\n<p>    +    }<br/>\n    +} else </p>\n{\n    +    // run default scheduler on non-isolated topologies\n    +    Set<String> allocatedTopologies = allocatedTopologies(topologyWorkerSpecs);\n    +    Topologies leftOverTopologies = leftoverTopologies(topologies, allocatedTopologies);\n    +    DefaultScheduler.defaultSchedule(leftOverTopologies, cluster);\n    +}\n<p>    +cluster.setBlacklistedHosts(origBlacklist);<br/>\n    +    }<br/>\n    +<br/>\n    +    public Set<ExecutorDetails> removeElemFromSet(Set<Set<ExecutorDetails>> executorsSets) </p>\n{\n    +Set<ExecutorDetails> elem = executorsSets.iterator().next();\n    +executorsSets.remove(elem);\n    +return elem;\n    +    }\n<p>    +<br/>\n    +    private List<TopologyDetails> isolatedTopologies(Collection<TopologyDetails> topologies) {<br/>\n    +Set<String> topologyNames = isoMachines.keySet();<br/>\n    +List<TopologyDetails> isoTopologies = new ArrayList<TopologyDetails>();<br/>\n    +for (TopologyDetails topo : topologies) {<br/>\n    +    if (topologyNames.contains(topo.getName())) </p>\n{\n    +isoTopologies.add(topo);\n    +    }\n<p>    +}<br/>\n    +return isoTopologies;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<String> isolatedTopoplogyIds(List<TopologyDetails> topologies) {<br/>\n    +Set<String> ids = new HashSet<String>();<br/>\n    +if (topologies != null && topologies.size() > 0) {<br/>\n    +    for (TopologyDetails topology : topologies) </p>\n{\n    +ids.add(topology.getId());\n    +    }\n<p>    +}<br/>\n    +return ids;<br/>\n    +    }<br/>\n    +<br/>\n    +    // map from topology id -> set of sets of executors<br/>\n    +    private Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs(List<TopologyDetails> topologies) {<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> workerSpecs = new HashMap<String, Set<Set<ExecutorDetails>>>();<br/>\n    +for (TopologyDetails topology : topologies) </p>\n{\n    +    workerSpecs.put(topology.getId(), computeWorkerSpecs(topology));\n    +}\n<p>    +return workerSpecs;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, List<AssignmentInfo>> hostAssignments(Cluster cluster) {<br/>\n    +Collection<SchedulerAssignment> assignmentValues =  cluster.getAssignments().values();<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = new HashMap<String, List<AssignmentInfo>>();<br/>\n    +<br/>\n    +for (SchedulerAssignment sa : assignmentValues) {<br/>\n    +    Map<WorkerSlot, List<ExecutorDetails>> slotExecutors = Utils.reverseMap(sa.getExecutorToSlot());<br/>\n    +    Set<Map.Entry<WorkerSlot, List<ExecutorDetails>>> entries = slotExecutors.entrySet();<br/>\n    +    for (Map.Entry<WorkerSlot, List<ExecutorDetails>> entry : entries) {<br/>\n    +WorkerSlot slot = entry.getKey();<br/>\n    +List<ExecutorDetails> executors = entry.getValue();<br/>\n    +<br/>\n    +String host = cluster.getHost(slot.getNodeId());<br/>\n    +AssignmentInfo ass = new AssignmentInfo(slot, sa.getTopologyId(), new HashSet<ExecutorDetails>(executors));<br/>\n    +List<AssignmentInfo> executorList = hostAssignments.get(host);<br/>\n    +if (executorList == null) </p>\n{\n    +    executorList = new ArrayList<AssignmentInfo>();\n    +    hostAssignments.put(host, executorList);\n    +}\n<p>    +executorList.add(ass);<br/>\n    +    }<br/>\n    +}<br/>\n    +return hostAssignments;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<Set<ExecutorDetails>> computeWorkerSpecs(TopologyDetails topology) {<br/>\n    +Map<String, List<ExecutorDetails>> compExecutors = Utils.reverseMap(topology.getExecutorToComponent());<br/>\n    +<br/>\n    +List<ExecutorDetails> allExecutors = new ArrayList<ExecutorDetails>();<br/>\n    +Collection<List<ExecutorDetails>> values = compExecutors.values();<br/>\n    +for (List<ExecutorDetails> eList : values) </p>\n{\n    +    allExecutors.addAll(eList);\n    +}\n<p>    +<br/>\n    +int numWorkers = topology.getNumWorkers();<br/>\n    +int bucketIndex = 0;<br/>\n    +Map<Integer, Set<ExecutorDetails>> bucketExecutors = new HashMap<Integer, Set<ExecutorDetails>>(numWorkers);<br/>\n    +for (ExecutorDetails executor : allExecutors) {<br/>\n    +    Set<ExecutorDetails> executors = bucketExecutors.get(bucketIndex);<br/>\n    +    if (executors == null) </p>\n{\n    +executors = new HashSet<ExecutorDetails>();\n    +bucketExecutors.put(bucketIndex, executors);\n    +    }\n<p>    +    executors.add(executor);<br/>\n    +    bucketIndex = (bucketIndex+1) % numWorkers;<br/>\n    +}<br/>\n    +<br/>\n    +return new HashSet<Set<ExecutorDetails>>(bucketExecutors.values());<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Map<Integer, Integer>> topologyMachineDistributions(List<TopologyDetails> isoTopologies) {<br/>\n    +Map<String, Map<Integer, Integer>> machineDistributions = new HashMap<String, Map<Integer, Integer>>();<br/>\n    +for (TopologyDetails topology : isoTopologies) </p>\n{\n    +    machineDistributions.put(topology.getId(), machineDistribution(topology));\n    +}\n<p>    +return machineDistributions;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Integer, Integer> machineDistribution(TopologyDetails topology) {<br/>\n    +int machineNum = isoMachines.get(topology.getName()).intValue();<br/>\n    +int workerNum = topology.getNumWorkers();<br/>\n    +TreeMap<Integer, Integer> distribution = Utils.integerDivided(workerNum, machineNum);<br/>\n    +<br/>\n    +if (distribution.containsKey(0)) </p>\n{\n    +    distribution.remove(0);\n    +}\n<p>    +return distribution;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentTopology(List<AssignmentInfo> assignments, String topologyId) {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (!topologyId.equals(ass.getTopologyId())) </p>\n{\n    +return false;\n    +    }<br/>\n    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentWorkerSpecs(List<AssignmentInfo> assigments, Set<Set<ExecutorDetails>> workerSpecs) {<br/>\n    +for (AssignmentInfo ass : assigments) {<br/>\n    +    if (!workerSpecs.contains(ass.getExecutors())) {    +return false;    +    }\n<p>    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void decrementDistribution(Map<Integer, Integer> distribution, int value) {<br/>\n    +Integer distValue = distribution.get(value);<br/>\n    +if (distValue != null) {<br/>\n    +    int newValue = distValue - 1;<br/>\n    +    if (newValue == 0) </p>\n{\n    +distribution.remove(value);\n    +    }\n<p> else </p>\n{\n    +distribution.put(value, newValue);\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Set<WorkerSlot>> hostUsedSlots(Cluster cluster) {<br/>\n    +Collection<WorkerSlot> usedSlots = cluster.getUsedSlots();<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = new HashMap<String, Set<WorkerSlot>>();<br/>\n    +for (WorkerSlot slot : usedSlots) {<br/>\n    +    String host = cluster.getHost(slot.getNodeId());<br/>\n    +    Set<WorkerSlot> slots = hostUsedSlots.get(host);<br/>\n    +    if (slots == null) </p>\n{\n    +slots = new HashSet<WorkerSlot>();\n    +hostUsedSlots.put(host, slots);\n    +    }\n<p>    +    slots.add(slot);<br/>\n    +}<br/>\n    +return hostUsedSlots;<br/>\n    +    }<br/>\n    +<br/>\n    +    // returns list of list of slots, reverse sorted by number of slots<br/>\n    +    private LinkedList<HostAssignableSlots> hostAssignableSlots(Cluster cluster) {<br/>\n    +List<WorkerSlot> assignableSlots = cluster.getAssignableSlots();<br/>\n    +Map<String, List<WorkerSlot>> hostAssignableSlots = new HashMap<String, List<WorkerSlot>>();<br/>\n    +for (WorkerSlot slot : assignableSlots) {<br/>\n    +    String host = cluster.getHost(slot.getNodeId());<br/>\n    +    List<WorkerSlot> slots = hostAssignableSlots.get(host);<br/>\n    +    if (slots == null) </p>\n{\n    +slots = new ArrayList<WorkerSlot>();\n    +hostAssignableSlots.put(host, slots);\n    +    }\n<p>    +    slots.add(slot);<br/>\n    +}<br/>\n    +List<HostAssignableSlots> sortHostAssignSlots = new ArrayList<HostAssignableSlots>();<br/>\n    +for (Map.Entry<String, List<WorkerSlot>> entry : hostAssignableSlots.entrySet()) </p>\n{\n    +    sortHostAssignSlots.add(new HostAssignableSlots(entry.getKey(), entry.getValue()));\n    +}\n<p>    +Collections.sort(sortHostAssignSlots, new Comparator<HostAssignableSlots>() {<br/>\n    +    @Override<br/>\n    +    public int compare(HostAssignableSlots o1, HostAssignableSlots o2) </p>\n{\n    +return o2.getWorkerSlots().size() - o1.getWorkerSlots().size();\n    +    }\n<p>    +});<br/>\n    +Collections.shuffle(sortHostAssignSlots);<br/>\n    +<br/>\n    +return new LinkedList<HostAssignableSlots>(sortHostAssignSlots);<br/>\n    +    }<br/>\n    +<br/>\n    +    private List<Integer> distributionSortedAmts(Map<Integer, Integer> distributions) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Will fix.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646034/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646040","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646040","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646040,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwNDA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T08:15:24Z","updated_at":"2025-01-24T14:20:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359#discussion_r70394757\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359#discussion_r70394757</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/scheduler/IsolationScheduler.java &#8212;<br/>\n    @@ -0,0 +1,417 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.scheduler;<br/>\n    +<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.Collections;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.HashSet;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Set;<br/>\n    +import java.util.TreeMap;<br/>\n    +<br/>\n    +import org.apache.commons.lang.Validate;<br/>\n    +import org.apache.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import org.apache.storm.Config;<br/>\n    +import org.apache.storm.scheduler.Cluster;<br/>\n    +import org.apache.storm.scheduler.ExecutorDetails;<br/>\n    +import org.apache.storm.scheduler.IScheduler;<br/>\n    +import org.apache.storm.scheduler.SchedulerAssignment;<br/>\n    +import org.apache.storm.scheduler.Topologies;<br/>\n    +import org.apache.storm.scheduler.TopologyDetails;<br/>\n    +import org.apache.storm.scheduler.WorkerSlot;<br/>\n    +<br/>\n    +// for each isolated topology:<br/>\n    +//   compute even distribution of executors -> workers on the number of workers specified for the topology<br/>\n    +//   compute distribution of workers to machines<br/>\n    +// determine host -> list of <span class=\"error\">&#91;slot, topology id, executors&#93;</span><br/>\n    +// iterate through hosts and: a machine is good if:<br/>\n    +//   1. only running workers from one isolated topology<br/>\n    +//   2. all workers running on it match one of the distributions of executors for that topology<br/>\n    +//   3. matches one of the # of workers<br/>\n    +// blacklist the good hosts and remove those workers from the list of need to be assigned workers<br/>\n    +// otherwise unassign all other workers for isolated topologies if assigned<br/>\n    +public class IsolationScheduler implements IScheduler {<br/>\n    +    private final static Logger LOG = LoggerFactory.getLogger(IsolationScheduler.class);<br/>\n    +<br/>\n    +    private Map<String, Number> isoMachines;<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public void prepare(Map conf) </p>\n{\n    +this.isoMachines = (Map<String, Number>) conf.get(Config.ISOLATION_SCHEDULER_MACHINES);\n    +Validate.notEmpty(isoMachines);\n    +    }\n<p>    +<br/>\n    +    // get host -> all assignable worker slots for non-blacklisted machines (assigned or not assigned)<br/>\n    +    // will then have a list of machines that need to be assigned (machine -> <span class=\"error\">&#91;topology, list of list of executors&#93;</span>)<br/>\n    +    // match each spec to a machine (who has the right number of workers), free everything else on that machine and assign those slots (do one topology at a time)<br/>\n    +    // blacklist all machines who had production slots defined<br/>\n    +    // log isolated topologies who weren't able to get enough slots / machines<br/>\n    +    // run default scheduler on isolated topologies that didn't have enough slots + non-isolated topologies on remaining machines<br/>\n    +    // set blacklist to what it was initially<br/>\n    +    @Override<br/>\n    +    public void schedule(Topologies topologies, Cluster cluster) {<br/>\n    +Set<String> origBlacklist = cluster.getBlacklistedHosts();<br/>\n    +List<TopologyDetails> isoTopologies = isolatedTopologies(topologies.getTopologies());<br/>\n    +Set<String> isoIds = isolatedTopoplogyIds(isoTopologies);<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs = topologyWorkerSpecs(isoTopologies);<br/>\n    +Map<String, Map<Integer, Integer>> topologyMachineDistributions = topologyMachineDistributions(isoTopologies);<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = hostAssignments(cluster);<br/>\n    +<br/>\n    +for (Map.Entry<String, List<AssignmentInfo>> entry : hostAssignments.entrySet()) {<br/>\n    +    List<AssignmentInfo> assignments = entry.getValue();<br/>\n    +    String topologyId = assignments.get(0).getTopologyId();<br/>\n    +    Map<Integer, Integer> distribution = topologyMachineDistributions.get(topologyId);<br/>\n    +    Set<Set<ExecutorDetails>> workerSpecs = topologyWorkerSpecs.get(topologyId);<br/>\n    +    int numWorkers = assignments.size();<br/>\n    +<br/>\n    +    if (isoIds.contains(topologyId)<br/>\n    +    && checkAssignmentTopology(assignments, topologyId)<br/>\n    +    && distribution.containsKey(numWorkers)<br/>\n    +    && checkAssignmentWorkerSpecs(assignments, workerSpecs)) {<br/>\n    +decrementDistribution(distribution, numWorkers);<br/>\n    +for (AssignmentInfo ass : assignments) </p>\n{\n    +    workerSpecs.remove(ass.getExecutors());\n    +}\n<p>    +cluster.blacklistHost(entry.getKey());<br/>\n    +    } else {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (isoIds.contains(ass.getTopologyId())) </p>\n{\n    +cluster.freeSlot(ass.getWorkerSlot());\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = hostUsedSlots(cluster);<br/>\n    +LinkedList<HostAssignableSlots> hss = hostAssignableSlots(cluster);<br/>\n    +List<String> failedTopologyIds = new ArrayList<String>();<br/>\n    +for (Map.Entry<String, Set<Set<ExecutorDetails>>> entry : topologyWorkerSpecs.entrySet()) {<br/>\n    +    String topologyId = entry.getKey();<br/>\n    +    Set<Set<ExecutorDetails>> executorSet = entry.getValue();<br/>\n    +    if (executorSet != null && executorSet.size() > 0) </p>\n{\n    +failedTopologyIds.add(topologyId);\n    +    }\n<p>    +    List<Integer> workerNum = distributionSortedAmts(topologyMachineDistributions.get(topologyId));<br/>\n    +    for (Integer num : workerNum) {<br/>\n    +HostAssignableSlots hostSlots = hss.peek();<br/>\n    +List<WorkerSlot> slot = hostSlots != null ? hostSlots.getWorkerSlots() : null;<br/>\n    +<br/>\n    +if (slot != null && slot.size() >= num.intValue()) {<br/>\n    +    hss.poll();<br/>\n    +    cluster.freeSlots(hostUsedSlots.get(hostSlots.getHostName()));<br/>\n    +    for (WorkerSlot tmpSlot : slot.subList(0, num)) </p>\n{\n    +Set<ExecutorDetails> executor = removeElemFromSet(executorSet);\n    +cluster.assign(tmpSlot, topologyId, executor);\n    +    }\n<p>    +    cluster.blacklistHost(hostSlots.getHostName());<br/>\n    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +if (failedTopologyIds.size() > 0) {<br/>\n    +    LOG.warn(\"Unable to isolate topologies \" + failedTopologyIds<br/>\n    +    + \". No machine had enough worker slots to run the remaining workers for these topologies. \"<br/>\n    +    + \"Clearing all other resources and will wait for enough resources for \"<br/>\n    +    + \"isolated topologies before allocating any other resources.\");<br/>\n    +    // clear workers off all hosts that are not blacklisted<br/>\n    +    Map<String, Set<WorkerSlot>> usedSlots = hostUsedSlots(cluster);<br/>\n    +    Set<Map.Entry<String, Set<WorkerSlot>>> entries = usedSlots.entrySet();<br/>\n    +    for (Map.Entry<String, Set<WorkerSlot>> entry : entries) {<br/>\n    +if (!cluster.isBlacklistedHost(entry.getKey())) </p>\n{\n    +    cluster.freeSlots(entry.getValue());\n    +}\n<p>    +    }<br/>\n    +} else </p>\n{\n    +    // run default scheduler on non-isolated topologies\n    +    Set<String> allocatedTopologies = allocatedTopologies(topologyWorkerSpecs);\n    +    Topologies leftOverTopologies = leftoverTopologies(topologies, allocatedTopologies);\n    +    DefaultScheduler.defaultSchedule(leftOverTopologies, cluster);\n    +}\n<p>    +cluster.setBlacklistedHosts(origBlacklist);<br/>\n    +    }<br/>\n    +<br/>\n    +    public Set<ExecutorDetails> removeElemFromSet(Set<Set<ExecutorDetails>> executorsSets) </p>\n{\n    +Set<ExecutorDetails> elem = executorsSets.iterator().next();\n    +executorsSets.remove(elem);\n    +return elem;\n    +    }\n<p>    +<br/>\n    +    private List<TopologyDetails> isolatedTopologies(Collection<TopologyDetails> topologies) {<br/>\n    +Set<String> topologyNames = isoMachines.keySet();<br/>\n    +List<TopologyDetails> isoTopologies = new ArrayList<TopologyDetails>();<br/>\n    +for (TopologyDetails topo : topologies) {<br/>\n    +    if (topologyNames.contains(topo.getName())) </p>\n{\n    +isoTopologies.add(topo);\n    +    }\n<p>    +}<br/>\n    +return isoTopologies;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<String> isolatedTopoplogyIds(List<TopologyDetails> topologies) {<br/>\n    +Set<String> ids = new HashSet<String>();<br/>\n    +if (topologies != null && topologies.size() > 0) {<br/>\n    +    for (TopologyDetails topology : topologies) </p>\n{\n    +ids.add(topology.getId());\n    +    }\n<p>    +}<br/>\n    +return ids;<br/>\n    +    }<br/>\n    +<br/>\n    +    // map from topology id -> set of sets of executors<br/>\n    +    private Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs(List<TopologyDetails> topologies) {<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> workerSpecs = new HashMap<String, Set<Set<ExecutorDetails>>>();<br/>\n    +for (TopologyDetails topology : topologies) </p>\n{\n    +    workerSpecs.put(topology.getId(), computeWorkerSpecs(topology));\n    +}\n<p>    +return workerSpecs;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, List<AssignmentInfo>> hostAssignments(Cluster cluster) {<br/>\n    +Collection<SchedulerAssignment> assignmentValues =  cluster.getAssignments().values();<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = new HashMap<String, List<AssignmentInfo>>();<br/>\n    +<br/>\n    +for (SchedulerAssignment sa : assignmentValues) {<br/>\n    +    Map<WorkerSlot, List<ExecutorDetails>> slotExecutors = Utils.reverseMap(sa.getExecutorToSlot());<br/>\n    +    Set<Map.Entry<WorkerSlot, List<ExecutorDetails>>> entries = slotExecutors.entrySet();<br/>\n    +    for (Map.Entry<WorkerSlot, List<ExecutorDetails>> entry : entries) {<br/>\n    +WorkerSlot slot = entry.getKey();<br/>\n    +List<ExecutorDetails> executors = entry.getValue();<br/>\n    +<br/>\n    +String host = cluster.getHost(slot.getNodeId());<br/>\n    +AssignmentInfo ass = new AssignmentInfo(slot, sa.getTopologyId(), new HashSet<ExecutorDetails>(executors));<br/>\n    +List<AssignmentInfo> executorList = hostAssignments.get(host);<br/>\n    +if (executorList == null) </p>\n{\n    +    executorList = new ArrayList<AssignmentInfo>();\n    +    hostAssignments.put(host, executorList);\n    +}\n<p>    +executorList.add(ass);<br/>\n    +    }<br/>\n    +}<br/>\n    +return hostAssignments;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<Set<ExecutorDetails>> computeWorkerSpecs(TopologyDetails topology) {<br/>\n    +Map<String, List<ExecutorDetails>> compExecutors = Utils.reverseMap(topology.getExecutorToComponent());<br/>\n    +<br/>\n    +List<ExecutorDetails> allExecutors = new ArrayList<ExecutorDetails>();<br/>\n    +Collection<List<ExecutorDetails>> values = compExecutors.values();<br/>\n    +for (List<ExecutorDetails> eList : values) </p>\n{\n    +    allExecutors.addAll(eList);\n    +}\n<p>    +<br/>\n    +int numWorkers = topology.getNumWorkers();<br/>\n    +int bucketIndex = 0;<br/>\n    +Map<Integer, Set<ExecutorDetails>> bucketExecutors = new HashMap<Integer, Set<ExecutorDetails>>(numWorkers);<br/>\n    +for (ExecutorDetails executor : allExecutors) {<br/>\n    +    Set<ExecutorDetails> executors = bucketExecutors.get(bucketIndex);<br/>\n    +    if (executors == null) </p>\n{\n    +executors = new HashSet<ExecutorDetails>();\n    +bucketExecutors.put(bucketIndex, executors);\n    +    }\n<p>    +    executors.add(executor);<br/>\n    +    bucketIndex = (bucketIndex+1) % numWorkers;<br/>\n    +}<br/>\n    +<br/>\n    +return new HashSet<Set<ExecutorDetails>>(bucketExecutors.values());<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Map<Integer, Integer>> topologyMachineDistributions(List<TopologyDetails> isoTopologies) {<br/>\n    +Map<String, Map<Integer, Integer>> machineDistributions = new HashMap<String, Map<Integer, Integer>>();<br/>\n    +for (TopologyDetails topology : isoTopologies) </p>\n{\n    +    machineDistributions.put(topology.getId(), machineDistribution(topology));\n    +}\n<p>    +return machineDistributions;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<Integer, Integer> machineDistribution(TopologyDetails topology) {<br/>\n    +int machineNum = isoMachines.get(topology.getName()).intValue();<br/>\n    +int workerNum = topology.getNumWorkers();<br/>\n    +TreeMap<Integer, Integer> distribution = Utils.integerDivided(workerNum, machineNum);<br/>\n    +<br/>\n    +if (distribution.containsKey(0)) </p>\n{\n    +    distribution.remove(0);\n    +}\n<p>    +return distribution;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentTopology(List<AssignmentInfo> assignments, String topologyId) {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (!topologyId.equals(ass.getTopologyId())) </p>\n{\n    +return false;\n    +    }<br/>\n    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private boolean checkAssignmentWorkerSpecs(List<AssignmentInfo> assigments, Set<Set<ExecutorDetails>> workerSpecs) {<br/>\n    +for (AssignmentInfo ass : assigments) {<br/>\n    +    if (!workerSpecs.contains(ass.getExecutors())) {    +return false;    +    }\n<p>    +}<br/>\n    +return true;<br/>\n    +    }<br/>\n    +<br/>\n    +    private void decrementDistribution(Map<Integer, Integer> distribution, int value) {<br/>\n    +Integer distValue = distribution.get(value);<br/>\n    +if (distValue != null) {<br/>\n    +    int newValue = distValue - 1;<br/>\n    +    if (newValue == 0) </p>\n{\n    +distribution.remove(value);\n    +    }\n<p> else </p>\n{\n    +distribution.put(value, newValue);\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +<br/>\n    +    private Map<String, Set<WorkerSlot>> hostUsedSlots(Cluster cluster) {<br/>\n    +Collection<WorkerSlot> usedSlots = cluster.getUsedSlots();<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = new HashMap<String, Set<WorkerSlot>>();<br/>\n    +for (WorkerSlot slot : usedSlots) {<br/>\n    +    String host = cluster.getHost(slot.getNodeId());<br/>\n    +    Set<WorkerSlot> slots = hostUsedSlots.get(host);<br/>\n    +    if (slots == null) </p>\n{\n    +slots = new HashSet<WorkerSlot>();\n    +hostUsedSlots.put(host, slots);\n    +    }\n<p>    +    slots.add(slot);<br/>\n    +}<br/>\n    +return hostUsedSlots;<br/>\n    +    }<br/>\n    +<br/>\n    +    // returns list of list of slots, reverse sorted by number of slots<br/>\n    +    private LinkedList<HostAssignableSlots> hostAssignableSlots(Cluster cluster) {<br/>\n    +List<WorkerSlot> assignableSlots = cluster.getAssignableSlots();<br/>\n    +Map<String, List<WorkerSlot>> hostAssignableSlots = new HashMap<String, List<WorkerSlot>>();<br/>\n    +for (WorkerSlot slot : assignableSlots) {<br/>\n    +    String host = cluster.getHost(slot.getNodeId());<br/>\n    +    List<WorkerSlot> slots = hostAssignableSlots.get(host);<br/>\n    +    if (slots == null) </p>\n{\n    +slots = new ArrayList<WorkerSlot>();\n    +hostAssignableSlots.put(host, slots);\n    +    }\n<p>    +    slots.add(slot);<br/>\n    +}<br/>\n    +List<HostAssignableSlots> sortHostAssignSlots = new ArrayList<HostAssignableSlots>();<br/>\n    +for (Map.Entry<String, List<WorkerSlot>> entry : hostAssignableSlots.entrySet()) </p>\n{\n    +    sortHostAssignSlots.add(new HostAssignableSlots(entry.getKey(), entry.getValue()));\n    +}\n<p>    +Collections.sort(sortHostAssignSlots, new Comparator<HostAssignableSlots>() {<br/>\n    +    @Override<br/>\n    +    public int compare(HostAssignableSlots o1, HostAssignableSlots o2) </p>\n{\n    +return o2.getWorkerSlots().size() - o1.getWorkerSlots().size();\n    +    }\n<p>    +});<br/>\n    +Collections.shuffle(sortHostAssignSlots);<br/>\n    +<br/>\n    +return new LinkedList<HostAssignableSlots>(sortHostAssignSlots);<br/>\n    +    }<br/>\n    +<br/>\n    +    private List<Integer> distributionSortedAmts(Map<Integer, Integer> distributions) {<br/>\n    +List<Integer> sorts = new ArrayList<Integer>();<br/>\n    +for (Map.Entry<Integer, Integer> entry : distributions.entrySet()) {<br/>\n    +    int workers = entry.getKey();<br/>\n    +    int machines = entry.getValue();<br/>\n    +    for (int i = 0; i < machines; i++) </p>\n{\n    +sorts.add(workers);\n    +    }\n<p>    +}<br/>\n    +Collections.sort(sorts, new Comparator<Integer>() {<br/>\n    +    @Override<br/>\n    +    public int compare(Integer o1, Integer o2) </p>\n{\n    +return o1.intValue() - o2.intValue();\n    +    }\n<p>    +});<br/>\n    +<br/>\n    +return sorts;<br/>\n    +    }<br/>\n    +<br/>\n    +    private Set<String> allocatedTopologies(Map<String, Set<Set<ExecutorDetails>>> workerSpecs) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    minor: topologyToWorkerSpecs might be easier to understand since workerSpecs is the value part of map.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646040/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646044","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646044","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646044,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwNDQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T08:25:34Z","updated_at":"2025-01-24T14:20:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359#discussion_r70396113\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359#discussion_r70396113</a></p>\n\n<p>    &#8212; Diff: storm-core/src/jvm/org/apache/storm/scheduler/IsolationScheduler.java &#8212;<br/>\n    @@ -0,0 +1,417 @@<br/>\n    +/**<br/>\n    + * Licensed to the Apache Software Foundation (ASF) under one<br/>\n    + * or more contributor license agreements.  See the NOTICE file<br/>\n    + * distributed with this work for additional information<br/>\n    + * regarding copyright ownership.  The ASF licenses this file<br/>\n    + * to you under the Apache License, Version 2.0 (the<br/>\n    + * \"License\"); you may not use this file except in compliance<br/>\n    + * with the License.  You may obtain a copy of the License at<br/>\n    + *<br/>\n    + * <a href=\"http://www.apache.org/licenses/LICENSE-2.0\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">http://www.apache.org/licenses/LICENSE-2.0</a><br/>\n    + *<br/>\n    + * Unless required by applicable law or agreed to in writing, software<br/>\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,<br/>\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>\n    + * See the License for the specific language governing permissions and<br/>\n    + * limitations under the License.<br/>\n    + */<br/>\n    +package org.apache.storm.scheduler;<br/>\n    +<br/>\n    +import java.util.ArrayList;<br/>\n    +import java.util.Collection;<br/>\n    +import java.util.Collections;<br/>\n    +import java.util.Comparator;<br/>\n    +import java.util.HashMap;<br/>\n    +import java.util.HashSet;<br/>\n    +import java.util.LinkedList;<br/>\n    +import java.util.List;<br/>\n    +import java.util.Map;<br/>\n    +import java.util.Set;<br/>\n    +import java.util.TreeMap;<br/>\n    +<br/>\n    +import org.apache.commons.lang.Validate;<br/>\n    +import org.apache.storm.utils.Utils;<br/>\n    +import org.slf4j.Logger;<br/>\n    +import org.slf4j.LoggerFactory;<br/>\n    +import org.apache.storm.Config;<br/>\n    +import org.apache.storm.scheduler.Cluster;<br/>\n    +import org.apache.storm.scheduler.ExecutorDetails;<br/>\n    +import org.apache.storm.scheduler.IScheduler;<br/>\n    +import org.apache.storm.scheduler.SchedulerAssignment;<br/>\n    +import org.apache.storm.scheduler.Topologies;<br/>\n    +import org.apache.storm.scheduler.TopologyDetails;<br/>\n    +import org.apache.storm.scheduler.WorkerSlot;<br/>\n    +<br/>\n    +// for each isolated topology:<br/>\n    +//   compute even distribution of executors -> workers on the number of workers specified for the topology<br/>\n    +//   compute distribution of workers to machines<br/>\n    +// determine host -> list of <span class=\"error\">&#91;slot, topology id, executors&#93;</span><br/>\n    +// iterate through hosts and: a machine is good if:<br/>\n    +//   1. only running workers from one isolated topology<br/>\n    +//   2. all workers running on it match one of the distributions of executors for that topology<br/>\n    +//   3. matches one of the # of workers<br/>\n    +// blacklist the good hosts and remove those workers from the list of need to be assigned workers<br/>\n    +// otherwise unassign all other workers for isolated topologies if assigned<br/>\n    +public class IsolationScheduler implements IScheduler {<br/>\n    +    private final static Logger LOG = LoggerFactory.getLogger(IsolationScheduler.class);<br/>\n    +<br/>\n    +    private Map<String, Number> isoMachines;<br/>\n    +<br/>\n    +    @Override<br/>\n    +    public void prepare(Map conf) </p>\n{\n    +this.isoMachines = (Map<String, Number>) conf.get(Config.ISOLATION_SCHEDULER_MACHINES);\n    +Validate.notEmpty(isoMachines);\n    +    }\n<p>    +<br/>\n    +    // get host -> all assignable worker slots for non-blacklisted machines (assigned or not assigned)<br/>\n    +    // will then have a list of machines that need to be assigned (machine -> <span class=\"error\">&#91;topology, list of list of executors&#93;</span>)<br/>\n    +    // match each spec to a machine (who has the right number of workers), free everything else on that machine and assign those slots (do one topology at a time)<br/>\n    +    // blacklist all machines who had production slots defined<br/>\n    +    // log isolated topologies who weren't able to get enough slots / machines<br/>\n    +    // run default scheduler on isolated topologies that didn't have enough slots + non-isolated topologies on remaining machines<br/>\n    +    // set blacklist to what it was initially<br/>\n    +    @Override<br/>\n    +    public void schedule(Topologies topologies, Cluster cluster) {<br/>\n    +Set<String> origBlacklist = cluster.getBlacklistedHosts();<br/>\n    +List<TopologyDetails> isoTopologies = isolatedTopologies(topologies.getTopologies());<br/>\n    +Set<String> isoIds = isolatedTopoplogyIds(isoTopologies);<br/>\n    +Map<String, Set<Set<ExecutorDetails>>> topologyWorkerSpecs = topologyWorkerSpecs(isoTopologies);<br/>\n    +Map<String, Map<Integer, Integer>> topologyMachineDistributions = topologyMachineDistributions(isoTopologies);<br/>\n    +Map<String, List<AssignmentInfo>> hostAssignments = hostAssignments(cluster);<br/>\n    +<br/>\n    +for (Map.Entry<String, List<AssignmentInfo>> entry : hostAssignments.entrySet()) {<br/>\n    +    List<AssignmentInfo> assignments = entry.getValue();<br/>\n    +    String topologyId = assignments.get(0).getTopologyId();<br/>\n    +    Map<Integer, Integer> distribution = topologyMachineDistributions.get(topologyId);<br/>\n    +    Set<Set<ExecutorDetails>> workerSpecs = topologyWorkerSpecs.get(topologyId);<br/>\n    +    int numWorkers = assignments.size();<br/>\n    +<br/>\n    +    if (isoIds.contains(topologyId)<br/>\n    +    && checkAssignmentTopology(assignments, topologyId)<br/>\n    +    && distribution.containsKey(numWorkers)<br/>\n    +    && checkAssignmentWorkerSpecs(assignments, workerSpecs)) {<br/>\n    +decrementDistribution(distribution, numWorkers);<br/>\n    +for (AssignmentInfo ass : assignments) </p>\n{\n    +    workerSpecs.remove(ass.getExecutors());\n    +}\n<p>    +cluster.blacklistHost(entry.getKey());<br/>\n    +    } else {<br/>\n    +for (AssignmentInfo ass : assignments) {<br/>\n    +    if (isoIds.contains(ass.getTopologyId())) </p>\n{\n    +cluster.freeSlot(ass.getWorkerSlot());\n    +    }\n<p>    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +Map<String, Set<WorkerSlot>> hostUsedSlots = hostUsedSlots(cluster);<br/>\n    +LinkedList<HostAssignableSlots> hss = hostAssignableSlots(cluster);<br/>\n    +List<String> failedTopologyIds = new ArrayList<String>();<br/>\n    +for (Map.Entry<String, Set<Set<ExecutorDetails>>> entry : topologyWorkerSpecs.entrySet()) {<br/>\n    +    String topologyId = entry.getKey();<br/>\n    +    Set<Set<ExecutorDetails>> executorSet = entry.getValue();<br/>\n    +    if (executorSet != null && executorSet.size() > 0) </p>\n{\n    +failedTopologyIds.add(topologyId);\n    +    }\n<p>    +    List<Integer> workerNum = distributionSortedAmts(topologyMachineDistributions.get(topologyId));<br/>\n    +    for (Integer num : workerNum) {<br/>\n    +HostAssignableSlots hostSlots = hss.peek();<br/>\n    +List<WorkerSlot> slot = hostSlots != null ? hostSlots.getWorkerSlots() : null;<br/>\n    +<br/>\n    +if (slot != null && slot.size() >= num.intValue()) {<br/>\n    +    hss.poll();<br/>\n    +    cluster.freeSlots(hostUsedSlots.get(hostSlots.getHostName()));<br/>\n    +    for (WorkerSlot tmpSlot : slot.subList(0, num)) </p>\n{\n    +Set<ExecutorDetails> executor = removeElemFromSet(executorSet);\n    +cluster.assign(tmpSlot, topologyId, executor);\n    +    }\n<p>    +    cluster.blacklistHost(hostSlots.getHostName());<br/>\n    +}<br/>\n    +    }<br/>\n    +}<br/>\n    +<br/>\n    +if (failedTopologyIds.size() > 0) {<br/>\n    +    LOG.warn(\"Unable to isolate topologies \" + failedTopologyIds<br/>\n    +    + \". No machine had enough worker slots to run the remaining workers for these topologies. \"<br/>\n    +    + \"Clearing all other resources and will wait for enough resources for \"<br/>\n    +    + \"isolated topologies before allocating any other resources.\");<br/>\n    +    // clear workers off all hosts that are not blacklisted<br/>\n    +    Map<String, Set<WorkerSlot>> usedSlots = hostUsedSlots(cluster);<br/>\n    +    Set<Map.Entry<String, Set<WorkerSlot>>> entries = usedSlots.entrySet();<br/>\n    +    for (Map.Entry<String, Set<WorkerSlot>> entry : entries) {<br/>\n    +if (!cluster.isBlacklistedHost(entry.getKey())) </p>\n{\n    +    cluster.freeSlots(entry.getValue());\n    +}\n<p>    +    }<br/>\n    +} else </p>\n{\n    +    // run default scheduler on non-isolated topologies\n    +    Set<String> allocatedTopologies = allocatedTopologies(topologyWorkerSpecs);\n    +    Topologies leftOverTopologies = leftoverTopologies(topologies, allocatedTopologies);\n    +    DefaultScheduler.defaultSchedule(leftOverTopologies, cluster);\n    +}\n<p>    +cluster.setBlacklistedHosts(origBlacklist);<br/>\n    +    }<br/>\n    +<br/>\n    +    public Set<ExecutorDetails> removeElemFromSet(Set<Set<ExecutorDetails>> executorsSets) {<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Minor: we could make this to have generic implementation (`Set<?> set`) as same as clojure code, or rename to specific to executorsSets and change public to private.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646044/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231978168","html_url":"https://github.com/apache/storm/pull/1359#issuecomment-231978168","issue_url":"https://api.github.com/repos/apache/storm/issues/1359","id":231978168,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTk3ODE2OA==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T08:53:38Z","updated_at":"2016-07-12T08:53:38Z","author_association":"CONTRIBUTOR","body":"I've done with taking a look, and looks good to me overall.\n\nSince @vesense does quick fix while reviewing, all my review comments are applied. \n+1 from me. Thanks for the great work.\n\n@abhishekagarwal87 Could you have time to continue reviewing, or it's done with reviewing?\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231978168/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646051","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646051","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646051,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwNTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T08:53:41Z","updated_at":"2025-01-24T14:20:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359</a></p>\n\n<p>    I've done with taking a look, and looks good to me overall.</p>\n\n<p>    Since @vesense does quick fix while reviewing, all my review comments are applied. <br/>\n    +1 from me. Thanks for the great work.</p>\n\n<p>    @abhishekagarwal87 Could you have time to continue reviewing, or it's done with reviewing?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646051/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231983018","html_url":"https://github.com/apache/storm/pull/1359#issuecomment-231983018","issue_url":"https://api.github.com/repos/apache/storm/issues/1359","id":231983018,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTk4MzAxOA==","user":{"login":"vesense","id":6711230,"node_id":"MDQ6VXNlcjY3MTEyMzA=","avatar_url":"https://avatars.githubusercontent.com/u/6711230?v=4","gravatar_id":"","url":"https://api.github.com/users/vesense","html_url":"https://github.com/vesense","followers_url":"https://api.github.com/users/vesense/followers","following_url":"https://api.github.com/users/vesense/following{/other_user}","gists_url":"https://api.github.com/users/vesense/gists{/gist_id}","starred_url":"https://api.github.com/users/vesense/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vesense/subscriptions","organizations_url":"https://api.github.com/users/vesense/orgs","repos_url":"https://api.github.com/users/vesense/repos","events_url":"https://api.github.com/users/vesense/events{/privacy}","received_events_url":"https://api.github.com/users/vesense/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:13:39Z","updated_at":"2016-07-12T09:13:39Z","author_association":"MEMBER","body":"Thanks @HeartSaVioR . I rebased the pull request.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231983018/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646058","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646058","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646058,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwNTg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:13:42Z","updated_at":"2025-01-24T14:20:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user vesense commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359</a></p>\n\n<p>    Thanks @HeartSaVioR . I rebased the pull request.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646058/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231985328","html_url":"https://github.com/apache/storm/pull/1359#issuecomment-231985328","issue_url":"https://api.github.com/repos/apache/storm/issues/1359","id":231985328,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTk4NTMyOA==","user":{"login":"vesense","id":6711230,"node_id":"MDQ6VXNlcjY3MTEyMzA=","avatar_url":"https://avatars.githubusercontent.com/u/6711230?v=4","gravatar_id":"","url":"https://api.github.com/users/vesense","html_url":"https://github.com/vesense","followers_url":"https://api.github.com/users/vesense/followers","following_url":"https://api.github.com/users/vesense/following{/other_user}","gists_url":"https://api.github.com/users/vesense/gists{/gist_id}","starred_url":"https://api.github.com/users/vesense/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vesense/subscriptions","organizations_url":"https://api.github.com/users/vesense/orgs","repos_url":"https://api.github.com/users/vesense/repos","events_url":"https://api.github.com/users/vesense/events{/privacy}","received_events_url":"https://api.github.com/users/vesense/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:23:49Z","updated_at":"2016-07-12T09:23:49Z","author_association":"MEMBER","body":"I find travis has some unit test failures in `org.apache.storm.nimbus-test`. I will spend my time to solve this before merging in.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231985328/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646060","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646060","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646060,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwNjA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:23:51Z","updated_at":"2025-01-24T14:20:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user vesense commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359</a></p>\n\n<p>    I find travis has some unit test failures in `org.apache.storm.nimbus-test`. I will spend my time to solve this before merging in.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646060/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231985615","html_url":"https://github.com/apache/storm/pull/1553#issuecomment-231985615","issue_url":"https://api.github.com/repos/apache/storm/issues/1553","id":231985615,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTk4NTYxNQ==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:25:03Z","updated_at":"2016-07-12T09:25:03Z","author_association":"CONTRIBUTOR","body":"+1\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231985615/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925611","html_url":"https://github.com/apache/storm/issues/5744#issuecomment-2612925611","issue_url":"https://api.github.com/repos/apache/storm/issues/5744","id":2612925611,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjU2MTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:25:05Z","updated_at":"2025-01-24T16:27:45Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1553\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1553</a></p>\n\n<p>    +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925611/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231986045","html_url":"https://github.com/apache/storm/pull/1359#issuecomment-231986045","issue_url":"https://api.github.com/repos/apache/storm/issues/1359","id":231986045,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTk4NjA0NQ==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:26:55Z","updated_at":"2016-07-12T09:26:55Z","author_association":"CONTRIBUTOR","body":"Oh I missed checking Travis build result. Thanks for noticing.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231986045/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646062","html_url":"https://github.com/apache/storm/issues/5076#issuecomment-2612646062","issue_url":"https://api.github.com/repos/apache/storm/issues/5076","id":2612646062,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI2NDYwNjI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:26:56Z","updated_at":"2025-01-24T14:20:52Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1359\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1359</a></p>\n\n<p>    Oh I missed checking Travis build result. Thanks for noticing.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612646062/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231988806","html_url":"https://github.com/apache/storm/pull/1526#issuecomment-231988806","issue_url":"https://api.github.com/repos/apache/storm/issues/1526","id":231988806,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTk4ODgwNg==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:37:18Z","updated_at":"2016-07-12T09:37:18Z","author_association":"CONTRIBUTOR","body":"Just rebased with master which fixes RAT issue. I'll merge after build shows green or at least issues are all unrelated.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231988806/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612920690","html_url":"https://github.com/apache/storm/issues/5710#issuecomment-2612920690","issue_url":"https://api.github.com/repos/apache/storm/issues/5710","id":2612920690,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjA2OTA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:37:21Z","updated_at":"2025-01-24T16:25:12Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1526\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1526</a></p>\n\n<p>    Just rebased with master which fixes RAT issue. I'll merge after build shows green or at least issues are all unrelated.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612920690/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/231989995","html_url":"https://github.com/apache/storm/pull/1522#issuecomment-231989995","issue_url":"https://api.github.com/repos/apache/storm/issues/1522","id":231989995,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMTk4OTk5NQ==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:42:00Z","updated_at":"2016-07-12T09:42:00Z","author_association":"CONTRIBUTOR","body":"+1 Travis error is unrelated.\n@lujinhong Could you squash the commits, or if you mind I can do that for merging step. Let me know which way do you prefer.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/231989995/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612878791","html_url":"https://github.com/apache/storm/issues/5429#issuecomment-2612878791","issue_url":"https://api.github.com/repos/apache/storm/issues/5429","id":2612878791,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI4Nzg3OTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T09:42:01Z","updated_at":"2025-01-24T16:05:15Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1522\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1522</a></p>\n\n<p>    +1 Travis error is unrelated.<br/>\n    @lujinhong Could you squash the commits, or if you mind I can do that for merging step. Let me know which way do you prefer.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612878791/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612923620","html_url":"https://github.com/apache/storm/issues/5731#issuecomment-2612923620","issue_url":"https://api.github.com/repos/apache/storm/issues/5731","id":2612923620,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjM2MjA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T10:13:19Z","updated_at":"2025-01-24T16:26:43Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\">kabhwan</a>:</i>\n<p>If my understanding is right, DisruptorQueue.publish() is only called with block=true from background thread (Flusher), and for other threads it's not blocked. (This change is from Disruptor Batching of Storm 1.0.0.)<br/>\nSo receive queues for tasks will receive tuples anyway unless OOME has occurred. There's no blocking on consumer side.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612923620/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612923627","html_url":"https://github.com/apache/storm/issues/5731#issuecomment-2612923627","issue_url":"https://api.github.com/repos/apache/storm/issues/5731","id":2612923627,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjM2Mjc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T11:30:59Z","updated_at":"2025-01-24T16:26:43Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abhishek.agarwal\">abhishek.agarwal</a>:</i>\n<p>I see. You mean to say that consumer may be slow but transfer thread will continue to populate receive queues. Since transfer thread doesn't slow down, spout too will keep pumping out the data. is that correct?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612923627/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612923628","html_url":"https://github.com/apache/storm/issues/5731#issuecomment-2612923628","issue_url":"https://api.github.com/repos/apache/storm/issues/5731","id":2612923628,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjM2Mjg=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T11:57:53Z","updated_at":"2025-01-24T16:26:43Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\">kabhwan</a>:</i>\n<p>Receive thread in downstream is not blocked at all, so transfer thread in upstream is not blocked at all unless there're some other issues which make worker unable to send messages (for example,  downstream worker crash)</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612923628/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925747","html_url":"https://github.com/apache/storm/issues/5745#issuecomment-2612925747","issue_url":"https://api.github.com/repos/apache/storm/issues/5745","id":2612925747,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjU3NDc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T13:21:16Z","updated_at":"2025-01-24T16:27:48Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user darionyaphet opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1555\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1555</a></p>\n\n<p>    <span class=\"error\">&#91;Storm 1963&#93;</span> Replace Put add with addColumn</p>\n\n<p>    <span class=\"error\">&#91;STORM-1963  Replace Put add with addColumn&#93;</span>(<a href=\"https://issues.apache.org/jira/browse/STORM-1963\" class=\"external-link\" rel=\"nofollow\">https://issues.apache.org/jira/browse/STORM-1963</a>)</p>\n\n<p>    HBase Put add() have deprecated , replace add() with addColumn()</p>\n\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/darionyaphet/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/darionyaphet/storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-1963\" title=\"Replace Put add with addColumn\" class=\"issue-link\" data-issue-key=\"STORM-1963\"><del>STORM-1963</del></a></p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1555.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1555.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1555</p>\n\n<hr />\n<p>commit 1667d888168985f2ba8b3da94f4d4d756d134ada<br/>\nAuthor: darionyaphet <darion.yaphet@gmail.com><br/>\nDate:   2016-07-11T13:36:48Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1957\" title=\"Support Storm JDBC batch insert\" class=\"issue-link\" data-issue-key=\"STORM-1957\"><del>STORM-1957</del></a> Support Storm JDBC batch insert</p>\n\n<p>commit c24bdd4f7533c84f53a52598dd3ee127a6eb2b3a<br/>\nAuthor: darionyaphet <darion.yaphet@gmail.com><br/>\nDate:   2016-07-12T13:19:14Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1963\" title=\"Replace Put add with addColumn\" class=\"issue-link\" data-issue-key=\"STORM-1963\"><del>STORM-1963</del></a> Replace Put add with addColumn</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925747/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612881310","html_url":"https://github.com/apache/storm/issues/5444#issuecomment-2612881310","issue_url":"https://api.github.com/repos/apache/storm/issues/5444","id":2612881310,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI4ODEzMTA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T13:25:05Z","updated_at":"2025-01-24T16:06:17Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kevinconaway\">kevinconaway</a>:</i>\n<p><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ptgoetz\" class=\"user-hover\" rel=\"ptgoetz\">P. Taylor Goetz</a> can this be backported to 0.10.2?  We're seeing this (and <a href=\"https://issues.apache.org/jira/browse/STORM-1394\" title=\"Netty Client never continue reconnection when worker started a moment ago.\" class=\"issue-link\" data-issue-key=\"STORM-1394\"><del>STORM-1394</del></a>) fairly frequently in Storm 0.10.0.  I backported this to a custom branch and it fixes the issue for us.</p>\n\n<p>We're unable to upgrade to Storm 1.0 due to <a href=\"https://issues.apache.org/jira/browse/STORM-1879\" title=\"Supervisor may not shut down workers cleanly\" class=\"issue-link\" data-issue-key=\"STORM-1879\"><del>STORM-1879</del></a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612881310/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612881317","html_url":"https://github.com/apache/storm/issues/5444#issuecomment-2612881317","issue_url":"https://api.github.com/repos/apache/storm/issues/5444","id":2612881317,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI4ODEzMTc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T14:37:56Z","updated_at":"2025-01-24T16:06:18Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\">kabhwan</a>:</i>\n<p>Sorry for chiming in, but have an update for you, suspected root issue of <a href=\"https://issues.apache.org/jira/browse/STORM-1879\" title=\"Supervisor may not shut down workers cleanly\" class=\"issue-link\" data-issue-key=\"STORM-1879\"><del>STORM-1879</del></a> is resolved and will be included to 1.0.2. I'm expecting that we will release 1.0.2 in several days, at most in this month.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612881317/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612881323","html_url":"https://github.com/apache/storm/issues/5444#issuecomment-2612881323","issue_url":"https://api.github.com/repos/apache/storm/issues/5444","id":2612881323,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI4ODEzMjM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:16:01Z","updated_at":"2025-01-24T16:06:18Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kevinconaway\">kevinconaway</a>:</i>\n<p>Thanks <a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan\" class=\"user-hover\" rel=\"kabhwan\">Jungtaek Lim</a>.</p>\n\n<p>That said, this backport is fairly non-invasive and does fix a very nasty issue which causes the topology to hang.  If fixes are still being made to 0.10.x, I'd like to see this one go in for those folks who are unwilling or unable to upgrade to 1.0.x</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612881323/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901020","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901020","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901020,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwMjA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:18:17Z","updated_at":"2025-01-24T16:15:28Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user hmcl opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1737\" title=\"storm-kafka-client has compilation errors with Apache Kafka 0.10\" class=\"issue-link\" data-issue-key=\"STORM-1737\"><del>STORM-1737</del></a>: storm-kafka-client has compilation errors with Apache Kafka 0.10</p>\n\n\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/hmcl/storm-apache\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/hmcl/storm-apache</a> <a href=\"https://issues.apache.org/jira/browse/STORM-1737\" title=\"storm-kafka-client has compilation errors with Apache Kafka 0.10\" class=\"issue-link\" data-issue-key=\"STORM-1737\"><del>STORM-1737</del></a></p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1556</p>\n\n<hr />\n<p>commit 04f00e56beb9799dc8b8fc732271b786ced5c21e<br/>\nAuthor: Hugo Louro <hmclouro@gmail.com><br/>\nDate:   2016-04-29T16:18:05Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1737\" title=\"storm-kafka-client has compilation errors with Apache Kafka 0.10\" class=\"issue-link\" data-issue-key=\"STORM-1737\"><del>STORM-1737</del></a>: storm-kafka-client has compilation errors with Apache Kafka 0.10</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901020/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232082098","html_url":"https://github.com/apache/storm/pull/1556#issuecomment-232082098","issue_url":"https://api.github.com/repos/apache/storm/issues/1556","id":232082098,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjA4MjA5OA==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:21:02Z","updated_at":"2016-07-12T15:21:02Z","author_association":"CONTRIBUTOR","body":"+1\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232082098/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901025","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901025","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901025,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwMjU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:21:04Z","updated_at":"2025-01-24T16:15:28Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556</a></p>\n\n<p>    +1</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901025/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232082479","html_url":"https://github.com/apache/storm/pull/1552#issuecomment-232082479","issue_url":"https://api.github.com/repos/apache/storm/issues/1552","id":232082479,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjA4MjQ3OQ==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:22:09Z","updated_at":"2016-07-12T15:22:09Z","author_association":"CONTRIBUTOR","body":"@HeartSaVioR @arunmahadevan don't want to add one more config for this. Let me know if you see any issues of keeping CORS. Will document in REST API doc.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232082479/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925256","html_url":"https://github.com/apache/storm/issues/5742#issuecomment-2612925256","issue_url":"https://api.github.com/repos/apache/storm/issues/5742","id":2612925256,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUyNTY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:22:11Z","updated_at":"2025-01-24T16:27:35Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1552\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1552</a></p>\n\n<p>    @HeartSaVioR @arunmahadevan don't want to add one more config for this. Let me know if you see any issues of keeping CORS. Will document in REST API doc.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925256/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232086198","html_url":"https://github.com/apache/storm/pull/1552#issuecomment-232086198","issue_url":"https://api.github.com/repos/apache/storm/issues/1552","id":232086198,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjA4NjE5OA==","user":{"login":"revans2","id":3441321,"node_id":"MDQ6VXNlcjM0NDEzMjE=","avatar_url":"https://avatars.githubusercontent.com/u/3441321?v=4","gravatar_id":"","url":"https://api.github.com/users/revans2","html_url":"https://github.com/revans2","followers_url":"https://api.github.com/users/revans2/followers","following_url":"https://api.github.com/users/revans2/following{/other_user}","gists_url":"https://api.github.com/users/revans2/gists{/gist_id}","starred_url":"https://api.github.com/users/revans2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/revans2/subscriptions","organizations_url":"https://api.github.com/users/revans2/orgs","repos_url":"https://api.github.com/users/revans2/repos","events_url":"https://api.github.com/users/revans2/events{/privacy}","received_events_url":"https://api.github.com/users/revans2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:32:56Z","updated_at":"2016-07-12T15:32:56Z","author_association":"CONTRIBUTOR","body":"I thought we already did a lot of this for the search side of things.\n\nhttps://github.com/apache/storm/blob/master/storm-core/src/jvm/org/apache/storm/ui/UIHelpers.java#L243-L245\n\nHow is this different and can we remove the other code if we are doing this?\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232086198/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925265","html_url":"https://github.com/apache/storm/issues/5742#issuecomment-2612925265","issue_url":"https://api.github.com/repos/apache/storm/issues/5742","id":2612925265,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUyNjU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:32:57Z","updated_at":"2025-01-24T16:27:35Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user revans2 commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1552\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1552</a></p>\n\n<p>    I thought we already did a lot of this for the search side of things.</p>\n\n<p>    <a href=\"https://github.com/apache/storm/blob/master/storm-core/src/jvm/org/apache/storm/ui/UIHelpers.java#L243-L245\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/blob/master/storm-core/src/jvm/org/apache/storm/ui/UIHelpers.java#L243-L245</a></p>\n\n<p>    How is this different and can we remove the other code if we are doing this?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925265/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232089991","html_url":"https://github.com/apache/storm/pull/1552#issuecomment-232089991","issue_url":"https://api.github.com/repos/apache/storm/issues/1552","id":232089991,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjA4OTk5MQ==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:44:51Z","updated_at":"2016-07-12T15:46:31Z","author_association":"CONTRIBUTOR","body":"@revans2 when we tried rebalance, debug and changing the logger that particular code wasn't working. Yes that can be removed. Mainly the pre-flight request is not being addressed by the current code.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232089991/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925272","html_url":"https://github.com/apache/storm/issues/5742#issuecomment-2612925272","issue_url":"https://api.github.com/repos/apache/storm/issues/5742","id":2612925272,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUyNzI=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:44:52Z","updated_at":"2025-01-24T16:27:35Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1552\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1552</a></p>\n\n<p>    @revans2 when we tried rebalance, debug and changing the logger that particular code wasn't working. Yes that can be removed.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925272/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232090936","html_url":"https://github.com/apache/storm/pull/1552#issuecomment-232090936","issue_url":"https://api.github.com/repos/apache/storm/issues/1552","id":232090936,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjA5MDkzNg==","user":{"login":"arunmahadevan","id":6792890,"node_id":"MDQ6VXNlcjY3OTI4OTA=","avatar_url":"https://avatars.githubusercontent.com/u/6792890?v=4","gravatar_id":"","url":"https://api.github.com/users/arunmahadevan","html_url":"https://github.com/arunmahadevan","followers_url":"https://api.github.com/users/arunmahadevan/followers","following_url":"https://api.github.com/users/arunmahadevan/following{/other_user}","gists_url":"https://api.github.com/users/arunmahadevan/gists{/gist_id}","starred_url":"https://api.github.com/users/arunmahadevan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arunmahadevan/subscriptions","organizations_url":"https://api.github.com/users/arunmahadevan/orgs","repos_url":"https://api.github.com/users/arunmahadevan/repos","events_url":"https://api.github.com/users/arunmahadevan/events{/privacy}","received_events_url":"https://api.github.com/users/arunmahadevan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:47:43Z","updated_at":"2016-07-12T15:47:43Z","author_association":"CONTRIBUTOR","body":"@harshach May be for now we can document in the REST api doc and expose configs in future if needed.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232090936/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925275","html_url":"https://github.com/apache/storm/issues/5742#issuecomment-2612925275","issue_url":"https://api.github.com/repos/apache/storm/issues/5742","id":2612925275,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUyNzU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T15:47:45Z","updated_at":"2025-01-24T16:27:35Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user arunmahadevan commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1552\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1552</a></p>\n\n<p>    @harshach May be for now we can document in the REST api doc and expose configs in future if needed.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925275/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925277","html_url":"https://github.com/apache/storm/issues/5742#issuecomment-2612925277","issue_url":"https://api.github.com/repos/apache/storm/issues/5742","id":2612925277,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUyNzc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T19:16:46Z","updated_at":"2025-01-24T16:27:35Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user harshach opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1557\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1557</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1960\" title=\"Add CORS support to STORM UI Rest api\" class=\"issue-link\" data-issue-key=\"STORM-1960\"><del>STORM-1960</del></a>. Add CORS support to STORM UI Rest api</p>\n\n\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/harshach/incubator-storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/harshach/incubator-storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-1960\" title=\"Add CORS support to STORM UI Rest api\" class=\"issue-link\" data-issue-key=\"STORM-1960\"><del>STORM-1960</del></a>-1.x</p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1557.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1557.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1557</p>\n\n<hr />\n<p>commit ef5cffa196cb0982f4e863f704c697fd471ad09e<br/>\nAuthor: Sriharsha Chintalapani <harsha@hortonworks.com><br/>\nDate:   2016-07-12T19:15:24Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1960\" title=\"Add CORS support to STORM UI Rest api\" class=\"issue-link\" data-issue-key=\"STORM-1960\"><del>STORM-1960</del></a>. Add CORS support to STORM UI Rest api.</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925277/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232150561","html_url":"https://github.com/apache/storm/pull/1552#issuecomment-232150561","issue_url":"https://api.github.com/repos/apache/storm/issues/1552","id":232150561,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjE1MDU2MQ==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T19:18:06Z","updated_at":"2016-07-12T19:18:47Z","author_association":"CONTRIBUTOR","body":"@revans2  for master I think this part and the one you linked https://github.com/apache/storm/blob/master/storm-core/src/jvm/org/apache/storm/ui/UIHelpers.java#L151 is taking care of it . Where as in 1.x-branch we don't have that. I added patch here for 1.x-branch https://github.com/apache/storm/pull/1557\ncc @arunmahadevan @HeartSaVioR \n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232150561/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925281","html_url":"https://github.com/apache/storm/issues/5742#issuecomment-2612925281","issue_url":"https://api.github.com/repos/apache/storm/issues/5742","id":2612925281,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MjUyODE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T19:18:09Z","updated_at":"2025-01-24T16:27:35Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1552\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1552</a></p>\n\n<p>    @revans2  for master I think this part and the one you linked <a href=\"https://github.com/apache/storm/blob/master/storm-core/src/jvm/org/apache/storm/ui/UIHelpers.java#L151\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/blob/master/storm-core/src/jvm/org/apache/storm/ui/UIHelpers.java#L151</a> is taking care of it . Where as in 1.x-branch we don't have that. I added patch here for 1.x-branch <a href=\"https://github.com/apache/storm/pull/1557\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1557</a></p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612925281/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901030","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901030","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901030,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwMzA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-12T23:44:54Z","updated_at":"2025-01-24T16:15:28Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556#discussion_r70542939\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556#discussion_r70542939</a></p>\n\n<p>    &#8212; Diff: external/storm-kafka/src/test/org/apache/storm/kafka/KafkaTestBroker.java &#8212;<br/>\n    @@ -17,21 +17,21 @@<br/>\n      */<br/>\n     package org.apache.storm.kafka;</p>\n\n<p>    +import org.apache.commons.io.FileUtils;<br/>\n     import org.apache.curator.framework.CuratorFramework;<br/>\n     import org.apache.curator.framework.CuratorFrameworkFactory;<br/>\n     import org.apache.curator.framework.imps.CuratorFrameworkState;<br/>\n     import org.apache.curator.retry.ExponentialBackoffRetry;<br/>\n     import org.apache.curator.test.InstanceSpec;<br/>\n     import org.apache.curator.test.TestingServer;</p>\n\n<p>    -import kafka.server.KafkaConfig;<br/>\n    -import kafka.server.KafkaServerStartable;<br/>\n    -import org.apache.commons.io.FileUtils;<br/>\n    -<br/>\n     import java.io.File;<br/>\n     import java.io.IOException;<br/>\n     import java.util.Properties;</p>\n\n<p>    +import kafka.server.KafkaConfig;<br/>\n    +import kafka.server.KafkaServerStartable;<br/>\n    +<br/>\n     /**<br/>\n    &#8212; End diff &#8211;</p>\n\n<p>    Out of scope, but we need to get rid of this comment.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901030/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232218113","html_url":"https://github.com/apache/storm/pull/1556#issuecomment-232218113","issue_url":"https://api.github.com/repos/apache/storm/issues/1556","id":232218113,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjIxODExMw==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:05:43Z","updated_at":"2016-07-13T00:06:32Z","author_association":"CONTRIBUTOR","body":"What's our strategy/plan to support version lines of Kafka? I think we need to guide storm-kafka to users that for 0.8 you need to blabla, and for 0.9, and for 0.10.\nAnd storm-kafka-client is no longer compatible with 0.9, it would be better to go with [STORM-1876](https://issues.apache.org/jira/browse/STORM-1876) (#1482). If this patch merged in without STORM-1876, 0.9 users should download the code, and **change directory to external/storm-kafka**, and build module with proper `kafka.version` and `kafka.artifact.id` parameters.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232218113/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901034","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901034","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901034,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwMzQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:05:45Z","updated_at":"2025-01-24T16:15:29Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556</a></p>\n\n<p>    What's our plan to support version lines of Kafka? I think we need to guide storm-kafka to users that for 0.8 you need to blabla, and for 0.9, and for 0.10.<br/>\n    And storm-kafka-client is no longer compatible with 0.9, it would be better to go with <a href=\"https://issues.apache.org/jira/browse/STORM-1876\" title=\"Provide option to build storm-kafka against different kafka clients\" class=\"issue-link\" data-issue-key=\"STORM-1876\"><del>STORM-1876</del></a>(<a href=\"https://issues.apache.org/jira/browse/STORM-1876\" class=\"external-link\" rel=\"nofollow\">https://issues.apache.org/jira/browse/STORM-1876</a>) (#1482). If this patch merged in without <a href=\"https://issues.apache.org/jira/browse/STORM-1876\" title=\"Provide option to build storm-kafka against different kafka clients\" class=\"issue-link\" data-issue-key=\"STORM-1876\"><del>STORM-1876</del></a>, 0.9 users should download the code, and *<b>change directory to external/storm-kafka</b>*, and build module with proper `kafka.version` and `kafka.artifact.id` parameters.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901034/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232219567","html_url":"https://github.com/apache/storm/pull/1556#issuecomment-232219567","issue_url":"https://api.github.com/repos/apache/storm/issues/1556","id":232219567,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjIxOTU2Nw==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:15:09Z","updated_at":"2016-07-13T00:15:09Z","author_association":"CONTRIBUTOR","body":"@HeartSaVioR 0.9 users won't be able to use the new API anyway. So why are we worried about that part. ). 0.9 users can still use storm-kafka but the new kafka consumer in storm-kafka-client\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232219567/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901040","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901040","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901040,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwNDA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:15:31Z","updated_at":"2025-01-24T16:15:29Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556</a></p>\n\n<p>    @HeartSaVioR 0.9 users won't be able to use the new API anyway. So why are we worried about that part. ). 0.9 users can still use storm-kafka but the new kafka consumer in storm-kafka-client</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901040/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232219720","html_url":"https://github.com/apache/storm/pull/1556#issuecomment-232219720","issue_url":"https://api.github.com/repos/apache/storm/issues/1556","id":232219720,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjIxOTcyMA==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:16:13Z","updated_at":"2016-07-13T00:16:13Z","author_association":"CONTRIBUTOR","body":"@HeartSaVioR I don't think this patch need to wait on storm-kafka changes in STORM-1876. Irrespective both these patches storm-kafka will work against 0.8, 0.9 and 0.10\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232219720/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901047","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901047","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901047,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwNDc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:16:31Z","updated_at":"2025-01-24T16:15:29Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556</a></p>\n\n<p>    @HeartSaVioR I don't think this patch need to wait on storm-kafka changes in <a href=\"https://issues.apache.org/jira/browse/STORM-1876\" title=\"Provide option to build storm-kafka against different kafka clients\" class=\"issue-link\" data-issue-key=\"STORM-1876\"><del>STORM-1876</del></a>. Irrespective both these patches storm-kafka will work against 0.8, 0.9 and 0.10</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901047/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232221223","html_url":"https://github.com/apache/storm/pull/1556#issuecomment-232221223","issue_url":"https://api.github.com/repos/apache/storm/issues/1556","id":232221223,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjIyMTIyMw==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:26:36Z","updated_at":"2016-07-13T00:26:36Z","author_association":"CONTRIBUTOR","body":"@harshach \nSorry I've confused with compatibility between client and broker version. Seems like kafka 0.9 broker is compatible with kafka 0.8 client. I guess you're based on this. Is it correct?\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232221223/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901051","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901051","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901051,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwNTE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:26:38Z","updated_at":"2025-01-24T16:15:29Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556</a></p>\n\n<p>    @harshach <br/>\n    Sorry I've confused with compatibility between client and broker version. Seems like kafka 0.9 broker is compatible with kafka 0.8 client. I guess you're based on this. Is it correct?</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901051/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232223670","html_url":"https://github.com/apache/storm/pull/1556#issuecomment-232223670","issue_url":"https://api.github.com/repos/apache/storm/issues/1556","id":232223670,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjIyMzY3MA==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:42:54Z","updated_at":"2016-07-13T00:42:54Z","author_association":"CONTRIBUTOR","body":"@HeartSaVioR Yes. Users can still use the storm-kafka connector (old api) to connect to any version of kafka. Given that this is new consumer api we better move to compatible API soon. Hence the reason to push this as part of 1.0.2 release.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232223670/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901057","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901057","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901057,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwNTc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:42:55Z","updated_at":"2025-01-24T16:15:29Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556</a></p>\n\n<p>    @HeartSaVioR Yes. Users can still use the storm-kafka connector (old api) to connect to any version of kafka. Given that this is new consumer api we better move to compatible API soon. Hence the reason to push this as part of 1.0.2 release.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901057/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918039","html_url":"https://github.com/apache/storm/issues/5692#issuecomment-2612918039","issue_url":"https://api.github.com/repos/apache/storm/issues/5692","id":2612918039,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTgwMzk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:44:24Z","updated_at":"2025-01-24T16:23:54Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>GitHub user roshannaik opened a pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1558\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1558</a></p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1910\" title=\"One topology can&#39;t use hdfs spout to read from two locations\" class=\"issue-link\" data-issue-key=\"STORM-1910\"><del>STORM-1910</del></a>  One topology cannot use hdfs spout to read from two locations</p>\n\n<p>    Changing the way the spout is configured. Using member functions as the primary mode of config... still have to supporting the older mode  (via conf object ) for backward compatibility.<br/>\n    Updated test code.</p>\n\n<p>You can merge this pull request into a Git repository by running:</p>\n\n<p>    $ git pull <a href=\"https://github.com/roshannaik/storm\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/roshannaik/storm</a> <a href=\"https://issues.apache.org/jira/browse/STORM-1910\" title=\"One topology can&#39;t use hdfs spout to read from two locations\" class=\"issue-link\" data-issue-key=\"STORM-1910\"><del>STORM-1910</del></a></p>\n\n<p>Alternatively you can review and apply these changes as the patch at:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1558.patch\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1558.patch</a></p>\n\n<p>To close this pull request, make a commit to your master/trunk branch<br/>\nwith (at least) the following in the commit message:</p>\n\n<p>    This closes #1558</p>\n\n<hr />\n<p>commit d3ec6021eee07d0f44ce2a3464622e22e6be0c91<br/>\nAuthor: Roshan Naik <roshan@hortonworks.com><br/>\nDate:   2016-07-13T00:39:56Z</p>\n\n<p>    <a href=\"https://issues.apache.org/jira/browse/STORM-1910\" title=\"One topology can&#39;t use hdfs spout to read from two locations\" class=\"issue-link\" data-issue-key=\"STORM-1910\"><del>STORM-1910</del></a> - One topology cannot use hdfs spout to read from two locations</p>\n\n<hr />","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918039/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232224233","html_url":"https://github.com/apache/storm/pull/1556#issuecomment-232224233","issue_url":"https://api.github.com/repos/apache/storm/issues/1556","id":232224233,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjIyNDIzMw==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:46:46Z","updated_at":"2016-07-13T00:46:46Z","author_association":"CONTRIBUTOR","body":"@hmcl Please update README.md to describe this module is compatible with 0.10.0.\n\n@harshach We're having potential users which already uses storm-kafka-client with Kafka 0.9. It might be better for them to guide not updating their storm-kafka-client version as same as storm-core due to client version change, or dropping usage of storm-kafka-client and back to storm-kafka.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232224233/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901061","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901061","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901061,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwNjE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:46:48Z","updated_at":"2025-01-24T16:15:29Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556</a></p>\n\n<p>    @hmcl Please update README.md to describe this module is compatible with 0.10.0.</p>\n\n<p>    @harshach We're having potential users which already uses storm-kafka-client with Kafka 0.9. It might be better for them to guide not updating their storm-kafka-client version as same as storm-core due to client version change, or dropping usage of storm-kafka-client and back to storm-kafka.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901061/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232224638","html_url":"https://github.com/apache/storm/pull/1556#issuecomment-232224638","issue_url":"https://api.github.com/repos/apache/storm/issues/1556","id":232224638,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjIyNDYzOA==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:49:48Z","updated_at":"2016-07-13T00:51:47Z","author_association":"CONTRIBUTOR","body":"And let's clarify: what I'm thinking about is not only API level compatibility but Kafka client - broker version compatibility. If my understanding is right, we modified storm-kafka version to 0.8 due to this issue, and same for STORM-1876.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232224638/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901066","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901066","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901066,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwNjY=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:49:50Z","updated_at":"2025-01-24T16:15:29Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user HeartSaVioR commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556</a></p>\n\n<p>    And let's clarify: what I'm thinking about is not only API level compatibility but Kafka client - broker version compatibility. We modified storm-kafka version to 0.8 due to this issue.</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901066/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/232224918","html_url":"https://github.com/apache/storm/pull/1556#issuecomment-232224918","issue_url":"https://api.github.com/repos/apache/storm/issues/1556","id":232224918,"node_id":"MDEyOklzc3VlQ29tbWVudDIzMjIyNDkxOA==","user":{"login":"harshach","id":38649,"node_id":"MDQ6VXNlcjM4NjQ5","avatar_url":"https://avatars.githubusercontent.com/u/38649?v=4","gravatar_id":"","url":"https://api.github.com/users/harshach","html_url":"https://github.com/harshach","followers_url":"https://api.github.com/users/harshach/followers","following_url":"https://api.github.com/users/harshach/following{/other_user}","gists_url":"https://api.github.com/users/harshach/gists{/gist_id}","starred_url":"https://api.github.com/users/harshach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harshach/subscriptions","organizations_url":"https://api.github.com/users/harshach/orgs","repos_url":"https://api.github.com/users/harshach/repos","events_url":"https://api.github.com/users/harshach/events{/privacy}","received_events_url":"https://api.github.com/users/harshach/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:51:53Z","updated_at":"2016-07-13T00:56:15Z","author_association":"CONTRIBUTOR","body":"@HeartSaVioR we released 1.0 like few weeks back and even they are using the new consumer api in 0.10 will be api compatible with 0.9 as well it just the parameter types that are changed. \n\nadd to the above comment I think asking them to go back to storm-kafka is downward progress. Older Kafka APIs are already deprecated and will get removed in the future releases. We should encourage them to use the new kafka client. \nIMO I don't think many of the users went to production so we should make sure any changes get in now than later. As I said above we can definitely make a note in README and also it can work with 0.9 broker as there aren't any changes to the wire protocol.\n","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/232224918/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901069","html_url":"https://github.com/apache/storm/issues/5572#issuecomment-2612901069","issue_url":"https://api.github.com/repos/apache/storm/issues/5572","id":2612901069,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MDEwNjk=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T00:51:54Z","updated_at":"2025-01-24T16:15:29Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on the issue:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1556\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1556</a></p>\n\n<p>    @HeartSaVioR we released 1.0 like few weeks back and even they are using the new consumer api in 0.10 will be api compatible with 0.9 as well it just the parameter types that are changed. </p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612901069/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918043","html_url":"https://github.com/apache/storm/issues/5692#issuecomment-2612918043","issue_url":"https://api.github.com/repos/apache/storm/issues/5692","id":2612918043,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTgwNDM=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T01:04:13Z","updated_at":"2025-01-24T16:23:54Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1558#discussion_r70550095\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1558#discussion_r70550095</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -291,10 +361,11 @@ public void open(Map conf, TopologyContext context, SpoutOutputCollector collect<br/>\n this.tupleCounter = 0;</p>\n\n<p> // Hdfs related settings</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>if( conf.containsKey(Configs.HDFS_URI)) {<br/>\n    +    if(this.hdfsUri==null && conf.containsKey(Configs.HDFS_URI)) {\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    can you space after if</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918043/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918045","html_url":"https://github.com/apache/storm/issues/5692#issuecomment-2612918045","issue_url":"https://api.github.com/repos/apache/storm/issues/5692","id":2612918045,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTgwNDU=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T01:04:23Z","updated_at":"2025-01-24T16:23:54Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1558#discussion_r70550104\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1558#discussion_r70550104</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -291,10 +361,11 @@ public void open(Map conf, TopologyContext context, SpoutOutputCollector collect<br/>\n this.tupleCounter = 0;</p>\n\n<p> // Hdfs related settings</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>if( conf.containsKey(Configs.HDFS_URI)) {<br/>\n    +    if(this.hdfsUri==null && conf.containsKey(Configs.HDFS_URI)) \n{\n   this.hdfsUri = conf.get(Configs.HDFS_URI).toString();\n    -    }\n<p> else </p>\n{\n    -      throw new RuntimeException(Configs.HDFS_URI + \" setting is required\");\n    +    }\n<p>    +    if(this.hdfsUri==null) {</p>\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    space after if</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918045/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918047","html_url":"https://github.com/apache/storm/issues/5692#issuecomment-2612918047","issue_url":"https://api.github.com/repos/apache/storm/issues/5692","id":2612918047,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTgwNDc=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T01:04:23Z","updated_at":"2025-01-24T16:23:54Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1558#discussion_r70550110\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1558#discussion_r70550110</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -322,33 +393,41 @@ public void open(Map conf, TopologyContext context, SpoutOutputCollector collect<br/>\n   }</p>\n\n<p> // Reader type config</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>if( conf.containsKey(Configs.READER_TYPE) ) {<br/>\n    +    if( readerType==null && conf.containsKey(Configs.READER_TYPE) ) {\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    space after if</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918047/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918050","html_url":"https://github.com/apache/storm/issues/5692#issuecomment-2612918050","issue_url":"https://api.github.com/repos/apache/storm/issues/5692","id":2612918050,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTgwNTA=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T01:04:26Z","updated_at":"2025-01-24T16:23:54Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1558#discussion_r70550119\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1558#discussion_r70550119</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -322,33 +393,41 @@ public void open(Map conf, TopologyContext context, SpoutOutputCollector collect<br/>\n   }</p>\n\n<p> // Reader type config</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>if( conf.containsKey(Configs.READER_TYPE) ) {<br/>\n    +    if( readerType==null && conf.containsKey(Configs.READER_TYPE) ) \n{\n   readerType = conf.get(Configs.READER_TYPE).toString();\n    -      checkValidReader(readerType);\n }\n<p>    +    checkValidReader(readerType);</p></li>\n</ul>\n\n\n<p> // &#8211; source dir config</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>if ( !conf.containsKey(Configs.SOURCE_DIR) ) {<br/>\n    +    if ( sourceDir==null && conf.containsKey(Configs.SOURCE_DIR) ) \n{\n    +      sourceDir = conf.get(Configs.SOURCE_DIR).toString();\n    +    }\n<p>    +    if( sourceDir==null ) {</p>\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    space after if</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918050/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918061","html_url":"https://github.com/apache/storm/issues/5692#issuecomment-2612918061","issue_url":"https://api.github.com/repos/apache/storm/issues/5692","id":2612918061,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTgwNjE=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T01:04:47Z","updated_at":"2025-01-24T16:23:54Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1558#discussion_r70550149\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1558#discussion_r70550149</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -357,9 +436,15 @@ public void open(Map conf, TopologyContext context, SpoutOutputCollector collect<br/>\n }</p>\n\n<p> // &#8211; lock dir config</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>String lockDir = !conf.containsKey(Configs.LOCK_DIR) ? getDefaultLockDir(sourceDirPath) : conf.get(Configs.LOCK_DIR).toString() ;<br/>\n    +    if( lockDir==null && conf.containsKey(Configs.LOCK_DIR) ) {\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    remove the new line after the if and space after if</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918061/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918064","html_url":"https://github.com/apache/storm/issues/5692#issuecomment-2612918064","issue_url":"https://api.github.com/repos/apache/storm/issues/5692","id":2612918064,"node_id":"MDEyOklzc3VlQ29tbWVudDI2MTI5MTgwNjQ=","user":{"login":"jira-importer","id":99357308,"node_id":"U_kgDOBewSfA","avatar_url":"https://avatars.githubusercontent.com/u/99357308?v=4","gravatar_id":"","url":"https://api.github.com/users/jira-importer","html_url":"https://github.com/jira-importer","followers_url":"https://api.github.com/users/jira-importer/followers","following_url":"https://api.github.com/users/jira-importer/following{/other_user}","gists_url":"https://api.github.com/users/jira-importer/gists{/gist_id}","starred_url":"https://api.github.com/users/jira-importer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jira-importer/subscriptions","organizations_url":"https://api.github.com/users/jira-importer/orgs","repos_url":"https://api.github.com/users/jira-importer/repos","events_url":"https://api.github.com/users/jira-importer/events{/privacy}","received_events_url":"https://api.github.com/users/jira-importer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2016-07-13T01:04:54Z","updated_at":"2025-01-24T16:23:54Z","author_association":"COLLABORATOR","body":"<i><a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=githubbot\">githubbot</a>:</i>\n<p>Github user harshach commented on a diff in the pull request:</p>\n\n<p>    <a href=\"https://github.com/apache/storm/pull/1558#discussion_r70550171\" class=\"external-link\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/apache/storm/pull/1558#discussion_r70550171</a></p>\n\n<p>    &#8212; Diff: external/storm-hdfs/src/main/java/org/apache/storm/hdfs/spout/HdfsSpout.java &#8212;<br/>\n    @@ -357,9 +436,15 @@ public void open(Map conf, TopologyContext context, SpoutOutputCollector collect<br/>\n }</p>\n\n<p> // &#8211; lock dir config</p>\n<ul class=\"alternate\" type=\"square\">\n\t<li>String lockDir = !conf.containsKey(Configs.LOCK_DIR) ? getDefaultLockDir(sourceDirPath) : conf.get(Configs.LOCK_DIR).toString() ;<br/>\n    +    if( lockDir==null && conf.containsKey(Configs.LOCK_DIR) ) \n{\n    +      lockDir = conf.get(Configs.LOCK_DIR).toString();\n    +    }\n<p>    +    if(lockDir==null) {</p>\n\t<ul class=\"alternate\" type=\"square\">\n\t\t<li>\n\t\t<ul class=\"alternate\" type=\"square\">\n\t\t\t<li>End diff &#8211;</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n</ul>\n\n\n<p>    space after if</p>","reactions":{"url":"https://api.github.com/repos/apache/storm/issues/comments/2612918064/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]