[{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699510633","html_url":"https://github.com/apache/iceberg/issues/417#issuecomment-699510633","issue_url":"https://api.github.com/repos/apache/iceberg/issues/417","id":699510633,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTUxMDYzMw==","user":{"login":"ericsun2","id":8866410,"node_id":"MDQ6VXNlcjg4NjY0MTA=","avatar_url":"https://avatars.githubusercontent.com/u/8866410?v=4","gravatar_id":"","url":"https://api.github.com/users/ericsun2","html_url":"https://github.com/ericsun2","followers_url":"https://api.github.com/users/ericsun2/followers","following_url":"https://api.github.com/users/ericsun2/following{/other_user}","gists_url":"https://api.github.com/users/ericsun2/gists{/gist_id}","starred_url":"https://api.github.com/users/ericsun2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ericsun2/subscriptions","organizations_url":"https://api.github.com/users/ericsun2/orgs","repos_url":"https://api.github.com/users/ericsun2/repos","events_url":"https://api.github.com/users/ericsun2/events{/privacy}","received_events_url":"https://api.github.com/users/ericsun2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-26T15:32:32Z","updated_at":"2020-09-29T18:48:41Z","author_association":"NONE","body":"How about providing fine control of timestamp conversion in the year/month/day/hour `Transforms` as a secondary optional parameter?\r\n\r\n`.hour(timestampValue)`  // current syntax\r\n`.hour(timestampValue, time_zone)`  // enhanced syntax\r\n`.hour(longValue)`  // default to EPOCH_MILLIS\r\n`.hour(longValue, EPOCH_MILLIS)`\r\n`.hour(longValue, EPOCH)`  // seconds since epoch, this option should also be popular, the community can make it default\r\n`.hour(longValue, EPOCH_MINS)`  // minutes since epoch\r\n`.hour(longValue, EPOCH_10MINS)`  // 10-minute units since epoch, this is just for fun here ^_^\r\n`.hour(longValue, EPOCH_HOURS)`  // hours since epoch\r\n\r\nThe IoT, telemetry and Java-based logging can use the long/int-based epoch offset with various precisions.\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699510633/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699511832","html_url":"https://github.com/apache/iceberg/issues/1281#issuecomment-699511832","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1281","id":699511832,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTUxMTgzMg==","user":{"login":"ericsun2","id":8866410,"node_id":"MDQ6VXNlcjg4NjY0MTA=","avatar_url":"https://avatars.githubusercontent.com/u/8866410?v=4","gravatar_id":"","url":"https://api.github.com/users/ericsun2","html_url":"https://github.com/ericsun2","followers_url":"https://api.github.com/users/ericsun2/followers","following_url":"https://api.github.com/users/ericsun2/following{/other_user}","gists_url":"https://api.github.com/users/ericsun2/gists{/gist_id}","starred_url":"https://api.github.com/users/ericsun2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ericsun2/subscriptions","organizations_url":"https://api.github.com/users/ericsun2/orgs","repos_url":"https://api.github.com/users/ericsun2/repos","events_url":"https://api.github.com/users/ericsun2/events{/privacy}","received_events_url":"https://api.github.com/users/ericsun2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-26T15:42:00Z","updated_at":"2020-09-26T15:42:51Z","author_association":"NONE","body":"So are you suggesting the Hive-style Virtual Partition Column which is only stored in metadata but not in the data files?\r\nThen that is probably against the original design of Iceberg.\r\nThe space waste for such repetitive values of `Identity()` Transform in Parquet/ORC should be close to nothing.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699511832/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699567199","html_url":"https://github.com/apache/iceberg/issues/1485#issuecomment-699567199","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1485","id":699567199,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU2NzE5OQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T00:57:45Z","updated_at":"2020-09-27T01:19:16Z","author_association":"CONTRIBUTOR","body":"> I actually would have assumed it was a bug if a \"Cache\" command was invalidated by another table operation, in my mind it should snapshot the table state at that moment. I know because the behavior is lazy in Spark your guarantees on \"when\" are a bit more iffy, but I think the Spark cache shouldn't be automatically invalidated.\r\n\r\n@RussellSpitzer  I'd like to point out that as of Spark 3.0, the behavior of `CACHE TABLE` is eager, unless the DDL is `CACHE LAZY TABLE` [as documented here](https://spark.apache.org/docs/3.0.0/sql-ref-syntax-aux-cache-cache-table.html#syntax) for caching tables (at least non-temporary tables).\r\n\r\nI understand that the behavior is different depending on whether or not the cached data is a `VIEW` or a `TABLE`, most notably whether or not those cached plans / datasets are considered temporary or not.\r\n\r\nI went searching for the best documentation I could on this, but the most recent thing I could find was the JIRA ticket that covers the update to allow for `Non-cascading cache invalidation`. It appears that non-cascading cache invalidation _should_ only take place when a temporary dataset or table/view is dropped in order to save memory, but the underlying query plans for the other cached collections of data are still valid (to avoid using `Table` or `View` or `Dataset`). E.g. cache invalidation is not cascaded as of Spark 2.4.x unless the query plans of the downstream cached datasets would have been invalidated, which does not include strictly dropping the original cached view / table / dataset that they might have been derived from. The non-cascading behavior appears to really only cover the cases when data is no longer persisted in memory or on disk etc in order to reclaim resources, but that otherwise `REFRESH`ing temporary tables _should_ invalidate the cache (possibly dependent on changes, I'm not sure) and any downstream cached views / query plans that would also be invalidated.  cc @aokolnychyi. So what I read in this ticket, which might be the most up to date documentation on \"intended\" cache behavior in various scenarios seems to line up with @rdblue's latest response.\r\n\r\nThe JIRA ticket is here: https://issues.apache.org/jira/browse/SPARK-24596\r\n\r\nFor convenience and reference, I've quoted the pertinent description of the intended high level behaviors from that JIRA ticket. Note that `regular mode` here refers to cache invalidation that does cascade to derived on cluster caches of datasets / query plans.\r\n\r\n```\r\n1. Drop tables and regular (persistent) views: regular mode2\r\n2. Drop temporary views: non-cascading mode\r\n3. Modify table contents (INSERT/UPDATE/MERGE/DELETE): regular mode\r\n4. Call DataSet.unpersist(): non-cascading mode\r\n5. Call Catalog.uncacheTable(): follow the same convention as drop tables/view, which is, use non-cascading mode for temporary views and regular mode for the rest\r\n```\r\n\r\nIn the associated PR (which does appear to have been merged in and released as of Spark 2.4.x), the description is further clarified with the following TLDR ([link to the PR])(https://github.com/apache/spark/pull/21594)\r\n\r\n```\r\nNote that a regular (persistent) view is a database object just like a table, so after dropping a regular view \r\n(whether cached or not cached), any query referring to that view should no long be valid. \r\nHence if a cached persistent view is dropped, we need to invalidate the all dependent caches \r\nso that exceptions will be thrown for any later reference. On the other hand, a temporary view is in \r\nfact equivalent to an unnamed DataSet, and dropping a temporary view should have no impact on queries \r\nreferencing that view.\r\n\r\nThus we should do non-cascading uncaching for temporary views, which also guarantees a consistent \r\nuncaching behavior between temporary views and unnamed DataSets.\r\n```\r\n\r\nI know that this discussion is about the observed change in behaviors that occur because of V2 tables (and potentially from using a catalog that is not part of Spark proper), but since this is the most recent explanation I could find that covered the questions that are being discussed, I thought it was relevant to the conversation.\r\n\r\nAfter going through all of this, I will say that I had originally agreed with @RussellSpitzer's take, especially on point 1, that the cache is a point in time referece and immutable (throwing away potentially the notion of consistency with `lazy` caching, which is no longer the default). However, our own experience and the documentation I could find does not line up with that.\r\nI will say now that I'm mostly in agreement with @rdblue, especially that the (possible) need / desire to call `REFRESH` should be documented and recommended in the near term.\r\n\r\nI also agree that we should delegate the choosing of cache invalidation for queries to Spark, but ensure that we have a means to get that information to Spark to allow it to do its thing. Particularly at the Catalog level.\r\n\r\nIn the long term, I think Spark users will expect the latest behavior of Spark as the standard. Though how long it takes for changes in behavior to propagate into the minds of users as the latest / most correct is not something we could really estimate. I use Spark quite often (though I've yet to do a production upgrade to Spark 3, admittedly) and I will admit I was surprised by some of the things I learned.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699567199/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699568949","html_url":"https://github.com/apache/iceberg/issues/1485#issuecomment-699568949","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1485","id":699568949,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU2ODk0OQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T01:17:05Z","updated_at":"2020-09-29T03:16:19Z","author_association":"CONTRIBUTOR","body":"I'd also like to point out that, according to what little documentation I could find, the cached query plan _might_ not be invalidated if its using a hadoop / file based Catalog. Specifically, the documentation implies that there's a need to call `REFRESH` to actually invalidate path based data. The [documentation on `REFRESH`](https://spark.apache.org/docs/latest/sql-ref-syntax-aux-cache-refresh.html) has this definition:\r\n\r\n```\r\nREFRESH is used to invalidate and refresh all the cached data (and the associated metadata)\r\nfor all Datasets that contains the given data source path.\r\nPath matching is by prefix, i.e. “/” would invalidate everything that is cached.\r\n```\r\nand further drives the point home that a `REFRESH` call is likely needed if things like `INSERT` etc are done to what I can only see as Hadoop based catalogs (or filesystem based catalogs) by giving this example in reference to path based resources.\r\n\r\n```\r\n-- The Path is resolved using the datasource's File Index.\r\nCREATE TABLE test(ID INT) using parquet;\r\nINSERT INTO test SELECT 1000;\r\nCACHE TABLE test;\r\nINSERT INTO test SELECT 100;\r\nREFRESH \"hdfs://path/to/table\";\r\n```\r\n\r\nI hope that this investigation can shed further light on the intended behavior and our assumptions, as well as what needs to be done to ensure correctness, particularly when dealing with `Tables` or essentially non-temporary `Views`. I believe what I've found heavily agrees with @rdblue's assertions and explanations about the caching of `Datasets` to be equivalent to the caching of `temporary views`.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699568949/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699569544","html_url":"https://github.com/apache/iceberg/pull/1489#issuecomment-699569544","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1489","id":699569544,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU2OTU0NA==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T01:24:08Z","updated_at":"2020-09-27T01:24:08Z","author_association":"CONTRIBUTOR","body":"> I'm just a scaredy cat, don't mind me :)\r\n\r\nNo worries @RussellSpitzer ! I will admit I had to do quite some digging to make peace with this. But definitely my own research agrees that weak key maps commonly use identity based comparison vs equality comparison (because of reference counting or however weak is actually implemented under the hood). So I certainly won't mind you if you don't mind me :) ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699569544/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699570155","html_url":"https://github.com/apache/iceberg/pull/1493#issuecomment-699570155","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1493","id":699570155,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU3MDE1NQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T01:32:00Z","updated_at":"2020-09-27T01:33:08Z","author_association":"CONTRIBUTOR","body":"> Does it fix the warning to use a lambda and cast to `Consumer` instead? This could be something like:\r\n> \r\n> ```java\r\n> Consumer<String> defaultDelete = (Consumer<String>) file -> io.delete(file);\r\n> ```\r\n\r\nI will look into this now! It would be nice to catch two birds with one stone. I'll also consider Russell's comments as well. I will admit I kept the initial scope of this PR small, as I am still getting fully acquainted with the details of Java functional programming (as I'm definitely more of a Scala dev in my day job). But this is a great opportunity to learn and that's definitely part of why I'm here.\r\n\r\nAs it currently stands, I don't believe this gets rid of the warnings to use a lambda and cast to consumer.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699570155/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699571079","html_url":"https://github.com/apache/iceberg/issues/1442#issuecomment-699571079","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1442","id":699571079,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU3MTA3OQ==","user":{"login":"simonsssu","id":12323514,"node_id":"MDQ6VXNlcjEyMzIzNTE0","avatar_url":"https://avatars.githubusercontent.com/u/12323514?v=4","gravatar_id":"","url":"https://api.github.com/users/simonsssu","html_url":"https://github.com/simonsssu","followers_url":"https://api.github.com/users/simonsssu/followers","following_url":"https://api.github.com/users/simonsssu/following{/other_user}","gists_url":"https://api.github.com/users/simonsssu/gists{/gist_id}","starred_url":"https://api.github.com/users/simonsssu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/simonsssu/subscriptions","organizations_url":"https://api.github.com/users/simonsssu/orgs","repos_url":"https://api.github.com/users/simonsssu/repos","events_url":"https://api.github.com/users/simonsssu/events{/privacy}","received_events_url":"https://api.github.com/users/simonsssu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T01:40:23Z","updated_at":"2020-09-27T01:40:23Z","author_association":"CONTRIBUTOR","body":"relate to PR: [https://github.com/apache/iceberg/pull/1515]","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699571079/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699572191","html_url":"https://github.com/apache/iceberg/issues/1437#issuecomment-699572191","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1437","id":699572191,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU3MjE5MQ==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T01:52:20Z","updated_at":"2020-09-27T01:52:20Z","author_association":"CONTRIBUTOR","body":"I tested it and found that there is indeed a problem with configuring the local directory to load hive-site.xml in flink application mode.\r\nSo my idea is to configure a hive conf dir to load hive-site.xml. This directory can be a local path or an hdfs path to be compatible with flink application mode. If it is a local directory, load it directly, if it is an hdfs directory , download it to the local tmp directory first, and then load it.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699572191/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699573375","html_url":"https://github.com/apache/iceberg/issues/1437#issuecomment-699573375","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1437","id":699573375,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU3MzM3NQ==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T02:09:49Z","updated_at":"2020-09-27T02:09:49Z","author_association":"CONTRIBUTOR","body":"> I think it's a good idea to load `hive-site.xml` and respect its defaults. But for cases like a missing warehouse directory for a catalog, I think we should prefer configuring the warehouse on the catalog itself. It doesn't make sense for multiple catalogs to use the same `hive-site.xml` setting for warehouse directory.\r\n\r\n\r\nMy idea is that the configuration of hive is obtained by loading hive-site.xml, but we also support users to configure warehouse. \r\n\r\n- If the user configures warehouse, the value in hive-site.xml will be overwritten, just like when we create hive table the location can be specified. \r\n- the user does not configure a warehouse, the default value in hive-site.xml is used. \r\n- the user does not specify a warehouse and hive-site.xml is not configured in hive-site.xml, an exception will be thrown.\r\n\r\nWhat do you think for this? @rdblue \r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699573375/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699576667","html_url":"https://github.com/apache/iceberg/pull/1491#issuecomment-699576667","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1491","id":699576667,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU3NjY2Nw==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T02:51:51Z","updated_at":"2020-09-27T02:51:51Z","author_association":"CONTRIBUTOR","body":"I found a few other places where there are `PruneColumns` classes that have the same behavior, i.e. not checking for null inside of the code in the class and not having a null precondition check in the constructor on the same field.\r\n\r\nI've updated those, but I need to take a closer look at a Python class of the same name as well as some classes related to Spark named `PruneColumnsWithoutReordering` and `PruneColumnsWithReordering`.\r\n\r\nDo you happen to know if Python typically null checks or is it possible that we assume things have gone through JVM code in certain cases and therefore don't add them? I'll check myself for cases, but I'd love it if you or someone could shed some insight onto that for Python inter-op. Possibly something I should ask on users@ or dev@? cc @rdblue ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699576667/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699578815","html_url":"https://github.com/apache/iceberg/pull/1493#issuecomment-699578815","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1493","id":699578815,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU3ODgxNQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T03:18:06Z","updated_at":"2020-09-27T03:18:06Z","author_association":"MEMBER","body":"To be clear I think suppressing is the right move here\n\nOn Sat, Sep 26, 2020, 8:32 PM Kyle Bendickson <notifications@github.com>\nwrote:\n\n> Does it fix the warning to use a lambda and cast to Consumer instead?\n> This could be something like:\n>\n> Consumer<String> defaultDelete = (Consumer<String>) file -> io.delete(file);\n>\n> I will look into this now! It would be nice to catch two birds with one\n> stone. I'll also consider Russell's comments as well. I will admit I kept\n> the initial scope of this PR small, as I am still getting fully acquainted\n> with the details of Java functional programming (as I'm definitely more of\n> a Scala dev in my day job). But this is a great opportunity to learn and\n> that's definitely part of why I'm here.\n>\n> —\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/iceberg/pull/1493#issuecomment-699570155>, or\n> unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AADE2YKNBE7JOY74MXTVY63SH2IZZANCNFSM4RW4XABQ>\n> .\n>\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699578815/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699580322","html_url":"https://github.com/apache/iceberg/issues/1437#issuecomment-699580322","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1437","id":699580322,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU4MDMyMg==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T03:38:40Z","updated_at":"2020-09-27T03:59:17Z","author_association":"MEMBER","body":"> In this mode, the user jar is parsed on the jobmanager node of the flink cluster. I think it may not be possible to load the local configuration file.\r\n\r\nIn this case,  I think we'd better to include hadoop & hive configurations in the `flink-kafka-iceberg.jar`, so that even if loading jar at job manager side,  we could parse the correct expected configurations. right ?   But that will introduce another problem,  if user want to access different hadoop clusters, they would need to package different jar for different clusters. \r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699580322/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699584492","html_url":"https://github.com/apache/iceberg/pull/1515#issuecomment-699584492","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1515","id":699584492,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU4NDQ5Mg==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T04:40:08Z","updated_at":"2020-09-27T04:40:08Z","author_association":"CONTRIBUTOR","body":"This is great work @simonsssu! I have a few notes, but thank you so much for this contribution. I have several users that for whatever reason do not have checkpointing enabled and so I do very much appreciate this.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699584492/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699591013","html_url":"https://github.com/apache/iceberg/pull/1473#issuecomment-699591013","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1473","id":699591013,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTU5MTAxMw==","user":{"login":"liukun4515","id":7450163,"node_id":"MDQ6VXNlcjc0NTAxNjM=","avatar_url":"https://avatars.githubusercontent.com/u/7450163?v=4","gravatar_id":"","url":"https://api.github.com/users/liukun4515","html_url":"https://github.com/liukun4515","followers_url":"https://api.github.com/users/liukun4515/followers","following_url":"https://api.github.com/users/liukun4515/following{/other_user}","gists_url":"https://api.github.com/users/liukun4515/gists{/gist_id}","starred_url":"https://api.github.com/users/liukun4515/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liukun4515/subscriptions","organizations_url":"https://api.github.com/users/liukun4515/orgs","repos_url":"https://api.github.com/users/liukun4515/repos","events_url":"https://api.github.com/users/liukun4515/events{/privacy}","received_events_url":"https://api.github.com/users/liukun4515/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T06:07:55Z","updated_at":"2020-09-27T06:08:45Z","author_association":"NONE","body":"when will this pr be merged? \r\nI want to implement `snapshot expire` SQL extension based on this pr.\r\n\r\n@aokolnychyi ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699591013/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699692610","html_url":"https://github.com/apache/iceberg/issues/1292#issuecomment-699692610","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1292","id":699692610,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTY5MjYxMA==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-27T21:51:41Z","updated_at":"2020-09-27T21:51:41Z","author_association":"CONTRIBUTOR","body":"Oops forgot to close this but this has been handled and it does not appear that there are any `ByteBufferBackingArray` errors in the current master.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699692610/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699718969","html_url":"https://github.com/apache/iceberg/pull/1493#issuecomment-699718969","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1493","id":699718969,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTcxODk2OQ==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T01:12:54Z","updated_at":"2020-09-28T01:12:54Z","author_association":"CONTRIBUTOR","body":"> Does it fix the warning to use a lambda and cast to `Consumer` instead? This could be something like:\r\n> \r\n> ```java\r\n> Consumer<String> defaultDelete = (Consumer<String>) file -> io.delete(file);\r\n> ```\r\n\r\n@rdblue I will be honest and say that I ran `clean build` from master in intelliJ after invalidating all caches and restarting and the only somewhat similar warning I could find was `[UnnecessaryLambda]` (which doesn't sound like what you're describing. I will double check that I don't get a warning like that when running from the CLI (as possibly IntelliJ is hiding this from me).\r\n\r\nI do however like your idea. I tried it, though I did get warnings about a possibly uninitialized variable for `ops` as I had to use `ops.io.delete(file)`. So I'm not sure that's better. Though now that I've found this same code in several classes, I'm thinking it might make sense to refactor it out for reusability?\r\n\r\nHere's the only Lambda related warning I could find:\r\n```\r\n[UnnecessaryLambda] Returning a lambda from a helper method or saving it in a constant is unnecessary; prefer to implement the functional interface method directly and use a method reference instead.\r\n(see https://errorprone.info/bugpattern/UnnecessaryLambda)\r\nDid you mean 'private  DatumReader<?> defaultCreateReaderFunc(Schema readSchema){'?\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699718969/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699720661","html_url":"https://github.com/apache/iceberg/issues/1437#issuecomment-699720661","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1437","id":699720661,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTcyMDY2MQ==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T01:21:16Z","updated_at":"2020-09-28T01:21:16Z","author_association":"CONTRIBUTOR","body":"hi ,@openinx \r\n\r\nNo matter which mode is used to submit flink jobs (sql client,standalone,yarn session, flink per job, application mode), flink will use FlinkCatalogFactory#createCatalog to create catalogs, so the difficulty lies in making FlinkCatalogFactory compatible with various submission modes. If hive file is included in the user jar  , Then FlinkCatalogFactory needs to parse the user jar  to obtain the hive configuration, but for other submission modes, it only needs to configure a hive local path. But I think it may be difficult for FlinkCatalogFactor to know which job mode the current user submits  in order to make different loading methods.\r\n\r\nIn addition, for other submission modes, we provide a hive local configuration path. If the user executes the DDL that creates the catalog in the code, such as the following code example:\r\n\r\n`\ttenv.executeSql(\"CREATE CATALOG hive_catalog WITH (\\n\" +\r\n\t\t\t\t\"  'type'='iceberg',\\n\" +\r\n\t\t\t\t\"  'catalog-type'='hive',\\n\" +\r\n\t\t\t\t\"  'uri'='thrift://localhost:9083'\" +\r\n\t\t\t\t\"  'warehouse'='hdfs://localhost/user/hive/warehouse'\" +\r\n\t\t\t\t\")\");`\r\n\r\n and the code is typed into a jar  and executed in application mode, then In this case, we are based on the hive path configured by the user ddl or the hive-site.xml contained in the jar ? If the two configurations are different, the user will be confused. The same ddl It can be executed in sql client, why can't it be executed in the program.\r\n\r\nSo my idea is to provide a hive conf path, which can be a local path or a hdfs path. If the user configures the hdfs path, we first download it to the local, and then load it. If the user submits the flink jar  in application mode, but the configured local path cannot find the path anymore, we will give the user some prompts and tell him that the application mode needs to configure the hdfs path.\r\n\r\nI think this is compatible with various user program submission modes. What do you think about this.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699720661/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699723440","html_url":"https://github.com/apache/iceberg/issues/1510#issuecomment-699723440","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1510","id":699723440,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTcyMzQ0MA==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T01:34:23Z","updated_at":"2020-09-28T01:34:23Z","author_association":"CONTRIBUTOR","body":"hi,@openinx \r\n\r\nI am not sure if this is an issue, but in my program I did introduce the jar of the maven warehouse, and some exceptions that the factory class could not be loaded would be reported. I finally found the reason is that the jar does not have the SPI configuration file. \r\n`org.apache.flink.table.factories.TableFactory`","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699723440/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699729302","html_url":"https://github.com/apache/iceberg/issues/1510#issuecomment-699729302","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1510","id":699729302,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTcyOTMwMg==","user":{"login":"openinx","id":5028729,"node_id":"MDQ6VXNlcjUwMjg3Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/5028729?v=4","gravatar_id":"","url":"https://api.github.com/users/openinx","html_url":"https://github.com/openinx","followers_url":"https://api.github.com/users/openinx/followers","following_url":"https://api.github.com/users/openinx/following{/other_user}","gists_url":"https://api.github.com/users/openinx/gists{/gist_id}","starred_url":"https://api.github.com/users/openinx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/openinx/subscriptions","organizations_url":"https://api.github.com/users/openinx/orgs","repos_url":"https://api.github.com/users/openinx/repos","events_url":"https://api.github.com/users/openinx/events{/privacy}","received_events_url":"https://api.github.com/users/openinx/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T02:03:01Z","updated_at":"2020-09-28T02:03:01Z","author_association":"MEMBER","body":"@zhangjun0x01  the flink sink connector in 0.9.1 is not complete,  the real available release version would be iceberg 0.10.0,   I guess the time point would be Oct.  Also,   the flink users won't depend on this `flink-iceberg.jar` directly,  instead they would use `flink-iceberg-runtime.jar`  which have shaded the common dependency jars such as guava etc. \r\n\r\nFor now, if you want to test this feature,  you might need to build the `flink-iceberg-runtime` jar by building the iceberg project now.  \r\n\r\nSo this issue could be closed now, right ? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699729302/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699730193","html_url":"https://github.com/apache/iceberg/issues/1510#issuecomment-699730193","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1510","id":699730193,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTczMDE5Mw==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T02:07:29Z","updated_at":"2020-09-28T02:07:29Z","author_association":"CONTRIBUTOR","body":"ok,I will close it ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699730193/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699778221","html_url":"https://github.com/apache/iceberg/pull/1509#issuecomment-699778221","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1509","id":699778221,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTc3ODIyMQ==","user":{"login":"JingsongLi","id":9601882,"node_id":"MDQ6VXNlcjk2MDE4ODI=","avatar_url":"https://avatars.githubusercontent.com/u/9601882?v=4","gravatar_id":"","url":"https://api.github.com/users/JingsongLi","html_url":"https://github.com/JingsongLi","followers_url":"https://api.github.com/users/JingsongLi/followers","following_url":"https://api.github.com/users/JingsongLi/following{/other_user}","gists_url":"https://api.github.com/users/JingsongLi/gists{/gist_id}","starred_url":"https://api.github.com/users/JingsongLi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JingsongLi/subscriptions","organizations_url":"https://api.github.com/users/JingsongLi/orgs","repos_url":"https://api.github.com/users/JingsongLi/repos","events_url":"https://api.github.com/users/JingsongLi/events{/privacy}","received_events_url":"https://api.github.com/users/JingsongLi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T05:27:49Z","updated_at":"2020-09-28T05:27:49Z","author_association":"CONTRIBUTOR","body":"> Let's take a look at `ScanOptions` in the next PR then. I would prefer to keep user-facing APIs simple, rather than leaking a SQL concern (options come from `WITH`) to users (need to use two builders). Since SQL will most likely use the `fromProperties` method, it may make sense to use a single builder, add `withProperties`, and pass properties from SQL as a map.\r\n\r\nGot it, I think I can change the `ScanOptions` to `ScanContext`, it is an internal helper class like `TableScanContext`.\r\nThen expose all setters to `FlinkSource.Builder`.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699778221/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699846321","html_url":"https://github.com/apache/iceberg/pull/1523#issuecomment-699846321","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1523","id":699846321,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTg0NjMyMQ==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T07:58:26Z","updated_at":"2020-09-28T07:58:26Z","author_association":"CONTRIBUTOR","body":"Two questions in mind on working for the PR:\r\n\r\n1) Do we want to be exhaustive on the example, like having an example dealing with all kind of transformations?\r\n\r\nI'm only dealing with `bucket` which is simpler one, and I'm not sure the information is enough for end users to deal with other transformations.\r\n\r\n2) Do we want to mention Spark JIRA issues to get rid of such requirements?\r\n\r\nIf I were just an end user, I would expect Iceberg to require nothing for me. Mentioning the Spark JIRA issues would implicitly say that \"We are aware of the issues and probably will work on our side, so please bear with the workaround for some time.\", but if we are not wanting to be committed to work for these JIRA issues, probably also better to not mentioning these JIRA issues at all.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699846321/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699903901","html_url":"https://github.com/apache/iceberg/issues/1513#issuecomment-699903901","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1513","id":699903901,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTkwMzkwMQ==","user":{"login":"SteNicholas","id":10048174,"node_id":"MDQ6VXNlcjEwMDQ4MTc0","avatar_url":"https://avatars.githubusercontent.com/u/10048174?v=4","gravatar_id":"","url":"https://api.github.com/users/SteNicholas","html_url":"https://github.com/SteNicholas","followers_url":"https://api.github.com/users/SteNicholas/followers","following_url":"https://api.github.com/users/SteNicholas/following{/other_user}","gists_url":"https://api.github.com/users/SteNicholas/gists{/gist_id}","starred_url":"https://api.github.com/users/SteNicholas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SteNicholas/subscriptions","organizations_url":"https://api.github.com/users/SteNicholas/orgs","repos_url":"https://api.github.com/users/SteNicholas/repos","events_url":"https://api.github.com/users/SteNicholas/events{/privacy}","received_events_url":"https://api.github.com/users/SteNicholas/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T09:50:51Z","updated_at":"2020-09-28T09:50:51Z","author_association":"MEMBER","body":"@stevenzwu I agree with you for the point that the return behavior of `TableOperations#current()` should be unified, which could be confused for users when `TableOperations#current()` returns null.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699903901/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699936582","html_url":"https://github.com/apache/iceberg/pull/1495#issuecomment-699936582","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1495","id":699936582,"node_id":"MDEyOklzc3VlQ29tbWVudDY5OTkzNjU4Mg==","user":{"login":"qphien","id":17759741,"node_id":"MDQ6VXNlcjE3NzU5NzQx","avatar_url":"https://avatars.githubusercontent.com/u/17759741?v=4","gravatar_id":"","url":"https://api.github.com/users/qphien","html_url":"https://github.com/qphien","followers_url":"https://api.github.com/users/qphien/followers","following_url":"https://api.github.com/users/qphien/following{/other_user}","gists_url":"https://api.github.com/users/qphien/gists{/gist_id}","starred_url":"https://api.github.com/users/qphien/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qphien/subscriptions","organizations_url":"https://api.github.com/users/qphien/orgs","repos_url":"https://api.github.com/users/qphien/repos","events_url":"https://api.github.com/users/qphien/events{/privacy}","received_events_url":"https://api.github.com/users/qphien/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T11:01:22Z","updated_at":"2020-09-29T05:32:12Z","author_association":"CONTRIBUTOR","body":"I think it is necessary to add a converter to transform Hive DDL schema to iceberg schema instead of specifying iceberg schema in TBLPROPERTIES. Maybe we can use \r\n```xml\r\n// Managed Table\r\nCREATE TABLE icebergTable (id int, day string)\r\nSTORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'\r\nTBLPROPERTIES('iceberg.mr.table.partition.spec'='day:day')\r\n\r\n// External Table\r\nCREATE EXTERNAL TABLE icebergTable (id int, day string)\r\nSTORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'\r\nLOCATION 'hdfs://path/to/table'\r\nTBLPROPERTIES('iceberg.mr.table.partition.spec'='id:identity')\r\n```\r\nto create managed/external table, `iceberg.mr.table.partition.spec` can be used to specify partition name and transform type.\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/699936582/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700143304","html_url":"https://github.com/apache/iceberg/pull/1478#issuecomment-700143304","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1478","id":700143304,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDE0MzMwNA==","user":{"login":"marton-bod","id":19599214,"node_id":"MDQ6VXNlcjE5NTk5MjE0","avatar_url":"https://avatars.githubusercontent.com/u/19599214?v=4","gravatar_id":"","url":"https://api.github.com/users/marton-bod","html_url":"https://github.com/marton-bod","followers_url":"https://api.github.com/users/marton-bod/followers","following_url":"https://api.github.com/users/marton-bod/following{/other_user}","gists_url":"https://api.github.com/users/marton-bod/gists{/gist_id}","starred_url":"https://api.github.com/users/marton-bod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marton-bod/subscriptions","organizations_url":"https://api.github.com/users/marton-bod/orgs","repos_url":"https://api.github.com/users/marton-bod/repos","events_url":"https://api.github.com/users/marton-bod/events{/privacy}","received_events_url":"https://api.github.com/users/marton-bod/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T16:28:41Z","updated_at":"2020-09-28T16:28:41Z","author_association":"COLLABORATOR","body":"@rdblue @rdsr @massdosage \r\nThanks a lot for your very valuable comments from last week!\r\nI have reworked the solution according to the proposal by @rdblue, and it came out simpler and better I think. I would greatly appreciate it if you could take a look at it once again. \r\nThank you!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700143304/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700176229","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-700176229","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":700176229,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDE3NjIyOQ==","user":{"login":"electrum","id":9230,"node_id":"MDQ6VXNlcjkyMzA=","avatar_url":"https://avatars.githubusercontent.com/u/9230?v=4","gravatar_id":"","url":"https://api.github.com/users/electrum","html_url":"https://github.com/electrum","followers_url":"https://api.github.com/users/electrum/followers","following_url":"https://api.github.com/users/electrum/following{/other_user}","gists_url":"https://api.github.com/users/electrum/gists{/gist_id}","starred_url":"https://api.github.com/users/electrum/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/electrum/subscriptions","organizations_url":"https://api.github.com/users/electrum/orgs","repos_url":"https://api.github.com/users/electrum/repos","events_url":"https://api.github.com/users/electrum/events{/privacy}","received_events_url":"https://api.github.com/users/electrum/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T17:29:47Z","updated_at":"2020-09-28T17:29:47Z","author_association":"CONTRIBUTOR","body":"Should we read the old metadata files as a fallback for data written before this addition?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700176229/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700187864","html_url":"https://github.com/apache/iceberg/pull/1519#issuecomment-700187864","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1519","id":700187864,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDE4Nzg2NA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T17:52:55Z","updated_at":"2020-09-28T17:52:55Z","author_association":"CONTRIBUTOR","body":"Thanks!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700187864/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700188974","html_url":"https://github.com/apache/iceberg/pull/1518#issuecomment-700188974","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1518","id":700188974,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDE4ODk3NA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T17:55:08Z","updated_at":"2020-09-28T17:55:08Z","author_association":"CONTRIBUTOR","body":"Thanks, @chenjunjiedada. I agree, this should be UTF-8.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700188974/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700191145","html_url":"https://github.com/apache/iceberg/pull/1521#issuecomment-700191145","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1521","id":700191145,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDE5MTE0NQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T17:59:20Z","updated_at":"2020-09-28T17:59:20Z","author_association":"CONTRIBUTOR","body":"Merged. Thanks @JingsongLi!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700191145/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700192803","html_url":"https://github.com/apache/iceberg/pull/1515#issuecomment-700192803","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1515","id":700192803,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDE5MjgwMw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T18:02:29Z","updated_at":"2020-09-28T18:02:29Z","author_association":"CONTRIBUTOR","body":"@simonsssu, can you update this PR's description to document what you propose for the sink's behavior?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700192803/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700205519","html_url":"https://github.com/apache/iceberg/issues/1513#issuecomment-700205519","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1513","id":700205519,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDIwNTUxOQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T18:27:16Z","updated_at":"2020-09-28T18:27:16Z","author_association":"CONTRIBUTOR","body":"`current` will return `null` only after refreshing the table throws `NoSuchTableException`. I think this is minor because callers would have ignored that exception to fail when current returns null.\r\n\r\nThat said, I think we can throw the exception and set `shouldRefresh = true`. That way, any call to get table metadata will trigger a refresh and either get the table back to a consistent state, or fail with the same exception.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700205519/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700225862","html_url":"https://github.com/apache/iceberg/pull/1503#issuecomment-700225862","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1503","id":700225862,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDIyNTg2Mg==","user":{"login":"thomaschow","id":2002564,"node_id":"MDQ6VXNlcjIwMDI1NjQ=","avatar_url":"https://avatars.githubusercontent.com/u/2002564?v=4","gravatar_id":"","url":"https://api.github.com/users/thomaschow","html_url":"https://github.com/thomaschow","followers_url":"https://api.github.com/users/thomaschow/followers","following_url":"https://api.github.com/users/thomaschow/following{/other_user}","gists_url":"https://api.github.com/users/thomaschow/gists{/gist_id}","starred_url":"https://api.github.com/users/thomaschow/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/thomaschow/subscriptions","organizations_url":"https://api.github.com/users/thomaschow/orgs","repos_url":"https://api.github.com/users/thomaschow/repos","events_url":"https://api.github.com/users/thomaschow/events{/privacy}","received_events_url":"https://api.github.com/users/thomaschow/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T19:08:58Z","updated_at":"2020-09-28T19:08:58Z","author_association":"CONTRIBUTOR","body":"> Is your use case similar? I'm interested because I think we might want to have first-class support for named snapshots, instead of having a property that selects by equality. What do you think?\r\n\r\nYep I think that would satisfy our use case. Do you have a pointer to a PR/issue/doc I can read? How far along is this feature? ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700225862/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700289423","html_url":"https://github.com/apache/iceberg/pull/1525#issuecomment-700289423","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1525","id":700289423,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDI4OTQyMw==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T21:24:37Z","updated_at":"2020-09-28T21:24:37Z","author_association":"MEMBER","body":"@chenjunjiedada  - This is going to be the basis action for the SQL Extension which will create/import table from Spark Tables","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700289423/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700289570","html_url":"https://github.com/apache/iceberg/pull/1525#issuecomment-700289570","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1525","id":700289570,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDI4OTU3MA==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T21:25:02Z","updated_at":"2020-09-28T21:25:02Z","author_association":"MEMBER","body":"cc @aokolnychyi + @rdblue If you have any time could you please review?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700289570/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700289714","html_url":"https://github.com/apache/iceberg/pull/1503#issuecomment-700289714","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1503","id":700289714,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDI4OTcxNA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T21:25:22Z","updated_at":"2020-09-28T21:25:22Z","author_association":"CONTRIBUTOR","body":"We've just talked about it internally. I don't think anyone has written up a doc or opened an issue.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700289714/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700290536","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-700290536","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":700290536,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDI5MDUzNg==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T21:27:22Z","updated_at":"2020-09-28T21:27:22Z","author_association":"CONTRIBUTOR","body":"> Should we read the old metadata files as a fallback for data written before this addition?\r\n\r\nWe could, but it doesn't seem worth the effort to maintain it to me. If other people disagree, I'm fine adding it.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700290536/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700292321","html_url":"https://github.com/apache/iceberg/pull/1503#issuecomment-700292321","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1503","id":700292321,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDI5MjMyMQ==","user":{"login":"jacques-n","id":183350,"node_id":"MDQ6VXNlcjE4MzM1MA==","avatar_url":"https://avatars.githubusercontent.com/u/183350?v=4","gravatar_id":"","url":"https://api.github.com/users/jacques-n","html_url":"https://github.com/jacques-n","followers_url":"https://api.github.com/users/jacques-n/followers","following_url":"https://api.github.com/users/jacques-n/following{/other_user}","gists_url":"https://api.github.com/users/jacques-n/gists{/gist_id}","starred_url":"https://api.github.com/users/jacques-n/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jacques-n/subscriptions","organizations_url":"https://api.github.com/users/jacques-n/orgs","repos_url":"https://api.github.com/users/jacques-n/repos","events_url":"https://api.github.com/users/jacques-n/events{/privacy}","received_events_url":"https://api.github.com/users/jacques-n/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T21:31:39Z","updated_at":"2020-09-28T21:31:39Z","author_association":"NONE","body":"I have some ideas I've been noodling on this. I hope to share them with the community soon!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700292321/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700297902","html_url":"https://github.com/apache/iceberg/pull/1514#issuecomment-700297902","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1514","id":700297902,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDI5NzkwMg==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T21:46:00Z","updated_at":"2020-09-28T21:46:00Z","author_association":"CONTRIBUTOR","body":"@mehtaashish23, could you update this to avoid using `CharSequence`? Also, it would be great to add a test for this case. I think you just need two data files and one equality delete that applies to both to reproduce it.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700297902/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700305873","html_url":"https://github.com/apache/iceberg/pull/1523#issuecomment-700305873","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1523","id":700305873,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDMwNTg3Mw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T21:56:29Z","updated_at":"2020-09-28T21:56:29Z","author_association":"CONTRIBUTOR","body":"Thanks for doing this, @HeartSaVioR! This is a great start and it will be really helpful to have this in our documentation.\r\n\r\n> Do we want to be exhaustive on the example, like having an example dealing with all kind of transformations?\r\n\r\nI don't think so. Most transformations work with equivalents from Spark: `ORDER BY CAST(ts AS DATE), category` will work for the other two columns. Only bucketing is difficult.\r\n\r\n> Do we want to mention Spark JIRA issues to get rid of such requirements?\r\n\r\nI think it would be helpful to have a paragraph or a callout that explains why this is required: we can't request a sort until sorting is supported and we can't inject the functions until Spark supports a `FunctionCatalog`.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700305873/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700306527","html_url":"https://github.com/apache/iceberg/pull/1523#issuecomment-700306527","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1523","id":700306527,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDMwNjUyNw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T21:58:18Z","updated_at":"2020-09-28T21:58:18Z","author_association":"CONTRIBUTOR","body":"Another thought:\r\n\r\nShould we create a utility method to register Iceberg transforms as Spark UDFs? Something that would look like this:\r\n\r\n```java\r\n// register a UDF for bucket(16, stringCol)\r\nIcebergSpark.registerIcebergUDF(spark, \"bucket16\", StringType.get());\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700306527/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700315600","html_url":"https://github.com/apache/iceberg/pull/1505#issuecomment-700315600","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1505","id":700315600,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDMxNTYwMA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T22:23:59Z","updated_at":"2020-09-28T22:23:59Z","author_association":"CONTRIBUTOR","body":"> We need the build changes, because the spark sql uses Hive code to interact with hive tables.\r\n\r\nThat sounds like a bug to me. We want to ensure that Spark does not interact with Iceberg tables using Hive. It should use Iceberg directly through the v2 interface instead. We'll need to find out why Spark is trying to load the table incorrectly. What catalog were you using?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700315600/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700317671","html_url":"https://github.com/apache/iceberg/pull/1503#issuecomment-700317671","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1503","id":700317671,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDMxNzY3MQ==","user":{"login":"thomaschow","id":2002564,"node_id":"MDQ6VXNlcjIwMDI1NjQ=","avatar_url":"https://avatars.githubusercontent.com/u/2002564?v=4","gravatar_id":"","url":"https://api.github.com/users/thomaschow","html_url":"https://github.com/thomaschow","followers_url":"https://api.github.com/users/thomaschow/followers","following_url":"https://api.github.com/users/thomaschow/following{/other_user}","gists_url":"https://api.github.com/users/thomaschow/gists{/gist_id}","starred_url":"https://api.github.com/users/thomaschow/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/thomaschow/subscriptions","organizations_url":"https://api.github.com/users/thomaschow/orgs","repos_url":"https://api.github.com/users/thomaschow/repos","events_url":"https://api.github.com/users/thomaschow/events{/privacy}","received_events_url":"https://api.github.com/users/thomaschow/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T22:30:11Z","updated_at":"2020-09-28T22:30:11Z","author_association":"CONTRIBUTOR","body":"we have probably a specific use case of this in that we effectively have a different \"snapshot-id\" that's exposed to users. Every time we query for a particular snapshot, we do not use the native iceberg snapshot-id rather this externally set one. So in a sense it is not \"tagging\", but abstracting away iceberg's internal snapshot-id. This behavior _could_ be implemented using tagging, but it sounds like it might not be the optimal way to do it.\r\n\r\nWe have considered implementing a different snapshot-id scheme but wanted to keep the iceberg internals in tact. \r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700317671/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700319080","html_url":"https://github.com/apache/iceberg/pull/1493#issuecomment-700319080","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1493","id":700319080,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDMxOTA4MA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-28T22:34:45Z","updated_at":"2020-09-28T22:34:45Z","author_association":"CONTRIBUTOR","body":"Thanks, @kbendick and @RussellSpitzer for looking into this. I'll merge this as it is now. We could probably refactor the code to avoid the warning, which was what I intended with the lambda suggestion. But in the end, we think that this use of an anonymous class is fine, so suppressing it is easier.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700319080/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700349409","html_url":"https://github.com/apache/iceberg/pull/1495#issuecomment-700349409","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1495","id":700349409,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDM0OTQwOQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T00:16:56Z","updated_at":"2020-09-29T00:16:56Z","author_association":"CONTRIBUTOR","body":"> I think it is necessary to add a converter to transform Hive DDL schema to iceberg schema instead of specifying iceberg schema in TBLPROPERTIES\r\n\r\nI agree that we want this to be the behavior. @pvary, what is the plan for using the DDL schema instead of a table property?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700349409/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700349919","html_url":"https://github.com/apache/iceberg/pull/1526#issuecomment-700349919","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1526","id":700349919,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDM0OTkxOQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T00:18:33Z","updated_at":"2020-09-29T00:18:33Z","author_association":"CONTRIBUTOR","body":"Looks good, and helps unblock #1497. Thanks @holdenk!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700349919/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700353804","html_url":"https://github.com/apache/iceberg/pull/1491#issuecomment-700353804","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1491","id":700353804,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDM1MzgwNA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T00:30:57Z","updated_at":"2020-09-29T00:30:57Z","author_association":"CONTRIBUTOR","body":"Looks good. Thanks, @kbendick!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700353804/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700362249","html_url":"https://github.com/apache/iceberg/pull/1478#issuecomment-700362249","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1478","id":700362249,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDM2MjI0OQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T01:00:52Z","updated_at":"2020-09-29T01:00:52Z","author_association":"CONTRIBUTOR","body":"Nice work, @marton-bod! This looks a lot better and I think we will be able to merge it soon. We should clean it up further by using the reflection helpers in iceberg-common first, though.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700362249/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700377063","html_url":"https://github.com/apache/iceberg/pull/1523#issuecomment-700377063","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1523","id":700377063,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDM3NzA2Mw==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T01:52:38Z","updated_at":"2020-09-29T04:38:47Z","author_association":"CONTRIBUTOR","body":"> I don't think so. Most transformations work with equivalents from Spark: ORDER BY CAST(ts AS DATE), category will work for the other two columns. Only bucketing is difficult.\r\n\r\nAh you're right. No need to calculate the actual partition value for sorting on date/time partition value. Good point.\r\n\r\n> I think it would be helpful to have a paragraph or a callout that explains why this is required: we can't request a sort until sorting is supported and we can't inject the functions until Spark supports a FunctionCatalog.\r\n\r\nSounds great. Probably note would work for a callout. I'll add the note. Thanks!\r\n\r\n> Should we create a utility method to register Iceberg transforms as Spark UDFs?\r\n\r\nI think it should be helpful. ~~Btw, can we deal with the Java-Scala interop trick in Iceberg side, or simply support Java side? I guess we probably don't want to deal with Scala directly, as it's tied to the Scala version. (The trick doesn't look to be tied to specific version of Scala though.)~~ Never mind, it simply works.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700377063/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700425651","html_url":"https://github.com/apache/iceberg/pull/1523#issuecomment-700425651","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1523","id":700425651,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDQyNTY1MQ==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T04:54:40Z","updated_at":"2020-09-29T04:54:40Z","author_association":"CONTRIBUTOR","body":"Reflected review comments. I just added the utility class here to reduce the doc content here as well, but it would be also reasonable to do it in separate PR. Either is OK to me.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700425651/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700437299","html_url":"https://github.com/apache/iceberg/pull/1495#issuecomment-700437299","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1495","id":700437299,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDQzNzI5OQ==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T05:34:06Z","updated_at":"2020-09-29T05:34:06Z","author_association":"CONTRIBUTOR","body":"> > I think it is necessary to add a converter to transform Hive DDL schema to iceberg schema instead of specifying iceberg schema in TBLPROPERTIES\r\n> \r\n> I agree that we want this to be the behavior. @pvary, what is the plan for using the DDL schema instead of a table property?\r\n\r\nI agree with you on this. It will be quite convoluted to access the Hive DDL columns and types. It will add another layer of complexity which I would like to address in another PR to keep the changes more reviewer friendly 😄","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700437299/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700464384","html_url":"https://github.com/apache/iceberg/issues/1442#issuecomment-700464384","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1442","id":700464384,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDQ2NDM4NA==","user":{"login":"JingsongLi","id":9601882,"node_id":"MDQ6VXNlcjk2MDE4ODI=","avatar_url":"https://avatars.githubusercontent.com/u/9601882?v=4","gravatar_id":"","url":"https://api.github.com/users/JingsongLi","html_url":"https://github.com/JingsongLi","followers_url":"https://api.github.com/users/JingsongLi/followers","following_url":"https://api.github.com/users/JingsongLi/following{/other_user}","gists_url":"https://api.github.com/users/JingsongLi/gists{/gist_id}","starred_url":"https://api.github.com/users/JingsongLi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JingsongLi/subscriptions","organizations_url":"https://api.github.com/users/JingsongLi/orgs","repos_url":"https://api.github.com/users/JingsongLi/repos","events_url":"https://api.github.com/users/JingsongLi/events{/privacy}","received_events_url":"https://api.github.com/users/JingsongLi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T05:54:21Z","updated_at":"2020-09-29T05:54:21Z","author_association":"CONTRIBUTOR","body":"Hi @simonsssu , can you explain more about the user cases?\r\nWithout checkpointing, it seems that consistency is not guaranteed at all. What are the disadvantages of opening checkpointing?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700464384/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700601465","html_url":"https://github.com/apache/iceberg/issues/1504#issuecomment-700601465","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1504","id":700601465,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDYwMTQ2NQ==","user":{"login":"zhangjun0x01","id":25563794,"node_id":"MDQ6VXNlcjI1NTYzNzk0","avatar_url":"https://avatars.githubusercontent.com/u/25563794?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjun0x01","html_url":"https://github.com/zhangjun0x01","followers_url":"https://api.github.com/users/zhangjun0x01/followers","following_url":"https://api.github.com/users/zhangjun0x01/following{/other_user}","gists_url":"https://api.github.com/users/zhangjun0x01/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjun0x01/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjun0x01/subscriptions","organizations_url":"https://api.github.com/users/zhangjun0x01/orgs","repos_url":"https://api.github.com/users/zhangjun0x01/repos","events_url":"https://api.github.com/users/zhangjun0x01/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjun0x01/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T10:02:17Z","updated_at":"2020-09-29T10:02:17Z","author_association":"CONTRIBUTOR","body":"I read it with a program, there are some jar conflicts, after modify the reference, it's fine\r\n\r\nI close it","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700601465/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700649623","html_url":"https://github.com/apache/iceberg/pull/1505#issuecomment-700649623","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1505","id":700649623,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDY0OTYyMw==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T11:47:21Z","updated_at":"2020-09-29T11:47:21Z","author_association":"CONTRIBUTOR","body":"> > We need the build changes, because the spark sql uses Hive code to interact with hive tables.\r\n> \r\n> That sounds like a bug to me. We want to ensure that Spark does not interact with Iceberg tables using Hive. It should use Iceberg directly through the v2 interface instead. We'll need to find out why Spark is trying to load the table incorrectly. What catalog were you using?\r\n\r\nI did the following 2 changes in the Iceberg code, and run the spark3 tests:\r\n- Remove the additional dependencies, and \r\n- Set the default value for  to `false` and run the spark3 tests.\r\n\r\nOne such test is `TestCreateTable.testCreateTable`. The drop table in the \"after\" fails with the exception below.\r\n\r\nIt uses HiveCatalog. See: [code](https://github.com/apache/iceberg/blob/1772f4f27b8a12d3e89a7f65b8b600b717e1f09d/spark/src/test/java/org/apache/iceberg/spark/SparkTestBase.java#L63)\r\n\r\nIt tries to run `DROP TABLE IF EXISTS testhive.default.table` using `spark.sql`. My understanding is that this is spark code, and it tries to delegate it to the embedded `org.apache.hadoop.hive.ql.metadata.Table` class which tries to read the StorageHandler, and fails.\r\n\r\nThis would mean that when Iceberg tables are using the HiveCatalog and Spark code tries to access them with SparkSQL, it will fail for several commands if we do not have `HiveIcebergStorageHandler` on the classpath.\r\n\r\nI am not sure we can change this part of Spark. I think,\r\n- We either have to add a note to the docs that an additional jar is needed if SparkSQL and HiveCatalog is used in conjunction, or \r\n- We have to add the jars to our runtime jars.\r\n\r\nYour thoughts?\r\n\r\nThe exception stack trace:\r\n```\r\n    java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Error in loading storage handler.org.apache.iceberg.mr.hive.HiveIcebergStorageHandler\r\n        at org.apache.hadoop.hive.ql.metadata.Table.getStorageHandler(Table.java:297)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.convertHiveTableToCatalogTable(HiveClientImpl.scala:465)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$getTableOption$3(HiveClientImpl.scala:424)\r\n        at scala.Option.map(Option.scala:230)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$getTableOption$1(HiveClientImpl.scala:424)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:294)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:227)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:226)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:276)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.getTableOption(HiveClientImpl.scala:422)\r\n        at org.apache.spark.sql.hive.client.HiveClient.getTable(HiveClient.scala:90)\r\n        at org.apache.spark.sql.hive.client.HiveClient.getTable$(HiveClient.scala:89)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.getTable(HiveClientImpl.scala:90)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog.getRawTable(HiveExternalCatalog.scala:120)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$getTable$1(HiveExternalCatalog.scala:719)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog.getTable(HiveExternalCatalog.scala:719)\r\n        at org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.getTable(ExternalCatalogWithListener.scala:138)\r\n        at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:446)\r\n        at org.apache.spark.sql.execution.command.DropTableCommand.run(ddl.scala:226)\r\n        at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\r\n        at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\r\n        at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79)\r\n        at org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:229)\r\n        at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)\r\n        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n        at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\r\n        at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n        at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)\r\n        at org.apache.spark.sql.Dataset.<init>(Dataset.scala:229)\r\n        at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\r\n        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\r\n        at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\r\n        at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:606)\r\n        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\r\n        at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:601)\r\n        at org.apache.iceberg.spark.SparkTestBase.sql(SparkTestBase.java:83)\r\n        at org.apache.iceberg.spark.sql.TestCreateTable.dropTestTable(TestCreateTable.java:47)\r\n```","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700649623/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700756335","html_url":"https://github.com/apache/iceberg/issues/1422#issuecomment-700756335","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1422","id":700756335,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDc1NjMzNQ==","user":{"login":"RussellSpitzer","id":413025,"node_id":"MDQ6VXNlcjQxMzAyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/413025?v=4","gravatar_id":"","url":"https://api.github.com/users/RussellSpitzer","html_url":"https://github.com/RussellSpitzer","followers_url":"https://api.github.com/users/RussellSpitzer/followers","following_url":"https://api.github.com/users/RussellSpitzer/following{/other_user}","gists_url":"https://api.github.com/users/RussellSpitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/RussellSpitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RussellSpitzer/subscriptions","organizations_url":"https://api.github.com/users/RussellSpitzer/orgs","repos_url":"https://api.github.com/users/RussellSpitzer/repos","events_url":"https://api.github.com/users/RussellSpitzer/events{/privacy}","received_events_url":"https://api.github.com/users/RussellSpitzer/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T14:46:47Z","updated_at":"2020-09-29T14:46:47Z","author_association":"MEMBER","body":"So it's been a while and we've gotten a bit of feedback on the PR's  - Thanks @kbendick , @aokolnychyi , and @rdblue \r\n\r\nSince I think at the moment it seems like the safer path is the MetadataTables based approach I'm going to start cleaning up and moving forward with that PR. \r\n\r\nFor me the big benefits of the other approach were mainly around code re-use and the possibility of other systems to use the same method for parallelization. Since we haven't really heard from anyone using presto, flink, or whatnot I'm going to assume that the benefit is probably not that great. We can always use a set of common ideas with all these platforms as well each having their own planning algorithm if need be.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700756335/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700794725","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-700794725","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":700794725,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDc5NDcyNQ==","user":{"login":"electrum","id":9230,"node_id":"MDQ6VXNlcjkyMzA=","avatar_url":"https://avatars.githubusercontent.com/u/9230?v=4","gravatar_id":"","url":"https://api.github.com/users/electrum","html_url":"https://github.com/electrum","followers_url":"https://api.github.com/users/electrum/followers","following_url":"https://api.github.com/users/electrum/following{/other_user}","gists_url":"https://api.github.com/users/electrum/gists{/gist_id}","starred_url":"https://api.github.com/users/electrum/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/electrum/subscriptions","organizations_url":"https://api.github.com/users/electrum/orgs","repos_url":"https://api.github.com/users/electrum/repos","events_url":"https://api.github.com/users/electrum/events{/privacy}","received_events_url":"https://api.github.com/users/electrum/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T15:45:20Z","updated_at":"2020-09-29T15:45:20Z","author_association":"CONTRIBUTOR","body":"The question is what to do when we access a historical snapshot for older snapshots. It seems we have a few choices:\r\n\r\n1. Use the current schema, as we do today.\r\n2. Fail the query.\r\n3. Fallback to reading old metadata files.\r\n\r\nUsing the current schema seems like the worst choice, as that results in inconsistent behavior for reasons that are invisible to the user. Failing the query would break behavior that works today.\r\n\r\nWhile I agree that having more code to handle older data is annoying, the complexity here seems low (~20 lines of code) relative to the benefit. We have much higher complexity in other areas, such as supporting non-projected identity columns for converted Hive tables (and that's not even covered by the specification).\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700794725/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700809758","html_url":"https://github.com/apache/iceberg/pull/1478#issuecomment-700809758","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1478","id":700809758,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDgwOTc1OA==","user":{"login":"marton-bod","id":19599214,"node_id":"MDQ6VXNlcjE5NTk5MjE0","avatar_url":"https://avatars.githubusercontent.com/u/19599214?v=4","gravatar_id":"","url":"https://api.github.com/users/marton-bod","html_url":"https://github.com/marton-bod","followers_url":"https://api.github.com/users/marton-bod/followers","following_url":"https://api.github.com/users/marton-bod/following{/other_user}","gists_url":"https://api.github.com/users/marton-bod/gists{/gist_id}","starred_url":"https://api.github.com/users/marton-bod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marton-bod/subscriptions","organizations_url":"https://api.github.com/users/marton-bod/orgs","repos_url":"https://api.github.com/users/marton-bod/repos","events_url":"https://api.github.com/users/marton-bod/events{/privacy}","received_events_url":"https://api.github.com/users/marton-bod/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T16:09:21Z","updated_at":"2020-09-29T16:09:21Z","author_association":"COLLABORATOR","body":"Thanks a lot for your review @rdblue, appreciate it! I agree with your comments and have made the improvements.\r\nGood idea to use `DynMethods`/`DynConstructors`, quite handy!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700809758/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700849695","html_url":"https://github.com/apache/iceberg/pull/1509#issuecomment-700849695","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1509","id":700849695,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDg0OTY5NQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T17:02:42Z","updated_at":"2020-09-29T17:02:42Z","author_association":"CONTRIBUTOR","body":"Looks good, @JingsongLi! I'd like to remove the Hadoop `Configuration` from the API, but that was an existing problem so there's no need to block this PR. Thank you!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700849695/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700856781","html_url":"https://github.com/apache/iceberg/pull/1523#issuecomment-700856781","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1523","id":700856781,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDg1Njc4MQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T17:14:41Z","updated_at":"2020-09-29T17:14:41Z","author_association":"CONTRIBUTOR","body":"Looks great! Thank you, @HeartSaVioR!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700856781/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700876752","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-700876752","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":700876752,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDg3Njc1Mg==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T17:48:47Z","updated_at":"2020-09-29T17:48:47Z","author_association":"CONTRIBUTOR","body":"> While I agree that having more code to handle older data is annoying, the complexity here seems low (~20 lines of code) relative to the benefit.\r\n\r\nI agree with that. And since we plan to make schema tracking required in v2, we can easily remove this work-around.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700876752/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700878417","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-700878417","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":700878417,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDg3ODQxNw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T17:51:42Z","updated_at":"2020-09-29T17:51:42Z","author_association":"CONTRIBUTOR","body":"@wypoon, are you interested in working on both? We could update this PR to use the work-around you implemented and to update the `Snapshot` API (add `Snapshot.schema()`). Then we can add the new schema tracking separately. What do you think?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700878417/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700880653","html_url":"https://github.com/apache/iceberg/issues/741#issuecomment-700880653","issue_url":"https://api.github.com/repos/apache/iceberg/issues/741","id":700880653,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDg4MDY1Mw==","user":{"login":"holdenk","id":59893,"node_id":"MDQ6VXNlcjU5ODkz","avatar_url":"https://avatars.githubusercontent.com/u/59893?v=4","gravatar_id":"","url":"https://api.github.com/users/holdenk","html_url":"https://github.com/holdenk","followers_url":"https://api.github.com/users/holdenk/followers","following_url":"https://api.github.com/users/holdenk/following{/other_user}","gists_url":"https://api.github.com/users/holdenk/gists{/gist_id}","starred_url":"https://api.github.com/users/holdenk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/holdenk/subscriptions","organizations_url":"https://api.github.com/users/holdenk/orgs","repos_url":"https://api.github.com/users/holdenk/repos","events_url":"https://api.github.com/users/holdenk/events{/privacy}","received_events_url":"https://api.github.com/users/holdenk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T17:55:41Z","updated_at":"2020-09-29T17:55:41Z","author_association":"CONTRIBUTOR","body":"Was this resolved in https://github.com/apache/iceberg/pull/745 ?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700880653/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700901054","html_url":"https://github.com/apache/iceberg/pull/1478#issuecomment-700901054","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1478","id":700901054,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDkwMTA1NA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T18:31:36Z","updated_at":"2020-09-29T18:32:15Z","author_association":"CONTRIBUTOR","body":"Thank you, @marton-bod! Looking good but there are a few more issues. Mostly, I'd prefer not to parse values in tests.\r\n\r\nAnd, if tests pass in Java 11, I think we should go ahead an keep the module in Java 11 as well.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700901054/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700902994","html_url":"https://github.com/apache/iceberg/pull/1425#issuecomment-700902994","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1425","id":700902994,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDkwMjk5NA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T18:34:54Z","updated_at":"2020-09-29T18:34:54Z","author_association":"CONTRIBUTOR","body":"@shardulm94, it sounds like we don't want to add the entries table, and we expect the files table to change to match the docs. In that case, I don't think there is much to do in this PR so I'll close it. Feel free to reopen it if you'd like to update it. Thanks!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700902994/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700905899","html_url":"https://github.com/apache/iceberg/issues/417#issuecomment-700905899","issue_url":"https://api.github.com/repos/apache/iceberg/issues/417","id":700905899,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDkwNTg5OQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T18:39:55Z","updated_at":"2020-09-29T18:39:55Z","author_association":"CONTRIBUTOR","body":"@ericsun2, what do you think about allowing type promotion from long to timestamp instead? Then you'd be able to use the field as a timestamp and be able to partition by it.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700905899/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700913708","html_url":"https://github.com/apache/iceberg/issues/417#issuecomment-700913708","issue_url":"https://api.github.com/repos/apache/iceberg/issues/417","id":700913708,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDkxMzcwOA==","user":{"login":"ericsun2","id":8866410,"node_id":"MDQ6VXNlcjg4NjY0MTA=","avatar_url":"https://avatars.githubusercontent.com/u/8866410?v=4","gravatar_id":"","url":"https://api.github.com/users/ericsun2","html_url":"https://github.com/ericsun2","followers_url":"https://api.github.com/users/ericsun2/followers","following_url":"https://api.github.com/users/ericsun2/following{/other_user}","gists_url":"https://api.github.com/users/ericsun2/gists{/gist_id}","starred_url":"https://api.github.com/users/ericsun2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ericsun2/subscriptions","organizations_url":"https://api.github.com/users/ericsun2/orgs","repos_url":"https://api.github.com/users/ericsun2/repos","events_url":"https://api.github.com/users/ericsun2/events{/privacy}","received_events_url":"https://api.github.com/users/ericsun2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T18:53:01Z","updated_at":"2020-09-29T18:56:03Z","author_association":"NONE","body":"\"type promotion\" is only 50% of the case/problem. For a given numeric value, it can represent various precision and hence different rollup/truncate logic.\r\n\r\nIf we limit the API to only take TIMESTAMP or EPOCH_MILLIS as input, then \"type promotion\" will be probably OK (except for time_zone override at partition spec level: do we only honor `spark.sql.session.timeZone` or `user.timezone`?). But users will have to do the math to convert epoch second/minute/hour offset value to millisecond first.\r\n\r\nWill the extra math conversion impact the predicate evaluation and pruning at query planning time later?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700913708/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700918564","html_url":"https://github.com/apache/iceberg/issues/1422#issuecomment-700918564","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1422","id":700918564,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDkxODU2NA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T19:01:23Z","updated_at":"2020-09-29T19:01:23Z","author_association":"CONTRIBUTOR","body":"I think that I agree with the metadata table approach. Because Presto can run tasks and planning at the same time, this is less of an issue. And the work done for Spark in option 2 could translate into a parallel scan on a Presto metadata table as well (converting partition predicates to filters on metadata table columns). Flink is much more likely to consume tables incrementally, so I think it wouldn't be a big issue there for now (but would be nice to hear from them).\r\n\r\nRisk is lower with option 2, and I think it sounds like the better option. It also pushes on the metadata tables in healthy ways: it would incentivize building pushdown in the files and entries metadata tables and might require adding a `delete_files` metadata table. Those are good side-effects of implementing this that way.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700918564/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700939262","html_url":"https://github.com/apache/iceberg/issues/417#issuecomment-700939262","issue_url":"https://api.github.com/repos/apache/iceberg/issues/417","id":700939262,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDkzOTI2Mg==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T19:36:32Z","updated_at":"2020-09-29T19:36:32Z","author_association":"CONTRIBUTOR","body":"Type promotion is already supported for some formats, like `TIMESTAMP_MILLIS` in Parquet. Iceberg will convert those values to microseconds when reading and can interact with them like normal timestamps. For type promotion on a long column, we would need to store metadata somewhere for how to interpret the long value and do the conversion to micros on read. Everything would then work like a normal timestamp.\r\n\r\nFor your time zone questions, Iceberg doesn't modify values. It is up to processing engines to modify values when it makes sense. Iceberg will store a timestamp in microseconds from epoch, UTC, and return the same value. Conversion from the session time zone or using a specific zone to UTC is always handled by processing engines.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700939262/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700945614","html_url":"https://github.com/apache/iceberg/pull/1515#issuecomment-700945614","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1515","id":700945614,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDk0NTYxNA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T19:44:53Z","updated_at":"2020-09-29T19:44:53Z","author_association":"CONTRIBUTOR","body":"@simonsssu, can you be more specific about what the behavior is in your implementation? Specifically, can you compare the checkpoint-based approach with the alternative? Are files released from writers on a timer? When are those files committed by the downstream writer? What guarantees are there (at least once, exactly once)?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700945614/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700948856","html_url":"https://github.com/apache/iceberg/pull/1505#issuecomment-700948856","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1505","id":700948856,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDk0ODg1Ng==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T19:50:40Z","updated_at":"2020-09-29T19:52:23Z","author_association":"CONTRIBUTOR","body":"Spark is using a v1 command to drop the table: `org.apache.spark.sql.execution.command.DropTableCommand`. That is unexpected because the test should be using an Iceberg implementation of Spark's `TableCatalog` for all of these operations. Can you find out what catalog was being used? My guess is that it was the built-in [`spark_catalog`](https://github.com/apache/iceberg/blob/1772f4f27b8a12d3e89a7f65b8b600b717e1f09d/spark3/src/test/java/org/apache/iceberg/spark/SparkCatalogTestBase.java#L66-L71) and that somehow the session catalog wrapper that we injected did not correctly detect that this table is Iceberg and not Hive.\r\n\r\nSo the question is probably why is [`loadTable`](https://github.com/apache/iceberg/blob/1772f4f27b8a12d3e89a7f65b8b600b717e1f09d/spark3/src/main/java/org/apache/iceberg/spark/SparkSessionCatalog.java#L116-L122) catching `NoSuchTableException` and returning the table through Hive?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700948856/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700956120","html_url":"https://github.com/apache/iceberg/issues/1422#issuecomment-700956120","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1422","id":700956120,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDk1NjEyMA==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T20:05:12Z","updated_at":"2020-09-29T20:05:26Z","author_association":"CONTRIBUTOR","body":"Sounds like we have an initial plan then. Excited to see progress on this.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700956120/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700957031","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-700957031","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":700957031,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDk1NzAzMQ==","user":{"login":"edwinchoi","id":773193,"node_id":"MDQ6VXNlcjc3MzE5Mw==","avatar_url":"https://avatars.githubusercontent.com/u/773193?v=4","gravatar_id":"","url":"https://api.github.com/users/edwinchoi","html_url":"https://github.com/edwinchoi","followers_url":"https://api.github.com/users/edwinchoi/followers","following_url":"https://api.github.com/users/edwinchoi/following{/other_user}","gists_url":"https://api.github.com/users/edwinchoi/gists{/gist_id}","starred_url":"https://api.github.com/users/edwinchoi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/edwinchoi/subscriptions","organizations_url":"https://api.github.com/users/edwinchoi/orgs","repos_url":"https://api.github.com/users/edwinchoi/repos","events_url":"https://api.github.com/users/edwinchoi/events{/privacy}","received_events_url":"https://api.github.com/users/edwinchoi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T20:07:02Z","updated_at":"2020-09-29T20:07:02Z","author_association":"NONE","body":"I think you need to check `.snapshots()` not `.snapshotLog()`. The latter seems to only retain the history of changes since the table was created/replaced. You can see in `TableMetadata.buildReplacement` that the prior history entries are not retained in the replacement.\r\n\r\nAlso, from what I can tell, the metadata is always refreshed after the snapshot has been created (e.g., `SnapshotProducer.commit()`, `BaseTransaction.commitTransaction()`, etc... each refresh the metadata as part of the commit protocol). If that is always the case, then the loop should match the `Snapshot` with the first `MetadataLogEntry` where `MetadataLogEntry.timestampMillis() >= Snapshot.timestampMillis()`, and not the last `MetadataLogEntry.timestampMillis() <= Snapshot.timestampMillis()`.\r\n\r\nAs a sanity check, the code could check the expected snapshot-id against the `TableMetadata` that is read.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700957031/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700959643","html_url":"https://github.com/apache/iceberg/issues/417#issuecomment-700959643","issue_url":"https://api.github.com/repos/apache/iceberg/issues/417","id":700959643,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDk1OTY0Mw==","user":{"login":"ericsun2","id":8866410,"node_id":"MDQ6VXNlcjg4NjY0MTA=","avatar_url":"https://avatars.githubusercontent.com/u/8866410?v=4","gravatar_id":"","url":"https://api.github.com/users/ericsun2","html_url":"https://github.com/ericsun2","followers_url":"https://api.github.com/users/ericsun2/followers","following_url":"https://api.github.com/users/ericsun2/following{/other_user}","gists_url":"https://api.github.com/users/ericsun2/gists{/gist_id}","starred_url":"https://api.github.com/users/ericsun2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ericsun2/subscriptions","organizations_url":"https://api.github.com/users/ericsun2/orgs","repos_url":"https://api.github.com/users/ericsun2/repos","events_url":"https://api.github.com/users/ericsun2/events{/privacy}","received_events_url":"https://api.github.com/users/ericsun2/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T20:12:10Z","updated_at":"2020-09-29T20:12:32Z","author_association":"NONE","body":"I am not trying to change how Iceberg serialize TIMESTAMP type. I am hoping that Iceberg can maximize the expressiveness and CBO/planner efficiency with clearer and more straightforward partition spec.\r\n\r\nFor example, \r\n\r\n1. express the epoch offset precision in partition spec **without** adding an extra derived physical field in the data file \r\n2. convert value to epoch millisecond during ETL as an extra field, then use this new field in partition spec\r\n\r\n--\r\n\r\n1. express the time zone in partition spec **without** adding an extra derived physical field in the data file \r\n2. convert value to TIMESTAMP in a particular time zone during ETL as an extra field, then use this new field in partition spec\r\n\r\nIf we want to make the most of the hidden partition style, I still favor option (1) a bit more :-)","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700959643/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700967918","html_url":"https://github.com/apache/iceberg/issues/1485#issuecomment-700967918","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1485","id":700967918,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDk2NzkxOA==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T20:28:05Z","updated_at":"2020-09-29T20:29:16Z","author_association":"CONTRIBUTOR","body":"This is a great discussion, thanks to everyone for taking a look at this!\r\n\r\nI completely agree with @rdblue and @bryanck that it is up to Spark to invalidate the cached relations just like it did for V1 tables. The only case where we would have to match it in Iceberg is in our stored procedures that may rollback table state or produce new snapshots (we will review this case by case).\r\n\r\nThen I'll sum up this discussion with the following points (feel free to correct):\r\n- Spark should refresh its cache for V2 tables to match V1 behavior (covers REFRESH, INSERT, etc).\r\n- Iceberg should refresh Spark cache when modifying tables in procedures.\r\n- We should extend `SparkTable` with an ability to refresh the underlying table if Iceberg caching catalog is not used to have consistent behavior independently whether cashing is enabled in Iceberg catalogs.\r\n- We need to override `equals` and `hashCode` in our table implementations.\r\n- We need to route writes through `IcebergSource` to catalogs.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700967918/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700971142","html_url":"https://github.com/apache/iceberg/pull/1473#issuecomment-700971142","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1473","id":700971142,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDk3MTE0Mg==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T20:34:33Z","updated_at":"2020-09-29T20:34:33Z","author_association":"CONTRIBUTOR","body":"@liukun4515, it will be great to have more people contributing to this. I'd like get this in ASAP.\r\n\r\nSounds like we just reached a consensus in #1485, which was a blocker for this work. I would like to gather more feedback from the community on the approach I am taking to move forward with this PR. I also have a few minor updates to the [design doc](https://docs.google.com/document/d/1Nf8c16R2hj4lSc-4sQg4oiUUV_F4XqZKth1woEo6TN8/edit#heading=h.v8gsu2fe19q2) and we then will be able to split the work between folks.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700971142/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700972656","html_url":"https://github.com/apache/iceberg/pull/1473#issuecomment-700972656","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1473","id":700972656,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDk3MjY1Ng==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T20:37:41Z","updated_at":"2020-09-29T20:37:41Z","author_association":"CONTRIBUTOR","body":"This is a list of points we need to discuss:\r\n\r\n- Overall procedure API\r\n- Whether we should care about overloaded procedures\r\n- Having separate namespace and table params\r\n- Whether we should allow quoted identifiers as params","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700972656/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700973213","html_url":"https://github.com/apache/iceberg/issues/1485#issuecomment-700973213","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1485","id":700973213,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMDk3MzIxMw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T20:38:52Z","updated_at":"2020-09-29T20:38:52Z","author_association":"CONTRIBUTOR","body":"> We need to override equals and hashCode in our table implementations.\r\n\r\nWhat would this be based on? The table identifier or path?\r\n\r\n> We need to route writes through IcebergSource to catalogs.\r\n\r\nYes, I think this is a good idea. We will need to make sure we have a good plan for how to pass paths through `Identifier` though.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/700973213/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701009397","html_url":"https://github.com/apache/iceberg/issues/1485#issuecomment-701009397","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1485","id":701009397,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTAwOTM5Nw==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T21:47:53Z","updated_at":"2020-09-29T21:47:53Z","author_association":"CONTRIBUTOR","body":"> What would this be based on? The table identifier or path?\r\n\r\nI think `SparkTable` can delegate to `equals` and `hashCode` of the underlying Iceberg `Table`. That, in turn, can use either its name (contains catalog name + full table name) or table location. If we use table names (i.e. identifiers), the same table loaded through different catalogs will NOT be considered the same. So it seems the table location is more promising. \r\n\r\n@rdblue, thoughts?\r\n","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701009397/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701028183","html_url":"https://github.com/apache/iceberg/issues/1485#issuecomment-701028183","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1485","id":701028183,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTAyODE4Mw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T22:35:33Z","updated_at":"2020-09-29T22:35:33Z","author_association":"CONTRIBUTOR","body":"I think equality should be by full table name table for metastore tables or by location for Hadoop tables.\r\n\r\nTables can share the same location, so it wouldn't be safe to assume that two tables are the same based on the backing location. And I also don't think we need to solve the case where the same table is loaded by two different catalogs. That's not going to come up very often and it is entirely reasonable to cache them separately.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701028183/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701030861","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-701030861","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":701030861,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTAzMDg2MQ==","user":{"login":"wypoon","id":3925490,"node_id":"MDQ6VXNlcjM5MjU0OTA=","avatar_url":"https://avatars.githubusercontent.com/u/3925490?v=4","gravatar_id":"","url":"https://api.github.com/users/wypoon","html_url":"https://github.com/wypoon","followers_url":"https://api.github.com/users/wypoon/followers","following_url":"https://api.github.com/users/wypoon/following{/other_user}","gists_url":"https://api.github.com/users/wypoon/gists{/gist_id}","starred_url":"https://api.github.com/users/wypoon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wypoon/subscriptions","organizations_url":"https://api.github.com/users/wypoon/orgs","repos_url":"https://api.github.com/users/wypoon/repos","events_url":"https://api.github.com/users/wypoon/events{/privacy}","received_events_url":"https://api.github.com/users/wypoon/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T22:44:02Z","updated_at":"2020-09-29T22:44:02Z","author_association":"CONTRIBUTOR","body":"Thanks everyone for your interest in this work!\r\n@rdblue, I think it makes sense to get a version of this PR in first, and separately, do the work to associate a schema with each snapshot, while aligning this PR with the other work as much as possible.\r\nTo check that we're on the same page, your original suggestion was to add a list `schemas` to table metadata, add a `schema-id` to each schema, and add a `schema-id` to each snapshot. When this is done, `Snapshot` should have a `schema()` method.\r\nIIUC, the schema still has to be read from the table metadata file, referenced using the `schema-id` from the snapshot. Thus an implementation of `Snapshot` would need a reference to the table metadata, correct?\r\nRight now, to get the schema, I need to start from the table metadata file. There is currently no obvious way to get from snapshot to table metadata. I'd need to change the implementation of `Snapshot` to have a reference to the current metadata. Does that make sense to you? Or am I missing something?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701030861/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701035738","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-701035738","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":701035738,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTAzNTczOA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T23:00:04Z","updated_at":"2020-09-29T23:00:04Z","author_association":"CONTRIBUTOR","body":"Good observations, @edwinchoi. I'm not sure why the snapshot log is cleared out when a table is replaced. That log should track the snapshot that was current a given time, which seems like the right one to use. We use it for time travel queries, for example. But since the log is not there, we can use the metadata file log instead as you suggested to find the snapshot that was current at some time.\r\n\r\nWe should not use the list of snapshots because there is no guarantee that any given snapshot was ever the current version (like a branch in git that is never the main branch).","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701035738/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701036575","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-701036575","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":701036575,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTAzNjU3NQ==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T23:02:34Z","updated_at":"2020-09-29T23:02:34Z","author_association":"CONTRIBUTOR","body":"> There is currently no obvious way to get from snapshot to table metadata\r\n\r\nYes, we will need to have a way to get the right schema from table metadata by ID. I think what might make sense for now is to pass a `Function<Long, Schema>` in that does the lookup by snapshot ID. Then the `schemaForSnapshot` method could be package-private and passed into the `Snapshot` through its constructor. All of this would be package-private so we can change it later as we need to.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701036575/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701043239","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-701043239","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":701043239,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTA0MzIzOQ==","user":{"login":"wypoon","id":3925490,"node_id":"MDQ6VXNlcjM5MjU0OTA=","avatar_url":"https://avatars.githubusercontent.com/u/3925490?v=4","gravatar_id":"","url":"https://api.github.com/users/wypoon","html_url":"https://github.com/wypoon","followers_url":"https://api.github.com/users/wypoon/followers","following_url":"https://api.github.com/users/wypoon/following{/other_user}","gists_url":"https://api.github.com/users/wypoon/gists{/gist_id}","starred_url":"https://api.github.com/users/wypoon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wypoon/subscriptions","organizations_url":"https://api.github.com/users/wypoon/orgs","repos_url":"https://api.github.com/users/wypoon/repos","events_url":"https://api.github.com/users/wypoon/events{/privacy}","received_events_url":"https://api.github.com/users/wypoon/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T23:22:14Z","updated_at":"2020-09-29T23:22:14Z","author_association":"CONTRIBUTOR","body":"> > There is currently no obvious way to get from snapshot to table metadata\r\n> \r\n> Yes, we will need to have a way to get the right schema from table metadata by ID. I think what might make sense for now is to pass a `Function<Long, Schema>` in that does the lookup by snapshot ID. Then the `schemaForSnapshot` method could be package-private and passed into the `Snapshot` through its constructor. All of this would be package-private so we can change it later as we need to.\r\n\r\nIt seems to me that it'd be simpler if in the future, `Snapshot` would have a `schemaId()` method rather than a `schema()` method; since the places that need to obtain a schema for a `Snapshot` already have a reference to `TableMetadata` at hand, and only need to call `Snapshot.schemaId()` and then use it to look up the schema in the `TableMetadata`. So the implementation of `getSchemaForSnapshot(long)` in `BaseTable` can stay the way it is now, and change later when `Snapshot.schemaId()` becomes available.\r\nWhat do you think?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701043239/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701046130","html_url":"https://github.com/apache/iceberg/pull/1523#issuecomment-701046130","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1523","id":701046130,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTA0NjEzMA==","user":{"login":"HeartSaVioR","id":1317309,"node_id":"MDQ6VXNlcjEzMTczMDk=","avatar_url":"https://avatars.githubusercontent.com/u/1317309?v=4","gravatar_id":"","url":"https://api.github.com/users/HeartSaVioR","html_url":"https://github.com/HeartSaVioR","followers_url":"https://api.github.com/users/HeartSaVioR/followers","following_url":"https://api.github.com/users/HeartSaVioR/following{/other_user}","gists_url":"https://api.github.com/users/HeartSaVioR/gists{/gist_id}","starred_url":"https://api.github.com/users/HeartSaVioR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HeartSaVioR/subscriptions","organizations_url":"https://api.github.com/users/HeartSaVioR/orgs","repos_url":"https://api.github.com/users/HeartSaVioR/repos","events_url":"https://api.github.com/users/HeartSaVioR/events{/privacy}","received_events_url":"https://api.github.com/users/HeartSaVioR/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T23:30:21Z","updated_at":"2020-09-29T23:30:21Z","author_association":"CONTRIBUTOR","body":"Thanks for reviewing and merging!","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701046130/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701049992","html_url":"https://github.com/apache/iceberg/issues/1485#issuecomment-701049992","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1485","id":701049992,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTA0OTk5Mg==","user":{"login":"aokolnychyi","id":6235869,"node_id":"MDQ6VXNlcjYyMzU4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/6235869?v=4","gravatar_id":"","url":"https://api.github.com/users/aokolnychyi","html_url":"https://github.com/aokolnychyi","followers_url":"https://api.github.com/users/aokolnychyi/followers","following_url":"https://api.github.com/users/aokolnychyi/following{/other_user}","gists_url":"https://api.github.com/users/aokolnychyi/gists{/gist_id}","starred_url":"https://api.github.com/users/aokolnychyi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aokolnychyi/subscriptions","organizations_url":"https://api.github.com/users/aokolnychyi/orgs","repos_url":"https://api.github.com/users/aokolnychyi/repos","events_url":"https://api.github.com/users/aokolnychyi/events{/privacy}","received_events_url":"https://api.github.com/users/aokolnychyi/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-29T23:41:59Z","updated_at":"2020-09-29T23:42:12Z","author_association":"CONTRIBUTOR","body":"Actually, you are right. We probably even *should* cache them separately. Let me submit a PR for this.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701049992/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701059248","html_url":"https://github.com/apache/iceberg/pull/1508#issuecomment-701059248","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1508","id":701059248,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTA1OTI0OA==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T00:10:04Z","updated_at":"2020-09-30T00:10:04Z","author_association":"CONTRIBUTOR","body":"I posted in a comment above, but I'll echo it here: I don't think we should be adding anything to the `Table` API that we are going to want to remove later. Since we don't have schema ids, I don't think we can add the API that we eventually want right now. Adding `Snapshot.schema` seems like something we can do earlier and that would be the most friendly API long term. That's why I suggest it. We can do something else, as long as we are careful and only add non-public methods.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701059248/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701098117","html_url":"https://github.com/apache/iceberg/pull/1499#issuecomment-701098117","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1499","id":701098117,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTA5ODExNw==","user":{"login":"electrum","id":9230,"node_id":"MDQ6VXNlcjkyMzA=","avatar_url":"https://avatars.githubusercontent.com/u/9230?v=4","gravatar_id":"","url":"https://api.github.com/users/electrum","html_url":"https://github.com/electrum","followers_url":"https://api.github.com/users/electrum/followers","following_url":"https://api.github.com/users/electrum/following{/other_user}","gists_url":"https://api.github.com/users/electrum/gists{/gist_id}","starred_url":"https://api.github.com/users/electrum/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/electrum/subscriptions","organizations_url":"https://api.github.com/users/electrum/orgs","repos_url":"https://api.github.com/users/electrum/repos","events_url":"https://api.github.com/users/electrum/events{/privacy}","received_events_url":"https://api.github.com/users/electrum/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T01:00:28Z","updated_at":"2020-09-30T01:00:28Z","author_association":"CONTRIBUTOR","body":"I've thought a lot about equality deletes and I think they are the wrong design for what I see as the common case. Deletes often occur declaratively via a SQL statement such as `DELETE FROM t WHERE x = 5`. We can execute this very efficiently by simply recording the `x = 5` rather than finding and recording all matching rows. That's great.\r\n\r\nWhat doesn't make sense is recording the file name. The delete applies to everything visible in the table. I actually can't think of any reason why we'd want to restrict it to a specific file. One way to solve this is to make the file name optional -- treat it as a special column in the table, that is only present in the delete file if needed as a filter.\r\n\r\nIf we remove the file name, then the equality delete becomes very small -- we would typically expect only one record per delete operation. At that point, having a separate file is overkill. Reading a separate file during planning for a single record is expensive. It would be better to store the equality delete inline, with the other metadata.\r\n\r\nNow that equality deletes are small and inline, we no longer have to limit them to simple equality. Basic range filters would cover common use cases, such as _\"delete all data older than X\"_.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701098117/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701114656","html_url":"https://github.com/apache/iceberg/pull/1515#issuecomment-701114656","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1515","id":701114656,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTExNDY1Ng==","user":{"login":"simonsssu","id":12323514,"node_id":"MDQ6VXNlcjEyMzIzNTE0","avatar_url":"https://avatars.githubusercontent.com/u/12323514?v=4","gravatar_id":"","url":"https://api.github.com/users/simonsssu","html_url":"https://github.com/simonsssu","followers_url":"https://api.github.com/users/simonsssu/followers","following_url":"https://api.github.com/users/simonsssu/following{/other_user}","gists_url":"https://api.github.com/users/simonsssu/gists{/gist_id}","starred_url":"https://api.github.com/users/simonsssu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/simonsssu/subscriptions","organizations_url":"https://api.github.com/users/simonsssu/orgs","repos_url":"https://api.github.com/users/simonsssu/repos","events_url":"https://api.github.com/users/simonsssu/events{/privacy}","received_events_url":"https://api.github.com/users/simonsssu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T02:05:12Z","updated_at":"2020-09-30T02:05:12Z","author_association":"CONTRIBUTOR","body":"> writers\r\n\r\nOK， I will add more documents.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701114656/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701146727","html_url":"https://github.com/apache/iceberg/issues/1524#issuecomment-701146727","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1524","id":701146727,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTE0NjcyNw==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T04:16:21Z","updated_at":"2020-09-30T04:16:31Z","author_association":"CONTRIBUTOR","body":"Thanks for bringing this up. As mentioned in the really large footer, we use [MkDocs](https://www.mkdocs.org/) for generating the documentation.\r\n\r\nI'm not incredibly familiar with the MkDocs system and how we configure it (especially the UI theme), but this feels like an issue that might be brought up to them.\r\n\r\nI'll let anybody with more experience in how the docs are generated chime in if possible.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701146727/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701147782","html_url":"https://github.com/apache/iceberg/issues/1468#issuecomment-701147782","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1468","id":701147782,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTE0Nzc4Mg==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T04:21:19Z","updated_at":"2020-09-30T04:21:19Z","author_association":"CONTRIBUTOR","body":"> We're doing something pluggable but the default implementation is on top of DynamoDB.\r\n\r\nThat's a good idea. I know that AWS Glue is backed by DynamoDB, so if you can make a catalog using Dynamo, then possibly the AWS team can implement the atomic swap in Glue. If I'm not mistaken, you'd need to use either read / write consistency or possibly a DynamoDB versioned object.\r\n\r\nLooking forward to seeing the DynamoDB catalog as I assume many companies looking to write to S3 are also likely using DynamoDB. I know that my company uses DynamoDB a ton so this would be a great work around until there is Glue Catalog support (which I've been giving some thought to myself).","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701147782/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701148058","html_url":"https://github.com/apache/iceberg/issues/1300#issuecomment-701148058","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1300","id":701148058,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTE0ODA1OA==","user":{"login":"kbendick","id":9833362,"node_id":"MDQ6VXNlcjk4MzMzNjI=","avatar_url":"https://avatars.githubusercontent.com/u/9833362?v=4","gravatar_id":"","url":"https://api.github.com/users/kbendick","html_url":"https://github.com/kbendick","followers_url":"https://api.github.com/users/kbendick/followers","following_url":"https://api.github.com/users/kbendick/following{/other_user}","gists_url":"https://api.github.com/users/kbendick/gists{/gist_id}","starred_url":"https://api.github.com/users/kbendick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kbendick/subscriptions","organizations_url":"https://api.github.com/users/kbendick/orgs","repos_url":"https://api.github.com/users/kbendick/repos","events_url":"https://api.github.com/users/kbendick/events{/privacy}","received_events_url":"https://api.github.com/users/kbendick/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T04:22:35Z","updated_at":"2020-09-30T04:22:35Z","author_association":"CONTRIBUTOR","body":"Given that our docs are developed from markdown in YAML files, I might go ahead and add this in.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701148058/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701174419","html_url":"https://github.com/apache/iceberg/pull/1514#issuecomment-701174419","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1514","id":701174419,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTE3NDQxOQ==","user":{"login":"mehtaashish23","id":75326,"node_id":"MDQ6VXNlcjc1MzI2","avatar_url":"https://avatars.githubusercontent.com/u/75326?v=4","gravatar_id":"","url":"https://api.github.com/users/mehtaashish23","html_url":"https://github.com/mehtaashish23","followers_url":"https://api.github.com/users/mehtaashish23/followers","following_url":"https://api.github.com/users/mehtaashish23/following{/other_user}","gists_url":"https://api.github.com/users/mehtaashish23/gists{/gist_id}","starred_url":"https://api.github.com/users/mehtaashish23/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mehtaashish23/subscriptions","organizations_url":"https://api.github.com/users/mehtaashish23/orgs","repos_url":"https://api.github.com/users/mehtaashish23/repos","events_url":"https://api.github.com/users/mehtaashish23/events{/privacy}","received_events_url":"https://api.github.com/users/mehtaashish23/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T05:59:53Z","updated_at":"2020-09-30T05:59:53Z","author_association":"CONTRIBUTOR","body":"@rdblue Incorporated the feedback, open for review.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701174419/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701237282","html_url":"https://github.com/apache/iceberg/issues/1090#issuecomment-701237282","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1090","id":701237282,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTIzNzI4Mg==","user":{"login":"chenjunjiedada","id":3960228,"node_id":"MDQ6VXNlcjM5NjAyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3960228?v=4","gravatar_id":"","url":"https://api.github.com/users/chenjunjiedada","html_url":"https://github.com/chenjunjiedada","followers_url":"https://api.github.com/users/chenjunjiedada/followers","following_url":"https://api.github.com/users/chenjunjiedada/following{/other_user}","gists_url":"https://api.github.com/users/chenjunjiedada/gists{/gist_id}","starred_url":"https://api.github.com/users/chenjunjiedada/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chenjunjiedada/subscriptions","organizations_url":"https://api.github.com/users/chenjunjiedada/orgs","repos_url":"https://api.github.com/users/chenjunjiedada/repos","events_url":"https://api.github.com/users/chenjunjiedada/events{/privacy}","received_events_url":"https://api.github.com/users/chenjunjiedada/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T08:14:27Z","updated_at":"2020-09-30T08:14:27Z","author_association":"COLLABORATOR","body":"I haven't seen this happen recently.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701237282/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701240758","html_url":"https://github.com/apache/iceberg/pull/1186#issuecomment-701240758","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1186","id":701240758,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTI0MDc1OA==","user":{"login":"chenjunjiedada","id":3960228,"node_id":"MDQ6VXNlcjM5NjAyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3960228?v=4","gravatar_id":"","url":"https://api.github.com/users/chenjunjiedada","html_url":"https://github.com/chenjunjiedada","followers_url":"https://api.github.com/users/chenjunjiedada/followers","following_url":"https://api.github.com/users/chenjunjiedada/following{/other_user}","gists_url":"https://api.github.com/users/chenjunjiedada/gists{/gist_id}","starred_url":"https://api.github.com/users/chenjunjiedada/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chenjunjiedada/subscriptions","organizations_url":"https://api.github.com/users/chenjunjiedada/orgs","repos_url":"https://api.github.com/users/chenjunjiedada/repos","events_url":"https://api.github.com/users/chenjunjiedada/events{/privacy}","received_events_url":"https://api.github.com/users/chenjunjiedada/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T08:21:12Z","updated_at":"2020-09-30T08:21:12Z","author_association":"COLLABORATOR","body":"The PR: https://github.com/apache/iceberg/pull/1219 starting to replace `IndexedRecord` to `Record`.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701240758/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701260351","html_url":"https://github.com/apache/iceberg/pull/1522#issuecomment-701260351","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1522","id":701260351,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTI2MDM1MQ==","user":{"login":"chenjunjiedada","id":3960228,"node_id":"MDQ6VXNlcjM5NjAyMjg=","avatar_url":"https://avatars.githubusercontent.com/u/3960228?v=4","gravatar_id":"","url":"https://api.github.com/users/chenjunjiedada","html_url":"https://github.com/chenjunjiedada","followers_url":"https://api.github.com/users/chenjunjiedada/followers","following_url":"https://api.github.com/users/chenjunjiedada/following{/other_user}","gists_url":"https://api.github.com/users/chenjunjiedada/gists{/gist_id}","starred_url":"https://api.github.com/users/chenjunjiedada/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chenjunjiedada/subscriptions","organizations_url":"https://api.github.com/users/chenjunjiedada/orgs","repos_url":"https://api.github.com/users/chenjunjiedada/repos","events_url":"https://api.github.com/users/chenjunjiedada/events{/privacy}","received_events_url":"https://api.github.com/users/chenjunjiedada/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T08:59:27Z","updated_at":"2020-09-30T08:59:27Z","author_association":"COLLABORATOR","body":"@rdblue , I see the spark parquet reader doesn't reuse the container while vectorized code path reuses the container. Any consideration on it?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701260351/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701442789","html_url":"https://github.com/apache/iceberg/pull/1505#issuecomment-701442789","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1505","id":701442789,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTQ0Mjc4OQ==","user":{"login":"pvary","id":19705742,"node_id":"MDQ6VXNlcjE5NzA1NzQy","avatar_url":"https://avatars.githubusercontent.com/u/19705742?v=4","gravatar_id":"","url":"https://api.github.com/users/pvary","html_url":"https://github.com/pvary","followers_url":"https://api.github.com/users/pvary/followers","following_url":"https://api.github.com/users/pvary/following{/other_user}","gists_url":"https://api.github.com/users/pvary/gists{/gist_id}","starred_url":"https://api.github.com/users/pvary/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pvary/subscriptions","organizations_url":"https://api.github.com/users/pvary/orgs","repos_url":"https://api.github.com/users/pvary/repos","events_url":"https://api.github.com/users/pvary/events{/privacy}","received_events_url":"https://api.github.com/users/pvary/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T14:52:45Z","updated_at":"2020-09-30T14:53:05Z","author_association":"CONTRIBUTOR","body":"> Spark is using a v1 command to drop the table: `org.apache.spark.sql.execution.command.DropTableCommand`. That is unexpected because the test should be using an Iceberg implementation of Spark's `TableCatalog` for all of these operations. Can you find out what catalog was being used? My guess is that it was the built-in [`spark_catalog`](https://github.com/apache/iceberg/blob/1772f4f27b8a12d3e89a7f65b8b600b717e1f09d/spark3/src/test/java/org/apache/iceberg/spark/SparkCatalogTestBase.java#L66-L71) and that somehow the session catalog wrapper that we injected did not correctly detect that this table is Iceberg and not Hive.\r\n> \r\n> So the question is probably why is [`loadTable`](https://github.com/apache/iceberg/blob/1772f4f27b8a12d3e89a7f65b8b600b717e1f09d/spark3/src/main/java/org/apache/iceberg/spark/SparkSessionCatalog.java#L116-L122) catching `NoSuchTableException` and returning the table through Hive?\r\n\r\nI did not have too much time to play around with this 😢, and I was not able to catch where the `DROP TABLE` command was hijacked yet.\r\nWhat I have confirmed:\r\n- It is only happening with `spark_catalog`\r\n- It is only for `DROP TABLE` - I have not found problems with another sql command\r\n\r\nWhat I have done:\r\n- Removed the dependencies\r\n\r\nSince this is an unrelated to the original change, we might want to file a separate Issue for it.\r\n\r\nWhat do you think @rdblue?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701442789/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701466352","html_url":"https://github.com/apache/iceberg/pull/1478#issuecomment-701466352","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1478","id":701466352,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTQ2NjM1Mg==","user":{"login":"marton-bod","id":19599214,"node_id":"MDQ6VXNlcjE5NTk5MjE0","avatar_url":"https://avatars.githubusercontent.com/u/19599214?v=4","gravatar_id":"","url":"https://api.github.com/users/marton-bod","html_url":"https://github.com/marton-bod","followers_url":"https://api.github.com/users/marton-bod/followers","following_url":"https://api.github.com/users/marton-bod/following{/other_user}","gists_url":"https://api.github.com/users/marton-bod/gists{/gist_id}","starred_url":"https://api.github.com/users/marton-bod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marton-bod/subscriptions","organizations_url":"https://api.github.com/users/marton-bod/orgs","repos_url":"https://api.github.com/users/marton-bod/repos","events_url":"https://api.github.com/users/marton-bod/events{/privacy}","received_events_url":"https://api.github.com/users/marton-bod/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T15:30:20Z","updated_at":"2020-09-30T15:31:07Z","author_association":"COLLABORATOR","body":"Thanks @rdblue once again for the improvement suggestions - I've addressed them.\r\nAs for JDK11, we do have test failures unfortunately (https://github.com/apache/iceberg/pull/1478#discussion_r497471538) therefore we'll need to go with JDK8 only for Hive3.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701466352/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701490583","html_url":"https://github.com/apache/iceberg/pull/1522#issuecomment-701490583","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1522","id":701490583,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTQ5MDU4Mw==","user":{"login":"rdblue","id":87915,"node_id":"MDQ6VXNlcjg3OTE1","avatar_url":"https://avatars.githubusercontent.com/u/87915?v=4","gravatar_id":"","url":"https://api.github.com/users/rdblue","html_url":"https://github.com/rdblue","followers_url":"https://api.github.com/users/rdblue/followers","following_url":"https://api.github.com/users/rdblue/following{/other_user}","gists_url":"https://api.github.com/users/rdblue/gists{/gist_id}","starred_url":"https://api.github.com/users/rdblue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rdblue/subscriptions","organizations_url":"https://api.github.com/users/rdblue/orgs","repos_url":"https://api.github.com/users/rdblue/repos","events_url":"https://api.github.com/users/rdblue/events{/privacy}","received_events_url":"https://api.github.com/users/rdblue/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T16:09:57Z","updated_at":"2020-09-30T16:09:57Z","author_association":"CONTRIBUTOR","body":"I noticed this a few months ago and tested the performance of the two paths. I didn't really see a speed up in my initial test so I didn't change the default. We just need to evaluate the performance to know whether to do this.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701490583/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701543813","html_url":"https://github.com/apache/iceberg/pull/1503#issuecomment-701543813","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1503","id":701543813,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTU0MzgxMw==","user":{"login":"thomaschow","id":2002564,"node_id":"MDQ6VXNlcjIwMDI1NjQ=","avatar_url":"https://avatars.githubusercontent.com/u/2002564?v=4","gravatar_id":"","url":"https://api.github.com/users/thomaschow","html_url":"https://github.com/thomaschow","followers_url":"https://api.github.com/users/thomaschow/followers","following_url":"https://api.github.com/users/thomaschow/following{/other_user}","gists_url":"https://api.github.com/users/thomaschow/gists{/gist_id}","starred_url":"https://api.github.com/users/thomaschow/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/thomaschow/subscriptions","organizations_url":"https://api.github.com/users/thomaschow/orgs","repos_url":"https://api.github.com/users/thomaschow/repos","events_url":"https://api.github.com/users/thomaschow/events{/privacy}","received_events_url":"https://api.github.com/users/thomaschow/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T17:48:04Z","updated_at":"2020-09-30T17:48:04Z","author_association":"CONTRIBUTOR","body":"@rdblue @jacques-n  I will close this and we will fork the behavior internally for now, given tagged snapshots will be a thing in the future. ","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701543813/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701578362","html_url":"https://github.com/apache/iceberg/issues/1142#issuecomment-701578362","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1142","id":701578362,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTU3ODM2Mg==","user":{"login":"holdenk","id":59893,"node_id":"MDQ6VXNlcjU5ODkz","avatar_url":"https://avatars.githubusercontent.com/u/59893?v=4","gravatar_id":"","url":"https://api.github.com/users/holdenk","html_url":"https://github.com/holdenk","followers_url":"https://api.github.com/users/holdenk/followers","following_url":"https://api.github.com/users/holdenk/following{/other_user}","gists_url":"https://api.github.com/users/holdenk/gists{/gist_id}","starred_url":"https://api.github.com/users/holdenk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/holdenk/subscriptions","organizations_url":"https://api.github.com/users/holdenk/orgs","repos_url":"https://api.github.com/users/holdenk/repos","events_url":"https://api.github.com/users/holdenk/events{/privacy}","received_events_url":"https://api.github.com/users/holdenk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T18:52:45Z","updated_at":"2020-09-30T18:52:45Z","author_association":"CONTRIBUTOR","body":"Should this issue be resolved? Looking in the code it seems that we do now use `newHadoopConf` since 4bb2b0893a5de0b0452cb9db32401729c098ca8b ?","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701578362/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701587925","html_url":"https://github.com/apache/iceberg/pull/1522#issuecomment-701587925","issue_url":"https://api.github.com/repos/apache/iceberg/issues/1522","id":701587925,"node_id":"MDEyOklzc3VlQ29tbWVudDcwMTU4NzkyNQ==","user":{"login":"holdenk","id":59893,"node_id":"MDQ6VXNlcjU5ODkz","avatar_url":"https://avatars.githubusercontent.com/u/59893?v=4","gravatar_id":"","url":"https://api.github.com/users/holdenk","html_url":"https://github.com/holdenk","followers_url":"https://api.github.com/users/holdenk/followers","following_url":"https://api.github.com/users/holdenk/following{/other_user}","gists_url":"https://api.github.com/users/holdenk/gists{/gist_id}","starred_url":"https://api.github.com/users/holdenk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/holdenk/subscriptions","organizations_url":"https://api.github.com/users/holdenk/orgs","repos_url":"https://api.github.com/users/holdenk/repos","events_url":"https://api.github.com/users/holdenk/events{/privacy}","received_events_url":"https://api.github.com/users/holdenk/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-09-30T19:10:51Z","updated_at":"2020-09-30T19:10:51Z","author_association":"CONTRIBUTOR","body":"Would the values produced by the ParquetReader iterable ever be returned directly to Spark? Say in the distributed planning that folks are considering? Because if so we should check to make sure the code path is one of the ones in Spark where it's ok.","reactions":{"url":"https://api.github.com/repos/apache/iceberg/issues/comments/701587925/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]