[{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110470780","html_url":"https://github.com/apache/hudi/issues/5262#issuecomment-1110470780","issue_url":"https://api.github.com/repos/apache/hudi/issues/5262","id":1110470780,"node_id":"IC_kwDOBI7nWM5CMHB8","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T02:40:14Z","updated_at":"2022-04-27T02:40:14Z","author_association":"CONTRIBUTOR","body":"@stym06 : do you have any updates in this regard.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110470780/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110470954","html_url":"https://github.com/apache/hudi/issues/5258#issuecomment-1110470954","issue_url":"https://api.github.com/repos/apache/hudi/issues/5258","id":1110470954,"node_id":"IC_kwDOBI7nWM5CMHEq","user":{"login":"nsivabalan","id":513218,"node_id":"MDQ6VXNlcjUxMzIxOA==","avatar_url":"https://avatars.githubusercontent.com/u/513218?v=4","gravatar_id":"","url":"https://api.github.com/users/nsivabalan","html_url":"https://github.com/nsivabalan","followers_url":"https://api.github.com/users/nsivabalan/followers","following_url":"https://api.github.com/users/nsivabalan/following{/other_user}","gists_url":"https://api.github.com/users/nsivabalan/gists{/gist_id}","starred_url":"https://api.github.com/users/nsivabalan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nsivabalan/subscriptions","organizations_url":"https://api.github.com/users/nsivabalan/orgs","repos_url":"https://api.github.com/users/nsivabalan/repos","events_url":"https://api.github.com/users/nsivabalan/events{/privacy}","received_events_url":"https://api.github.com/users/nsivabalan/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T02:40:36Z","updated_at":"2022-04-27T02:40:36Z","author_association":"CONTRIBUTOR","body":"@ChenShuai1981 : do you have any updates on this regard? ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110470954/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110472030","html_url":"https://github.com/apache/hudi/pull/5292#issuecomment-1110472030","issue_url":"https://api.github.com/repos/apache/hudi/issues/5292","id":1110472030,"node_id":"IC_kwDOBI7nWM5CMHVe","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T02:42:53Z","updated_at":"2022-04-27T02:42:53Z","author_association":"CONTRIBUTOR","body":"As discussed, we're going to have all changes for Hadoop/Hive/Spark 3.x upgrades in one PR: #5402. Closing this one.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110472030/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110473711","html_url":"https://github.com/apache/hudi/pull/5408#issuecomment-1110473711","issue_url":"https://api.github.com/repos/apache/hudi/issues/5408","id":1110473711,"node_id":"IC_kwDOBI7nWM5CMHvv","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T02:46:24Z","updated_at":"2022-04-27T02:46:24Z","author_association":"CONTRIBUTOR","body":"This is for CI testing only.  Closing it now.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110473711/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110473863","html_url":"https://github.com/apache/hudi/pull/5407#issuecomment-1110473863","issue_url":"https://api.github.com/repos/apache/hudi/issues/5407","id":1110473863,"node_id":"IC_kwDOBI7nWM5CMHyH","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T02:46:40Z","updated_at":"2022-04-27T02:46:40Z","author_association":"CONTRIBUTOR","body":"This is for CI testing only.  Closing it now.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110473863/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110539259","html_url":"https://github.com/apache/hudi/pull/5432#issuecomment-1110539259","issue_url":"https://api.github.com/repos/apache/hudi/issues/5432","id":1110539259,"node_id":"IC_kwDOBI7nWM5CMXv7","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T04:53:25Z","updated_at":"2022-04-27T04:53:25Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"1a53ea2b021079025b6a3fe6ebb1184d26a3aa64\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8317\",\n    \"triggerID\" : \"1a53ea2b021079025b6a3fe6ebb1184d26a3aa64\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"1b8c38d3e2be174fdac0e5f525e06dee234c7b3b\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8318\",\n    \"triggerID\" : \"1b8c38d3e2be174fdac0e5f525e06dee234c7b3b\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"9056508c9810d860c83ee2ce544da6e74ca53a14\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8320\",\n    \"triggerID\" : \"9056508c9810d860c83ee2ce544da6e74ca53a14\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"68114ae7aa12737724497cb6b696a97e06b6dcea\",\n    \"status\" : \"SUCCESS\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8338\",\n    \"triggerID\" : \"68114ae7aa12737724497cb6b696a97e06b6dcea\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 68114ae7aa12737724497cb6b696a97e06b6dcea Azure: [SUCCESS](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8338) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110539259/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110540762","html_url":"https://github.com/apache/hudi/pull/5441#issuecomment-1110540762","issue_url":"https://api.github.com/repos/apache/hudi/issues/5441","id":1110540762,"node_id":"IC_kwDOBI7nWM5CMYHa","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T04:56:51Z","updated_at":"2022-04-27T04:56:51Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"8bc3917fb279a102c97b82f51c8053ee46ed8069\",\n    \"status\" : \"CANCELED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8340\",\n    \"triggerID\" : \"8bc3917fb279a102c97b82f51c8053ee46ed8069\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"1478ed5a3aef86a00bb4161351efb70081d79ae7\",\n    \"status\" : \"PENDING\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8342\",\n    \"triggerID\" : \"1478ed5a3aef86a00bb4161351efb70081d79ae7\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 8bc3917fb279a102c97b82f51c8053ee46ed8069 Azure: [CANCELED](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8340) \n* 1478ed5a3aef86a00bb4161351efb70081d79ae7 Azure: [PENDING](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8342) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110540762/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110540763","html_url":"https://github.com/apache/hudi/issues/5249#issuecomment-1110540763","issue_url":"https://api.github.com/repos/apache/hudi/issues/5249","id":1110540763,"node_id":"IC_kwDOBI7nWM5CMYHb","user":{"login":"toninis","id":24205345,"node_id":"MDQ6VXNlcjI0MjA1MzQ1","avatar_url":"https://avatars.githubusercontent.com/u/24205345?v=4","gravatar_id":"","url":"https://api.github.com/users/toninis","html_url":"https://github.com/toninis","followers_url":"https://api.github.com/users/toninis/followers","following_url":"https://api.github.com/users/toninis/following{/other_user}","gists_url":"https://api.github.com/users/toninis/gists{/gist_id}","starred_url":"https://api.github.com/users/toninis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/toninis/subscriptions","organizations_url":"https://api.github.com/users/toninis/orgs","repos_url":"https://api.github.com/users/toninis/repos","events_url":"https://api.github.com/users/toninis/events{/privacy}","received_events_url":"https://api.github.com/users/toninis/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T04:56:51Z","updated_at":"2022-04-27T04:56:51Z","author_association":"NONE","body":"@yihua I will try test this today . Thanks ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110540763/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110567040","html_url":"https://github.com/apache/hudi/pull/5441#issuecomment-1110567040","issue_url":"https://api.github.com/repos/apache/hudi/issues/5441","id":1110567040,"node_id":"IC_kwDOBI7nWM5CMeiA","user":{"login":"vinothchandar","id":1179324,"node_id":"MDQ6VXNlcjExNzkzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1179324?v=4","gravatar_id":"","url":"https://api.github.com/users/vinothchandar","html_url":"https://github.com/vinothchandar","followers_url":"https://api.github.com/users/vinothchandar/followers","following_url":"https://api.github.com/users/vinothchandar/following{/other_user}","gists_url":"https://api.github.com/users/vinothchandar/gists{/gist_id}","starred_url":"https://api.github.com/users/vinothchandar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinothchandar/subscriptions","organizations_url":"https://api.github.com/users/vinothchandar/orgs","repos_url":"https://api.github.com/users/vinothchandar/repos","events_url":"https://api.github.com/users/vinothchandar/events{/privacy}","received_events_url":"https://api.github.com/users/vinothchandar/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T05:42:34Z","updated_at":"2022-04-27T05:42:34Z","author_association":"MEMBER","body":"Otherwise lgtm to land. Look forward to this contribution. Also please take note of the recent work around async index building #4640 , would be cool to have this integrated so that indexes can be built and rebuilt asynchronously!","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110567040/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110586344","html_url":"https://github.com/apache/hudi/issues/5435#issuecomment-1110586344","issue_url":"https://api.github.com/repos/apache/hudi/issues/5435","id":1110586344,"node_id":"IC_kwDOBI7nWM5CMjPo","user":{"login":"Doorwood","id":23451872,"node_id":"MDQ6VXNlcjIzNDUxODcy","avatar_url":"https://avatars.githubusercontent.com/u/23451872?v=4","gravatar_id":"","url":"https://api.github.com/users/Doorwood","html_url":"https://github.com/Doorwood","followers_url":"https://api.github.com/users/Doorwood/followers","following_url":"https://api.github.com/users/Doorwood/following{/other_user}","gists_url":"https://api.github.com/users/Doorwood/gists{/gist_id}","starred_url":"https://api.github.com/users/Doorwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Doorwood/subscriptions","organizations_url":"https://api.github.com/users/Doorwood/orgs","repos_url":"https://api.github.com/users/Doorwood/repos","events_url":"https://api.github.com/users/Doorwood/events{/privacy}","received_events_url":"https://api.github.com/users/Doorwood/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T06:16:31Z","updated_at":"2022-04-27T06:16:49Z","author_association":"NONE","body":"@yihua Thanks for your reply,I have tried your suggestions.This problem seems solved.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110586344/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110592113","html_url":"https://github.com/apache/hudi/issues/5385#issuecomment-1110592113","issue_url":"https://api.github.com/repos/apache/hudi/issues/5385","id":1110592113,"node_id":"IC_kwDOBI7nWM5CMkpx","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T06:25:07Z","updated_at":"2022-04-27T06:25:07Z","author_association":"CONTRIBUTOR","body":"> what do you mean by schema update? Is the modifying existing hudi table before upsert? Or you talking about just adding _hoodie_is_deleted to the data set used for the upsert?\r\n\r\nSo you need to change the schema by adding the `_hoodie_is_deleted` to schema before the next upsert.  Then, for the upsert, you need to have the field `_hoodie_is_deleted` for the batch and set the `_hoodie_is_deleted` to true for the records to be deleted.  You can find a concrete example below derived from the [Deletes docs](https://hudi.apache.org/docs/writing_data/#deletes).\r\n\r\n> Also is _hoodie_is_deleted a system field? If so why isnt it always present?\r\n\r\n`_hoodie_is_deleted` is used by the write client internally to identify deletes.  Only when you want to support both inserts, updates, and deletes in the same batch with UPSERT operation, you need this field.  We're going to relax this requirement of adding `_hoodie_is_deleted` in the future.  This field is not required in all cases, e.g., the DELETE operation, normal inserts, upserts without deletes.\r\n\r\n> Is there a good example of this?\r\n\r\nYou can check [Deletes docs](https://hudi.apache.org/docs/writing_data/#deletes):\r\n\r\n- Using DataSource or DeltaStreamer to delete records: add a column named `_hoodie_is_deleted` to DataSet. The value of this column must be set to `true` for all the records to be deleted and either `false` or left `null` for any records which are to be upserted.\r\n\r\nLet's say the original schema is:\r\n```\r\n{\r\n  \"type\":\"record\",\r\n  \"name\":\"example_tbl\",\r\n  \"fields\":[{\r\n     \"name\": \"uuid\",\r\n     \"type\": \"String\"\r\n  }, {\r\n     \"name\": \"ts\",\r\n     \"type\": \"string\"\r\n  },  {\r\n     \"name\": \"partitionPath\",\r\n     \"type\": \"string\"\r\n  }, {\r\n     \"name\": \"rank\",\r\n     \"type\": \"long\"\r\n  }\r\n]}\r\n```\r\nMake sure you add `_hoodie_is_deleted` column:\r\n```\r\n{\r\n  \"type\":\"record\",\r\n  \"name\":\"example_tbl\",\r\n  \"fields\":[{\r\n     \"name\": \"uuid\",\r\n     \"type\": \"String\"\r\n  }, {\r\n     \"name\": \"ts\",\r\n     \"type\": \"string\"\r\n  },  {\r\n     \"name\": \"partitionPath\",\r\n     \"type\": \"string\"\r\n  }, {\r\n     \"name\": \"rank\",\r\n     \"type\": \"long\"\r\n  }, {\r\n    \"name\" : \"_hoodie_is_deleted\",\r\n    \"type\" : \"boolean\",\r\n    \"default\" : false\r\n  }\r\n]}\r\n```\r\nThen any record you want to delete you can mark `_hoodie_is_deleted` as true:\r\n```\r\n{\"ts\": 0.0, \"uuid\": \"19tdb048-c93e-4532-adf9-f61ce6afe10\", \"rank\": 1045, \"partitionpath\": \"americas/brazil/sao_paulo\", \"_hoodie_is_deleted\" : true}\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110592113/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110600966","html_url":"https://github.com/apache/hudi/issues/5395#issuecomment-1110600966","issue_url":"https://api.github.com/repos/apache/hudi/issues/5395","id":1110600966,"node_id":"IC_kwDOBI7nWM5CMm0G","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T06:37:39Z","updated_at":"2022-04-27T06:37:39Z","author_association":"CONTRIBUTOR","body":"@todd5167 the point is that even before `fs.delete(dirPath, false)` is called, the subfolders should have been deleted already.  So I'm wondering why the subfolders are not deleted in the first place.  If you're not comfortable sharing the whole `.hoodie` folder, could you simply list the `.hoodie` folder with `aws s3 ls <table_path>/.hoodie`?  Or you can take a screenshot of the files in `.hoodie` folder in S3 Web UI.  I'm interested in the timeline of the table, and the type of instance `20220421063410412`, whether it is deltacommit, compaction, etc.\r\n\r\n> I have restored from flink savepoint multiple times and keep getting this error. \r\n\r\nI guess you mean you tried to restart the flink job but kept hitting the same exception.  I assume you're not talking about Hudi restore or savepoint?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110600966/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110601695","html_url":"https://github.com/apache/hudi/pull/5441#issuecomment-1110601695","issue_url":"https://api.github.com/repos/apache/hudi/issues/5441","id":1110601695,"node_id":"IC_kwDOBI7nWM5CMm_f","user":{"login":"huberylee","id":11664307,"node_id":"MDQ6VXNlcjExNjY0MzA3","avatar_url":"https://avatars.githubusercontent.com/u/11664307?v=4","gravatar_id":"","url":"https://api.github.com/users/huberylee","html_url":"https://github.com/huberylee","followers_url":"https://api.github.com/users/huberylee/followers","following_url":"https://api.github.com/users/huberylee/following{/other_user}","gists_url":"https://api.github.com/users/huberylee/gists{/gist_id}","starred_url":"https://api.github.com/users/huberylee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/huberylee/subscriptions","organizations_url":"https://api.github.com/users/huberylee/orgs","repos_url":"https://api.github.com/users/huberylee/repos","events_url":"https://api.github.com/users/huberylee/events{/privacy}","received_events_url":"https://api.github.com/users/huberylee/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T06:38:38Z","updated_at":"2022-04-27T06:38:38Z","author_association":"CONTRIBUTOR","body":"> +1 but can we rename the RFC title to be more specific about the lucene index? There is also a separate record level/HFile backed index going on.\r\n> \r\n> So may be \"Introduce Lucene based secondary indexing\" ?\r\n\r\nWe want to introduce a common architecture for secondary index, and lucene based secondary index is one specific implementation.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110601695/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110602355","html_url":"https://github.com/apache/hudi/pull/5441#issuecomment-1110602355","issue_url":"https://api.github.com/repos/apache/hudi/issues/5441","id":1110602355,"node_id":"IC_kwDOBI7nWM5CMnJz","user":{"login":"huberylee","id":11664307,"node_id":"MDQ6VXNlcjExNjY0MzA3","avatar_url":"https://avatars.githubusercontent.com/u/11664307?v=4","gravatar_id":"","url":"https://api.github.com/users/huberylee","html_url":"https://github.com/huberylee","followers_url":"https://api.github.com/users/huberylee/followers","following_url":"https://api.github.com/users/huberylee/following{/other_user}","gists_url":"https://api.github.com/users/huberylee/gists{/gist_id}","starred_url":"https://api.github.com/users/huberylee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/huberylee/subscriptions","organizations_url":"https://api.github.com/users/huberylee/orgs","repos_url":"https://api.github.com/users/huberylee/repos","events_url":"https://api.github.com/users/huberylee/events{/privacy}","received_events_url":"https://api.github.com/users/huberylee/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T06:39:32Z","updated_at":"2022-04-27T06:39:32Z","author_association":"CONTRIBUTOR","body":"> Otherwise lgtm to land. Look forward to this contribution. Also please take note of the recent work around async index building #4640 , would be cool to have this integrated so that indexes can be built and rebuilt asynchronously!\r\n\r\nOK.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110602355/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110614113","html_url":"https://github.com/apache/hudi/issues/5371#issuecomment-1110614113","issue_url":"https://api.github.com/repos/apache/hudi/issues/5371","id":1110614113,"node_id":"IC_kwDOBI7nWM5CMqBh","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T06:54:44Z","updated_at":"2022-04-27T06:54:44Z","author_association":"CONTRIBUTOR","body":"> I also have a question relating to async compaction. I found that the `org.apache.hudi.sink.compact.HoodieFlinkCompactor` job is a flink batch job, does this mean I have to run this compaction job periodically, at when and in what frequency?\r\n\r\nWe have supported the service mode now, you can take a try ~","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110614113/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110617305","html_url":"https://github.com/apache/hudi/issues/5280#issuecomment-1110617305","issue_url":"https://api.github.com/repos/apache/hudi/issues/5280","id":1110617305,"node_id":"IC_kwDOBI7nWM5CMqzZ","user":{"login":"arunb2w","id":38204827,"node_id":"MDQ6VXNlcjM4MjA0ODI3","avatar_url":"https://avatars.githubusercontent.com/u/38204827?v=4","gravatar_id":"","url":"https://api.github.com/users/arunb2w","html_url":"https://github.com/arunb2w","followers_url":"https://api.github.com/users/arunb2w/followers","following_url":"https://api.github.com/users/arunb2w/following{/other_user}","gists_url":"https://api.github.com/users/arunb2w/gists{/gist_id}","starred_url":"https://api.github.com/users/arunb2w/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arunb2w/subscriptions","organizations_url":"https://api.github.com/users/arunb2w/orgs","repos_url":"https://api.github.com/users/arunb2w/repos","events_url":"https://api.github.com/users/arunb2w/events{/privacy}","received_events_url":"https://api.github.com/users/arunb2w/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T06:58:53Z","updated_at":"2022-04-27T06:58:53Z","author_association":"NONE","body":"@codope Attaching my docker resources for your reference\r\n<img width=\"682\" alt=\"Screenshot 2022-04-27 at 12 26 24 PM\" src=\"https://user-images.githubusercontent.com/38204827/165459689-d74dadf6-0926-4cb4-a5c9-ba349f29c54c.png\">\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110617305/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110621179","html_url":"https://github.com/apache/hudi/issues/5395#issuecomment-1110621179","issue_url":"https://api.github.com/repos/apache/hudi/issues/5395","id":1110621179,"node_id":"IC_kwDOBI7nWM5CMrv7","user":{"login":"todd5167","id":24680803,"node_id":"MDQ6VXNlcjI0NjgwODAz","avatar_url":"https://avatars.githubusercontent.com/u/24680803?v=4","gravatar_id":"","url":"https://api.github.com/users/todd5167","html_url":"https://github.com/todd5167","followers_url":"https://api.github.com/users/todd5167/followers","following_url":"https://api.github.com/users/todd5167/following{/other_user}","gists_url":"https://api.github.com/users/todd5167/gists{/gist_id}","starred_url":"https://api.github.com/users/todd5167/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/todd5167/subscriptions","organizations_url":"https://api.github.com/users/todd5167/orgs","repos_url":"https://api.github.com/users/todd5167/repos","events_url":"https://api.github.com/users/todd5167/events{/privacy}","received_events_url":"https://api.github.com/users/todd5167/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T07:03:40Z","updated_at":"2022-04-27T07:03:40Z","author_association":"CONTRIBUTOR","body":"@yihua   Because this problem causes the flink job to restart frequently, I use fs.delete(dirPath, true) to delete the folder.After I changed the code again, the ./hoodie folder was cleaned up by me. I re-consume historical data and incremental data again.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110621179/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110648342","html_url":"https://github.com/apache/hudi/issues/3657#issuecomment-1110648342","issue_url":"https://api.github.com/repos/apache/hudi/issues/3657","id":1110648342,"node_id":"IC_kwDOBI7nWM5CMyYW","user":{"login":"chaplinthink","id":7960313,"node_id":"MDQ6VXNlcjc5NjAzMTM=","avatar_url":"https://avatars.githubusercontent.com/u/7960313?v=4","gravatar_id":"","url":"https://api.github.com/users/chaplinthink","html_url":"https://github.com/chaplinthink","followers_url":"https://api.github.com/users/chaplinthink/followers","following_url":"https://api.github.com/users/chaplinthink/following{/other_user}","gists_url":"https://api.github.com/users/chaplinthink/gists{/gist_id}","starred_url":"https://api.github.com/users/chaplinthink/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chaplinthink/subscriptions","organizations_url":"https://api.github.com/users/chaplinthink/orgs","repos_url":"https://api.github.com/users/chaplinthink/repos","events_url":"https://api.github.com/users/chaplinthink/events{/privacy}","received_events_url":"https://api.github.com/users/chaplinthink/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T07:32:46Z","updated_at":"2022-04-27T07:32:46Z","author_association":"CONTRIBUTOR","body":"> Can you use 0.10.1 please, the bug is already fixed.\r\n\r\nThx, It's ok. I found out that it was due to a docker hadoop container issue that caused","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110648342/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110714139","html_url":"https://github.com/apache/hudi/issues/5442#issuecomment-1110714139","issue_url":"https://api.github.com/repos/apache/hudi/issues/5442","id":1110714139,"node_id":"IC_kwDOBI7nWM5CNCcb","user":{"login":"qianchutao","id":72595723,"node_id":"MDQ6VXNlcjcyNTk1NzIz","avatar_url":"https://avatars.githubusercontent.com/u/72595723?v=4","gravatar_id":"","url":"https://api.github.com/users/qianchutao","html_url":"https://github.com/qianchutao","followers_url":"https://api.github.com/users/qianchutao/followers","following_url":"https://api.github.com/users/qianchutao/following{/other_user}","gists_url":"https://api.github.com/users/qianchutao/gists{/gist_id}","starred_url":"https://api.github.com/users/qianchutao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qianchutao/subscriptions","organizations_url":"https://api.github.com/users/qianchutao/orgs","repos_url":"https://api.github.com/users/qianchutao/repos","events_url":"https://api.github.com/users/qianchutao/events{/privacy}","received_events_url":"https://api.github.com/users/qianchutao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T08:34:45Z","updated_at":"2022-04-27T08:34:45Z","author_association":"CONTRIBUTOR","body":"I've encountered this problem before and never found a reason, asking commiters in the community never got an answer","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110714139/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110730357","html_url":"https://github.com/apache/hudi/pull/5413#issuecomment-1110730357","issue_url":"https://api.github.com/repos/apache/hudi/issues/5413","id":1110730357,"node_id":"IC_kwDOBI7nWM5CNGZ1","user":{"login":"kazdy","id":27806231,"node_id":"MDQ6VXNlcjI3ODA2MjMx","avatar_url":"https://avatars.githubusercontent.com/u/27806231?v=4","gravatar_id":"","url":"https://api.github.com/users/kazdy","html_url":"https://github.com/kazdy","followers_url":"https://api.github.com/users/kazdy/followers","following_url":"https://api.github.com/users/kazdy/following{/other_user}","gists_url":"https://api.github.com/users/kazdy/gists{/gist_id}","starred_url":"https://api.github.com/users/kazdy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kazdy/subscriptions","organizations_url":"https://api.github.com/users/kazdy/orgs","repos_url":"https://api.github.com/users/kazdy/repos","events_url":"https://api.github.com/users/kazdy/events{/privacy}","received_events_url":"https://api.github.com/users/kazdy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T08:46:35Z","updated_at":"2022-04-27T08:46:35Z","author_association":"CONTRIBUTOR","body":"Hi, \r\nI see similar thing has been added to 0.11 docs:\r\nhttps://hudi.apache.org/docs/next/quick-start-guide#modifying-table-properties\r\n\r\nNot sure if this PR is needed anymore, maybe only for 0.10.1?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110730357/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110750154","html_url":"https://github.com/apache/hudi/pull/5406#issuecomment-1110750154","issue_url":"https://api.github.com/repos/apache/hudi/issues/5406","id":1110750154,"node_id":"IC_kwDOBI7nWM5CNLPK","user":{"login":"dongkelun","id":13376555,"node_id":"MDQ6VXNlcjEzMzc2NTU1","avatar_url":"https://avatars.githubusercontent.com/u/13376555?v=4","gravatar_id":"","url":"https://api.github.com/users/dongkelun","html_url":"https://github.com/dongkelun","followers_url":"https://api.github.com/users/dongkelun/followers","following_url":"https://api.github.com/users/dongkelun/following{/other_user}","gists_url":"https://api.github.com/users/dongkelun/gists{/gist_id}","starred_url":"https://api.github.com/users/dongkelun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dongkelun/subscriptions","organizations_url":"https://api.github.com/users/dongkelun/orgs","repos_url":"https://api.github.com/users/dongkelun/repos","events_url":"https://api.github.com/users/dongkelun/events{/privacy}","received_events_url":"https://api.github.com/users/dongkelun/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T09:02:11Z","updated_at":"2022-04-28T03:47:59Z","author_association":"CONTRIBUTOR","body":"I'm wrong. Whether async clean or not, we shouldn't keep he last commit before the earliest commit to retain. I will change the code again","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110750154/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110755904","html_url":"https://github.com/apache/hudi/issues/5280#issuecomment-1110755904","issue_url":"https://api.github.com/repos/apache/hudi/issues/5280","id":1110755904,"node_id":"IC_kwDOBI7nWM5CNMpA","user":{"login":"arunb2w","id":38204827,"node_id":"MDQ6VXNlcjM4MjA0ODI3","avatar_url":"https://avatars.githubusercontent.com/u/38204827?v=4","gravatar_id":"","url":"https://api.github.com/users/arunb2w","html_url":"https://github.com/arunb2w","followers_url":"https://api.github.com/users/arunb2w/followers","following_url":"https://api.github.com/users/arunb2w/following{/other_user}","gists_url":"https://api.github.com/users/arunb2w/gists{/gist_id}","starred_url":"https://api.github.com/users/arunb2w/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arunb2w/subscriptions","organizations_url":"https://api.github.com/users/arunb2w/orgs","repos_url":"https://api.github.com/users/arunb2w/repos","events_url":"https://api.github.com/users/arunb2w/events{/privacy}","received_events_url":"https://api.github.com/users/arunb2w/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T09:07:19Z","updated_at":"2022-04-27T09:09:25Z","author_association":"NONE","body":"I have also tried with the below config as well but still the same error persists. I have also uninstalled and reinstalled docker in my mac before running this\r\nI am running docker demo in Apple M1 chip. Are there any issues related to that?\r\n\r\n<img width=\"665\" alt=\"Screenshot 2022-04-27 at 2 35 49 PM\" src=\"https://user-images.githubusercontent.com/38204827/165483734-e2c3785e-4013-4df8-9c71-7918bda6c6e7.png\">\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110755904/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110771677","html_url":"https://github.com/apache/hudi/pull/5436#issuecomment-1110771677","issue_url":"https://api.github.com/repos/apache/hudi/issues/5436","id":1110771677,"node_id":"IC_kwDOBI7nWM5CNQfd","user":{"login":"YannByron","id":10036681,"node_id":"MDQ6VXNlcjEwMDM2Njgx","avatar_url":"https://avatars.githubusercontent.com/u/10036681?v=4","gravatar_id":"","url":"https://api.github.com/users/YannByron","html_url":"https://github.com/YannByron","followers_url":"https://api.github.com/users/YannByron/followers","following_url":"https://api.github.com/users/YannByron/following{/other_user}","gists_url":"https://api.github.com/users/YannByron/gists{/gist_id}","starred_url":"https://api.github.com/users/YannByron/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YannByron/subscriptions","organizations_url":"https://api.github.com/users/YannByron/orgs","repos_url":"https://api.github.com/users/YannByron/repos","events_url":"https://api.github.com/users/YannByron/events{/privacy}","received_events_url":"https://api.github.com/users/YannByron/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T09:21:50Z","updated_at":"2022-04-27T10:01:43Z","author_association":"CONTRIBUTOR","body":"> left some initial comments. I think the main decision here is whether or not to reuse the existing record level commit metadata and build CDC on top or do a separate `.cdc` folder? Can you clarify what exactly is contained in the files under .cdc.?\r\n\r\nSorry for leaving some points that i can't make clear in this RFC doc. let me mention them here, and i'll update RFC later.\r\n\r\n1. for COW tables, query efficiency is the main focus. I definitely do not want to write out the log files, if i have to persist the CDC data. So it has to, i prefer to double-write. But i will try to reuse the normal data files, and reduce extra workload. And answer the question above: `.cdc` folder will keep these files that we have to write out.\r\n\r\n2. for MOR tables, we care about the write efficiency. In my thoughts and design, i try to avoid to write any more data and files. But in some cases, for example, call the `HoodieMergeHandle` to execute the data writing, then will write out a base file rather than a log file. I have to write CDC file to record the changing. And when query CDC for MOR, we need to merge inc data written in log Files and base files to judge which records are deleted, which ones are updated (for those, we also need to find the previous values), and which ones are inserted.\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110771677/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110836451","html_url":"https://github.com/apache/hudi/issues/5290#issuecomment-1110836451","issue_url":"https://api.github.com/repos/apache/hudi/issues/5290","id":1110836451,"node_id":"IC_kwDOBI7nWM5CNgTj","user":{"login":"easonwood","id":5763104,"node_id":"MDQ6VXNlcjU3NjMxMDQ=","avatar_url":"https://avatars.githubusercontent.com/u/5763104?v=4","gravatar_id":"","url":"https://api.github.com/users/easonwood","html_url":"https://github.com/easonwood","followers_url":"https://api.github.com/users/easonwood/followers","following_url":"https://api.github.com/users/easonwood/following{/other_user}","gists_url":"https://api.github.com/users/easonwood/gists{/gist_id}","starred_url":"https://api.github.com/users/easonwood/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/easonwood/subscriptions","organizations_url":"https://api.github.com/users/easonwood/orgs","repos_url":"https://api.github.com/users/easonwood/repos","events_url":"https://api.github.com/users/easonwood/events{/privacy}","received_events_url":"https://api.github.com/users/easonwood/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T10:26:49Z","updated_at":"2022-04-27T10:26:49Z","author_association":"NONE","body":"@codope \r\n@nsivabalan \r\nI didn't try disabling the metadata.\r\nI set this config:\r\n\"hoodie.fail.on.timeline.archiving\" -> \"false\"\r\nAnd the task runs well now.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110836451/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110913528","html_url":"https://github.com/apache/hudi/pull/5443#issuecomment-1110913528","issue_url":"https://api.github.com/repos/apache/hudi/issues/5443","id":1110913528,"node_id":"IC_kwDOBI7nWM5CNzH4","user":{"login":"xiarixiaoyao","id":13514703,"node_id":"MDQ6VXNlcjEzNTE0NzAz","avatar_url":"https://avatars.githubusercontent.com/u/13514703?v=4","gravatar_id":"","url":"https://api.github.com/users/xiarixiaoyao","html_url":"https://github.com/xiarixiaoyao","followers_url":"https://api.github.com/users/xiarixiaoyao/followers","following_url":"https://api.github.com/users/xiarixiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/xiarixiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/xiarixiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiarixiaoyao/subscriptions","organizations_url":"https://api.github.com/users/xiarixiaoyao/orgs","repos_url":"https://api.github.com/users/xiarixiaoyao/repos","events_url":"https://api.github.com/users/xiarixiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/xiarixiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T11:58:05Z","updated_at":"2022-04-27T11:58:05Z","author_association":"CONTRIBUTOR","body":"@danny0405 @bvaradar  If you have free time，could you pls help review this pr, thanks very much","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110913528/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110950019","html_url":"https://github.com/apache/hudi/pull/5436#issuecomment-1110950019","issue_url":"https://api.github.com/repos/apache/hudi/issues/5436","id":1110950019,"node_id":"IC_kwDOBI7nWM5CN8CD","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T12:37:49Z","updated_at":"2022-04-27T12:37:49Z","author_association":"CONTRIBUTOR","body":"> > left some initial comments. I think the main decision here is whether or not to reuse the existing record level commit metadata and build CDC on top or do a separate `.cdc` folder? Can you clarify what exactly is contained in the files under .cdc.?\r\n> \r\n> Sorry for leaving some points that i can't make clear in this RFC doc. let me mention them here, and i'll update RFC later.\r\n> \r\n> 1. for COW tables, query efficiency is the main focus. I definitely do not want to write out the log files, if i have to persist the CDC data. So it has to, i prefer to double-write. But i will try to reuse the normal data files, and reduce extra workload. And answer the question above: `.cdc` folder will keep these files that we have to write out.\r\n> 2. for MOR tables, we care about the write efficiency. In my thoughts and design, i try to avoid to write any more data and files. But in some cases, for example, call the `HoodieMergeHandle` to execute the data writing, then will write out a base file rather than a log file. I have to write CDC file to record the changing. And when query CDC for MOR, we need to merge inc data written in log Files and base files to judge which records are deleted, which ones are updated (for those, we also need to find the previous values), and which ones are inserted.\r\n\r\nI general, the design guidelines to consider at 1st priority is not to double write, for these reasons:\r\n\r\n1. The CDC details records occupies several times the storage cost than the actual base data files. This is not acceptable for production, especially for lake format, we already have active timeline commits for history snapshots;\r\n2. The double write would reduce the write throughput obviously;\r\n3. If we double write that log files, we need to handle the transaction for the data file completeness and the CDC logs, for example, how about we write the log success but the data files failed, should we failover, and how we do the failover ? Recover from the log files ? There are many corner cases to handle just like we did to metadata table already.\r\n4. What about the TTL of the log files, should it be separate managed from the data files ? Say we keep 10 latest commits for data files, should we also keep that for log files ? How to clean them, and which component to clean them ? The existing cleaning service ? Note that the log data set is huge and the cleaning should be enough efficient.\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110950019/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110951342","html_url":"https://github.com/apache/hudi/pull/5443#issuecomment-1110951342","issue_url":"https://api.github.com/repos/apache/hudi/issues/5443","id":1110951342,"node_id":"IC_kwDOBI7nWM5CN8Wu","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T12:39:16Z","updated_at":"2022-04-27T12:39:16Z","author_association":"CONTRIBUTOR","body":"What do you mean when you saying `batch/cow/snapshot` ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110951342/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110958170","html_url":"https://github.com/apache/hudi/pull/5443#issuecomment-1110958170","issue_url":"https://api.github.com/repos/apache/hudi/issues/5443","id":1110958170,"node_id":"IC_kwDOBI7nWM5CN-Ba","user":{"login":"trushev","id":42293632,"node_id":"MDQ6VXNlcjQyMjkzNjMy","avatar_url":"https://avatars.githubusercontent.com/u/42293632?v=4","gravatar_id":"","url":"https://api.github.com/users/trushev","html_url":"https://github.com/trushev","followers_url":"https://api.github.com/users/trushev/followers","following_url":"https://api.github.com/users/trushev/following{/other_user}","gists_url":"https://api.github.com/users/trushev/gists{/gist_id}","starred_url":"https://api.github.com/users/trushev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/trushev/subscriptions","organizations_url":"https://api.github.com/users/trushev/orgs","repos_url":"https://api.github.com/users/trushev/repos","events_url":"https://api.github.com/users/trushev/events{/privacy}","received_events_url":"https://api.github.com/users/trushev/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T12:46:49Z","updated_at":"2022-04-27T12:46:49Z","author_association":"CONTRIBUTOR","body":"> What do you mean when you saying `batch/cow/snapshot` ?\r\n\r\nThis PR covers the following case\r\n```\r\n'read.streaming.enabled' = 'false',\r\n'table.type' = 'COPY_ON_WRITE',\r\n'hoodie.datasource.query.type' = 'snapshot'\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110958170/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110963313","html_url":"https://github.com/apache/hudi/pull/5445#issuecomment-1110963313","issue_url":"https://api.github.com/repos/apache/hudi/issues/5445","id":1110963313,"node_id":"IC_kwDOBI7nWM5CN_Rx","user":{"login":"JerryYue-M","id":10253313,"node_id":"MDQ6VXNlcjEwMjUzMzEz","avatar_url":"https://avatars.githubusercontent.com/u/10253313?v=4","gravatar_id":"","url":"https://api.github.com/users/JerryYue-M","html_url":"https://github.com/JerryYue-M","followers_url":"https://api.github.com/users/JerryYue-M/followers","following_url":"https://api.github.com/users/JerryYue-M/following{/other_user}","gists_url":"https://api.github.com/users/JerryYue-M/gists{/gist_id}","starred_url":"https://api.github.com/users/JerryYue-M/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JerryYue-M/subscriptions","organizations_url":"https://api.github.com/users/JerryYue-M/orgs","repos_url":"https://api.github.com/users/JerryYue-M/repos","events_url":"https://api.github.com/users/JerryYue-M/events{/privacy}","received_events_url":"https://api.github.com/users/JerryYue-M/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T12:52:12Z","updated_at":"2022-04-27T12:52:12Z","author_association":"CONTRIBUTOR","body":"@dannyhchen @wangxianghu \r\ncan you review this latest pr.\r\nvery thankful","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1110963313/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111048795","html_url":"https://github.com/apache/hudi/issues/5385#issuecomment-1111048795","issue_url":"https://api.github.com/repos/apache/hudi/issues/5385","id":1111048795,"node_id":"IC_kwDOBI7nWM5COUJb","user":{"login":"p-powell","id":71663919,"node_id":"MDQ6VXNlcjcxNjYzOTE5","avatar_url":"https://avatars.githubusercontent.com/u/71663919?v=4","gravatar_id":"","url":"https://api.github.com/users/p-powell","html_url":"https://github.com/p-powell","followers_url":"https://api.github.com/users/p-powell/followers","following_url":"https://api.github.com/users/p-powell/following{/other_user}","gists_url":"https://api.github.com/users/p-powell/gists{/gist_id}","starred_url":"https://api.github.com/users/p-powell/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/p-powell/subscriptions","organizations_url":"https://api.github.com/users/p-powell/orgs","repos_url":"https://api.github.com/users/p-powell/repos","events_url":"https://api.github.com/users/p-powell/events{/privacy}","received_events_url":"https://api.github.com/users/p-powell/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T14:07:43Z","updated_at":"2022-04-27T14:07:43Z","author_association":"NONE","body":"@yihua Thanks for the response. Does that mean that this test case fails then? https://github.com/apache/hudi/pull/3541/commits/694300477f61a9169c15cac1ddf67368dbf5dd1b\r\nThe above test case does not add _hoodie_is_deleted to the existing hudi table before writing a dataset with _hoodie_is_deleted column. \r\n\r\nAlso, what is the best way to modify the schema of an existing hudi table?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111048795/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111127124","html_url":"https://github.com/apache/hudi/pull/5436#issuecomment-1111127124","issue_url":"https://api.github.com/repos/apache/hudi/issues/5436","id":1111127124,"node_id":"IC_kwDOBI7nWM5COnRU","user":{"login":"YannByron","id":10036681,"node_id":"MDQ6VXNlcjEwMDM2Njgx","avatar_url":"https://avatars.githubusercontent.com/u/10036681?v=4","gravatar_id":"","url":"https://api.github.com/users/YannByron","html_url":"https://github.com/YannByron","followers_url":"https://api.github.com/users/YannByron/followers","following_url":"https://api.github.com/users/YannByron/following{/other_user}","gists_url":"https://api.github.com/users/YannByron/gists{/gist_id}","starred_url":"https://api.github.com/users/YannByron/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YannByron/subscriptions","organizations_url":"https://api.github.com/users/YannByron/orgs","repos_url":"https://api.github.com/users/YannByron/repos","events_url":"https://api.github.com/users/YannByron/events{/privacy}","received_events_url":"https://api.github.com/users/YannByron/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T15:15:17Z","updated_at":"2022-04-27T15:15:17Z","author_association":"CONTRIBUTOR","body":"> I general, the design guidelines to consider at 1st priority is not to double write, for these reasons:\r\n> \r\n> 1. The CDC details records occupies several times the storage cost than the actual base data files. This is not acceptable for production, especially for lake format, we already have active timeline commits for history snapshots;\r\n> 2. The double write would reduce the write throughput obviously;\r\n> 3. If we double write that log files, we need to handle the transaction for the data file completeness and the CDC logs, for example, how about we write the log success but the data files failed, should we failover, and how we do the failover ? Recover from the log files ? There are many corner cases to handle just like we did to metadata table already.\r\n> 4. What about the TTL of the log files, should it be separate managed from the data files ? Say we keep 10 latest commits for data files, should we also keep that for log files ? How to clean them, and which component to clean them ? The existing cleaning service ? Note that the log data set is huge and the cleaning should be enough efficient.\r\n\r\n1. Now, we have two table types: COW and MOR. As a lake format, We need to have different concerns for different table types that can use in different scenario. As i said above, we should focus more on query performance for COW tables, and write performance for MOR tables. Your solution in google doc do the same things for both. If i understand your solution correctly, it need a full-join to detect the changing for cow.  It is implemented with two time-travel queries, i.e, we need to load the two versions of file group, even just one record is changed for cow table (at most streaming cases, maybe just a very tiny fraction is changed in one commit). \r\n2. `the write throughput` is the main point for MOR. At most cases, we do not need to write out extra cdc files. The timing at which the CDC files has to be generated is when the MOR table will write out the base file, not log file. After all, in the normal cases, the MOR table also need to rewrite the base file, not always write to log file.\r\n3. Hudi transaction is managed by timeline. Failure to write CDC files or data files should not complete the commit correctly.\r\n4. The management about log files is as usual. Only CDC files, we need to consider to clean them in time by the clean service.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111127124/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111304219","html_url":"https://github.com/apache/hudi/issues/5442#issuecomment-1111304219","issue_url":"https://api.github.com/repos/apache/hudi/issues/5442","id":1111304219,"node_id":"IC_kwDOBI7nWM5CPSgb","user":{"login":"mandar-mw","id":81189671,"node_id":"MDQ6VXNlcjgxMTg5Njcx","avatar_url":"https://avatars.githubusercontent.com/u/81189671?v=4","gravatar_id":"","url":"https://api.github.com/users/mandar-mw","html_url":"https://github.com/mandar-mw","followers_url":"https://api.github.com/users/mandar-mw/followers","following_url":"https://api.github.com/users/mandar-mw/following{/other_user}","gists_url":"https://api.github.com/users/mandar-mw/gists{/gist_id}","starred_url":"https://api.github.com/users/mandar-mw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mandar-mw/subscriptions","organizations_url":"https://api.github.com/users/mandar-mw/orgs","repos_url":"https://api.github.com/users/mandar-mw/repos","events_url":"https://api.github.com/users/mandar-mw/events{/privacy}","received_events_url":"https://api.github.com/users/mandar-mw/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T17:45:40Z","updated_at":"2022-04-27T17:45:40Z","author_association":"NONE","body":"I am going to close this issue because our suspicion is that it is very specific to the way we bootstrapped data for this table. We are in touch with hudi team on slack to debug this further","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111304219/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111340686","html_url":"https://github.com/apache/hudi/issues/5361#issuecomment-1111340686","issue_url":"https://api.github.com/repos/apache/hudi/issues/5361","id":1111340686,"node_id":"IC_kwDOBI7nWM5CPbaO","user":{"login":"pratyakshsharma","id":30863489,"node_id":"MDQ6VXNlcjMwODYzNDg5","avatar_url":"https://avatars.githubusercontent.com/u/30863489?v=4","gravatar_id":"","url":"https://api.github.com/users/pratyakshsharma","html_url":"https://github.com/pratyakshsharma","followers_url":"https://api.github.com/users/pratyakshsharma/followers","following_url":"https://api.github.com/users/pratyakshsharma/following{/other_user}","gists_url":"https://api.github.com/users/pratyakshsharma/gists{/gist_id}","starred_url":"https://api.github.com/users/pratyakshsharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pratyakshsharma/subscriptions","organizations_url":"https://api.github.com/users/pratyakshsharma/orgs","repos_url":"https://api.github.com/users/pratyakshsharma/repos","events_url":"https://api.github.com/users/pratyakshsharma/events{/privacy}","received_events_url":"https://api.github.com/users/pratyakshsharma/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T18:25:16Z","updated_at":"2022-04-27T18:25:16Z","author_association":"CONTRIBUTOR","body":"@ksrihari93 https://github.com/apache/hudi/pull/5031 ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111340686/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111347648","html_url":"https://github.com/apache/hudi/issues/5385#issuecomment-1111347648","issue_url":"https://api.github.com/repos/apache/hudi/issues/5385","id":1111347648,"node_id":"IC_kwDOBI7nWM5CPdHA","user":{"login":"pratyakshsharma","id":30863489,"node_id":"MDQ6VXNlcjMwODYzNDg5","avatar_url":"https://avatars.githubusercontent.com/u/30863489?v=4","gravatar_id":"","url":"https://api.github.com/users/pratyakshsharma","html_url":"https://github.com/pratyakshsharma","followers_url":"https://api.github.com/users/pratyakshsharma/followers","following_url":"https://api.github.com/users/pratyakshsharma/following{/other_user}","gists_url":"https://api.github.com/users/pratyakshsharma/gists{/gist_id}","starred_url":"https://api.github.com/users/pratyakshsharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pratyakshsharma/subscriptions","organizations_url":"https://api.github.com/users/pratyakshsharma/orgs","repos_url":"https://api.github.com/users/pratyakshsharma/repos","events_url":"https://api.github.com/users/pratyakshsharma/events{/privacy}","received_events_url":"https://api.github.com/users/pratyakshsharma/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T18:32:33Z","updated_at":"2022-04-27T18:32:33Z","author_association":"CONTRIBUTOR","body":"it is not necessary to add the column first before actually writing data with that column. Hudi can implicitly take care of that provided the schema is evolved in backward compatible ways. Hope that helps.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111347648/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111356586","html_url":"https://github.com/apache/hudi/issues/5395#issuecomment-1111356586","issue_url":"https://api.github.com/repos/apache/hudi/issues/5395","id":1111356586,"node_id":"IC_kwDOBI7nWM5CPfSq","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T18:43:00Z","updated_at":"2022-04-27T18:43:00Z","author_association":"CONTRIBUTOR","body":"@todd5167 Got it.  If you can also provide the steps in your setup to reproduce the problem, we can try to reproduce the problem on our end as well to identify the root cause.  @danny0405 are you aware of a similar issue of deleting marker directory in Flink?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111356586/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111412056","html_url":"https://github.com/apache/hudi/issues/5223#issuecomment-1111412056","issue_url":"https://api.github.com/repos/apache/hudi/issues/5223","id":1111412056,"node_id":"IC_kwDOBI7nWM5CPs1Y","user":{"login":"suryaprasanna","id":20996567,"node_id":"MDQ6VXNlcjIwOTk2NTY3","avatar_url":"https://avatars.githubusercontent.com/u/20996567?v=4","gravatar_id":"","url":"https://api.github.com/users/suryaprasanna","html_url":"https://github.com/suryaprasanna","followers_url":"https://api.github.com/users/suryaprasanna/followers","following_url":"https://api.github.com/users/suryaprasanna/following{/other_user}","gists_url":"https://api.github.com/users/suryaprasanna/gists{/gist_id}","starred_url":"https://api.github.com/users/suryaprasanna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/suryaprasanna/subscriptions","organizations_url":"https://api.github.com/users/suryaprasanna/orgs","repos_url":"https://api.github.com/users/suryaprasanna/repos","events_url":"https://api.github.com/users/suryaprasanna/events{/privacy}","received_events_url":"https://api.github.com/users/suryaprasanna/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T19:45:55Z","updated_at":"2022-04-27T19:45:55Z","author_association":"CONTRIBUTOR","body":"@sharathkola I have already verified the commit files, they look good.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111412056/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111420094","html_url":"https://github.com/apache/hudi/issues/5451#issuecomment-1111420094","issue_url":"https://api.github.com/repos/apache/hudi/issues/5451","id":1111420094,"node_id":"IC_kwDOBI7nWM5CPuy-","user":{"login":"kazdy","id":27806231,"node_id":"MDQ6VXNlcjI3ODA2MjMx","avatar_url":"https://avatars.githubusercontent.com/u/27806231?v=4","gravatar_id":"","url":"https://api.github.com/users/kazdy","html_url":"https://github.com/kazdy","followers_url":"https://api.github.com/users/kazdy/followers","following_url":"https://api.github.com/users/kazdy/following{/other_user}","gists_url":"https://api.github.com/users/kazdy/gists{/gist_id}","starred_url":"https://api.github.com/users/kazdy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kazdy/subscriptions","organizations_url":"https://api.github.com/users/kazdy/orgs","repos_url":"https://api.github.com/users/kazdy/repos","events_url":"https://api.github.com/users/kazdy/events{/privacy}","received_events_url":"https://api.github.com/users/kazdy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T19:55:03Z","updated_at":"2022-04-27T19:55:03Z","author_association":"CONTRIBUTOR","body":"Hi, I would add this jar to your job:\r\nhttps://mvnrepository.com/artifact/org.apache.hudi/hudi-aws\r\n\r\nI think these dependencies were separated from Spark bundle in Hudi 0.10.1 release: \r\nhttps://github.com/apache/hudi/pull/4542","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111420094/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111432645","html_url":"https://github.com/apache/hudi/issues/5021#issuecomment-1111432645","issue_url":"https://api.github.com/repos/apache/hudi/issues/5021","id":1111432645,"node_id":"IC_kwDOBI7nWM5CPx3F","user":{"login":"kazdy","id":27806231,"node_id":"MDQ6VXNlcjI3ODA2MjMx","avatar_url":"https://avatars.githubusercontent.com/u/27806231?v=4","gravatar_id":"","url":"https://api.github.com/users/kazdy","html_url":"https://github.com/kazdy","followers_url":"https://api.github.com/users/kazdy/followers","following_url":"https://api.github.com/users/kazdy/following{/other_user}","gists_url":"https://api.github.com/users/kazdy/gists{/gist_id}","starred_url":"https://api.github.com/users/kazdy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kazdy/subscriptions","organizations_url":"https://api.github.com/users/kazdy/orgs","repos_url":"https://api.github.com/users/kazdy/repos","events_url":"https://api.github.com/users/kazdy/events{/privacy}","received_events_url":"https://api.github.com/users/kazdy/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T20:08:15Z","updated_at":"2022-04-27T20:08:15Z","author_association":"CONTRIBUTOR","body":"Hi, I'm also interested in this feature being available in Athena (and Resdhift Spectrum maybe?).\r\n\r\nI sent an email to athena-feedback@amazon.com to get some visibility:\r\n> If you would like Athena support for writing Hudi datasets, send feedback to <[athena-feedback@amazon.com](mailto:athena-feedback@amazon.com)>.\r\nhttps://docs.aws.amazon.com/athena/latest/ug/querying-hudi.html#querying-hudi-in-athena-considerations-and-limitations\r\n\r\nI am going to reach out to AWS account/architect working with us with a feature request to get this on their roadmap.\r\nBut then isn't it dependent on the work on the new presto/trino connector? Not sure if this is related, but would like to understand before talking to AWS folks :)","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111432645/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111530355","html_url":"https://github.com/apache/hudi/issues/5451#issuecomment-1111530355","issue_url":"https://api.github.com/repos/apache/hudi/issues/5451","id":1111530355,"node_id":"IC_kwDOBI7nWM5CQJtz","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T22:09:50Z","updated_at":"2022-04-27T22:09:50Z","author_association":"CONTRIBUTOR","body":"@jdattani As @kazdy suggested, you need to add `hudi-aws` jar for classes that are specific to AWS.  Let us know if adding the jar works.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111530355/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111532666","html_url":"https://github.com/apache/hudi/issues/5452#issuecomment-1111532666","issue_url":"https://api.github.com/repos/apache/hudi/issues/5452","id":1111532666,"node_id":"IC_kwDOBI7nWM5CQKR6","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T22:13:35Z","updated_at":"2022-04-27T22:13:35Z","author_association":"CONTRIBUTOR","body":"@santoshsb could you post the Hudi write config used to write the table and the commands to reproduce the problem?  @xiarixiaoyao could you provide some insights around schema evolution?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111532666/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111537861","html_url":"https://github.com/apache/hudi/issues/5385#issuecomment-1111537861","issue_url":"https://api.github.com/repos/apache/hudi/issues/5385","id":1111537861,"node_id":"IC_kwDOBI7nWM5CQLjF","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-27T22:22:01Z","updated_at":"2022-04-27T22:22:08Z","author_association":"CONTRIBUTOR","body":"> The above test case does not add _hoodie_is_deleted to the existing hudi table before writing a dataset with _hoodie_is_deleted column.\r\n\r\nIn that case, the dataset to be written has the new schema, and Hudi automatically picks that up and evolves the table schema when writing the data.\r\n\r\n> Also, what is the best way to modify the schema of an existing hudi table?\r\n\r\nAs @pratyakshsharma mentioned, you don't explicitly modify the schema of an existing Hudi table manually.  Hudi takes care of it in a backward-compatible way.  You only need to provide the new schema or the data with new schema.  For the example I gave, the changed schema is passed to Deltastreamer as an argument so that the deltasteamer can pick that up, and update the table with the right schema.  For Spark datasource (e.g., `df.write`), you don't even need to change the schema, since the dataframe to write has embedded schema with the field `_hoodie_is_deleted`.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111537861/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111623168","html_url":"https://github.com/apache/hudi/pull/5453#issuecomment-1111623168","issue_url":"https://api.github.com/repos/apache/hudi/issues/5453","id":1111623168,"node_id":"IC_kwDOBI7nWM5CQgYA","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T00:57:28Z","updated_at":"2022-04-28T00:57:28Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"74f6177886e338df24c4bfcfaab53e3eab7f00f4\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8350\",\n    \"triggerID\" : \"74f6177886e338df24c4bfcfaab53e3eab7f00f4\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 74f6177886e338df24c4bfcfaab53e3eab7f00f4 Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8350) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111623168/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111652198","html_url":"https://github.com/apache/hudi/issues/5395#issuecomment-1111652198","issue_url":"https://api.github.com/repos/apache/hudi/issues/5395","id":1111652198,"node_id":"IC_kwDOBI7nWM5CQndm","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T01:49:53Z","updated_at":"2022-04-28T01:49:53Z","author_association":"CONTRIBUTOR","body":"> deleteAnyLeftOverMarkers\r\n\r\nI'm not quite sure, we actually clean the MARKER folder each time we commit an instant, and here we do it again when the instant was archived? (curious about the background here ?), and like what @codope saied, the call in [#L682-L684](https://github.com/apache/hudi/blob/762623a15cfeba6f3fe936c238d660685ae62b50/hudi-common/src/main/java/org/apache/hudi/common/fs/FSUtils.java#L682-L684) already delete recursively first.\r\n\r\nThe instant commit and archiving both happens in JobManager in single thread, so there should not be parallelism problem.\r\n\r\n@todd5167 Did you write to the same table from two separate Flink jobs ?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111652198/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111662836","html_url":"https://github.com/apache/hudi/pull/5436#issuecomment-1111662836","issue_url":"https://api.github.com/repos/apache/hudi/issues/5436","id":1111662836,"node_id":"IC_kwDOBI7nWM5CQqD0","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T02:10:36Z","updated_at":"2022-04-28T02:13:56Z","author_association":"CONTRIBUTOR","body":">We need to have different concerns for different table types that can use in different scenario. As i said above, we should focus more on query performance for COW tables, and write performance for MOR tables. \r\n\r\nI don't think so, the write characteristics difference of COW and MOR table is a fact but that does not mean we should deteriorate current performance for both. Actually most of the streaming users use the COW table, they did expect a normal throughput of streaming ingestion. Double write is totally not acceptable for the latency and throughput, not to say the storage cost. BTW, there is not full joins of my COW solution, but just another iterator cost.\r\n\r\n>the write throughput is the main point for MOR. At most cases, we do not need to write out extra cdc files. The timing at which the CDC files has to be generated is when the MOR table will write out the base file, not log fil\r\n\r\nI don't think so, can you imagine a little the user scenarios of consuming the CDC change logs ? The users expect a low end-to-end latency for ETL pipelining. Based on the real use case, you solution for MOR table is even not impractical.\r\nI would vote a totally -1 for this.\r\n\r\n> Hudi transaction is managed by timeline. Failure to write CDC files or data files should not complete the commit correctly\r\n\r\nYou may need to read my concern again to answer my question.\r\n\r\n>The management about log files is as usual. Only CDC files, we need to consider to clean them in time by the clean service.\r\n\r\nYou need to give more details here, actually i don't think the current cleaning service for data files should also take care of the CDC log files cleaning. that is too heavy for the component, at least we should make a new separate cleaning service to not mess up the existing cleaning strategy.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111662836/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111665061","html_url":"https://github.com/apache/hudi/pull/5436#issuecomment-1111665061","issue_url":"https://api.github.com/repos/apache/hudi/issues/5436","id":1111665061,"node_id":"IC_kwDOBI7nWM5CQqml","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T02:15:01Z","updated_at":"2022-04-28T02:15:01Z","author_association":"CONTRIBUTOR","body":"Here is a design doc from Apache Iceberg: https://docs.google.com/document/d/1bN6rdLNcYOHnT3xVBfB33BoiPO06aKBo56SZmuU9pnY/edit, a general design rule is not to double write, you can take a reference and find the reasons from the Iceberg insight.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111665061/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111670084","html_url":"https://github.com/apache/hudi/pull/5436#issuecomment-1111670084","issue_url":"https://api.github.com/repos/apache/hudi/issues/5436","id":1111670084,"node_id":"IC_kwDOBI7nWM5CQr1E","user":{"login":"YannByron","id":10036681,"node_id":"MDQ6VXNlcjEwMDM2Njgx","avatar_url":"https://avatars.githubusercontent.com/u/10036681?v=4","gravatar_id":"","url":"https://api.github.com/users/YannByron","html_url":"https://github.com/YannByron","followers_url":"https://api.github.com/users/YannByron/followers","following_url":"https://api.github.com/users/YannByron/following{/other_user}","gists_url":"https://api.github.com/users/YannByron/gists{/gist_id}","starred_url":"https://api.github.com/users/YannByron/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YannByron/subscriptions","organizations_url":"https://api.github.com/users/YannByron/orgs","repos_url":"https://api.github.com/users/YannByron/repos","events_url":"https://api.github.com/users/YannByron/events{/privacy}","received_events_url":"https://api.github.com/users/YannByron/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T02:22:53Z","updated_at":"2022-04-28T02:22:53Z","author_association":"CONTRIBUTOR","body":"@vinothchandar\r\n\r\nTo share how i think about the CDC scenario:\r\nThe CDC scenario should be **a whole pipeline** that maybe from ODW to DWD, to DWS, to the other downstream. It's not just **a simple, single read/write job**. So we can't just focus on the upstream write efficiency, and ignore the downstream query efficiency. We need to balance them, should consider the problem from the perspective of the whole incremental warehouse.\r\n\r\nBack to this solution, in the cases that we have to write out CDC files, no matter whether the table is mor or cow, i think at most streaming scenes, just a fraction of data need to be inserted/updated/deleted. Let me make it a little bit clearer with numbers. There is a file with 100 records, and 5 records of these will be changed. Then we rewrite a base file in which 95 records have been kept and 5 records have been changed. But, just 5 records will be written out the CDC files. i think this can be acceptable.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111670084/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111686117","html_url":"https://github.com/apache/hudi/pull/5307#issuecomment-1111686117","issue_url":"https://api.github.com/repos/apache/hudi/issues/5307","id":1111686117,"node_id":"IC_kwDOBI7nWM5CQvvl","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T02:52:46Z","updated_at":"2022-04-28T02:52:46Z","author_association":"CONTRIBUTOR","body":"> @yihua : this has to go into RC2 right ?\r\n\r\nForgot to reply.  It is in RC2.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111686117/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111689002","html_url":"https://github.com/apache/hudi/issues/5395#issuecomment-1111689002","issue_url":"https://api.github.com/repos/apache/hudi/issues/5395","id":1111689002,"node_id":"IC_kwDOBI7nWM5CQwcq","user":{"login":"todd5167","id":24680803,"node_id":"MDQ6VXNlcjI0NjgwODAz","avatar_url":"https://avatars.githubusercontent.com/u/24680803?v=4","gravatar_id":"","url":"https://api.github.com/users/todd5167","html_url":"https://github.com/todd5167","followers_url":"https://api.github.com/users/todd5167/followers","following_url":"https://api.github.com/users/todd5167/following{/other_user}","gists_url":"https://api.github.com/users/todd5167/gists{/gist_id}","starred_url":"https://api.github.com/users/todd5167/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/todd5167/subscriptions","organizations_url":"https://api.github.com/users/todd5167/orgs","repos_url":"https://api.github.com/users/todd5167/repos","events_url":"https://api.github.com/users/todd5167/events{/privacy}","received_events_url":"https://api.github.com/users/todd5167/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T02:58:52Z","updated_at":"2022-04-28T02:58:52Z","author_association":"CONTRIBUTOR","body":"> > deleteAnyLeftOverMarkers\r\n> \r\n> I'm not quite sure, we actually clean the MARKER folder each time we commit an instant, and here we do it again when the instant was archived? (curious about the background here ?), and like what @codope saied, the call in [#L682-L684](https://github.com/apache/hudi/blob/762623a15cfeba6f3fe936c238d660685ae62b50/hudi-common/src/main/java/org/apache/hudi/common/fs/FSUtils.java#L682-L684) already delete recursively first.\r\n> \r\n> The instant commit and archiving both happens in JobManager in single thread, so there should not be parallelism problem.\r\n> \r\n> @todd5167 Did you write to the same table from two separate Flink jobs ?\r\n\r\n@danny0405  A flink job corresponds to a hudi table.   checkpoint config:\r\n```\r\nInterval\t10m 0s\r\nTimeout\t 3m 0s\r\nMinimum Pause Between Checkpoints\t0ms\r\nMaximum Concurrent Checkpoints\t2\r\n```\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111689002/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111697151","html_url":"https://github.com/apache/hudi/issues/5452#issuecomment-1111697151","issue_url":"https://api.github.com/repos/apache/hudi/issues/5452","id":1111697151,"node_id":"IC_kwDOBI7nWM5CQyb_","user":{"login":"santoshsb","id":15146609,"node_id":"MDQ6VXNlcjE1MTQ2NjA5","avatar_url":"https://avatars.githubusercontent.com/u/15146609?v=4","gravatar_id":"","url":"https://api.github.com/users/santoshsb","html_url":"https://github.com/santoshsb","followers_url":"https://api.github.com/users/santoshsb/followers","following_url":"https://api.github.com/users/santoshsb/following{/other_user}","gists_url":"https://api.github.com/users/santoshsb/gists{/gist_id}","starred_url":"https://api.github.com/users/santoshsb/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/santoshsb/subscriptions","organizations_url":"https://api.github.com/users/santoshsb/orgs","repos_url":"https://api.github.com/users/santoshsb/repos","events_url":"https://api.github.com/users/santoshsb/events{/privacy}","received_events_url":"https://api.github.com/users/santoshsb/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T03:15:36Z","updated_at":"2022-04-28T03:15:36Z","author_association":"NONE","body":"Thanks @yihua, here are the detailed spark shell commands we used \r\n\r\n`./spark-shell --jars '/Users/balamats/work/hudi/packaging/hudi-spark-bundle/target/hudi-spark3.2-bundle_2.12-0.12.0-SNAPSHOT.jar' --conf 'spark.serializer=org.apache.spark.serializer.KryoSerializer'\r\n\r\nimport org.apache.spark.sql.SaveMode\r\nimport org.apache.spark.sql.functions._\r\nimport org.apache.hudi.DataSourceWriteOptions\r\nimport org.apache.hudi.DataSourceReadOptions\r\nimport org.apache.hudi.config.HoodieWriteConfig\r\nimport org.apache.hudi.hive.MultiPartKeysValueExtractor\r\n\r\n//Define a Patient FHIR resource, for simplicity have deleted most of the elements and retained a few\r\nval orgString = \"\"\"{\"resourceType\":\"Patient\",\"id\":\"4ad86a5c-926e-439b-9352-f8ac9ab780f1\",\"lastUpdated\":\"2022-03-11T15:18:18.90836+05:30\",\"source\":\"4a0701fe-5c3b-482b-895d-875fcbd21481\",\"gender\":\"male\",\"birthDate\":\"1974-01-05\",\"maritalStatus\":{\"coding\":[{\"system\":\"http://terminology.hl7.org/CodeSystem/v3-MaritalStatus\",\"code\":\"M\",\"display\":\"M\"}],\"text\":\"M\"}}\"\"\"\r\n\r\n//Convert to dataframe\r\nval orgStringDf = spark.read.json(Seq(orgString).toDS)\r\n\r\n//Specify common DataSourceWriteOptions in the single hudiOptions variable\r\nval hudiOptions = Map[String,String](\r\n  HoodieWriteConfig.TABLE_NAME -> \"patient_hudi\",\r\n  DataSourceWriteOptions.TABLE_TYPE_OPT_KEY -> \"COPY_ON_WRITE\", \r\n  DataSourceWriteOptions.RECORDKEY_FIELD_OPT_KEY -> \"id\",\r\n  DataSourceWriteOptions.PARTITIONPATH_FIELD_OPT_KEY -> \"source\",\r\n  DataSourceWriteOptions.PRECOMBINE_FIELD_OPT_KEY -> \"lastUpdated\",\r\n DataSourceWriteOptions.HIVE_STYLE_PARTITIONING_OPT_KEY -> \"true\"\r\n)\r\n\r\n//Write the orgStringDf to a Hudi table\r\norgStringDf.write\r\n    .format(\"org.apache.hudi\")\r\n    .option(DataSourceWriteOptions.OPERATION_OPT_KEY, DataSourceWriteOptions.INSERT_OPERATION_OPT_VAL)\r\n    .options(hudiOptions)\r\n    .mode(SaveMode.Overwrite)\r\n    .save(\"/Users/balamats/work/data/updateTst/json_schema_tst/hudi\")\r\n\r\n//Read the Hudi table\r\nval patienthudi  = spark.read.format(\"hudi\").load(\"/Users/balamats/work/data/updateTst/json_schema_tst/hudi\")\r\n\r\n//Printschema\r\npatienthudi.printSchema\r\nroot\r\n |-- _hoodie_commit_time: string (nullable = true)\r\n |-- _hoodie_commit_seqno: string (nullable = true)\r\n |-- _hoodie_record_key: string (nullable = true)\r\n |-- _hoodie_partition_path: string (nullable = true)\r\n |-- _hoodie_file_name: string (nullable = true)\r\n |-- birthDate: string (nullable = true)\r\n |-- gender: string (nullable = true)\r\n |-- id: string (nullable = true)\r\n |-- lastUpdated: string (nullable = true)\r\n |-- maritalStatus: struct (nullable = true)\r\n |    |-- coding: array (nullable = true)\r\n |    |    |-- element: struct (containsNull = true)\r\n |    |    |    |-- code: string (nullable = true)\r\n |    |    |    |-- display: string (nullable = true)\r\n |    |    |    |-- system: string (nullable = true)\r\n |    |-- text: string (nullable = true)\r\n |-- resourceType: string (nullable = true)\r\n |-- source: string (nullable = true)\r\n\r\n //Select fields to verify\r\n patienthudi.select(\"id\",\"gender\",\"maritalStatus\").show(false)\r\n+------------------------------------+------+---------------------------------------------------------------------+\r\n|id                                  |gender|maritalStatus                                                        |\r\n+------------------------------------+------+---------------------------------------------------------------------+\r\n|4ad86a5c-926e-439b-9352-f8ac9ab780f1|male  |{[{M, M, http://terminology.hl7.org/CodeSystem/v3-MaritalStatus}], M}|\r\n+------------------------------------+------+---------------------------------------------------------------------+\r\n\r\n//Update: Based on our usecase add a new patient resource, this resource might contain new columns and might not have existing columns (normal use case with FHIR data)\r\n\r\nval updatedString =  \"\"\"{\"resourceType\":\"Patient\",\"id\":\"596c7a94-bada-4303-85d4-7067c586999e\",\"lastUpdated\":\"2022-04-20T15:18:18.90836+05:30\",\"source\":\"4a0701fe-5c3b-482b-895d-875fcbd2148a\",\"gender\":\"female\",\"birthDate\":\"2005-08-30\",\"multipleBirthBoolean\":true}\"\"\"\r\n\r\n//Convert the new resource string into DF\r\nval updatedStringDf = spark.read.json(Seq(updatedString).toDS)\r\n\r\n//Check the schema of the new resource that is being added\r\nupdatedStringDf.printSchema\r\nroot\r\n |-- birthDate: string (nullable = true)\r\n |-- gender: string (nullable = true)\r\n |-- id: string (nullable = true)\r\n |-- lastUpdated: string (nullable = true)\r\n |-- multipleBirthBoolean: boolean (nullable = true)\r\n |-- resourceType: string (nullable = true)\r\n |-- source: string (nullable = true)\r\n\r\n\r\n//Upsert the new resource\r\nupdatedStringDf.write\r\n    .format(\"org.apache.hudi\")\r\n    .options(hudiOptions)\r\n    .option(DataSourceWriteOptions.OPERATION_OPT_KEY, DataSourceWriteOptions.UPSERT_OPERATION_OPT_VAL)\r\n    .option(DataSourceWriteOptions.PAYLOAD_CLASS_OPT_KEY, \"org.apache.hudi.common.model.EmptyHoodieRecordPayload\")\r\n    .mode(SaveMode.Append)\r\n    .save(\"/Users/balamats/work/data/updateTst/json_schema_tst/hudi\")\r\n\r\n//Read the Hudi table\r\nval patienthudi  = spark.read.format(\"hudi\").load(\"/Users/balamats/work/data/updateTst/json_schema_tst/hudi\")\r\n\r\n//Print the schema after adding the new record\r\npatienthudi.printSchema\r\nroot\r\n |-- _hoodie_commit_time: string (nullable = true)\r\n |-- _hoodie_commit_seqno: string (nullable = true)\r\n |-- _hoodie_record_key: string (nullable = true)\r\n |-- _hoodie_partition_path: string (nullable = true)\r\n |-- _hoodie_file_name: string (nullable = true)\r\n |-- birthDate: string (nullable = true)\r\n |-- gender: string (nullable = true)\r\n |-- id: string (nullable = true)\r\n |-- lastUpdated: string (nullable = true)\r\n |-- multipleBirthBoolean: boolean (nullable = true)\r\n |-- resourceType: string (nullable = true)\r\n |-- source: string (nullable = true)\r\n\r\n //Select fields to verify\r\n patienthudi.select(\"id\",\"gender\",\"maritalStatus\").show(false)\r\norg.apache.spark.sql.AnalysisException: cannot resolve 'maritalStatus' given input columns: [_hoodie_commit_seqno, _hoodie_commit_time, _hoodie_file_name, _hoodie_partition_path, _hoodie_record_key, birthDate, gender, id, lastUpdated, multipleBirthBoolean, resourceType, source];\r\n'Project [id#130, gender#129, 'maritalStatus]\r\n+- Relation [_hoodie_commit_time#123,_hoodie_commit_seqno#124,_hoodie_record_key#125,_hoodie_partition_path#126,_hoodie_file_name#127,birthDate#128,gender#129,id#130,lastUpdated#131,multipleBirthBoolean#132,resourceType#133,source#134] parquet\r\n\r\n  at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:54)\r\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:179)\r\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:175)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUpWithPruning$2(TreeNode.scala:535)\r\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUpWithPruning(TreeNode.scala:535)\r\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUpWithPruning$1(QueryPlan.scala:181)\r\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:193)\r\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\r\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:193)\r\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:204)\r\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:209)\r\n  at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n  at scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n  at scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n  at scala.collection.AbstractTraversable.map(Traversable.scala:108)\r\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:209)\r\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:214)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:323)\r\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:214)\r\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUpWithPruning(QueryPlan.scala:181)\r\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:161)\r\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:175)\r\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:94)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:263)\r\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:94)\r\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:91)\r\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:182)\r\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:205)\r\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\r\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:202)\r\n  at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:88)\r\n  at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\r\n  at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:196)\r\n  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n  at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:196)\r\n  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:88)\r\n  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:86)\r\n  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:78)\r\n  at org.apache.spark.sql.Dataset$.$anonfun$ofRows$1(Dataset.scala:90)\r\n  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:88)\r\n  at org.apache.spark.sql.Dataset.withPlan(Dataset.scala:3734)\r\n  at org.apache.spark.sql.Dataset.select(Dataset.scala:1454)\r\n  at org.apache.spark.sql.Dataset.select(Dataset.scala:1471)\r\n  ... 49 elided`\r\n\r\nOur expectation after adding the second row was, \r\n1. The new column \"multipleBirthBoolean\" should have been added to the schema and would be null for the previous entry.\r\n2. The existing \"maritalStatus\" column present in the destination schema added by the first entry should be present after adding the second entry and should have been null for the second entry. \r\n\r\nWe might be missing some config or we feel that when we add a new entry it should contain all the columns present in the destination schema regardless if they are NULL they should be present, If we do need a uber schema we didn't find the spark code to convert our second dataframe \"updatedStringDf\" to add those columns with NULL values, basically reading the uber schema and merging it into \"updatedStringDf\" with NULL values. We did try these commands while creating the second dataframe\r\n\r\n`val updatedStringDf = spark.read.schema(patientHudi.schema).json(Seq(updatedString).toDS)`\r\n\r\nBut than the new schema for the updatedStringDf misses the \"multipleBirthBoolean\" column present in the second entry.\r\n\r\n`root\r\n |-- birthDate: string (nullable = true)\r\n |-- gender: string (nullable = true)\r\n |-- id: string (nullable = true)\r\n |-- lastUpdated: string (nullable = true)\r\n |-- maritalStatus: struct (nullable = true)\r\n |    |-- coding: array (nullable = true)\r\n |    |    |-- element: struct (containsNull = true)\r\n |    |    |    |-- code: string (nullable = true)\r\n |    |    |    |-- display: string (nullable = true)\r\n |    |    |    |-- system: string (nullable = true)\r\n |    |-- text: string (nullable = true)\r\n |-- resourceType: string (nullable = true)\r\n |-- source: string (nullable = true)`\r\n\r\nThanks for the help.\r\nSantosh\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111697151/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111703266","html_url":"https://github.com/apache/hudi/pull/5286#issuecomment-1111703266","issue_url":"https://api.github.com/repos/apache/hudi/issues/5286","id":1111703266,"node_id":"IC_kwDOBI7nWM5CQz7i","user":{"login":"xicm","id":36392121,"node_id":"MDQ6VXNlcjM2MzkyMTIx","avatar_url":"https://avatars.githubusercontent.com/u/36392121?v=4","gravatar_id":"","url":"https://api.github.com/users/xicm","html_url":"https://github.com/xicm","followers_url":"https://api.github.com/users/xicm/followers","following_url":"https://api.github.com/users/xicm/following{/other_user}","gists_url":"https://api.github.com/users/xicm/gists{/gist_id}","starred_url":"https://api.github.com/users/xicm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xicm/subscriptions","organizations_url":"https://api.github.com/users/xicm/orgs","repos_url":"https://api.github.com/users/xicm/repos","events_url":"https://api.github.com/users/xicm/events{/privacy}","received_events_url":"https://api.github.com/users/xicm/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T03:27:48Z","updated_at":"2022-04-28T03:27:48Z","author_association":"CONTRIBUTOR","body":"Thanks for review, if there is a conflict with other submits when you reveiw, ping me, I will fix.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111703266/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111708499","html_url":"https://github.com/apache/hudi/pull/5436#issuecomment-1111708499","issue_url":"https://api.github.com/repos/apache/hudi/issues/5436","id":1111708499,"node_id":"IC_kwDOBI7nWM5CQ1NT","user":{"login":"XuQianJin-Stars","id":10494131,"node_id":"MDQ6VXNlcjEwNDk0MTMx","avatar_url":"https://avatars.githubusercontent.com/u/10494131?v=4","gravatar_id":"","url":"https://api.github.com/users/XuQianJin-Stars","html_url":"https://github.com/XuQianJin-Stars","followers_url":"https://api.github.com/users/XuQianJin-Stars/followers","following_url":"https://api.github.com/users/XuQianJin-Stars/following{/other_user}","gists_url":"https://api.github.com/users/XuQianJin-Stars/gists{/gist_id}","starred_url":"https://api.github.com/users/XuQianJin-Stars/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/XuQianJin-Stars/subscriptions","organizations_url":"https://api.github.com/users/XuQianJin-Stars/orgs","repos_url":"https://api.github.com/users/XuQianJin-Stars/repos","events_url":"https://api.github.com/users/XuQianJin-Stars/events{/privacy}","received_events_url":"https://api.github.com/users/XuQianJin-Stars/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T03:39:47Z","updated_at":"2022-04-28T03:39:47Z","author_association":"CONTRIBUTOR","body":"I learned that delta lake also extracted the CDF for processing. I think that the CDF can be extracted to better control the data and specifications in the CDC. I also read iceberg's design document that basically plagiarizes and reuses the existing logic of hudi . https://databricks.com/blog/2021/06/09/how-to-simplify-cdc-with-delta-lakes-change-data-feed.html","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111708499/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111713903","html_url":"https://github.com/apache/hudi/issues/5452#issuecomment-1111713903","issue_url":"https://api.github.com/repos/apache/hudi/issues/5452","id":1111713903,"node_id":"IC_kwDOBI7nWM5CQ2hv","user":{"login":"xiarixiaoyao","id":13514703,"node_id":"MDQ6VXNlcjEzNTE0NzAz","avatar_url":"https://avatars.githubusercontent.com/u/13514703?v=4","gravatar_id":"","url":"https://api.github.com/users/xiarixiaoyao","html_url":"https://github.com/xiarixiaoyao","followers_url":"https://api.github.com/users/xiarixiaoyao/followers","following_url":"https://api.github.com/users/xiarixiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/xiarixiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/xiarixiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiarixiaoyao/subscriptions","organizations_url":"https://api.github.com/users/xiarixiaoyao/orgs","repos_url":"https://api.github.com/users/xiarixiaoyao/repos","events_url":"https://api.github.com/users/xiarixiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/xiarixiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T03:50:56Z","updated_at":"2022-04-28T03:50:56Z","author_association":"CONTRIBUTOR","body":"@santoshsb\r\nmultipleBirthBoolean is a new column to be added,  but How to determine its added position？  is it added as the last column or somewhere  else ？ \r\n\r\nIf the above questions can be answered ， i think i can help you to solve the problem\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111713903/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111715248","html_url":"https://github.com/apache/hudi/issues/5452#issuecomment-1111715248","issue_url":"https://api.github.com/repos/apache/hudi/issues/5452","id":1111715248,"node_id":"IC_kwDOBI7nWM5CQ22w","user":{"login":"santoshsb","id":15146609,"node_id":"MDQ6VXNlcjE1MTQ2NjA5","avatar_url":"https://avatars.githubusercontent.com/u/15146609?v=4","gravatar_id":"","url":"https://api.github.com/users/santoshsb","html_url":"https://github.com/santoshsb","followers_url":"https://api.github.com/users/santoshsb/followers","following_url":"https://api.github.com/users/santoshsb/following{/other_user}","gists_url":"https://api.github.com/users/santoshsb/gists{/gist_id}","starred_url":"https://api.github.com/users/santoshsb/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/santoshsb/subscriptions","organizations_url":"https://api.github.com/users/santoshsb/orgs","repos_url":"https://api.github.com/users/santoshsb/repos","events_url":"https://api.github.com/users/santoshsb/events{/privacy}","received_events_url":"https://api.github.com/users/santoshsb/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T03:54:18Z","updated_at":"2022-04-28T03:54:18Z","author_association":"NONE","body":"@xiarixiaoyao we are not concerned about the position as long as its there in the schema (either as the last column or somewhere else) along with all the existing columns.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111715248/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111733322","html_url":"https://github.com/apache/hudi/pull/5445#issuecomment-1111733322","issue_url":"https://api.github.com/repos/apache/hudi/issues/5445","id":1111733322,"node_id":"IC_kwDOBI7nWM5CQ7RK","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T04:30:47Z","updated_at":"2022-04-28T04:30:47Z","author_association":"CONTRIBUTOR","body":"[api_patch.patch.zip](https://github.com/apache/hudi/files/8579506/api_patch.patch.zip)\r\nThanks, i have write a patch, but i'm not sure whether we should go this direction, why not just use SQL directly.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111733322/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111746671","html_url":"https://github.com/apache/hudi/pull/5447#issuecomment-1111746671","issue_url":"https://api.github.com/repos/apache/hudi/issues/5447","id":1111746671,"node_id":"IC_kwDOBI7nWM5CQ-hv","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T04:58:56Z","updated_at":"2022-04-28T04:58:56Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"9cf0136bcc582b2ca47f06eec2fa49e114c15651\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8349\",\n    \"triggerID\" : \"9cf0136bcc582b2ca47f06eec2fa49e114c15651\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"db057b18ade8b991aaab3c1f59cb3a746f26bb56\",\n    \"status\" : \"SUCCESS\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8353\",\n    \"triggerID\" : \"db057b18ade8b991aaab3c1f59cb3a746f26bb56\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* db057b18ade8b991aaab3c1f59cb3a746f26bb56 Azure: [SUCCESS](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8353) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111746671/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111749145","html_url":"https://github.com/apache/hudi/issues/5346#issuecomment-1111749145","issue_url":"https://api.github.com/repos/apache/hudi/issues/5346","id":1111749145,"node_id":"IC_kwDOBI7nWM5CQ_IZ","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T05:04:26Z","updated_at":"2022-04-28T05:04:26Z","author_association":"CONTRIBUTOR","body":"@danny0405 do you have any idea on why the `HiveConf` class is not found from the Flink bundle?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111749145/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111750027","html_url":"https://github.com/apache/hudi/issues/5330#issuecomment-1111750027","issue_url":"https://api.github.com/repos/apache/hudi/issues/5330","id":1111750027,"node_id":"IC_kwDOBI7nWM5CQ_WL","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T05:06:21Z","updated_at":"2022-04-28T05:06:21Z","author_association":"CONTRIBUTOR","body":"@Guanpx have you tried the latest master and see if the fix solves the problem for you?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111750027/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111754225","html_url":"https://github.com/apache/hudi/issues/5301#issuecomment-1111754225","issue_url":"https://api.github.com/repos/apache/hudi/issues/5301","id":1111754225,"node_id":"IC_kwDOBI7nWM5CRAXx","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T05:14:40Z","updated_at":"2022-04-28T05:14:40Z","author_association":"CONTRIBUTOR","body":"This is related to HUDI-3511.  Tracking the progress there and closing this issue.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111754225/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111758104","html_url":"https://github.com/apache/hudi/issues/5442#issuecomment-1111758104","issue_url":"https://api.github.com/repos/apache/hudi/issues/5442","id":1111758104,"node_id":"IC_kwDOBI7nWM5CRBUY","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T05:22:15Z","updated_at":"2022-04-28T05:22:15Z","author_association":"CONTRIBUTOR","body":"@mandar-mw In order to deduplicate records within and across commits for INSERT operation, you need to see both of the following configs to be `true` (they are `false` by default): [`hoodie.datasource.write.insert.drop.duplicates`](https://hudi.apache.org/docs/configurations#hoodiedatasourcewriteinsertdropduplicates) and [`hoodie.combine.before.insert`](https://hudi.apache.org/docs/configurations#hoodiecombinebeforeinsert).  Let me know if this helps to solve your problem.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111758104/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111758882","html_url":"https://github.com/apache/hudi/issues/5442#issuecomment-1111758882","issue_url":"https://api.github.com/repos/apache/hudi/issues/5442","id":1111758882,"node_id":"IC_kwDOBI7nWM5CRBgi","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T05:23:53Z","updated_at":"2022-04-28T05:23:53Z","author_association":"CONTRIBUTOR","body":"@qianchutao Feel free to open a separate Github issue for your problem if it still happens.  We can help you promptly.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111758882/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111767712","html_url":"https://github.com/apache/hudi/issues/5290#issuecomment-1111767712","issue_url":"https://api.github.com/repos/apache/hudi/issues/5290","id":1111767712,"node_id":"IC_kwDOBI7nWM5CRDqg","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T05:36:04Z","updated_at":"2022-04-28T05:36:04Z","author_association":"CONTRIBUTOR","body":"@easonwood Great that it's working fine now.  We have fixed a few issues around empty instant files and metadata table update logic since Hudi 0.8.0. You can also give the latest master a try with metadata table enabled.  I'll close this issue now.  Feel free to reopen the issue if you see more problems.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111767712/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111770935","html_url":"https://github.com/apache/hudi/issues/5280#issuecomment-1111770935","issue_url":"https://api.github.com/repos/apache/hudi/issues/5280","id":1111770935,"node_id":"IC_kwDOBI7nWM5CREc3","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T05:43:08Z","updated_at":"2022-04-28T05:43:08Z","author_association":"CONTRIBUTOR","body":"@arunb2w The docker demo is not fully supported on Apple M1 chip yet, which is arm64 architecture.  That breaks some functionality of Hadoop and Hive in the demo.  We have a Jira ticket to track it: HUDI-2786","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111770935/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111785202","html_url":"https://github.com/apache/hudi/issues/5431#issuecomment-1111785202","issue_url":"https://api.github.com/repos/apache/hudi/issues/5431","id":1111785202,"node_id":"IC_kwDOBI7nWM5CRH7y","user":{"login":"YuangZhang","id":28397485,"node_id":"MDQ6VXNlcjI4Mzk3NDg1","avatar_url":"https://avatars.githubusercontent.com/u/28397485?v=4","gravatar_id":"","url":"https://api.github.com/users/YuangZhang","html_url":"https://github.com/YuangZhang","followers_url":"https://api.github.com/users/YuangZhang/followers","following_url":"https://api.github.com/users/YuangZhang/following{/other_user}","gists_url":"https://api.github.com/users/YuangZhang/gists{/gist_id}","starred_url":"https://api.github.com/users/YuangZhang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YuangZhang/subscriptions","organizations_url":"https://api.github.com/users/YuangZhang/orgs","repos_url":"https://api.github.com/users/YuangZhang/repos","events_url":"https://api.github.com/users/YuangZhang/events{/privacy}","received_events_url":"https://api.github.com/users/YuangZhang/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T06:09:42Z","updated_at":"2022-04-28T06:09:42Z","author_association":"CONTRIBUTOR","body":"> @YuangZhang could you provide the steps with the environment for reproducing the issue, e.g., which Hudi and Flink versions are used, which file system is used for the target Hudi table, etc.?\r\n\r\nhudi version 0.11.0 build from release-0.11.0 \r\nflink version 1.13.5\r\nthe file system is hdfs","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111785202/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111800234","html_url":"https://github.com/apache/hudi/issues/5451#issuecomment-1111800234","issue_url":"https://api.github.com/repos/apache/hudi/issues/5451","id":1111800234,"node_id":"IC_kwDOBI7nWM5CRLmq","user":{"login":"jdattani","id":14809344,"node_id":"MDQ6VXNlcjE0ODA5MzQ0","avatar_url":"https://avatars.githubusercontent.com/u/14809344?v=4","gravatar_id":"","url":"https://api.github.com/users/jdattani","html_url":"https://github.com/jdattani","followers_url":"https://api.github.com/users/jdattani/followers","following_url":"https://api.github.com/users/jdattani/following{/other_user}","gists_url":"https://api.github.com/users/jdattani/gists{/gist_id}","starred_url":"https://api.github.com/users/jdattani/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jdattani/subscriptions","organizations_url":"https://api.github.com/users/jdattani/orgs","repos_url":"https://api.github.com/users/jdattani/repos","events_url":"https://api.github.com/users/jdattani/events{/privacy}","received_events_url":"https://api.github.com/users/jdattani/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T06:32:45Z","updated_at":"2022-04-28T06:32:45Z","author_association":"NONE","body":"@kazdy @yihua I tried including hudi-aws jar to Glue Dependent JARs path. But still getting the exact same error. Is there anything else I can try?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111800234/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111801665","html_url":"https://github.com/apache/hudi/issues/5372#issuecomment-1111801665","issue_url":"https://api.github.com/repos/apache/hudi/issues/5372","id":1111801665,"node_id":"IC_kwDOBI7nWM5CRL9B","user":{"login":"CodeCooker17","id":64473732,"node_id":"MDQ6VXNlcjY0NDczNzMy","avatar_url":"https://avatars.githubusercontent.com/u/64473732?v=4","gravatar_id":"","url":"https://api.github.com/users/CodeCooker17","html_url":"https://github.com/CodeCooker17","followers_url":"https://api.github.com/users/CodeCooker17/followers","following_url":"https://api.github.com/users/CodeCooker17/following{/other_user}","gists_url":"https://api.github.com/users/CodeCooker17/gists{/gist_id}","starred_url":"https://api.github.com/users/CodeCooker17/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CodeCooker17/subscriptions","organizations_url":"https://api.github.com/users/CodeCooker17/orgs","repos_url":"https://api.github.com/users/CodeCooker17/repos","events_url":"https://api.github.com/users/CodeCooker17/events{/privacy}","received_events_url":"https://api.github.com/users/CodeCooker17/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T06:34:45Z","updated_at":"2022-04-28T06:34:45Z","author_association":"CONTRIBUTOR","body":"\r\n\r\n\r\n> @meitianjinbu Following up on this, the Hudi bundles have shaded HBase-related classes so the bundle should work. In what flow do you see compatibility issues, e.g., writing, querying, `SparkHoodieHBaseIndex`, etc.? Could you also provide reproducible steps and error stacktrace if there is any?\r\n\r\nThe default value of hbase.defaults.for.version.skip in hbase-site.xml is false. This will cause the following exception to occur once the local hbase version is lower than 2.4.9. So it would be better if it is set to true by default.\r\n`\r\nCaused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238) ... 21 more Caused by: java.lang.ExceptionInInitializerError at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.<init>(ConnectionManager.java:658) ... 26 more Caused by: java.lang.RuntimeException: hbase-default.xml file seems to be for an older version of HBase (2.4.9), this version is 1.3.0 at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:71) at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) at org.apache.hadoop.hbase.client.ConnectionManager.<clinit>(ConnectionManager.java:235)`","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111801665/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111833777","html_url":"https://github.com/apache/hudi/issues/5280#issuecomment-1111833777","issue_url":"https://api.github.com/repos/apache/hudi/issues/5280","id":1111833777,"node_id":"IC_kwDOBI7nWM5CRTyx","user":{"login":"arunb2w","id":38204827,"node_id":"MDQ6VXNlcjM4MjA0ODI3","avatar_url":"https://avatars.githubusercontent.com/u/38204827?v=4","gravatar_id":"","url":"https://api.github.com/users/arunb2w","html_url":"https://github.com/arunb2w","followers_url":"https://api.github.com/users/arunb2w/followers","following_url":"https://api.github.com/users/arunb2w/following{/other_user}","gists_url":"https://api.github.com/users/arunb2w/gists{/gist_id}","starred_url":"https://api.github.com/users/arunb2w/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arunb2w/subscriptions","organizations_url":"https://api.github.com/users/arunb2w/orgs","repos_url":"https://api.github.com/users/arunb2w/repos","events_url":"https://api.github.com/users/arunb2w/events{/privacy}","received_events_url":"https://api.github.com/users/arunb2w/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T07:15:48Z","updated_at":"2022-04-28T07:15:48Z","author_association":"NONE","body":"okay thanks. can you please suggest are there any alternatives to run hudi in local for development purpose. ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111833777/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111837416","html_url":"https://github.com/apache/hudi/pull/5445#issuecomment-1111837416","issue_url":"https://api.github.com/repos/apache/hudi/issues/5445","id":1111837416,"node_id":"IC_kwDOBI7nWM5CRUro","user":{"login":"JerryYue-M","id":10253313,"node_id":"MDQ6VXNlcjEwMjUzMzEz","avatar_url":"https://avatars.githubusercontent.com/u/10253313?v=4","gravatar_id":"","url":"https://api.github.com/users/JerryYue-M","html_url":"https://github.com/JerryYue-M","followers_url":"https://api.github.com/users/JerryYue-M/followers","following_url":"https://api.github.com/users/JerryYue-M/following{/other_user}","gists_url":"https://api.github.com/users/JerryYue-M/gists{/gist_id}","starred_url":"https://api.github.com/users/JerryYue-M/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JerryYue-M/subscriptions","organizations_url":"https://api.github.com/users/JerryYue-M/orgs","repos_url":"https://api.github.com/users/JerryYue-M/repos","events_url":"https://api.github.com/users/JerryYue-M/events{/privacy}","received_events_url":"https://api.github.com/users/JerryYue-M/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T07:20:18Z","updated_at":"2022-04-28T07:20:18Z","author_association":"CONTRIBUTOR","body":"> [api_patch.patch.zip](https://github.com/apache/hudi/files/8579506/api_patch.patch.zip) Thanks, i have write a patch, but i'm not sure whether we should go this direction, why not just use SQL directly.\r\nthe reason \r\n1. some user only use datastream api to do complex operation such as operate flink state ,then they get a datastream which wanted to be insert into table\r\n2. read a hoodie table as a data stream will also be needed.because of do a complex operation or just they know well with datastream api\r\n\r\n\r\nfor your patch.LGTM\r\nonly one question. RowData is only for table format instead of datastream. Row type will better in low-level APIs\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111837416/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111843176","html_url":"https://github.com/apache/hudi/pull/5445#issuecomment-1111843176","issue_url":"https://api.github.com/repos/apache/hudi/issues/5445","id":1111843176,"node_id":"IC_kwDOBI7nWM5CRWFo","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T07:27:07Z","updated_at":"2022-04-28T07:27:07Z","author_association":"CONTRIBUTOR","body":"> > [api_patch.patch.zip](https://github.com/apache/hudi/files/8579506/api_patch.patch.zip) Thanks, i have write a patch, but i'm not sure whether we should go this direction, why not just use SQL directly.\r\n> > the reason\r\n> \r\n> 1. some user only use datastream api to do complex operation such as operate flink state ,then they get a datastream which wanted to be insert into table\r\n> 2. read a hoodie table as a data stream will also be needed.because of do a complex operation or just they know well with datastream api\r\n> \r\n> for your patch.LGTM only one question. RowData is only for table format instead of datastream. Row type will better in low-level APIs\r\n\r\nRowData is more efficient than Row, the flink connectors /formats all adapter to that. I think row data is enough.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111843176/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111844591","html_url":"https://github.com/apache/hudi/issues/5346#issuecomment-1111844591","issue_url":"https://api.github.com/repos/apache/hudi/issues/5346","id":1111844591,"node_id":"IC_kwDOBI7nWM5CRWbv","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T07:28:51Z","updated_at":"2022-04-28T07:28:51Z","author_association":"CONTRIBUTOR","body":"You need to package the jar under path `packaging/hudi-flink-bundle`, if you package the jar under root path, the shade pattern for Hive is overridden, this is a bug i guess.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111844591/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111845322","html_url":"https://github.com/apache/hudi/pull/5445#issuecomment-1111845322","issue_url":"https://api.github.com/repos/apache/hudi/issues/5445","id":1111845322,"node_id":"IC_kwDOBI7nWM5CRWnK","user":{"login":"JerryYue-M","id":10253313,"node_id":"MDQ6VXNlcjEwMjUzMzEz","avatar_url":"https://avatars.githubusercontent.com/u/10253313?v=4","gravatar_id":"","url":"https://api.github.com/users/JerryYue-M","html_url":"https://github.com/JerryYue-M","followers_url":"https://api.github.com/users/JerryYue-M/followers","following_url":"https://api.github.com/users/JerryYue-M/following{/other_user}","gists_url":"https://api.github.com/users/JerryYue-M/gists{/gist_id}","starred_url":"https://api.github.com/users/JerryYue-M/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JerryYue-M/subscriptions","organizations_url":"https://api.github.com/users/JerryYue-M/orgs","repos_url":"https://api.github.com/users/JerryYue-M/repos","events_url":"https://api.github.com/users/JerryYue-M/events{/privacy}","received_events_url":"https://api.github.com/users/JerryYue-M/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T07:29:39Z","updated_at":"2022-04-28T07:29:39Z","author_association":"CONTRIBUTOR","body":"> \r\n\r\nok i see LGTM","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111845322/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111845910","html_url":"https://github.com/apache/hudi/pull/5185#issuecomment-1111845910","issue_url":"https://api.github.com/repos/apache/hudi/issues/5185","id":1111845910,"node_id":"IC_kwDOBI7nWM5CRWwW","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T07:30:22Z","updated_at":"2022-04-28T07:30:22Z","author_association":"CONTRIBUTOR","body":"@wxplovecc Can you take a look again, i have left some comments.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111845910/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111847010","html_url":"https://github.com/apache/hudi/issues/5395#issuecomment-1111847010","issue_url":"https://api.github.com/repos/apache/hudi/issues/5395","id":1111847010,"node_id":"IC_kwDOBI7nWM5CRXBi","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T07:31:45Z","updated_at":"2022-04-28T07:31:45Z","author_association":"CONTRIBUTOR","body":"So you do not write into same table from two separate Flink jobs.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111847010/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111852364","html_url":"https://github.com/apache/hudi/pull/5445#issuecomment-1111852364","issue_url":"https://api.github.com/repos/apache/hudi/issues/5445","id":1111852364,"node_id":"IC_kwDOBI7nWM5CRYVM","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T07:38:07Z","updated_at":"2022-04-28T07:38:07Z","author_association":"CONTRIBUTOR","body":"Your build fails, you may need to fix it.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111852364/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111853053","html_url":"https://github.com/apache/hudi/pull/5445#issuecomment-1111853053","issue_url":"https://api.github.com/repos/apache/hudi/issues/5445","id":1111853053,"node_id":"IC_kwDOBI7nWM5CRYf9","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T07:39:00Z","updated_at":"2022-04-28T07:39:00Z","author_association":"CONTRIBUTOR","body":"Can you also apply the patch and rewrite the tests then ? There is no need to add methods to `Pipelines` clazz now.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111853053/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111854012","html_url":"https://github.com/apache/hudi/pull/5445#issuecomment-1111854012","issue_url":"https://api.github.com/repos/apache/hudi/issues/5445","id":1111854012,"node_id":"IC_kwDOBI7nWM5CRYu8","user":{"login":"JerryYue-M","id":10253313,"node_id":"MDQ6VXNlcjEwMjUzMzEz","avatar_url":"https://avatars.githubusercontent.com/u/10253313?v=4","gravatar_id":"","url":"https://api.github.com/users/JerryYue-M","html_url":"https://github.com/JerryYue-M","followers_url":"https://api.github.com/users/JerryYue-M/followers","following_url":"https://api.github.com/users/JerryYue-M/following{/other_user}","gists_url":"https://api.github.com/users/JerryYue-M/gists{/gist_id}","starred_url":"https://api.github.com/users/JerryYue-M/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JerryYue-M/subscriptions","organizations_url":"https://api.github.com/users/JerryYue-M/orgs","repos_url":"https://api.github.com/users/JerryYue-M/repos","events_url":"https://api.github.com/users/JerryYue-M/events{/privacy}","received_events_url":"https://api.github.com/users/JerryYue-M/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T07:40:10Z","updated_at":"2022-04-28T07:40:10Z","author_association":"CONTRIBUTOR","body":"> Can you also apply the patch and rewrite the tests then ? There is no need to add methods to `Pipelines` clazz now.\r\nok, I will apply the patch and rewrite the tests","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111854012/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111877973","html_url":"https://github.com/apache/hudi/pull/5434#issuecomment-1111877973","issue_url":"https://api.github.com/repos/apache/hudi/issues/5434","id":1111877973,"node_id":"IC_kwDOBI7nWM5CRelV","user":{"login":"onlywangyh","id":16820412,"node_id":"MDQ6VXNlcjE2ODIwNDEy","avatar_url":"https://avatars.githubusercontent.com/u/16820412?v=4","gravatar_id":"","url":"https://api.github.com/users/onlywangyh","html_url":"https://github.com/onlywangyh","followers_url":"https://api.github.com/users/onlywangyh/followers","following_url":"https://api.github.com/users/onlywangyh/following{/other_user}","gists_url":"https://api.github.com/users/onlywangyh/gists{/gist_id}","starred_url":"https://api.github.com/users/onlywangyh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/onlywangyh/subscriptions","organizations_url":"https://api.github.com/users/onlywangyh/orgs","repos_url":"https://api.github.com/users/onlywangyh/repos","events_url":"https://api.github.com/users/onlywangyh/events{/privacy}","received_events_url":"https://api.github.com/users/onlywangyh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T08:08:08Z","updated_at":"2022-04-28T08:08:27Z","author_association":"CONTRIBUTOR","body":"done\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111877973/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111878476","html_url":"https://github.com/apache/hudi/pull/5434#issuecomment-1111878476","issue_url":"https://api.github.com/repos/apache/hudi/issues/5434","id":1111878476,"node_id":"IC_kwDOBI7nWM5CRetM","user":{"login":"danny0405","id":7644508,"node_id":"MDQ6VXNlcjc2NDQ1MDg=","avatar_url":"https://avatars.githubusercontent.com/u/7644508?v=4","gravatar_id":"","url":"https://api.github.com/users/danny0405","html_url":"https://github.com/danny0405","followers_url":"https://api.github.com/users/danny0405/followers","following_url":"https://api.github.com/users/danny0405/following{/other_user}","gists_url":"https://api.github.com/users/danny0405/gists{/gist_id}","starred_url":"https://api.github.com/users/danny0405/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danny0405/subscriptions","organizations_url":"https://api.github.com/users/danny0405/orgs","repos_url":"https://api.github.com/users/danny0405/repos","events_url":"https://api.github.com/users/danny0405/events{/privacy}","received_events_url":"https://api.github.com/users/danny0405/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T08:08:38Z","updated_at":"2022-04-28T08:08:38Z","author_association":"CONTRIBUTOR","body":"@onlywangyh You may need to fix the build failure.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111878476/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111892672","html_url":"https://github.com/apache/hudi/pull/5434#issuecomment-1111892672","issue_url":"https://api.github.com/repos/apache/hudi/issues/5434","id":1111892672,"node_id":"IC_kwDOBI7nWM5CRiLA","user":{"login":"onlywangyh","id":16820412,"node_id":"MDQ6VXNlcjE2ODIwNDEy","avatar_url":"https://avatars.githubusercontent.com/u/16820412?v=4","gravatar_id":"","url":"https://api.github.com/users/onlywangyh","html_url":"https://github.com/onlywangyh","followers_url":"https://api.github.com/users/onlywangyh/followers","following_url":"https://api.github.com/users/onlywangyh/following{/other_user}","gists_url":"https://api.github.com/users/onlywangyh/gists{/gist_id}","starred_url":"https://api.github.com/users/onlywangyh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/onlywangyh/subscriptions","organizations_url":"https://api.github.com/users/onlywangyh/orgs","repos_url":"https://api.github.com/users/onlywangyh/repos","events_url":"https://api.github.com/users/onlywangyh/events{/privacy}","received_events_url":"https://api.github.com/users/onlywangyh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T08:23:45Z","updated_at":"2022-04-28T08:23:45Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111892672/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111963890","html_url":"https://github.com/apache/hudi/issues/5452#issuecomment-1111963890","issue_url":"https://api.github.com/repos/apache/hudi/issues/5452","id":1111963890,"node_id":"IC_kwDOBI7nWM5CRzjy","user":{"login":"xiarixiaoyao","id":13514703,"node_id":"MDQ6VXNlcjEzNTE0NzAz","avatar_url":"https://avatars.githubusercontent.com/u/13514703?v=4","gravatar_id":"","url":"https://api.github.com/users/xiarixiaoyao","html_url":"https://github.com/xiarixiaoyao","followers_url":"https://api.github.com/users/xiarixiaoyao/followers","following_url":"https://api.github.com/users/xiarixiaoyao/following{/other_user}","gists_url":"https://api.github.com/users/xiarixiaoyao/gists{/gist_id}","starred_url":"https://api.github.com/users/xiarixiaoyao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiarixiaoyao/subscriptions","organizations_url":"https://api.github.com/users/xiarixiaoyao/orgs","repos_url":"https://api.github.com/users/xiarixiaoyao/repos","events_url":"https://api.github.com/users/xiarixiaoyao/events{/privacy}","received_events_url":"https://api.github.com/users/xiarixiaoyao/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T09:21:08Z","updated_at":"2022-04-28T09:21:08Z","author_association":"CONTRIBUTOR","body":"@santoshsb  pls use follow code to solve your problem\r\n```\r\n    def createNewDF(df: DataFrame, oldTableSchema: StructType): DataFrame = {\r\n      val writeSchema = df.schema\r\n      val neededSchema = {\r\n        val neededFields = mutable.ListBuffer[StructField]()\r\n        oldTableSchema.foreach(neededFields.append(_))\r\n        writeSchema.filterNot { col =>\r\n          oldTableSchema.exists(targetCol => SQLConf.get.resolver(targetCol.name, col.name))\r\n        }.foreach(neededFields.append(_))\r\n        StructType(neededFields)\r\n      }\r\n\r\n      val missingCols = {\r\n        neededSchema.zipWithIndex.map { case (field, index) =>\r\n          (index,  writeSchema.indexWhere(p => SQLConf.get.resolver(p.name, field.name)))\r\n        }.toMap\r\n      }\r\n\r\n      val filledRdd = df.rdd.mapPartitions { iter =>\r\n        iter.map { row =>\r\n          val tmp = new Array[Any](neededSchema.length)\r\n          for (i <- (0 to tmp.length - 1)) {\r\n            val index = missingCols.getOrDefault(i, -1)\r\n            tmp.update(i, if (index != -1) row.get(index) else null)\r\n          }\r\n          Row.fromSeq(tmp)\r\n        }\r\n      }\r\n      spark.createDataFrame(filledRdd, neededSchema)\r\n    }\r\n\r\n    val orgString = \"\"\"{\"resourceType\":\"Patient\",\"id\":\"4ad86a5c-926e-439b-9352-f8ac9ab780f1\",\"lastUpdated\":\"2022-03-11T15:18:18.90836+05:30\",\"source\":\"4a0701fe-5c3b-482b-895d-875fcbd21481\",\"gender\":\"male\",\"birthDate\":\"1974-01-05\",\"maritalStatus\":{\"coding\":[{\"system\":\"http://terminology.hl7.org/CodeSystem/v3-MaritalStatus\",\"code\":\"M\",\"display\":\"M\"}],\"text\":\"M\"}}\"\"\"\r\n\r\n    val sqlContext = spark.sqlContext\r\n    import sqlContext.implicits._\r\n    val orgStringDf = spark.read.json(Seq(orgString).toDS())\r\n\r\n    val hudiOptions = Map[String,String](\r\n      HoodieWriteConfig.TABLE_NAME -> \"patient_hudi\",\r\n      DataSourceWriteOptions.TABLE_TYPE_OPT_KEY -> \"COPY_ON_WRITE\",\r\n      DataSourceWriteOptions.RECORDKEY_FIELD_OPT_KEY -> \"id\",\r\n      DataSourceWriteOptions.PARTITIONPATH_FIELD_OPT_KEY -> \"source\",\r\n      DataSourceWriteOptions.PRECOMBINE_FIELD_OPT_KEY -> \"lastUpdated\",\r\n      DataSourceWriteOptions.HIVE_STYLE_PARTITIONING_OPT_KEY -> \"true\"\r\n    )\r\n\r\n    orgStringDf.write\r\n      .format(\"org.apache.hudi\")\r\n      .option(DataSourceWriteOptions.OPERATION_OPT_KEY, DataSourceWriteOptions.INSERT_OPERATION_OPT_VAL)\r\n      .options(hudiOptions)\r\n      .mode(SaveMode.Overwrite)\r\n      .save(\"/tmp/default/clustering/updateTst/json_schema_tst/hudi\")\r\n\r\n    val patienthudi = spark.read.format(\"hudi\").load(\"/tmp/default/clustering/updateTst/json_schema_tst/hudi\")\r\n\r\n\r\n    val updatedString = \"\"\"{\"resourceType\":\"Patient\",\"id\":\"596c7a94-bada-4303-85d4-7067c586999e\",\"lastUpdated\":\"2022-04-20T15:18:18.90836+05:30\",\"source\":\"4a0701fe-5c3b-482b-895d-875fcbd2148a\",\"gender\":\"female\",\"birthDate\":\"2005-08-30\",\"multipleBirthBoolean\":true}\"\"\"\r\n    val updatedStringDf = createNewDF(spark.read.json(Seq(updatedString).toDS), patienthudi.schema)\r\n\r\n    updatedStringDf.write\r\n      .format(\"org.apache.hudi\")\r\n      .options(hudiOptions)\r\n      .option(DataSourceWriteOptions.OPERATION_OPT_KEY, DataSourceWriteOptions.UPSERT_OPERATION_OPT_VAL)\r\n      .option(DataSourceWriteOptions.PAYLOAD_CLASS_OPT_KEY, \"org.apache.hudi.common.model.EmptyHoodieRecordPayload\")\r\n      .mode(SaveMode.Append)\r\n      .save(\"/tmp/default/clustering/updateTst/json_schema_tst/hudi\")\r\n    val patienthudi1 = spark.read.format(\"hudi\").load(\"/tmp/default/clustering/updateTst/json_schema_tst/hudi\")\r\n    patienthudi1.select(\"id\",\"gender\",\"maritalStatus\").show(false)\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1111963890/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112023970","html_url":"https://github.com/apache/hudi/issues/5451#issuecomment-1112023970","issue_url":"https://api.github.com/repos/apache/hudi/issues/5451","id":1112023970,"node_id":"IC_kwDOBI7nWM5CSCOi","user":{"login":"jdattani","id":14809344,"node_id":"MDQ6VXNlcjE0ODA5MzQ0","avatar_url":"https://avatars.githubusercontent.com/u/14809344?v=4","gravatar_id":"","url":"https://api.github.com/users/jdattani","html_url":"https://github.com/jdattani","followers_url":"https://api.github.com/users/jdattani/followers","following_url":"https://api.github.com/users/jdattani/following{/other_user}","gists_url":"https://api.github.com/users/jdattani/gists{/gist_id}","starred_url":"https://api.github.com/users/jdattani/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jdattani/subscriptions","organizations_url":"https://api.github.com/users/jdattani/orgs","repos_url":"https://api.github.com/users/jdattani/repos","events_url":"https://api.github.com/users/jdattani/events{/privacy}","received_events_url":"https://api.github.com/users/jdattani/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T10:13:09Z","updated_at":"2022-04-28T10:13:09Z","author_association":"NONE","body":"Update: I ended up including all three jars removed from here into Glue Dependent Jars path https://github.com/apache/hudi/pull/4542\r\n\r\ncom.amazonaws:dynamodb-lock-client\r\ncom.amazonaws:aws-java-sdk-dynamodb\r\ncom.amazonaws:aws-java-sdk-core\r\n\r\nThe error changed, now getting: An error occurred while calling o255.save. Unable to acquire lock, lock object null.\r\nIssue similar to the one mentioned here: https://github.com/apache/hudi/issues/4456 and using the same config as suggested in that.  The only difference against what is suggested [in the issue 4456, ](https://github.com/apache/hudi/issues/4456#issuecomment-1041228841) is that I have table already created. \r\n\r\n```\r\n2022-04-28 10:00:19,695 ERROR [spark-listener-group-eventLog] scheduler.AsyncEventQueue (Logging.scala:logError(94)): Listener EventLoggingListener threw an exception\r\njava.util.ConcurrentModificationException\r\n\tat java.util.Hashtable$Enumerator.next(Hashtable.java:1408)\r\n\tat scala.collection.convert.Wrappers$JPropertiesWrapper$$anon$6.next(Wrappers.scala:424)\r\n\tat scala.collection.convert.Wrappers$JPropertiesWrapper$$anon$6.next(Wrappers.scala:420)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\r\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\r\n\r\nFile \"/opt/amazon/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 328, in get_return_value\r\n    format(target_id, \".\", name), value)\r\npy4j.protocol.Py4JJavaError: An error occurred while calling o255.save.\r\n: **org.apache.hudi.exception.HoodieLockException: Unable to acquire lock, lock object null**\r\n\tat org.apache.hudi.client.transaction.lock.LockManager.lock(LockManager.java:76)\r\n\tat org.apache.hudi.client.transaction.TransactionManager.beginTransaction(TransactionManager.java:51)\r\n\tat org.apache.hudi.client.SparkRDDWriteClient.getTableAndInitCtx(SparkRDDWriteClient.java:430)\r\n\tat org.apache.hudi.client.SparkRDDWriteClient.upsert(SparkRDDWriteClient.java:157)\r\n\tat org.apache.hudi.DataSourceUtils.doWriteOperation(DataSourceUtils.java:217)\r\n\tat org.apache.hudi.HoodieSparkSqlWriter$.write(HoodieSparkSqlWriter.scala:277)\r\n\tat org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:164)\r\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:46)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:90)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:134)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:133)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:107)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:232)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:110)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:135)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:107)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:232)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:135)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:253)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:134)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:68)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\n```\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112023970/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112039704","html_url":"https://github.com/apache/hudi/pull/5185#issuecomment-1112039704","issue_url":"https://api.github.com/repos/apache/hudi/issues/5185","id":1112039704,"node_id":"IC_kwDOBI7nWM5CSGEY","user":{"login":"wxplovecc","id":3350718,"node_id":"MDQ6VXNlcjMzNTA3MTg=","avatar_url":"https://avatars.githubusercontent.com/u/3350718?v=4","gravatar_id":"","url":"https://api.github.com/users/wxplovecc","html_url":"https://github.com/wxplovecc","followers_url":"https://api.github.com/users/wxplovecc/followers","following_url":"https://api.github.com/users/wxplovecc/following{/other_user}","gists_url":"https://api.github.com/users/wxplovecc/gists{/gist_id}","starred_url":"https://api.github.com/users/wxplovecc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wxplovecc/subscriptions","organizations_url":"https://api.github.com/users/wxplovecc/orgs","repos_url":"https://api.github.com/users/wxplovecc/repos","events_url":"https://api.github.com/users/wxplovecc/events{/privacy}","received_events_url":"https://api.github.com/users/wxplovecc/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T10:25:17Z","updated_at":"2022-04-28T10:25:17Z","author_association":"CONTRIBUTOR","body":"> @wxplovecc Can you take a look again, i have left some comments.\r\n\r\nThere is nothing @danny0405 Can you review this again","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112039704/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112097288","html_url":"https://github.com/apache/hudi/issues/5382#issuecomment-1112097288","issue_url":"https://api.github.com/repos/apache/hudi/issues/5382","id":1112097288,"node_id":"IC_kwDOBI7nWM5CSUII","user":{"login":"lihuahui5683","id":31878723,"node_id":"MDQ6VXNlcjMxODc4NzIz","avatar_url":"https://avatars.githubusercontent.com/u/31878723?v=4","gravatar_id":"","url":"https://api.github.com/users/lihuahui5683","html_url":"https://github.com/lihuahui5683","followers_url":"https://api.github.com/users/lihuahui5683/followers","following_url":"https://api.github.com/users/lihuahui5683/following{/other_user}","gists_url":"https://api.github.com/users/lihuahui5683/gists{/gist_id}","starred_url":"https://api.github.com/users/lihuahui5683/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lihuahui5683/subscriptions","organizations_url":"https://api.github.com/users/lihuahui5683/orgs","repos_url":"https://api.github.com/users/lihuahui5683/repos","events_url":"https://api.github.com/users/lihuahui5683/events{/privacy}","received_events_url":"https://api.github.com/users/lihuahui5683/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T11:35:00Z","updated_at":"2022-04-28T11:35:00Z","author_association":"NONE","body":"@codope Thanks for your reply.\r\nI used CDH6.3.2. I have tried to upgrade Hive 2.3.4 and hive 3.1.2. The same exception occurs in Hive 2.3.4 and Hive 2.1.1. Hive 3.1.2 causes metaStore startup failure.Do you have a way to upgrade the CDH Hive version?\r\nThe _ro table can be used normally.\r\n\r\nI used flink CDC(flink-1.13.6) to read mysql to write hudi, and used hive to query hudi _rt table.\r\nThe steps are as follows:\r\n```\r\n./bin/sql-client.sh\r\nset sql-client.execution.result-mode=tableau;\r\nset execution.checkpointing.interval=30sec;\r\n\r\ncreate table role (\r\n  channel_id bigint,\r\n  org_game_id string,\r\n  pf smallint,\r\n  org_server_id string,\r\n  org_user_id string,\r\n  org_role_id string,\r\n  role_name string,\r\n  role_lvl int,\r\n  vip_lvl int,\r\n  role_strength bigint,\r\n  role_create_time timestamp(3),\r\n  first_pay_lvl int,\r\n  first_pay_date bigint,\r\n  pay_money decimal(10,2),\r\n  pay_num bigint,\r\n  last_pay_date bigint,\r\n  last_login_date bigint,\r\n  PRIMARY KEY(channel_id,org_game_id,pf,org_user_id,org_server_id,org_role_id) NOT ENFORCED\r\n) WITH (\r\n  'connector'='mysql-cdc',\r\n  'hostname'='192.168.20.76',\r\n  'port'='3306',\r\n  'username'='root',\r\n  'password'='k8U@*hy4icomxz',\r\n  'database-name'='test',\r\n  'table-name'='role_info',\r\n  'server-time-zone'='Asia/Shanghai',\r\n  'scan.startup.mode'='initial',\r\n  'scan.snapshot.fetch.size'='1024',\r\n  'debezium.min.row.count.to.stream.result'='500'\r\n);\r\n\r\ncreate view role_v as select *, date_format(role_create_time, 'yyyy-MM-dd') as dt from role;\r\n\r\ncreate table role_sync_hive (\r\n  channel_id bigint,\r\n  org_game_id string,\r\n  pf smallint,\r\n  org_server_id string,\r\n  org_user_id string,\r\n  org_role_id string,\r\n  role_name string,\r\n  role_lvl int,\r\n  vip_lvl int,\r\n  role_strength bigint,\r\n  role_create_time timestamp(3),\r\n  first_pay_lvl int,\r\n  first_pay_date bigint,\r\n  pay_money decimal(10,2),\r\n  pay_num bigint,\r\n  last_pay_date bigint,\r\n  last_login_date bigint,\r\n  dt string,\r\n  PRIMARY KEY(channel_id,org_game_id,pf,org_user_id,org_server_id,org_role_id) NOT ENFORCED\r\n)\r\npartitioned by (dt, org_game_id)\r\nwith (\r\n  'connector'='hudi',\r\n  'path'='hdfs://mycluster/hudi/role_sync_hive',\r\n  'hoodie.datasource.write.recordkey.field'='channel_id.org_game_id.pf.org_user_id.org_server_id.org_role_id',\r\n  'write.precombine.field'='role_create_time',\r\n  'write.tasks'='4',\r\n  'compaction.tasks'='4',\r\n  'write.rate.limit'='2000',\r\n  'table.type'='MERGE_ON_READ',\r\n  'compaction.async.enabled'='true',\r\n  'compaction.schedule.enabled'='true',\r\n  'compaction.trigger.strategy'='num_commits',\r\n  'compaction.delta_commits'='1',\r\n  'compaction.delta_seconds'='60',\r\n  'changelog.enabled'='true',\r\n  'read.streaming.enabled'='true',\r\n  'read.streaming.check-interval'='3',\r\n  'hive_sync.enable'='true',\r\n  'hive_sync.mode'='hms',\r\n  'hive_sync.metastore.uris' = 'thrift://192.168.20.77:9083',\r\n  'hive_sync.table'='role_sync_hive',\r\n  'hive_sync.db'='hudi',\r\n  'hive_sync.username'='hive',\r\n  'hive_sync.password'='',\r\n  'hive_sync.support_timestamp'='true'\r\n);\r\n\r\ninsert into role_sync_hive select channel_id, org_game_id, pf, org_server_id, org_user_id, org_role_id, role_name, role_lvl, vip_lvl, role_strength, role_create_time, first_pay_lvl, first_pay_date, pay_money, pay_num, last_pay_date, last_login_date, dt from role_v;\r\n```\r\nHive Query statement:\r\n```\r\nadd jar hdfs://mycluster/hudi/jars/hudi-hadoop-mr-bundle-0.10.0.jar;\r\nset hive.input.format = org.apache.hudi.hadoop.hive.HoodieCombineHiveInputFormat;\r\nset hoodie.role_sync_hive.consume.mode=INCREMENTAL;\r\nset hoodie.role_sync_hive.consume.max.commits=3;\r\nset mapreduce.input.fileinputformat.split.maxsize=128;\r\nset hive.fetch.task.conversion=none;\r\nset hoodie.role_sync_hive.consume.start.timestamp=20220420143200507;\r\n\r\nselect count(*) from role_sync_hive_rt where `_hoodie_commit_time` > '20220420143200507';\r\n```","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112097288/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112117453","html_url":"https://github.com/apache/hudi/pull/5370#issuecomment-1112117453","issue_url":"https://api.github.com/repos/apache/hudi/issues/5370","id":1112117453,"node_id":"IC_kwDOBI7nWM5CSZDN","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T12:00:12Z","updated_at":"2022-04-28T12:00:12Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"df32ef8792075fff6f08820820f5f68c62f8415d\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8166\",\n    \"triggerID\" : \"df32ef8792075fff6f08820820f5f68c62f8415d\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"51b4f79677fb36f66698edccb5205270faaf2696\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8173\",\n    \"triggerID\" : \"51b4f79677fb36f66698edccb5205270faaf2696\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"95ca56ff2e76f43017333195df1c40b4cfa3aa0a\",\n    \"status\" : \"UNKNOWN\",\n    \"url\" : \"TBD\",\n    \"triggerID\" : \"95ca56ff2e76f43017333195df1c40b4cfa3aa0a\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"4bde7abd738d375a17b7d1df92248227127db21b\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8175\",\n    \"triggerID\" : \"4bde7abd738d375a17b7d1df92248227127db21b\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"07f2f122f1fe0fe8c0097af16e3c1772fa84dabc\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8197\",\n    \"triggerID\" : \"07f2f122f1fe0fe8c0097af16e3c1772fa84dabc\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"bb0c0c4323ffbf605def455ded35130b6ed39500\",\n    \"status\" : \"UNKNOWN\",\n    \"url\" : \"TBD\",\n    \"triggerID\" : \"bb0c0c4323ffbf605def455ded35130b6ed39500\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"0376db30f4a84a9344a3d1d6b7c0bc9e8824bc2e\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8339\",\n    \"triggerID\" : \"0376db30f4a84a9344a3d1d6b7c0bc9e8824bc2e\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"4989c96be4d484c5db17e442a3f2f87d43a7be69\",\n    \"status\" : \"DELETED\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8341\",\n    \"triggerID\" : \"4989c96be4d484c5db17e442a3f2f87d43a7be69\",\n    \"triggerType\" : \"PUSH\"\n  }, {\n    \"hash\" : \"f8863fd21c46ff0cc5e422ac323d36a252125895\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8360\",\n    \"triggerID\" : \"f8863fd21c46ff0cc5e422ac323d36a252125895\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 95ca56ff2e76f43017333195df1c40b4cfa3aa0a UNKNOWN\n* bb0c0c4323ffbf605def455ded35130b6ed39500 UNKNOWN\n* f8863fd21c46ff0cc5e422ac323d36a252125895 Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8360) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112117453/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112163057","html_url":"https://github.com/apache/hudi/pull/5434#issuecomment-1112163057","issue_url":"https://api.github.com/repos/apache/hudi/issues/5434","id":1112163057,"node_id":"IC_kwDOBI7nWM5CSkLx","user":{"login":"onlywangyh","id":16820412,"node_id":"MDQ6VXNlcjE2ODIwNDEy","avatar_url":"https://avatars.githubusercontent.com/u/16820412?v=4","gravatar_id":"","url":"https://api.github.com/users/onlywangyh","html_url":"https://github.com/onlywangyh","followers_url":"https://api.github.com/users/onlywangyh/followers","following_url":"https://api.github.com/users/onlywangyh/following{/other_user}","gists_url":"https://api.github.com/users/onlywangyh/gists{/gist_id}","starred_url":"https://api.github.com/users/onlywangyh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/onlywangyh/subscriptions","organizations_url":"https://api.github.com/users/onlywangyh/orgs","repos_url":"https://api.github.com/users/onlywangyh/repos","events_url":"https://api.github.com/users/onlywangyh/events{/privacy}","received_events_url":"https://api.github.com/users/onlywangyh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T12:49:29Z","updated_at":"2022-04-28T12:49:29Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112163057/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112246491","html_url":"https://github.com/apache/hudi/pull/5459#issuecomment-1112246491","issue_url":"https://api.github.com/repos/apache/hudi/issues/5459","id":1112246491,"node_id":"IC_kwDOBI7nWM5CS4jb","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T14:04:08Z","updated_at":"2022-04-28T14:04:08Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"13cd731543f8cebb0f81d4a5342bb2de382de5e3\",\n    \"status\" : \"FAILURE\",\n    \"url\" : \"https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8366\",\n    \"triggerID\" : \"13cd731543f8cebb0f81d4a5342bb2de382de5e3\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* 13cd731543f8cebb0f81d4a5342bb2de382de5e3 Azure: [FAILURE](https://dev.azure.com/apache-hudi-ci-org/785b6ef4-2f42-4a89-8f0e-5f0d7039a0cc/_build/results?buildId=8366) \n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112246491/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112263194","html_url":"https://github.com/apache/hudi/pull/1650#issuecomment-1112263194","issue_url":"https://api.github.com/repos/apache/hudi/issues/1650","id":1112263194,"node_id":"IC_kwDOBI7nWM5CS8oa","user":{"login":"pratyakshsharma","id":30863489,"node_id":"MDQ6VXNlcjMwODYzNDg5","avatar_url":"https://avatars.githubusercontent.com/u/30863489?v=4","gravatar_id":"","url":"https://api.github.com/users/pratyakshsharma","html_url":"https://github.com/pratyakshsharma","followers_url":"https://api.github.com/users/pratyakshsharma/followers","following_url":"https://api.github.com/users/pratyakshsharma/following{/other_user}","gists_url":"https://api.github.com/users/pratyakshsharma/gists{/gist_id}","starred_url":"https://api.github.com/users/pratyakshsharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pratyakshsharma/subscriptions","organizations_url":"https://api.github.com/users/pratyakshsharma/orgs","repos_url":"https://api.github.com/users/pratyakshsharma/repos","events_url":"https://api.github.com/users/pratyakshsharma/events{/privacy}","received_events_url":"https://api.github.com/users/pratyakshsharma/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T14:17:10Z","updated_at":"2022-04-28T14:17:10Z","author_association":"CONTRIBUTOR","body":"@bvaradar ping.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112263194/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112265612","html_url":"https://github.com/apache/hudi/pull/1650#issuecomment-1112265612","issue_url":"https://api.github.com/repos/apache/hudi/issues/1650","id":1112265612,"node_id":"IC_kwDOBI7nWM5CS9OM","user":{"login":"hudi-bot","id":79415918,"node_id":"MDQ6VXNlcjc5NDE1OTE4","avatar_url":"https://avatars.githubusercontent.com/u/79415918?v=4","gravatar_id":"","url":"https://api.github.com/users/hudi-bot","html_url":"https://github.com/hudi-bot","followers_url":"https://api.github.com/users/hudi-bot/followers","following_url":"https://api.github.com/users/hudi-bot/following{/other_user}","gists_url":"https://api.github.com/users/hudi-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/hudi-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hudi-bot/subscriptions","organizations_url":"https://api.github.com/users/hudi-bot/orgs","repos_url":"https://api.github.com/users/hudi-bot/repos","events_url":"https://api.github.com/users/hudi-bot/events{/privacy}","received_events_url":"https://api.github.com/users/hudi-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T14:19:18Z","updated_at":"2022-04-28T14:19:18Z","author_association":"NONE","body":"<!--\nMeta data\n{\n  \"version\" : 1,\n  \"metaDataEntries\" : [ {\n    \"hash\" : \"a61fab359735c015be4dc29a67f39fc3e24ea5cd\",\n    \"status\" : \"UNKNOWN\",\n    \"url\" : \"TBD\",\n    \"triggerID\" : \"a61fab359735c015be4dc29a67f39fc3e24ea5cd\",\n    \"triggerType\" : \"PUSH\"\n  } ]\n}-->\n## CI report:\n\n* a61fab359735c015be4dc29a67f39fc3e24ea5cd UNKNOWN\n\n<details>\n<summary>Bot commands</summary>\n  @hudi-bot supports the following commands:\n\n - `@hudi-bot run azure` re-run the last Azure build\n</details>","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112265612/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112308752","html_url":"https://github.com/apache/hudi/pull/5434#issuecomment-1112308752","issue_url":"https://api.github.com/repos/apache/hudi/issues/5434","id":1112308752,"node_id":"IC_kwDOBI7nWM5CTHwQ","user":{"login":"onlywangyh","id":16820412,"node_id":"MDQ6VXNlcjE2ODIwNDEy","avatar_url":"https://avatars.githubusercontent.com/u/16820412?v=4","gravatar_id":"","url":"https://api.github.com/users/onlywangyh","html_url":"https://github.com/onlywangyh","followers_url":"https://api.github.com/users/onlywangyh/followers","following_url":"https://api.github.com/users/onlywangyh/following{/other_user}","gists_url":"https://api.github.com/users/onlywangyh/gists{/gist_id}","starred_url":"https://api.github.com/users/onlywangyh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/onlywangyh/subscriptions","organizations_url":"https://api.github.com/users/onlywangyh/orgs","repos_url":"https://api.github.com/users/onlywangyh/repos","events_url":"https://api.github.com/users/onlywangyh/events{/privacy}","received_events_url":"https://api.github.com/users/onlywangyh/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T14:55:00Z","updated_at":"2022-04-28T14:55:00Z","author_association":"CONTRIBUTOR","body":"I get the build error.\r\n```\r\n[ERROR] Errors: \r\n[ERROR]   TestSchemaPostProcessor>UtilitiesTestBase.setup:156 » Spark Only one SparkCont...\r\n[ERROR]   TestSchemaPostProcessor>UtilitiesTestBase.setup:156 » Spark Only one SparkCont...\r\n[ERROR]   TestSchemaPostProcessor>UtilitiesTestBase.setup:156 » Spark Only one SparkCont...\r\n[ERROR]   TestSchemaPostProcessor>UtilitiesTestBase.setup:156 » Spark Only one SparkCont...\r\n[ERROR]   TestSchemaPostProcessor>UtilitiesTestBase.setup:156 » Spark Only one SparkCont...\r\n[ERROR]   TestSchemaPostProcessor>UtilitiesTestBase.setup:156 » Spark Only one SparkCont...\r\n[ERROR]   TestSchemaPostProcessor>UtilitiesTestBase.setup:156 » Spark Only one SparkCont...\r\n[ERROR]   TestKafkaAvroSchemaDeserializer>UtilitiesTestBase.setup:156 » Spark Only one S...\r\n```\r\nThis `UtilitiesTestBase.setup` is not change what's problem here?.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112308752/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112309196","html_url":"https://github.com/apache/hudi/issues/5249#issuecomment-1112309196","issue_url":"https://api.github.com/repos/apache/hudi/issues/5249","id":1112309196,"node_id":"IC_kwDOBI7nWM5CTH3M","user":{"login":"toninis","id":24205345,"node_id":"MDQ6VXNlcjI0MjA1MzQ1","avatar_url":"https://avatars.githubusercontent.com/u/24205345?v=4","gravatar_id":"","url":"https://api.github.com/users/toninis","html_url":"https://github.com/toninis","followers_url":"https://api.github.com/users/toninis/followers","following_url":"https://api.github.com/users/toninis/following{/other_user}","gists_url":"https://api.github.com/users/toninis/gists{/gist_id}","starred_url":"https://api.github.com/users/toninis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/toninis/subscriptions","organizations_url":"https://api.github.com/users/toninis/orgs","repos_url":"https://api.github.com/users/toninis/repos","events_url":"https://api.github.com/users/toninis/events{/privacy}","received_events_url":"https://api.github.com/users/toninis/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T14:55:25Z","updated_at":"2022-04-28T14:55:25Z","author_association":"NONE","body":"@yihua  Tested with 0.12.0-Snapshot (https://github.com/apache/hudi/commit/52953c8f5e8d9d62a6913649235891be8960d50f) and got the same result . Shutdown hook again not called 😞 ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112309196/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112340895","html_url":"https://github.com/apache/hudi/issues/5455#issuecomment-1112340895","issue_url":"https://api.github.com/repos/apache/hudi/issues/5455","id":1112340895,"node_id":"IC_kwDOBI7nWM5CTPmf","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T15:21:37Z","updated_at":"2022-04-28T15:21:37Z","author_association":"CONTRIBUTOR","body":"@nsivabalan @rmahindra123 do you guys know how to regarding Glue Catalog?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112340895/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":1,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112354777","html_url":"https://github.com/apache/hudi/issues/5456#issuecomment-1112354777","issue_url":"https://api.github.com/repos/apache/hudi/issues/5456","id":1112354777,"node_id":"IC_kwDOBI7nWM5CTS_Z","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T15:34:06Z","updated_at":"2022-04-28T15:34:06Z","author_association":"CONTRIBUTOR","body":"@Neuw84 The `HoodieDeltaStreamer` takes the `--spark-master` option to override the default Spark master to use, i.e., the same variable you mentioned, when you use `spark-submit` to run `HoodieDeltaStreamer`. I think your point is that, if the `HoodieDeltaStreamer` constructor is used, the Spark master config can be overwritten by what's configured in `JavaSparkContext jssc`, is that the case?\r\n\r\nFeel free to create a Jira ticket [here](https://issues.apache.org/jira/projects/HUDI/issues) for this feature inquiry and work on it.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112354777/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112368428","html_url":"https://github.com/apache/hudi/issues/5457#issuecomment-1112368428","issue_url":"https://api.github.com/repos/apache/hudi/issues/5457","id":1112368428,"node_id":"IC_kwDOBI7nWM5CTWUs","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T15:46:26Z","updated_at":"2022-04-28T15:46:26Z","author_association":"CONTRIBUTOR","body":"@Chosen123Wang To understand the issue, could you share the Hudi write configs and the steps and commands to reproduce the problem?  It looks like you're using Flink instead of Spark to write the data.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112368428/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112373019","html_url":"https://github.com/apache/hudi/pull/5406#issuecomment-1112373019","issue_url":"https://api.github.com/repos/apache/hudi/issues/5406","id":1112373019,"node_id":"IC_kwDOBI7nWM5CTXcb","user":{"login":"dongkelun","id":13376555,"node_id":"MDQ6VXNlcjEzMzc2NTU1","avatar_url":"https://avatars.githubusercontent.com/u/13376555?v=4","gravatar_id":"","url":"https://api.github.com/users/dongkelun","html_url":"https://github.com/dongkelun","followers_url":"https://api.github.com/users/dongkelun/followers","following_url":"https://api.github.com/users/dongkelun/following{/other_user}","gists_url":"https://api.github.com/users/dongkelun/gists{/gist_id}","starred_url":"https://api.github.com/users/dongkelun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dongkelun/subscriptions","organizations_url":"https://api.github.com/users/dongkelun/orgs","repos_url":"https://api.github.com/users/dongkelun/repos","events_url":"https://api.github.com/users/dongkelun/events{/privacy}","received_events_url":"https://api.github.com/users/dongkelun/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T15:50:47Z","updated_at":"2022-04-28T15:50:47Z","author_association":"CONTRIBUTOR","body":"@hudi-bot run azure","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112373019/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112433258","html_url":"https://github.com/apache/hudi/issues/5456#issuecomment-1112433258","issue_url":"https://api.github.com/repos/apache/hudi/issues/5456","id":1112433258,"node_id":"IC_kwDOBI7nWM5CTmJq","user":{"login":"Neuw84","id":5920770,"node_id":"MDQ6VXNlcjU5MjA3NzA=","avatar_url":"https://avatars.githubusercontent.com/u/5920770?v=4","gravatar_id":"","url":"https://api.github.com/users/Neuw84","html_url":"https://github.com/Neuw84","followers_url":"https://api.github.com/users/Neuw84/followers","following_url":"https://api.github.com/users/Neuw84/following{/other_user}","gists_url":"https://api.github.com/users/Neuw84/gists{/gist_id}","starred_url":"https://api.github.com/users/Neuw84/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Neuw84/subscriptions","organizations_url":"https://api.github.com/users/Neuw84/orgs","repos_url":"https://api.github.com/users/Neuw84/repos","events_url":"https://api.github.com/users/Neuw84/events{/privacy}","received_events_url":"https://api.github.com/users/Neuw84/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T16:46:20Z","updated_at":"2022-04-28T17:00:05Z","author_association":"CONTRIBUTOR","body":"Hi @yihua, \r\n\r\nThe thing is that no default value should be in that class in order to be able to inherit to whatever the master is in serverless Spark engines such as AWS Glue where the master is not known. The idea is to remove that default value (```local[2] ```), add an option to build a Java Spark Context without the default value and change the documentation in the ```cli``` options. \r\n\r\nIs a small change, but that will enable to use the DeltaStreamer in managed environments such as AWS Glue. Have opened this jira ticket to work on this. \r\n\r\nhttps://issues.apache.org/jira/browse/HUDI-3994\r\n\r\nThanks ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112433258/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112440532","html_url":"https://github.com/apache/hudi/issues/5367#issuecomment-1112440532","issue_url":"https://api.github.com/repos/apache/hudi/issues/5367","id":1112440532,"node_id":"IC_kwDOBI7nWM5CTn7U","user":{"login":"vingov","id":1142498,"node_id":"MDQ6VXNlcjExNDI0OTg=","avatar_url":"https://avatars.githubusercontent.com/u/1142498?v=4","gravatar_id":"","url":"https://api.github.com/users/vingov","html_url":"https://github.com/vingov","followers_url":"https://api.github.com/users/vingov/followers","following_url":"https://api.github.com/users/vingov/following{/other_user}","gists_url":"https://api.github.com/users/vingov/gists{/gist_id}","starred_url":"https://api.github.com/users/vingov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vingov/subscriptions","organizations_url":"https://api.github.com/users/vingov/orgs","repos_url":"https://api.github.com/users/vingov/repos","events_url":"https://api.github.com/users/vingov/events{/privacy}","received_events_url":"https://api.github.com/users/vingov/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T16:54:18Z","updated_at":"2022-04-28T16:54:18Z","author_association":"CONTRIBUTOR","body":"@nsivabalan - It's almost done, I can send the PR tonight for the blog then I will follow up with extensive docs.","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112440532/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112477307","html_url":"https://github.com/apache/hudi/issues/5298#issuecomment-1112477307","issue_url":"https://api.github.com/repos/apache/hudi/issues/5298","id":1112477307,"node_id":"IC_kwDOBI7nWM5CTw57","user":{"login":"rahil-c","id":32500120,"node_id":"MDQ6VXNlcjMyNTAwMTIw","avatar_url":"https://avatars.githubusercontent.com/u/32500120?v=4","gravatar_id":"","url":"https://api.github.com/users/rahil-c","html_url":"https://github.com/rahil-c","followers_url":"https://api.github.com/users/rahil-c/followers","following_url":"https://api.github.com/users/rahil-c/following{/other_user}","gists_url":"https://api.github.com/users/rahil-c/gists{/gist_id}","starred_url":"https://api.github.com/users/rahil-c/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rahil-c/subscriptions","organizations_url":"https://api.github.com/users/rahil-c/orgs","repos_url":"https://api.github.com/users/rahil-c/repos","events_url":"https://api.github.com/users/rahil-c/events{/privacy}","received_events_url":"https://api.github.com/users/rahil-c/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T17:31:29Z","updated_at":"2022-04-30T00:39:24Z","author_association":"CONTRIBUTOR","body":"@kasured Im currently looking into this and was able to reproduce the issue after running your [https://github.com/kasured/hudi-compaction-5298](https://github.com/kasured/hudi-compaction-5298/tree/main/src/main/scala/com/example/hudi). \r\n\r\nWhen I built hudi 0.11.0 (from master) with profile `spark3.1` and provided my 0.11.0 `spark bundle jar` to your sample reproduction I noticed that I did not get the `FileNotFoundException` anymore when running it. Im currently looking to see if the fix https://github.com/apache/hudi/pull/4753 can be backported to 0.9.0 ","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112477307/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112522324","html_url":"https://github.com/apache/hudi/issues/5363#issuecomment-1112522324","issue_url":"https://api.github.com/repos/apache/hudi/issues/5363","id":1112522324,"node_id":"IC_kwDOBI7nWM5CT75U","user":{"login":"parisni","id":9535350,"node_id":"MDQ6VXNlcjk1MzUzNTA=","avatar_url":"https://avatars.githubusercontent.com/u/9535350?v=4","gravatar_id":"","url":"https://api.github.com/users/parisni","html_url":"https://github.com/parisni","followers_url":"https://api.github.com/users/parisni/followers","following_url":"https://api.github.com/users/parisni/following{/other_user}","gists_url":"https://api.github.com/users/parisni/gists{/gist_id}","starred_url":"https://api.github.com/users/parisni/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/parisni/subscriptions","organizations_url":"https://api.github.com/users/parisni/orgs","repos_url":"https://api.github.com/users/parisni/repos","events_url":"https://api.github.com/users/parisni/events{/privacy}","received_events_url":"https://api.github.com/users/parisni/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T18:19:04Z","updated_at":"2022-04-28T18:19:04Z","author_association":"CONTRIBUTOR","body":"Indeed, this is exactly what I am looking for !\nthanks\n\nOn Tue, 2022-04-26 at 19:33 -0700, Sivabalan Narayanan wrote:\n> would this work for you https://github.com/apache/hudi/pull/4960 or\n> are you looking for something else?\n> \n> \n","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112522324/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112631217","html_url":"https://github.com/apache/hudi/issues/5460#issuecomment-1112631217","issue_url":"https://api.github.com/repos/apache/hudi/issues/5460","id":1112631217,"node_id":"IC_kwDOBI7nWM5CUWex","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T20:36:02Z","updated_at":"2022-04-28T20:36:02Z","author_association":"CONTRIBUTOR","body":"@zhilinli123 To help you identify the root cause, could you provide the steps/commands to reproduce the issue, including how multiple tables are written?  Could you also show the full timeline in `.hoodie` folder, including the `20220428191757755` which throws the error? Did you run any concurrent writers or aysnc table services on the same table?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112631217/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112633524","html_url":"https://github.com/apache/hudi/issues/5460#issuecomment-1112633524","issue_url":"https://api.github.com/repos/apache/hudi/issues/5460","id":1112633524,"node_id":"IC_kwDOBI7nWM5CUXC0","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T20:38:59Z","updated_at":"2022-04-28T20:38:59Z","author_association":"CONTRIBUTOR","body":"Based on the current information, it's likely that the same marker is created twice and the second attempt fails.  @danny0405 do you know if Flink has special handling around creating direct markers?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112633524/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112635290","html_url":"https://github.com/apache/hudi/issues/5460#issuecomment-1112635290","issue_url":"https://api.github.com/repos/apache/hudi/issues/5460","id":1112635290,"node_id":"IC_kwDOBI7nWM5CUXea","user":{"login":"yihua","id":2497195,"node_id":"MDQ6VXNlcjI0OTcxOTU=","avatar_url":"https://avatars.githubusercontent.com/u/2497195?v=4","gravatar_id":"","url":"https://api.github.com/users/yihua","html_url":"https://github.com/yihua","followers_url":"https://api.github.com/users/yihua/followers","following_url":"https://api.github.com/users/yihua/following{/other_user}","gists_url":"https://api.github.com/users/yihua/gists{/gist_id}","starred_url":"https://api.github.com/users/yihua/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihua/subscriptions","organizations_url":"https://api.github.com/users/yihua/orgs","repos_url":"https://api.github.com/users/yihua/repos","events_url":"https://api.github.com/users/yihua/events{/privacy}","received_events_url":"https://api.github.com/users/yihua/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-28T20:41:14Z","updated_at":"2022-04-28T20:41:14Z","author_association":"CONTRIBUTOR","body":"@zhilinli123 by \"compression failure\", do you mean the Hudi compaction fails and `20220428191757755` is a scheduled compaction?  Have you tried to restart and retry the Flink job and see the ingestion can proceed?","reactions":{"url":"https://api.github.com/repos/apache/hudi/issues/comments/1112635290/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]